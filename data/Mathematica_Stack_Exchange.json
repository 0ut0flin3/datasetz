{"front end - Usage of \\[InvisibleApplication] and other related invisible characters": "\nIt is used in TraditionalForm output, e.g. here:\nTraditionalForm[ Hypergeometric2F1[a,b,c,x] ]\n\nWithout \\[InvisibleApplication] it would probably be hard for Mathematica to parse it back to \nInputForm. Probably it is used in more places internally.\nIn order to get rid of it:\nLocate the file UnicodeCharacters.tr in /usr/local/Wolfram/Mathematica/8.0/SystemFiles/FrontEnd/TextResources (or the equivalent under Windows or MacOSX), make a backup of the file, open it and delete the line \n0xF76D         \\[InvisibleApplication]         ($@$ ...\n\nThen your cat can jump on the keyboard again.\n", "functions - What best practices or performance considerations are there for choosing between Cases, Position, Pick and Select?": "\nIn my view, Cases and Position are in one camp (pattern-based functions used for general expression destructuring), while Select is in another: (more) special-purpose functions optimized to work on certain efficient data structures. \nAs was mentioned already, both Cases and Select do generally unpack when used with packed arrays. What wasn't mentioned is that Select can easily be compiled, including compilation to C:\nsel = Compile[{{lst, _Integer, 2}}, Select[lst, #[[2]] > 0 &], \n        CompilationTarget -> \"C\", RuntimeOptions -> \"Speed\"];\n\nIn[98]:= (res3 = sel[test]);//Timing\nOut[98]= {0.125,Null}\n\nwhich gives an order of magnitude speed-up in the case at hand. Needless to say, Cases, being a general function using patterns, cannot be compiled and any attempt to do so will result in a callback to the main evaluator in the compiled code, which destroys the purpose.\nAnother difference is that Select can also work on sparse arrays, while Cases and Position can't.\nOTOH, Cases and Position are more general in that they can work on arbitrary expressions (not necessarily packed or even regular arrays), and at an arbitrary level. If you happen to have an (even numerical) irregular nested list, where you can't utilize packing, Cases and Position may be able to do things Select can't (Select is limited to one level only). Performance-wise, Cases / Position can also be very efficient, if the test patterns are constructed properly (mostly syntactic patterns, with no Condition or PatternTest involved, and preferably not containing things like __, ___ etc as sub-parts).\nThere are instances when Cases (Position also, but not as much) are practially indispensable, and this is when you want to collect some information about the expression, while preventing its parts from evaluation. For example, getting all symbols involved in an expression expr, in unevaluated form, wrapped in HoldComplete (say), is as simple as this:\nCases[expr, s_Symbol :> HoldComplete[s], {0, Infinity}, Heads -> True]\n\nand quite efficient as well. Generally, patterns and destructuring are very (perhaps most) powerful metaprogramming tools that Mathematica provides.\nSo, my final advice is this: when you have an expression with a fixed regular structure, or even better, numerical packed array, Select or other more precise operations (Pick etc) may be advantageous, and also more natural. When you have some general (perhaps symbolic) expression, and want to get some non-trivial information from it, Cases, Position and other pattern-based functions may be a natural choice.\n", "cdf format - How can I embed a Manipulate (or other interactive graphics) in my website using CDF?": "\nUPDATE\nSee: Why does Wolfram Research no longer support the CDF plugin?\nThen: Web Delivery: Cloud\nAlso: Wolfram Notebook Embedder\nLEGACY\nThis is just to update everyone on this topic. Wolfram Research released detailed blog and video tutorial \"CDF Embedding in a Nutshell\". It shows how to use built-in Mathematica wizard to deploy CDF online into HTML pages and Word Press blogs. URL:\nhttp://blog.wolfram.com/2012/02/22/mathematica-qa-series-cdf-embedding-in-a-nutshell/\n", "topology - Generating a topological space diagram for an n-element set": "\nI suspect this is a fundamentally difficult problem, because as you pointed out, it boils down to drawing hypergraphs which, it seems, Mathematica does not have built in support for.\nIt isn't hard though, to automatically generate some kind of visualization of topologies.\nI used the elegant topologyQ function proposed by kguler over at the stackoverflow question you linked to:\ntopologyQ[x_List] := Intersection[x, #] === # &[\nUnion[{Union @@ x}, Intersection @@@ Rest@#, Union @@@ #] &@\nSubsets@x]\n\nAnd then a little bit of (substantially less elegant) code I wrote myself:\nRandomTopoTable[n_] := \nModule[{Sets = \n Reverse[Sort[\n  RandomSample[#, RandomChoice[Range[Length[#]]]] &[\n   Subsets[Range[n]]]]], \nGenerateRow = \n Function[{set}, {#, Background -> If[MemberQ[set, #], Red, White],\n     Frame -> True} & /@ Range[n]]}, \n{If[topologyQ[Sets] && MemberQ[Sets, Range[n]],\n  Style[\"GOOD\", Darker[Green]], Style[\"BAD\", Red]], \n  Grid[({Range[n]}~Join~((Item @@@ # &) /@ (GenerateRow /@ Sets))), \n  Frame -> All, Background -> {Lighter[Gray], None}]}];\n\nTable[Column[RandomTopoTable[3]], {20}]\n\nAnd this is the output for n=3, but it works for other choices of n too:\n\nThis is presenting a random sample of the subsets of the subsets of original set, e.g. a random selection of \"potential topologies\".\n", "graphics - Is there a way to have Plot draw points on a function where the function is undefined as circles as in textbooks?": "\nBy using Exclusions and ExclusionsStyle like this\nPlot[1/Sin[\u03c0 x], {x, -3, 3},\n  Exclusions -> Sin[\u03c0 x] == 0, \n  ExclusionsStyle -> {Thin, Directive[Red, PointSize[0.02]]}\n]\n\nyou can define the location of the discontinuities and the style for poles and discontinuity boundaries, respectively.\n\nAlso the Wolfram Blog, March 2011 has more examples on this topic.\n", "symbolic - How to symbolically do matrix \"Block Inversion\"?": "\nMathematica does not support this directly. You can do things of this sort using an external package called NCAlgebra.\nhttp://math.ucsd.edu/~ncalg/\nThe relevant documentation may be found at\nhttp://math.ucsd.edu/~ncalg/DOWNLOAD2010/DOCUMENTATION/html/NCBIGDOCch4.html#x8-510004.4\nIn particular have a look at \"4.4.8 NCLDUDecomposition[aMatrix, Options]\"\nUsing this package, you would find the block inverse of the example matrix using:\nc=0;    \ninverse = NCInverse[matrix]  \n(* Out[] = {{inv[a], -inv[a] ** b ** inv[d]}, {0, inv[d]}} *)\n\nHere inv[a] represents the general inverse of the a block of the matrix and the ** represents non-commutative (i.e. matrix) multiplication. This approach works for larger (3x3, 4x4, etc) square block matrices as well.\n", "numerics - Can Mathematica propose an exact value based on an approximate one?": "\nI can offer a round-about method.\nFirst compute the numerical approximation. I obtain, to high precision,\nIn[24]:= N[Sum[1/(2*n!), {n, 0, 100}], 100]\n\nOut[24]= 1.\\\n3591409142295226176801437356763312488786235468499797874834838138620383\\\n15176773797285691089262583214\n\nNow paste that into a Wolfram|Alpha query, accessed by clicking on the '+' sign at upper left of a fresh input cell. This gives, among other things, possible closed forms.\nTo the best of my knowledge, the heuristic methods used by W|A for this task are not directly exposed in any other way in Mathematica proper.\n", "reference request - Where can I find examples of good Mathematica programming practice?": "\nHere's a collection of resources that I started on Mathgroup (a collection of Mathematica learning resources) and updated here at Stack Overflow. As this site is dedicated to Mathematica it makes more sense to maintain it here. This represents a huge amount of information; of course it's not exhaustive so feel free to improve it! Also, don't hesitate to share it and suggest other interesting links! Remember, you can always search the online Documentation Center of Mathematica, that is identical to the built-in help of the latest software version.\nLinks to more advanced aspects of the program that you can start to appreciate once you understand the basics are provided in separate answers (below) as this post became too large.\n\nTips and Tricks\nAdvanced evaluation, patterns and neat algorithms\n\nIntroduction\n\nIf you're just beginning try to have a look at these videos.\nMathematica Basics, Elementary Programming in Mathematica\nHands-on Start to Mathematica\nSeveral introductory videos by Jon McLoone\nand many other video introductions and tutorials from the official Wolfram website \nAn elementary introduction to the Wolfram language\nFast introduction for programmers \nIs it necessary to have a prior computational background or is it possible to learn Mathematica as a first programming language? \nWhat are the most common pitfalls awaiting new users? \nHow To-s: full solutions for particular tasks from the online documentation  \nEasy-to-understand animations explaining common Mathematica functions\nSal Mangano's videos for using pure functions, Part and patterns\nIntroductory videos of various applications of Mathematica\nWhat is the best Mathematica tutorial for young people? \n\nBasic advices for people new to Mathematica\nFunctional style\nAvoid iterative programming using loops like For or Do, use instead functional programming functions Map, Scan, MapThread, Fold, FoldList, ... and pure functions. This makes the code cleaner and faster.  \n\nFunctional Programming, Functional Programming: Quick Start \nPure functions\nWhat does # mean in Mathematica? \nAlternatives to procedural loops and iterating over lists in Mathematica \nAn example: Programming a numerical method in the functional style \nHow to understand the usage of Inner and Outer figuratively? \n\nTranspose and dimensions\n\nSomething not easy to guess alone at the beginning: if you have x={1,2} and y={3,4},\ndoing Transpose[{x,y}] or {x,y}ESC tr ESC in the front end will produce {{1,3},{2,4}} (format compatible with ListPlot). This animation helps understand why.\nYou can also use the second argument of Transpose to reorder the indices of a multidimensional list.\nDon't forget to regularly control the output of the lists you generate using Dimensions.\n\nGet familiar with shorthand syntax (@, &, ##, /@, /., etc.)\n\nOperator Input Forms\nwhen is f@g not the same as f[g]? \n\nProgramming easily\n\nGetting help: Execute ?Map for example for a short description of a function, or press F1 on a function name for more details and examples about it. You can solve many problems by adapting examples to your needs.  \nAuto-completion: Start typing the name of a function and (in Mathematica 9+) select from the pop-up auto-completion menu, or press Ctrl+k to get a list of functions which names start with what has already been entered. Once the name of the function is written completely press Ctrl+Shift+k (on Mac, Cmd+k) to get a list of its arguments.\nFunction templates: In Mathematica 9, after typing a function name, press Ctrl+Shift+k (on Mac, Cmd+Shift+k) and click on the desired form from the pop-up menu to insert a template with named placeholders for the arguments. \nOther useful shortcuts are described in the post Using the Mathematica front-end efficiently for editing notebooks.\nUse palettes in the Palettes menu especially when you're beginning.\nIn Mathematica 8, use the natural input capability of Wolfram Alpha, for example type \"= graph 2 x + 1 between 0 and 3\" without the quotes and see the command associated with the result.\n\nTutorials\n\nAn elementary introduction to the Wolfram language, by Stephen Wolfram\nFast introduction for programmers \nFundamentals of Mathematica Programming (by Richard Gaylord, great tutorial for an overview of the logic behind Mathematica: patterns)\nVideo tutorial also available    \nIntroduction to Mathematica (by Thomas Hahn, another succinct overview of Mathematica)  \nTutorial Collection by WRI (lots of extra documentation and examples, available as free PDFs, also available and up-to-date in Help > Virtual Book in Mathematica). \nProgramming Paradigms via Mathematica (A First Course) \nMathematica Tutorial: A New Resource for Developers \nWolfram's Mathematica 101 \nhttp://bmia.bmt.tue.nl/Software/Downloads/Campus/TrainingMathematicaEnglish.zip\nhttp://bmia.bmt.tue.nl/Software/Mathematica/Tutorials/index.html \nA problem centered approach \nA beginner's guide to Mathematica \nhttp://math.sduhsd.net/MathematiClub/tutorials.htm \nhttp://www.austincc.edu/mmcguff/mathematica/ \nhttp://www.mtholyoke.edu/courses/hnichols/phys303/ \nhttp://www.apam.columbia.edu/courses/ap1601y/ (Introduction to Computational Mathematics and Physics)  \nhttp://ftp.physics.uwa.edu.au/pub/MATH2200/2012/Lectures/ (Applied Mathematics)\nhttp://ftp.physics.uwa.edu.au/pub/MATH2200/2009/Lectures (path for some lectures in pdf) \nhttp://en.wikibooks.org/wiki/Mathematica \nhttp://www.cs.purdue.edu/homes/ayg/CS590C/www/mathematica/math.html (Basic tutorial)   \nhttps://stackoverflow.com/questions/4430998/mathematica-what-is-symbolic-programming  (What is symbolic programming)   \nhttp://www.cer.ethz.ch/resec/people/tsteger/Econ_Model_Math_1.pdf \nhttp://www.physics.umd.edu/enp/jjkelly (An introduction to Mathematica as well as some physics courses)   \nDo you know of any web-based university course that is entirely Mathematica based? \nhttp://homepage.cem.itesm.mx/jose.luis.gomez/data/mathematica (Tutorials in Spanish)\nMathematica programming (some examples of the various programming paradigms that can be used in Mathematica)\n\nFAQ\n\nhttp://12000.org/my_notes/faq/mma_notes/MMA.htm  (FAQ)  \nhttps://stackoverflow.com/questions/tagged/mathematica?sort=faq&pagesize=15  (FAQ on Stack Overflow)  \nhttps://mathematica.stackexchange.com/questions?sort=faq (FAQ on this site)   \nhttp://library.wolfram.com/conferences/conference98/Lichtblau/SymbolicFAQ.nb (Symbolic FAQ)  \n\nBooks\n\nStephen Wolfram's The Mathematica Book (online, version 5.2), available for free  \nMathematica programming: an advanced introduction (online) by Leonid Shifrin, available for free\nTutorial Collection by WRI (lots of extra documentation and examples, available as free pdfs, also available and up-to-date in Help > Virtual Book in Mathematica). \nMathematica Cookbook by Sal Mangano (O'Reilly, 2010)\nMathematica in Action by Stan Wagon (Springer, 2010)\nMathematica: A Problem-Centered Approach by Roozbeh Hazrat (Springer, 2010)\nMathematica Navigator by Heikki Ruskeepaa (Academic Press, 2009)\nThe Mathematica GuideBooks (for Programming, Numerics, Graphics, Symbolics) by Michael Trott (Springer, 2004-2005)  \nAn introduction to programming with Mathematica by Paul R. Wellin, Richard J. Gaylord and Samuel N. Kamin (Cambridge University Press, 2005); contains an example of Domain Specific Language (DSL) creation.\nMastering Mathematica by John W. Gray (Academic Press, 1997)\nProgramming in Mathematica by Roman Maeder (Addison-Wesley Professional, 1997)\nProgramming with Mathematica\u00ae: An Introduction by Paul Wellin (Cambridge University Press, 2013)  \nPower Programming With Mathematica: The Kernel, by David B. Wagner (Mcgraw-Hill, 1997), out of print but scanned copy available here.  \nhttp://blog.wolfram.com/2014/01/10/read-up-on-mathematica-in-many-subjects \n\nWolfram Websites\nLearn \n\nhttp://www.wolfram.com/broadcast/ \nhttp://www.wolfram.com/training/courses (Online video courses, most are free)\nhttp://www.wolfram.com/training/special-event/ (Links to videos of past conferences)  \nSlides of seminars \nhttp://www.youtube.com/user/WolframResearch \nAn elementary introduction to the Wolfram language\nFast introduction for programmers\nData drop quick reference \n\nExamples \n\nhttp://demonstrations.wolfram.com\nHow To-s \nhttp://www.wolfram.com/mathematica/new-in-8\nhttp://www.wolfram.com/mathematica/new-in-9\nhttp://www.wolfram.com/mathematica/new-in-10/\nhttp://www.wolfram.com/mathematica/new-in-11/\nhttp://www.wolfram.com/training/special-event/new-in-mathematica-10/ \nA plot gallery for Mathematica 9 \nhttp://www.wolfram.com/language/ \n\nResources \n\nhttp://www.wolfram.com/mathematica/resources \nhttp://library.wolfram.com/ (Great amount of resources here) \nhttp://support.wolfram.com/kb/topic/mathematica (Knowledge base)    \nhttp://www.mathematica-journal.com \nHelp\nHelp > Virtual Book \nhttp://www.wolfram.com/support/learn/ \nhttp://www.wolfram.com/books/ \nhttp://reference.wolfram.com\n\nBlogs \n\nhttp://community.wolfram.com \nhttp://blog.wolfram.com \nhttp://blog.wolframalpha.com \nhttp://blog.stephenwolfram.com \nhttp://twitter.com/#!/mathematicatip \n\nOther related sites \n\nhttp://www.mathematica25.com\nSMP\nhttp://blog.stephenwolfram.com/2013/06/there-was-a-time-before-mathematica\nhttp://blog.stephenwolfram.com/data/uploads/2013/06/SMPHandbook.pdf \nhttp://www.wolframalpha.com \nWolfram Science: the official site of Stephen Wolfram's New Kind of Science\nNKS forum\nLecture notes from NKS summer schools\nPrograms from the notes\nDemonstrations \nhttp://computerbasedmath.org/ \nhttp://education.wolfram.com (Some interactive basic math courses, useful for curious young people)  \nhttp://www.wolfram.com/webresources.html  (other Mathematica related sites)  \n\nVirtual conferences \n\nhttp://www.wolfram.com/events/virtual-conference/spring-2013 \nhttp://www.wolfram.com/events/virtual-conference/2012 \nhttp://www.wolfram.com/events/virtual-conference/2011 \n\nMathematica one-liner competition\n\nhttp://www.wolfram.com/events/techconf2010/competition.html\nhttp://www.wolfram.com/events/technology-conference/2011/one-liners.html \nhttp://www.wolfram.com/training/special-event/mathematica-experts-live-one-liner-competition-2012 \n\nWolfram technology conferences\n\nhttp://www.wolfram.com/events/technology-conference/2016 \n2015, http://www.wolfram.com/events/technology-conference/2015\n2014, http://www.wolfram.com/events/technology-conference/2014 \n2013, http://www.wolfram.com/events/technology-conference/2013 \n2012, http://www.wolfram.com/events/technology-conference/2012 \n2011, http://www.wolfram.com/events/technology-conference/2011 \n2010, http://www.wolfram.com/events/techconf2010 \n2009, 2007, 2006, 2005, 2004, 2003, 2001, 1999, 1998, 1997, 1994, 1992 \nhttp://library.wolfram.com/infocenter/Conferences/ \n\n", "plotting - RegionPlot is producing odd gaps, even for simple functions. Is there an option to prevent this?": "\nJust increase the number of PlotPoints\nRegionPlot[x^2 < y && y < x^4, {x, -3, 3}, {y, 0, 3}, \n  PlotPoints -> 100]\n\n\n", "parallelization - How to run mathlink external commands in parallel?": "\nFirst I'd like to mention that I am currently using LibraryLink, and that LibraryFunctions can be shared with parallel kernels with DistributeDefinitions.  When using Parallelize, this happens automatically.  (I'm assuming that you have local parallel kernels.  For remote ones, see here.)\nFor MathLink programs, this will not work.  Let's try it:\nFirst, let's launch the kernels:\nIn[6]:= LaunchKernels[]\n\nThen install the addtwo example into the main kernel:\nIn[7]:= SetDirectory[$InstallationDirectory <> \n   \"/SystemFiles/Links/MathLink/DeveloperKit/\" <> $SystemID <> \n   \"/PrebuiltExamples/\"];\n\nIn[8]:= link = Install[\"addtwo\"]    \nOut[8]= LinkObject[\"addtwo\", 23, 11]\n\nIt will not work in parallel kernels even after distribution the definitions because the connection exists only between addtwo and the main kernel:\nIn[9]:= DistributeDefinitions[AddTwo]    \nOut[9]= AddTwo\n\nIn[10]:= ParallelEvaluate[Print@AddTwo[2, 2]]\n\n(kernel 2) LinkObject::linkn: Argument LinkObject[addtwo,23,11] in LinkWrite[LinkObject[addtwo,23,11],CallPacket[0,{2,2}]] has an invalid LinkObject number; the link may be closed.\n\n(kernel 1) LinkObject::linkn: Argument LinkObject[addtwo,23,11] in LinkWrite[LinkObject[addtwo,23,11],CallPacket[0,{2,2}]] has an invalid LinkObject number; the link may be closed.\n\n(kernel 2) $Failed\n\n(kernel 1) $Failed\n\nOut[10]= {Null, Null}\n\nNow lets install it into each parallel kernel:\nIn[11]:= ParallelEvaluate[Install[\"addtwo\"]]    \nOut[11]= {LinkObject[\"addtwo\", 6, 6], LinkObject[\"addtwo\", 6, 6]}\n\nIn[12]:= ParallelEvaluate[Print@AddTwo[2, 2]]\n\n(kernel 1) 4\n\n(kernel 2) 4\n\nOut[12]= {Null, Null}\n\nAs you can see, now it works in each of them, but the addtwo process will also exist in three copies (on a two-core machine). Note: you will have to run ParallelNeeds[] if you load any packages required by the sub kernels.\nI must note that unlike with LibraryLink, I have no practical experience with this.\n\nCaveat:  This problem didn't come up in my tests, but I think it may be possible that the symbol AddTwo will get auto-synchronized between the kernels, so they might lose the connection to their own addtwo process.  This could be avoided by placing the AddTwo symbol into a different context than Global ` (see here and here), but unfortunately you won't have control over this unless you are writing your MathLink programs yourself.\n", "performance tuning - File-backed lists/variables for handling large data": "\nPreamble\nI spent some time and designed and implemented a tiny framework to deal with this problem, over the last two days. Here is what I've got. The main ideas will involve implementing a simple key-value store in Mathematica based on a file system, heavy use and automatic generation of UpValues, some OOP - inspired ideas, Compress, and a few other things. Those who know my posts, I have to warn that this is going to be an unusually long one.\nThe problem and ideas behind the solution\n\nLet me describe the limitations of my system right away. Since the general problem is tough, I consider a very simplified version, but one which can be useful in its own right, and which can serve as a good starting point for future developments. The problem is how to file-back a large ragged numerical list, whose sublists are possibly packed, but generally of different lengths. Let me tell from the start that since I can not use .mx files to avoid platform-dependence, the performance of this won't be stellar. This is a clear speed/memory trade-off situation, and the performance will be merely average. Perhaps, one could make a few tweaks. The overall design was more of my concern here, and I hope I've got a few things right in that department.\nLet us say we have a large list already constructed in  memory in Mathematica, call it testList. Its elements are lists themselves. What I will do is traverse it element by element. For a given element (sub-list), we will analyze how much memory it occupies, and if this amount exceeds a certain threshold that we specify, we will create a key-value pair for it. The key will be some dummy generated symbol, and the value will be a file name for a file where we will save a contents of this element. We will actually Compress the element first, and save the compressed data.\nLow-level OOP-style data exchange API\nEDIT\nSince using .mx files is so much faster, I added some switch functions which will allow one to switch between using usual files and .mx files:\nClearAll[$fileNameFunction,fileName, $importFunction,import, $exportFunction, \n  export,  $compressFunction, $uncompressFunction]\n\n$fileNameFunction = fileName;\n$importFunction  = import;\n$exportFunction = export;\n$compressFunction = Compress;\n$uncompressFunction = Uncompress;\n\nfileName[dir_, hash_] := \n   FileNameJoin[{dir, StringJoin[\"data\", ToString[hash], \".dat\"]}];\nmxFileName[dir_, hash_] := \n   FileNameJoin[{dir, StringJoin[\"data\", ToString[hash], \".mx\"]}];\nimport =  \n   Function[fname, Import[fname, \"String\"]];\nexport = \n   Function[{fname, compressedValue}, \n      Export[fname, compressedValue, \"String\"]];\nmxImport = \n   Function[fname, Block[{data}, Get[fname]; data]];\nmxExport = \n   Function[{fname, compressedValue}, \n       Block[{data = compressedValue}, DumpSave[fname, data]]];\n\nIn addition, compression / uncompression we will also be able to switch on and off. Note also that other functions down the page have been modified accordingly.\nEND EDIT\nAs a second component, we need some high-level structure, which will represent the \"skeleton\" of the original list, and which will manage the on-demand data fetching and saving. As such a structure, I will use just a single symbol, say s. Here is the function which implements the management (the large one):    \nClearAll[definePartAPI];\ndefinePartAPI[s_Symbol, part_Integer, dir_String] :=\n LetL[{sym = Unique[], hash = Hash[sym], \n     fname = $fileNameFunction[dir, hash]\n   },\n   sym := sym =  $uncompressFunction@$importFunction[fname];\n   s /: HoldPattern[Part[s, part]] := sym;\n\n   (* Release memory and renew for next reuse *)\n   s /: releasePart[s, part] :=\n       Replace[Hold[$uncompressFunction@$importFunction[fname]], \n          Hold[def_] :> (ClearAll[sym]; sym := sym = def)];\n\n   (* Check if on disk *)\n   s /: savedOnDisk[s, part] := FileExistsQ[fname];\n\n   (* remove from disk *)\n   s /: removePartOnDisk[s, part] := DeleteFile[fname];\n\n   (* save new on disk *)\n   s /: savePartOnDisk[s, part, value_] :=\n      $exportFunction[fname, $compressFunction @value];\n\n   (* Set a given part to a new value *)\n   If[! TrueQ[setPartDefined[s]],\n     s /: setPart[s, pt_, value_] :=\n       Module[{},\n         savePartOnDisk[s, pt, value];\n         releasePart[s, pt];\n         value\n       ];\n     s /: setPartDefined[s] = True;\n   ];\n(* Release the API for this part. Irreversible *)\ns /: releaseAPI[s, part] := Remove[sym];\n];\n\nHow it works\nLet me now explain what happens here. First, LetL is a sequentially-binding version of With, which I will display in a minute. It allows to avoid nested With statements. The parameters of the function are the main top-level symbol s, the part index, and the directory where our key-value store will be located. Basically, in OO terms, this function creates an instance of a class, with these methods: Part (part extraction), releasePart (releasing the memory occupied by the part, and getting ready to extract it from file again, savedOnDisk - checks is the part has been backed into a file, removePartOnDisk - deletes the backing file for the part,  savePartOnDisk - save the part contents to a file, and releaseAPI - needed to release resources at the end.\nAll this is implemented via UpValues for s. In particular, the Part is overloaded, so now when I call s[[part]], it will look and feel like I extracted the part of s (not true of course, but very convenient). The content of the part is stored in the generated symbol sym, which is unique for a given part. Notice that the definition is lazy and self-uncompressing. This is a similar technique to one I used in this answer. Upon the first call, sym loads the content from file and uncompresses it, and then assigns it to itself. All subsequent calls will be constant time, with the content of the part stored in sym.  Note also that when I call releasePart, I remove the direct part content from sym, feed it to the garbage collector, and reconstruct back the lazy definition for sym. This is my mechanism to be able to release part content when no longer needed, but also be able to load it back again on demand. \nThere are two important points to note regarding Compress. One is that it does not unpack packed arrays. Another is that it is cross-platform. Both are huge wins for us. Note that, essentially, for each part I create an instance of a class, where sym plays a role of instance variable. Note also that I use the Hash of the name of sym, to construct the file name. There are two flaws with this approach actually. One is that there in principle can be hash collisions, and currently I don't handle them at all. Another is that the symbols sym are unique only within a single session, while, as we'll see, I will be exporting their definitions. Both problems are surmountable, but for the sake of simplicity, I ignore them for now. So, the above code represents the low-level data-exchange API on the level of a single list's part.\nHere is the code for LetL macro:\n(* A macro to bind sequentially. Generates nested With at run-time *)\nClearAll[LetL];\nSetAttributes[LetL, HoldAll];\nLetL /: Verbatim[SetDelayed][lhs_, rhs : HoldPattern[LetL[{__}, _]]] :=  \n  Block[{With},\n    Attributes[With] = {HoldAll};\n    lhs := Evaluate[rhs]];\nLetL[{}, expr_] := expr;\nLetL[{head_}, expr_] := With[{head}, expr];\nLetL[{head_, tail__}, expr_] :=\n  Block[{With}, Attributes[With] = {HoldAll};\n   With[{head}, Evaluate[LetL[{tail}, expr]]]];\n\nThe details of how it works are explained in much detail  here.\nHigher-level interface: the list-building function\nThis is the main function used in list-building. Its name pretty much tells what it does - it extends the list with one more element. This, however, does not cost us a performance penalty, since our \"list\" is faked - it is a symbol s which pretends to be a list but in fact is not (it is more like a hash-table filled with class instances).\nClearAll[appendTo];\nOptions[appendTo] = {\n   ElementSizeLimit :> $elementSizeLimit,\n   DestinationDirectory :> $destinationDirectory\n };\nappendTo[s_Symbol, value_, opts : OptionsPattern[]] :=\n  LetL[{len = Length[s], part = len + 1,\n     dir = OptionValue[DestinationDirectory],\n     blim = OptionValue[ElementSizeLimit]\n    },\n    definePartAPI[s, part, dir];\n    s /: Length[s] = part;\n    If[ByteCount[value] > blim,\n       definePartAPI[s, part, dir];\n       savePartOnDisk[s, part, value];\n       releasePart[s, part],\n       (* else *)\n       With[{compressed = $compressFunction @value}, \n         s /: Part[s, part] := \n            (s /: Part[s, part] = $uncompressFunction@compressed);\n         s /: Part[s, part, parts___] := Part[s, part][[parts]];\n  ]]];\n\nAs you can see from this code, not all parts of the list are backed by files. Those which are below the threshold in terms of size, are merely compressed and also assigned to s via UpValues and overloaded Part, but are not on the disk. The code of this function is pretty self-explanatory, so I will move on.\nIntegration with the system and initialization\nThe following function (partially) integrates my construction with some commands that we all love. This will help to better masquerade our symbol s so that in many respects it now behaves as an ordinary list.\nClearAll[initList];\ninitList[s_Symbol] :=\n  Module[{},\n   ClearAll[s];\n   (* Set a new value for part, including update on disk *)\n   s /: Length[s] = 0;\n   s /: HoldPattern[Take[s, {n_}]] := s[[n]];\n   s /: HoldPattern[Take[s, n_]] := Take[s, {1, n}];\n   s /: HoldPattern[Take[s, {m_, n_}]] := Table[s[[i]], {i, m, n}];\n   s /: HoldPattern[Drop[s, {n_}]] := Drop[s, {n, n}];\n   s /: HoldPattern[Drop[s, n_]] := \n      Table[s[[i]], {i, n + 1, Length[s]}];\n   s /: HoldPattern[Drop[s, {m_, n_}]] :=\n        Table[s[[i]], {i, Range[m - 1] ~~ Join ~~ Range[n + 1, Length[s]]}];\n   s /: Map[f_, s] := Table[f[s[[i]]], {i, Length[s]}];\n   s /: HoldPattern[First[s]] := s[[1]];\n   s /: HoldPattern[Last[s]] := s[[Length[s]]];\n   s /: HoldPattern[Rest[s]] := Drop[s, 1];\n   s /: HoldPattern[Most[s]] := Take[s, {1, Length[s] - 1}];\n   s /: Position[s, patt_] :=\n      If[# === {}, {}, First@#] &@\n        Reap[Do[If[MatchQ[s[[i]], patt], Sow[{i}]], {i, Length[s]}]][[2]]\n  ];\n\nThe above code probably does not need any comments.\nSettings\nThere are a few settings I use, basically defaults for the directory and the size threshold.\nClearAll[releasePart, savedOnDisk, removePartOnDisk, removePartOnDisk,\n   savePartOnDisk, releaseAPI]\n$destinationDirectory = $TemporaryDirectory ;\n$elementSizeLimit = 50000;\n\nHigher-level and management-level functions\nThe following functions realize higher-level API which is actually what the end user is supposed to work with.\nClearAll[appendList];\nappendList[s_Symbol, l_List, opts : OptionsPattern[]] :=\n   Do[appendTo[s, l[[i]], opts], {i, 1, Length[l]}];\n\nClearAll[removeStorage];\nremoveStorage[s_Symbol] :=\n   Do[If[savedOnDisk[s, i], removePartOnDisk[s, i]], {i, Length[s]}];\n\nClearAll[releaseAllMemory];\nreleaseAllMemory[s_Symbol] :=\n   Do[releasePart[s, i], {i, Length[s]}];\n\nThe last several functions are concerned with disk management, and storing the main structure / definitions on disk. The point is that in the process of creating our key-value store, we generated lots of UpValues for s, and all those private symbols sym for each part, must also be saved together with s, if we want to fully reconstruct the environment on a fresh kernel.\nThis will find the dependencies of the main symbol s. We only use UpValues, so this is quite straightforward.\n(* Our current system only has one-step dependencies*)\nClearAll[getDependencies];\ngetDependencies[s_Symbol] :=\n Thread[\n   Prepend[\n     Union@Cases[UpValues[s],\n     sym_Symbol /; Context[sym] =!= \"System`\" :> HoldComplete[sym],\n     {0, Infinity}, Heads -> True],\n   HoldComplete[s]\n  ],\n  HoldComplete] \n\nThis generates a file name. It is important that the extension for the main file is .m (Mathematica package) - will come to that later.\nClearAll[getMainListFileName];\nOptions[getMainListFileName] = {\n   DestinationDirectory :> $destinationDirectory,\n   ListFileName -> Automatic\n };\ngetMainListFileName[s_Symbol, opts : OptionsPattern[]] :=\n  LetL[{fn = OptionValue[ListFileName],\n    fname = If[fn === Automatic, ToString[s] <> \".m\", fn],\n    fullfname = FileNameJoin[{OptionValue[ DestinationDirectory], fname}]},\n   fullfname];\n\nThis function saves the main symbol s and those on which it depends (definitions) in a plain .m format to the disk.\nClearAll[storeMainList];\nstoreMainList[s_Symbol, opts : OptionsPattern[]] :=\n  LetL[{filteredOpts  = \n      Sequence @@ FilterRules[{opts}, Options[getMainListFileName]],\n      fname  = getMainListFileName[s, filteredOpts]},\n    releaseAllMemory[s];\n    If[FileExistsQ[fname], DeleteFile[fname]];\n    Replace[getDependencies[s],\n       HoldComplete[syms_] :> Save[fname , Unevaluated[syms]]]];\n\nA call to releaseAllMemory is important, since it converts all possibly expanded definitions of sym-s for various parts back to lazy form, and in that form they will be saved.\nThis function does the inverse: it loads the environment, on a fresh kernel:\nClearAll[retrieveMainList];\nretrieveMainList[s_Symbol, opts : OptionsPattern[]] :=\n  LetL[{filteredOpts  = \n      Sequence @@ FilterRules[{opts}, Options[getMainListFileName]],\n      fname  = getMainListFileName[s, filteredOpts],\n      imported =  Import[fname , \"HeldExpressions\"]\n     },\n    ReleaseHold[imported /.\n       {TagSet -> TagSetDelayed, UpSet -> UpSetDelayed}\n       ] /; imported =!= $Failed;\n    ];\n\n retrieveMainList[___] := $Failed;\n\nThere are a few subtleties here. The problem is that Save converts delayed UpValue definitions (made with TagSetDelayed or UpSetDelayed), into immediate ones (which looks like a bug to me, but anyways). Therefore, I have to load the package in unevaluated form and do back replacements manually, before I allow it to run.\nThe last function here will completely remove all the generated files from the file system:\nClearAll[deleteListComplete];\ndeleteListComplete[s_Symbol, opts : OptionsPattern[]] :=\n LetL[{filteredOpts  = \n    Sequence @@ FilterRules[{opts}, Options[getMainListFileName]],\n    fname  = getMainListFileName[s, filteredOpts]},\n    removeStorage[s];\n    If[FileExistsQ[fname], DeleteFile[fname]];\n    Do[releaseAPI[s, i], {i, Length[s]}];\n    ClearAll[s]]; \n\nThis completes the current version of the system, and now we are ready to start using it.\nExamples and benchmarks\nInitialization\nThe following may be considered as a quick guide to the usage.\n$HistoryLength = 0\n\nWe first generated a reasonably small piece of data, to have something to play with:\nsmallTest = RandomInteger[100, #] & /@ RandomInteger[{10000, 20000}, 300];\n\nI will chose our top-level symbol to have a name test. Before we start anything, we must initialize it:\ninitList[test]\n\nConvertin a list\nWe now convert our list into our key-value structure: \nIn[83]:= appendList[test,smallTest,DestinationDirectory:>\"C:\\\\Temp\\\\LargeData\"];//Timing\nOut[83]= {2.906,Null}\n\nThis was about 18Mb:\nIn[84]:= ByteCount[smallTest]\nOut[84]= 18193688\n\nAnd we generated about 230 files:\nIn[87]:= FileNames[\"*.dat\",{\"C:\\\\Temp\\\\LargeData\"}]//Short\nOut[87]//Short= {C:\\Temp\\LargeData\\data530106946.dat,<<234>>,\n      C:\\Temp\\LargeData\\data530554672.dat}\n\nDetails and tests...\nNote that I intentionally chose a high enough threshold so that not all parts of smallTest ended up in files, some were assigned in-memory only:\nIn[95]:= Length[test]\nOut[95]= 300\n\nIn[97]:= Position[Table[savedOnDisk[test,i],{i,Length[test]}],False]//Short\nOut[97]//Short= {{3},{5},{7},{33},{34},{35},{39},<<50>>,{277},{280},{287},{290},{298},{299},{300}}\n\nLet us now test that our file-backed system keeps the right results. We pick some random positions:\nIn[99]:= randomPos = RandomSample[Range[Length[test]],20]\nOut[99]= {287,214,9,294,32,263,12,141,282,85,213,108,22,197,77,67,41,286,146,38}\n\nAnd test:\nIn[100]:= test[[#]]==smallTest[[#]]&/@randomPos//Timing\nOut[100]= {0.203, {True,True,True,True,True,True,True,True,True,True,\nTrue,True,True,True,True,True,True,True,True,True}}\n\nNote that the second time the test is instant, since memoization is now at work, and there's no need to uncompress again:\nIn[101]:= test[[#]]==smallTest[[#]]&/@randomPos//Timing\nOut[101]= {0.,{True,True,True,True,True,True,True,True,True,True,True,\nTrue,True,True,True,True,True,True,True,True}}\n\nAnother test:\nIn[102]:= Take[test, {10, 20}] == Take[smallTest, {10, 20}]\nOut[102]= True\n\nAdding new elements\nLet us append some elements to our list now:\nappendTo[test, Range[10000]]\n\nWe check the length:\nIn[105]:= Length[test]\nOut[105]= 301\n\nWe can also test directly:\nIn[116]:= test[[301]]//Short\nOut[116]//Short= {1,2,3,4,5,6,7,8,9,10,<<9980>>,9991,9992,\n9993,9994,9995,9996,9997,9998,9999,10000}\n\nIn[117]:= Last@test//Short\nOut[117]//Short= {1,2,3,4,5,6,7,8,9,10,<<9980>>,9991,9992,\n 9993,9994,9995,9996,9997,9998,9999,10000}\n\nWe can append wholesale as well:\nIn[118]:= appendList[test, Partition[Range[10000, 60000], 10000]]\n\nIn[119]:= Length[test]\nOut[119]= 306\n\nMemory management\nI will now illustrate memory management: we will force it to load from disk and uncompress all parts:\nIn[120]:= MemoryInUse[]\nOut[120]= 49040104\n\nIn[121]:= Take[test, {1, Length[test]}];\n\nIn[122]:= MemoryInUse[]\nOut[122]= 64273408\n\nWe now release all memory, and return to lazy self-uncompressing definitions.\nIn[123]:= releaseAllMemory[test];\n\nIn[124]:= MemoryInUse[]\nOut[124]= 49079560\n\nSaving and reconstructing the environment\nLet us now save our environment:\nIn[125]:= \nstoreMainList[test, DestinationDirectory :> \"C:\\\\Temp\\\\LargeData\"] // AbsoluteTiming\n\nOut[125]= {1.1015625, Null}\n\nWe now quit the kernel:\nQuit\n\nand now try to reconstruct it back:\nIn[126]:= \nretrieveMainList[test, \n   DestinationDirectory :> \"C:\\\\Temp\\\\LargeData\"] // AbsoluteTiming\n\nOut[126]= {1.2294922, Null}\n\nWe can see that we are in business:\nIn[127]:= Length[test]\nOut[127]= 306\n\nIn[128]:= test[[301]]//Short\nOut[128]//Short= {1,2,3,4,5,6,7,8,9,10,<<9980>>,9991,9992,9993,\n9994,9995,9996,9997,9998,9999,10000}\n\nRemoving the key-value store - uninstall\nFinally, this will remove all the files from the system completely:\nIn[129]:= deleteListComplete[test,DestinationDirectory:>\"C:\\\\Temp\\\\LargeData\"]//Timing\nOut[129]= {0.031,Null}\n\nLarger tests\nI will throw in a few larger tests, which are still kind of toy tests, but a bit more representative. We start with this:\nIn[130]:= MemoryInUse[]\nOut[130]= 44668800\n\nNow we create a reasonably large dataset:\nIn[131]:= mediumTest = RandomInteger[100,#]&/@RandomInteger[{100000,200000},1000];\nIn[132]:= ByteCount[mediumTest]\n\nThis tells how large\nOut[132]= 607800752\nIn[133]:= initList[test]\n\nIt takes slightly more than a minute to convert it to our data store:\nIn[134]:= \nappendList[test, mediumTest, \n   DestinationDirectory :> \"C:\\\\Temp\\\\LargeData\",\n   ElementSizeLimit:>20000]; //Timing\nOut[134]= {73.906,Null}\n\nThe memory consumption is just amazing (the lack of it!):\nIn[135]:= MemoryInUse[]\nOut[135]= 657753176\n\nThis is pretty much what the initial memory use was plus the memory occupied by mediumTest - our construction takes almost no memory because everything is cached and lazy.\nHere we extract some element (which is not that small):\nIn[136]:= test[[10]]//Short//Timing\nOut[136]= {0.047,{1,19,82,24,54,12,25,5,11,4,74,7,75,\n   <<176964>>,93,5,12,25,97,89,56,59,46,35,95,1,49}}\n\nAll the next times, this will be instantly for this particular element, until we decide to release the cache. We take some more now:\nIn[137]:= Take[test,{10,30}]//Short//Timing\nOut[137]= {0.5,{<<1>>}}\n\nIn[138]:= ByteCount[Take[test,{10,30}]]\nOut[138]= 13765152\n\nWe now take about a third of the total data set - it takes several seconds:\nIn[139]:= (chunk = Take[test,{1,300}]);//Timing\nOut[139]= {6.75,Null}\n\nIn[140]:= ByteCount[chunk]\nOut[140]= 180658600\n\nNeed for speed: Turning on .mx files\nIf we sacrifice being cross-platform for speed, we get 10-40x speedup by using .mx files, and in this regime I'll be hard-pressed to see any database solution beating this in terms of performance. Here are the same benchmarks as before, done with .mx files.\nFirst, switch to .mx:\n$fileNameFunction = mxFileName;\n$importFunction  = mxImport ;\n$exportFunction = mxExport ;\n$compressFunction = Identity;\n$uncompressFunction = Identity;\n\nNote also that I disabled compressing, for maximal speed. The benchmarks:\nIn[57]:= MemoryInUse[]\nOut[57]= 18638744\n\nIn[58]:= mediumTest = RandomInteger[100,#]&/@RandomInteger[{100000,200000},1000];\n\nIn[59]:= ByteCount[mediumTest]\nOut[59]= 594434920\n\nIn[60]:= initList[test]\n\nIn[61]:= appendList[test,mediumTest,DestinationDirectory:>\"C:\\\\Temp\\\\LargeData\"];//Timing\nOut[61]= {14.797,Null}\n\nIn[62]:= MemoryInUse[]\nOut[62]= 618252872\n\nExtraction of a singe list element (including loading from disk) is now instantly:\nIn[63]:= test[[10]]//Short//Timing\nOut[63]= {0.,{7,17,36,41,54,62,49,78,63,62,84,83,14,42,42,\n    <<184520>>,83,0,64,25,86,84,89,17,71,94,84,3,6,23,38}}\n\nExtracting 20 elements is also pretty fast:\nIn[64]:= Take[test,{10,30}];//Timing\nOut[64]= {0.047,Null}\n\nIn[65]:= ByteCount[Take[test,{10,30}]]//AbsoluteTiming\nOut[65]= {0.,12279632}\n\nWe now extract about 300 elements, with the total size af about 180Mb:\nIn[66]:= (chunk = Take[test,{1,300}]);//AbsoluteTiming\nOut[66]= {0.3281250,Null}\n\nIn[67]:= ByteCount[chunk]\nOut[67]= 178392632\n\nTo my mind, this is blazing fast. \nSummary and conclusions\nI presented here a tiny but complete implementation of a key-value store, which may make it possible to work with large files which don't fit in memory, notably lists. From the technical viewpoint, this is by far the most serious application of UpValues I have ever written. I think the simplicity of the code illustrates the power of UpValues well. They also made it possible to have nice syntactic sugar, and be able to use the familiar commands such as Part, Take, etc.\nThe implementation has many flaws, and it is still not clear to me whether it is efficient enough to be useful, but I think this may represent a good starting point. \nEDIT \nAs it turns out, using .mx files gives a huge speedup (which is not unexpected of course). If speed is absolutely crucial, one can use .mx files for all computations and only use normal files to import from or export to another computer. I plan to build a layer which would automate that, but so far, this can be done manually, based on the single-part API in the code above. \nEND EDIT \nAll ideas, suggestions etc - most welcome!\n", "image processing - ImageAlign doesn't always work correctly": "\nThe subimage may be too small:\nImageCorrespondingPoints[mandrill, eye]\n\nreturns\n{{}, {}}\n\nWhen you take more of the image (e.g., replace \"91\" by \"191\"), Mathematica finds some corresponding points and ImageAlign works.\n\"Too small\" probably depends on the nature of the two images as well as their sizes.  The docs state that ImageCorrespondingPoints uses ImageKeyPoints which in turn is said to use the SURF method to find keypoints.  Indeed,\nImageKeypoints[eye]\n\nreturns an empty list.  If you increase the \"91\" to \"100\", a single keypoint is obtained, a pair of corresponding points is found, and ImageAlign succeeds.\n", "curated data - Is it possible to invoke the OEIS from Mathematica?": "\nThere is a Mathematica package exactly for this at the OEIS wiki.\nSomewhat related: there's also a package for formatting data into the OEIS format.\nWolframAlpha also has some of this information, though I'm not sure how to get the $n^{\\mathrm{th}}$ term of the sequence.\nIn[1] := WolframAlpha[\"A004001\", {{\"TermsPod:IntegerSequence\", 1}, \"ComputableData\"}]\n\nOut[1] = {1, 1, 2, 2, 3, 4, 4, 4, 5, 6, 7, 7, 8, 8, 8, 8, 9, 10, 11,\n          12, 12, 13, 14, 14, 15}\n\nOr:\nIn[1] := WolframAlpha[\"A018900\", {{\"Continuation\", 1}, \"ComputableData\"}]\n\nOut[1] = {3, 5, 6, 9, 10, 12, 17, 18, 20, 24, 33, 34, 36, 40, 48, 65, 66, 68, 72}\n\n", "polynomials - Is there a way to Collect[] for more than one symbol?": "\nWell, I am more inclined to try something that leverages Mathematica \"knowledge\" of polynomials.\nIn fact, in Mathematica 7 and 8, you can collect by $x-y$. However, it only works if $(x-y)$ is explicitly apparent in the form of the argument seen by the Collect function.\nSo, this works:\nCollect[a (x - y)^3 + b (x - y)^2 + c (x - y) + d, x - y]\n\nBut, this doesn't:\nCollect[Expand[a (x - y)^3 + b (x - y)^2 + c (x - y) + d], x - y]\n\nI would use PolynomialReduce but I don't have an automated way for doing what you need.\nNevertheless it looks promising as the following does return {a, b, c, d}:\nFlatten[\n    PolynomialReduce[\n        d + c x + b x^2 + a x^3 - c y - 2 b x y - 3 a x^2 y\n             + b y^2 + 3 a x y^2 - a y^3,\n        Table[(x - y)^i, {i, 3, 1, -1}],\n        {x, y}\n    ]\n]\n\nBut I can use this approach for other factorizations.\nFor example, consider the following expansion Expand[z (x - y)^6 + w (x - y)^4 + t (x - y)^2 + s]. Using this expansion I am able to retrieve the coefficients in terms\nof powers of x^2 - 2 x y + y^2:\nFlatten[\n    PolynomialReduce[\n    s + t x^2 + w x^4 - 2 t x y - 4 w x^3 y + t y^2 + 6 w x^2 y^2 - \n        4 w x y^3 + w y^4 + x^6 z - 6 x^5 y z + 15 x^4 y^2 z - \n        20 x^3 y^3 z + 15 x^2 y^4 z - 6 x y^5 z + y^6 z, \n    Table[(x^2 - 2 x y + y^2)^i, {i, 3, 1, -1}],\n    {x, y}\n    ]\n]\n\n", "plotting - How to create regular (planar) graphs?": "\nMy friend C.P and I worked out these solutions. The 1st is C.P.s' Here we go. \nFirst things to know:\n1) New Graph[] and related functionality in v8.0.4 is powerful in the sense that it does not only create an image but also stores all the information, including vertex coordinates, in that Graph[] object.\n2) There is a GridGraph[...] function that makes exactly what it is named for \nNow starting from GridGraph[...] you can simply add or remove edges to it to get your diagrams. \ng[m_, n_] := \n GridGraph[{m, n}, VertexSize -> 0.3, VertexStyle -> White, \n  EdgeStyle -> Black]\n\nedges[m_, n_] := \n Flatten[Table[\n   If[Mod[j, m] != 0 && (j + m + 1 <= n*m), \n    UndirectedEdge[j + m + 1, j], {}], {j, 1, n*m}]]\n\naltg[m_, n_] := EdgeAdd[g[m, n], edges[m, n]]\n\naltg[7, 5]\n\n\nThe rest of your diagrams can follow in the same manner. Another way would be to figure out\nthe formula for construction of adjacency matrix for your diagrams. Then just use AdjacencyGraph[...].\nBut probably the easiest way to solve this (not necessarily efficient) is to understand the visual connection between your vertices. Then connect elements of an array exactly in this way and flatten the array. You should get creative with vertex coordinates though.\nmat[m_, n_] := Flatten@Table[{\n    If[i < m, a[i, j] \\[UndirectedEdge] a[i + 1, j], {}],\n    If[j < n, a[i, j] \\[UndirectedEdge] a[i, j + 1], {}],\n    If[i < m && j < n, a[i, j] \\[UndirectedEdge] a[i + 1, j + 1], {}]\n    }, {i, m}, {j, n}]\n\ng[m_, n_] := \n Graph[mat[m, n], \n  VertexCoordinates -> \n   Thread[Sort[VertexList[Graph[mat[m, n]]]] -> \n     Flatten[Table[{i, j}, {i, m}, {j, n}], 1]], VertexSize -> 0.4, \n  VertexStyle -> White]\n\ng[7, 5]\n\n\n\n===================     UPDATE     ===================\n\nI just realized that we have some beautiful built in data for this type of things.\nSetProperty[GraphData[{\"KingsTour\", {10, 10}}], {VertexSize -> 0.4, \nVertexStyle -> White, EdgeStyle -> Black}]\n\n\nSetProperty[GraphData[{\"KnightsTour\", {10, 10}}], {VertexSize -> 0.4, \nVertexStyle -> White, EdgeStyle -> Black}]\n\n\n", "How to use Union on list of lists without sorting them first?": "\nSorting of sub-lists seems unavoidable since this is what brings them to a \"canonical form\" in this problem. If you don't care about the order of your resulting sub-lists, you could used DeleteDuplicates in place of Union though - this should be faster for large lists.\n", "graphics3d - Texture mapping and resizing a sphere primitive in Mathematica": "\nYou could use a combination of Translate and Scale. Suppose the radii and centres of the circles are given by\nradii = RandomReal[{.1, .6}, 8];\ncentres = RandomReal[{-2, 2}, {8, 3}];\n\nThen using the original sphere\nimage = ExampleData[{\"ColorTexture\", \"GiraffeFur\"}];\nsphere = SphericalPlot3D[1, {theta, 0, Pi}, {phi, 0, 2 Pi}, Mesh -> None, \n  TextureCoordinateFunction -> ({#5, 1 - #4} &), \n  PlotStyle -> Directive[Texture[image]], Lighting -> \"Neutral\", \n  Axes -> False, Boxed -> False];\n\nYou could do for example\nGraphics3D[MapThread[Translate[Scale[sphere[[1]], #1], #2] &, {radii, centres}]]\n\nWhich produces something like this\n\n", "recursion - How can I implement dynamic programming for a function with more than one argument?": "\nYes, there is, although the speed-up is not as dramatic as for 1D memoization:\nClearAll[CharlierC];\nCharlierC[0, a_, x_] := 1;\nCharlierC[1, a_, x_] := x - a;\nCharlierC[n_Integer, a_, x_] :=\n  Module[{al, xl},\n    Set @@ Hold[CharlierC[n, al_, xl_],          \n        Expand[(xl - al - n + 1) CharlierC[n - 1, al, xl] - \n             al (n - 1) CharlierC[n - 2, al, xl]\n        ]];\n    CharlierC[n, a, x]\n];\n\n(Thanks to @Mike Bantegui for pointing out the wastefulness of Simplify, which has now been removed).\nWhat you memoize here are function definitions.Expand is used to not accumulate the complexity too fast. The idea is that I first create a new pattern-based definition, using a number of tricks to fool the scoping variable - renaming mechanism but localize pattern variables, and then evaluate this definition.\nFor example:\nIn[249]:= CharlierC[20,a,x];//Timing\nOut[249]= {0.063,Null}\n\nIn[250]:= CharlierC[25,a,x];//Timing\nOut[250]= {0.078,Null}\n\nWhile with clear definitions:\nIn[260]:= CharlierC[25,a,x];//Timing\nOut[260]= {0.094,Null}\n\nHere are a first few generated definitions:\nIn[262]:= Take[DownValues[CharlierC],4]\nOut[262]= \n{HoldPattern[CharlierC[0,a_,x_]]:>1,\n HoldPattern[CharlierC[1,a_,x_]]:>x-a,\n HoldPattern[CharlierC[2,al$4106_,xl$4106_]]:>\n      al$4106^2-xl$4106-2 al$4106 xl$4106+xl$4106^2,\n HoldPattern[CharlierC[3,al$4105_,xl$4105_]]:>\n   -al$4105^3+2 xl$4105+3 al$4105 xl$4105+3 al$4105^2 xl$4105\n       -3 xl$4105^2-3 al$4105 xl$4105^2+xl$4105^3}\n\n", "formatting - Best way to give presentations with Mathematica": "\nYou can create SlideShows using Mathematica and run it to demonstrate presentation.\nMain advantage of using such Slideshow over Powerpoint / PDF is that you can play dynamic content. \n\nThis Link gives further details on how to create\nhttp://reference.wolfram.com/mathematica/howto/CreateASlideShow.html\nThis screencast gives detailed steps on how to create slideshows\nhttp://www.wolfram.com/broadcast/screencasts/howtocreateaslideshow/?w=800&h=600\nThis notebook has some cool tips\nhttp://library.wolfram.com/infocenter/TechNotes/5299/Tips.nb?file_id=5035\n\nWith CDF format available with Mathematica now , Presentation can be saved in cdf format and can be presented using any browser in which CDF Player is installed\nQuick tips for Inpatients ! \n\nCreate Slide Show File -> New -> Slide Show\nOpen Slide Show Palette Palettes -> Slide Show\nRun Slide Show View Environment -> SlideShow\nRun in Full Screen Mode Presentation Size -> Full Screen\n\n", "How can I get Overlay to position graphics according to coordinates?": "\nCan you use Show? It produces the same thing as your first plot:\nGraphics1 = Graphics[{Red, Disk[{0, 0}, 3, {0, Pi/4}]}];  \ngraphics2 = Graphics[{Blue, Disk[{0, 0}, 10, {0, Pi/2}]}];  \nShow[{graphics2, graphics1}]\n\n\nIf you want to add other options, it works as well:\nShow[{graphics2, graphics1}, PlotRange->{{-10, +10}, {-10, +10}}]\n\n\nYou should note that Show is order dependent. It draws it in the order that's specified\n", "assignment - Clearing a specific definition": "\nYou can use Unset for this, like so:\na[b_, c_] =.\n\n=. works with UpValues too (the full form of this has TagUnset):\na /: Subscript[a,2] =.\n\nYou need to use the same pattern in Unset that you used in the definition.  Get this using Information (i.e. ?a).\n", "cdf format - What are the exact guidelines for what is allowed in a CDF?": "\nSal there is a security problem when you embed CDFs that is analogous to when you open a CDF from an untrusted directory. So though a CDF may work on your desktop you may/will run into problems when embedded. Many causes of this including bugs in how things get screened. For example I had a case where a tick function with down values triggered a security issue whereas an equivalent tick function without down values did not (Wolfram advised that it was down values that were causing that particular problem although in the case in question it shouldn't have caused a problem. I'm told that particular bug/problem has been fixed in current builds but until a new version of Mma is released you may want to try replacing functions with pure functions and see what happens).\nFor other instances where the grey boxes appear there appears to be no way around this without an Mma build that allows higher level security signing. However you will note the difference between an embedded CDF and one that opens in a webpage in fullscreen and displays the dynamic content warning, i.e. the button that you press to allow dynamic content to be considered safe. So one way around some, but not all, of these problems is described here\nChange\ncdf.embed(\"http://path.to/myCDF.cdf\", 500, 600);\n\nto \ncdf.embed(\"http://path.to/myCDF.cdf\", 500, 600,{fullscreen:'true'});\n\n", "assignment - How can I randomly generate a unique, unused symbol?": "\nUnique will do precisely this.  Try for example Unique[x], which returns a symbol with a name similar to x$123.\nHere I should mention the Temporary attribute as well, which, when associated with a symbol, causes that symbol to be removed from the system when it's no longer referenced.  This is occasionally useful when you need Unique.\nBut whenever you do something like this, the question comes up: why can't you just use localization (Module/Block)?\n", "front end - Creating custom notation": "\nYou may wish to use the Notation package.\nIt lets you do these things fairly easily. I'd copy and paste some examples but they don't really copy and paste well. Read through the tutorials and you'll see some examples of how to do this.\nYou may also be interested in the Vector Analysis package.\n", "performance tuning - Choosing among different function definitions without sacrificing speed": "\nWhat I'd do (this is just one way of doing it out of many) is to make functions F and G local and generate them at run-time:\nFFromFile[filename_] := FFromFile[filename] = Module[{ ...}, ...]\nFAnalytic[a_, b_, c_] := a^2 + b^2 + c^2;\nGenerateData[phi_, opts : OptionsPattern[]] :=\n  Module[{F, G},\n   If[OptionValue[Model] === \"File\",\n     F[a_, b_, c_] := FFromFile[OptionValue[Source]][a, b, c],\n     (* else *)\n     F[a_, b_, c_] := FAnalytic[a, b, c]\n   ];\n   G[d_, e_, f_, phiLocal_] :=\n     Block[{g, h, i},\n       (*do a bunch of calculations to figure out g and h*)\n       i = F[g, h, 5];\n       (*do more calculations involving i*)\n     ];\n   NIntegrate[G[x, y, z, phi, opts], {x, 2, 10}, {y, 0, x}, {z, 0, 3},\n     Method -> \"QuasiMonteCarlo\",  PrecisionGoal -> 3]];\n\n", "export - How can I ensure graphics exported in WMF format don't have text-spacing problems?": "\nI can only guess that the following could be a work-around for you (I don't have Windows). Define the following wrapper function for Export:\noutlinedExport[name_, gr_, opts : OptionsPattern[]] := \n Export[name, \n  First@ImportString[ExportString[gr, \"PDF\"], \"PDF\", \n    \"TextMode\" -> \"Outlines\"], opts]\n\nOn my Mac, I cannot export to WMF so I'll have to trust that it will work the same way it does with SVG which I did try. Assuming your graphics object is g, you would do something like this:\noutlinedExport[\"output.wmf\", g, ImageSize -> 600]\n\nThere is no need to embed any fonts because they have all been replaced by outlined paths (again, not sure if Mathematica on Windows does this properly). The downside is that the file size increases, but the upside is that you'll never have any font headaches again.\n", "assignment - What is the distinction between DownValues, UpValues, SubValues, and OwnValues?": "\nIn Mathematica, all functions are really just patterns, and there are different kinds of those.\nLet's start with OwnValues, which is the pattern type of a variable as you know it from other programming languages. The symbol having the OwnValue has, as the name suggests, intrinsic, \"own\", value.\n In[1] := a = 2; OwnValues[a]\nOut[1] := {HoldPattern[a] :> 2}\n\n\nA DownValue is defined when the variable itself does not have a meaning, but can get one when combined with the proper arguments. This is the case for the most function definitions\nf[x_] := x^2\n\nThis defines a pattern for f specifying that each time f[...] is encountered, it is to be replaced by ...^2. This pattern is meaningless if there is a lonely f,\n In[2] := f\nOut[2] := f\n\nHowever, when encountered with an argument downwards (i.e. down the internal structure of the command you entered), the pattern applies,\n In[3] := f[b]\nOut[3] := b^2\n\nYou can see the generated rule using\n In[4] := DownValues[f]\nOut[4] := {HoldPattern[f[x_]] :> x^2}\n\n\nThe next type of pattern concerns UpValues. Sometimes, it's convenient not to associate the rule to the outermost symbol. For example, you may want to have a symbol whose value is 2 when it has a subscript of 1, for example to define a special case in a sequence. This would be entered as follows:\nc /: Subscript[c, 1] := 2\n\nIf the symbol c is encountered, neither of the discussed patterns apply. c on its own has no own hence no OwnValue, and looking down the command tree of c when seeing Subscript[c,1] yields nothing, since c is already on an outermost branch. An UpValue solves this problem: a symbol having an UpValue defines a pattern where not only the children, but also the parents are to be investigated, i.e. Mathematica has to look up the command tree to see whether the pattern is to be applied.\n In[5] := UpValues[c]\nOut[5] := {HoldPattern[Subscript[c, 1]] :> 2}\n\n\nThe last command is SubValues, which is used for definitions of the type\nd[e][f] = x;\n\nThis defines neither an OwnValue nor a DownValue for d, since it does not really define the value for the atomic object d itself, but for d[e], which is a composite. Read the definition above as (d[e])[f]=x.\n In[6] := SubValues[d]\nOut[6] := {HoldPattern[d[e][f]] :> x}\n\n(Intuitively, an OwnValue for d[e] is created, however calling for this results in an error, i.e. OwnValues[d[e]] creates Argument d[e] at position 1 is expected to be a symbol.)\n", "dynamic - What causes Manipulate to stop evaluating expressions?": "\nPlease try this. I prefer to remove all unneeded dynamics from the code by making the Manipulate use a Trigger so that I see better what is the dynamic object in all of these things, and added TrackedSymbols on only the trigger variable, and moved globals into the Manipulate as I do not like to see globals. (you can also use Module inside Manipulate if you want). \nNot seeing any hangups any more. The Trigger is probably what you want to use for this type of simulation setup. \nManipulate[\n {r, v, a} = Step[r, v, a, dt];\n\n Grid[{\n   {Show[{Graphics@Circle[{0, 0}, 1], \n      Graphics[{PointSize[Large], Red, Point[r]}]}]},\n   {r, Norm@r}\n   }\n  ],\n\n Control[{{dt, 0.005, \"dt:\"}, 0.00001, 1, 0.00001, \n   ControlType -> Trigger, DisplayAllSteps -> True, \n   ImageSize -> Small, AnimationRate -> Automatic}],\n\n {{r, {1, 0}}, None},\n {{v, {0, 1}}, None},\n {{a, {-1, 0}}, None},\n TrackedSymbols :> {dt},\n Initialization :>\n  {\n   Step[r_, v_, a_, dt_] := Block[{nr, nv, na},\n     nv = v + dt/2 a;\n     nr = r + dt nv;\n     na = -nr;\n     nv = nv + dt/2 a;\n     {nr, nv, na}\n     ]\n   }\n ]\n\n", "performance tuning - How can I improve the speed of eigenvalue decompositions for large matrices?": "\nMathematica is every bit as fast as Matlab for these types of computations.  The source of the discrepancy arises from the fact that Timing keeps track of total time used by all processors when Mathematica distributes the computation across them.  We can examine a fair comparison using AbsoluteTiming, which is more comparable to Matlab's tic and toc.\nConsider the following computed on my Macbook Pro:\nt1 = First[Timing[Eigenvalues[RandomReal[{0, 1},\n  {1000, 1000}]]]];\nt2 = First[AbsoluteTiming[Eigenvalues[RandomReal[{0, 1},\n  {1000, 1000}]]]];\n{t1, t2}\n\n{5.16576, 1.329784}\nAgain, the only difference is the use of Timing versus AbsoluteTiming.  You can watch the wall clock to convince yourself that the faster time is accurate.  Let's try this with with the OP's code:\ntimingsGood = With[{x = RandomReal[NormalDistribution[], {#, #}]}, \n  Eigenvalues[x]; // AbsoluteTiming // First] & /@ \n  Range[500, 5000, 500];\ntimingsBad = With[{x = RandomReal[NormalDistribution[], {#, #}]}, \n  Eigenvalues[x]; // Timing // First] & /@ \n  Range[500, 5000, 500];\nColumn[{timingsGood, timingsBad, timingsBad/timingsGood}]\n\n\nNote that the (incorrect) Timing result is always consistently about three times longer than the (correct) AbsoluteTiming result, which accounts just about exactly for the OP's observations.\nI ran a suite of numerical comparisons that I created several years ago.  Here are my results:\n\nThere are differences.  Matlab is notably faster at singular value, Cholesky, and QR factorizations.  Mathematica is slightly faster at sparse eigenvalue computations.  They seem to be generally quite close to one another.  There are a few other types of computations as well.  Symbolically, Mathematica is way faster than Matlab's symbolic toolbox.\n", "graphics - Speeding up this fractal-generating code": "\nUse these 3 components: compile, C, parallel computing.\nAlso to speed up coloring instead of ArrayPlot use\nGraphics[Raster[Rescale[...], ColorFunction -> \"TemperatureMap\"]]\n\nIn such cases Compile is essential. Compile to C with parallelization will speed it up even more, but you need to have a C compiler installed. Note difference for usage of C and parallelization may show for rather greater image resolution and more cores. \nmandelComp = \n  Compile[{{c, _Complex}}, \n   Module[{num = 1}, \n    FixedPoint[(num++; #^2 + c) &, 0, 99, \n     SameTest -> (Re[#]^2 + Im[#]^2 >= 4 &)]; num], \n   CompilationTarget -> \"C\", RuntimeAttributes -> {Listable}, \n   Parallelization -> True];\n\ndata = ParallelTable[\n   a + I b, {a, -.715, -.61, .0001}, {b, -.5, -.4, .0001}];\n\nGraphics[Raster[Rescale[mandelComp[data]], \n  ColorFunction -> \"TemperatureMap\"], ImageSize -> 800, PlotRangePadding -> 0]\n\n\nThis is just a prototype - you can figure out a better coloring. Another way is to use LibraryFunction - we have Mandelbrot built in:\nmlf = LibraryFunctionLoad[\"demo_numerical\", \"mandelbrot\", {Complex}, \n   Integer];\nn = 501; samples = \n Table[mlf[x + I y], {y, -1.25, 1.25, 2.5/(n - 1)}, {x, -2., .5, \n   2.5/(n - 1)}];\ncolormap = \n  Function[If[# == 0, {0., 0., 0.},  Part[r, #]]] /. \n   r -> RandomReal[1, {1000, 3}];\nGraphics[Raster[Map[colormap, samples, {2}]], ImageSize -> 512]\n\n\nNow, if you have a proper NVIDIA graphics card you can do some GPU computing with CUDA or OpenCL. I use OpenCL here because I got the source (from documentation btw):\nNeeds[\"OpenCLLink`\"]\n\nsrc = \"\n  __kernel void mandelbrot_kernel(__global mint * set, float zoom, \\\nfloat bailout, mint width, mint height) {\n     int xIndex = get_global_id(0);\n     int yIndex = get_global_id(1);\n     int ii;\n\n     float x0 = zoom*(width/3 - xIndex);\n     float y0 = zoom*(height/2 - yIndex);\n     float tmp, x = 0, y = 0;\n     float c;\n\n     if (xIndex < width && yIndex < height) {\n         for (ii = 0; (x*x+y*y <= bailout) && (ii < MAX_ITERATIONS); \\\nii++) {\n              tmp = x*x - y*y +x0;\n              y = 2*x*y + y0;\n              x = tmp;\n          }\n          c = ii - log(log(sqrt(x*x + y*y)))/log(2.0);\n          if (ii == MAX_ITERATIONS) {\n              set[3*(xIndex + yIndex*width)] = 0;\n              set[3*(xIndex + yIndex*width) + 1] = 0;\n              set[3*(xIndex + yIndex*width) + 2] = 0;\n          } else {\n              set[3*(xIndex + yIndex*width)] = ii*c/4 + 20;\n              set[3*(xIndex + yIndex*width) + 1] = ii*c/4;\n              set[3*(xIndex + yIndex*width) + 2] = ii*c/4 + 5;\n          }\n      }\n  }\n  \";\n\nMandelbrotSet = \n  OpenCLFunctionLoad[src, \n   \"mandelbrot_kernel\", {{_Integer, _, \"Output\"}, \"Float\", \n    \"Float\", _Integer, _Integer}, {16, 16}, \n   \"Defines\" -> {\"MAX_ITERATIONS\" -> 100}];\n\nwidth = 2048;\nheight = 1024;\nmem = OpenCLMemoryAllocate[Integer, {height, width, 3}];\n\nres = MandelbrotSet[mem, 0.0017, 8.0, width, height, {width, height}];\n\nImage[OpenCLMemoryGet[First[res]], \"Byte\"]\n\n\nReferences:\nFractals CDF paper\nCompile to C\nLibraryFunction \nOpenCL \nDemonstrations\n", "Manipulate evaluation sequence": "\nAccording to my previous experiences and this post, the sequence goes like this (please feel free to correct me in this post):\n\nFrom the documentation: \n\nManipulate generates a DynamicModule object, with the variables u, v, etc. specified as local. \n\nThat is, first Manipulate wraps its result into DynamicModule, then...\n...gives unique names to local variables (as it is a scoping construct).\nNext, the body of Manipulate is evaluated in standard order.\nThe output cell is created by evaluating the result of the DynamicModule (or the Manipulate).\nIf there was any Initialization :> init inside Manipulate, it is now evaluated \"when the result is first displayed in a particular session\".\nIf there is any Deinitialization :> deinit inside Manipulate and the dynamic output cannot be displayed any more, deinit is evaluated.\n\nContraintuitively, Initialization is called almost ultimately which caused me some frustration over time.\nTo understand how to load a package with your dynamic content by Needs, see my answer here.\n", "programming - Continuous evaluation of complex calculations": "\nThere have been several good examples of nice interactive visualizations in the answers so far.\nYour question was a very general one, so I will mention the intended general solution: Monitor.\nFor example, this combines very nicely with NDSolve's StepMonitor along with a ProgressIndicator:\nIn[13]:= Monitor[\n NDSolve[{D[u[t, x], {t, 2}] == D[u[t, x], {x, 2}] + Sin[u[t, x]], \n   u[0, x] == E^-x^2, Derivative[1, 0][u][0, x] == 0, \n   u[t, -10] == u[t, 10]}, u, {t, 0, 100}, {x, -10, 10}, \n  StepMonitor :> (sol = u[t, x]; time = t)], \n Column[{Plot[sol, {x, -10, 10}, PlotRange -> {0, 8}, \n    Filling -> Axis], ProgressIndicator[time, {0, 100}]}]\n ]\n\nIt looks like this while it is evaluating:\n\n(This is a modified version of an example in the documentation for StepMonitor.)\nUsing Monitor[..., ProgressIndicator[...]] is a very useful idiom. I guess I use it several times per week. (With a bit of extra code you can monitor e.g. ParallelTable this way too: https://stackoverflow.com/questions/7352461/monitoring-progress-of-a-parallel-computation-in-mathematica/7376332#7376332.)\n", "Difficulties in creating strict and robust equivalence between two symbols using the Notation package": "\nYou appear to be looking for the functionality of $PreRead:\n$PreRead = # /. \"beta\" -> \"\\[Beta]\" &;\n\n\n", "list manipulation - Flatten command: matrix as second argument": "\nOne convenient way to think of Flatten with the second argument is that it performs something like Transpose for ragged (irregular) lists. Here is a simple example:\nIn[63]:=  Flatten[{{1,2,3},{4,5},{6,7},{8,9,10}},{{2},{1}}]\nOut[63]= {{1,4,6,8},{2,5,7,9},{3,10}}\n\nWhat happens is that elements which constituted level 1 in the original list are now constituents at level 2 in the result, and vice versa. This is exactly what Transpose does, but done for irregular lists. Note however, that some information about positions is lost here, so we can not directly inverse the operation:\nIn[65]:= Flatten[{{1,4,6,8},{2,5,7,9},{3,10}},{{2},{1}}]\nOut[65]= {{1,2,3},{4,5,10},{6,7},{8,9}}\n\nTo have it reversed correctly, we'd have to do something like this:\nIn[67]:= Flatten/@Flatten[{{1,4,6,8},{2,5,7,9},{3,{},{},10}},{{2},{1}}]\nOut[67]= {{1,2,3},{4,5},{6,7},{8,9,10}}\n\nA more interesting example is when we have deeper nesting:\nIn[68]:= Flatten[{{{1,2,3},{4,5}},{{6,7},{8,9,10}}},{{2},{1},{3}}]\nOut[68]= {{{1,2,3},{6,7}},{{4,5},{8,9,10}}}\n\nHere again, we can see that Flatten effectively worked like (generalized) Transpose, interchanging pieces at the first 2 levels. The following will be harder to understand:\nIn[69]:=  Flatten[{{{1, 2, 3}, {4, 5}}, {{6, 7}, {8, 9,  10}}}, {{3}, {1}, {2}}]\nOut[69]= {{{1, 4}, {6, 8}}, {{2, 5}, {7, 9}}, {{3}, {10}}}\n\nThe following image illustrates this generalized transpose:\n\nWe may do it in two consecutive steps:\nIn[72]:=  step1 = Flatten[{{{1,2,3},{4,5}},{{6,7},{8,9,10}}},{{1},{3},{2}}]\nOut[72]= {{{1,4},{2,5},{3}},{{6,8},{7,9},{10}}}\n\nIn[73]:= step2 =  Flatten[step1,{{2},{1},{3}}]\nOut[73]= {{{1,4},{6,8}},{{2,5},{7,9}},{{3},{10}}}\n\nSince the permutation {3,1,2} can be obtained as {1,3,2} followed by {2,1,3}. Another way to see how it works is to use numbers which indicate the position in the list structure:\nFlatten[{{{111, 112, 113}, {121, 122}}, {{211, 212}, {221, 222, 223}}}, {{3}, {1}, {2}}]\n(*\n==> {{{111, 121}, {211, 221}}, {{112, 122}, {212, 222}}, {{113}, {223}}}\n*)\n\nFrom this, one can see that in the outermost list (first level), the third index (corresponding the third level of the original list) grows, in each member list (second level) the first element grows per element (corresponding to the first level of the original list), and finally in the innermost (third level) lists, the second index grows, corresponding to the second level in the original list. Generally, if the k-th element of the list passed as second element is {n}, growing the k-th index in the resulting list structure corresponds to increasing the n-th index in the original structure.\nFinally, one can combine several levels to effectively flatten the sub-levels, like so:\nIn[74]:=  Flatten[{{{1,2,3},{4,5}},{{6,7},{8,9,10}}},{{2},{1,3}}]\nOut[74]= {{1,2,3,6,7},{4,5,8,9,10}}\n\n", "output formatting - Can the Notation function support complex structures on its left hand side?": "\nSo (I guess that) the problem occurs because\nNotation[LHS \\[DoubleLongLeftRightArrow] RHS] converts the LHS into boxes,\nwhere OverBar[x] is OverscriptBox[x,\"_\"].\nIt then interprets the underscore as a Blank (_), which it tries to match up with a pattern on the RHS.  \nI'm sure that I've used the Notation package with OverBars before and have not had troubles with it. But then again, maybe not.\nAnyway, you can forget about the Notation package for this since you can easily use the underlying box mechanism to implement the notation that you want:\nMakeBoxes[afstarbar, form_] := InterpretationBox[\n    OverscriptBox[SuperscriptBox[\"af\", \"*\"], \"_\"], afstarbar]\n\n", "persistence - Saving Mathematica kernel state?": "\nWhile it is true that you can not save a full state of the kernel, in some cases it may be enough for your purposes to save all symbols' definitions in some context(s), such as Global` (or whatever other contexts are of interest to you). This can be done via DumpSave, like\nDumpSave[\"state.mx\", \"Global`\"]\n\nThe .mx file generated by DumpSave will be platform-specific though. By using Get at some later point, you can reconstruct the values stored in symbols in those contexts you saved:\nGet[\"state.mx\"]\n\nAs stated already by @ruebenko, this will not generally fully reconstruct the kernel state. But if you manage to correctly account for all symbols (defined by you) which affect your computations, and depending on the circumstances, this may be enough for many practical purposes.\n", "plotting - Plot Option Precedence while combining Plots with Show[]": "\nFirst a little background:\nAll of Mathematica's plotting functions produce a Graphics expression (or Graphics3D, but let's talk about Graphics now).  The Graphics expression is simply a representation of what you see in the graphic.  You can look at it by converting the output cell to InputForm (Ctrl-Shift-I).  For example, Plot will produce Graphics with Lines in it.\nSome of the options to plotting functions are passed on directly to Graphics an affect its appearance (how its contents get rendered).  An example is Axes.  Some others control what the plotting function will put into the graphics.  Examples are PlotStyle or PlotMarkers.  These are specific to (and different for) each plotting function.\nHow Show works:\nIt combines several Graphics expressions into one.  The returned Graphics expression will inherit its options from the first one passed to Show.  In Show you can override some Graphics options directly, but of course this will only override options for Graphics, and not the plotting functions that produced the graphics (as those have already finished running by the time Show sees their output).\nSo \nShow[ListPlot[... , Op1], Plot[... , Op2], Op3] \n\nis equivalent to \nShow[ListPlot[... , Op3, Op1], Plot[...]]\n\nor to\nShow[ListPlot[...], Plot[...], Op3, Op1]\n\nbut this is only valid for ListPlot options that are also Graphics options.  It is not valid for PlotMarkers.\nAlso note that if the same option is specified several times in the same Graphics, the first one takes precedence. (Thanks J. M.!)\n", "function construction - which is better, using Assert[] or manual checks on arguments and other computations?": "\nLike in other programming languages, such as C or Java, assertions are used to catch errors in the logic of your code. With discipline, you can also use exceptions for a similar purpose (see e.g. this discussion for an example).\nUsing patterns and returning a function unevaluated is useful in different types of situations. The linked above answer also discusses when which is more appropriate. Very roughly, there are 3 different situations:\n\nYou want to pre-emptively catch certain errors in your logic, since you know that certain things definitely can not normally happen. At the same time, these checks can not be easily reduced to input argument checks. And, finally, the error, if occurs, is purely in your logic, and otherwise things are within your control. Then, use assertions. I would not use assertions to filter out unwanted input - this is what pattern-checks in function definitions are for. Using asserts in their place would typically make code clumsier, more fragile and less readable.\nYour function can not move further with its computations, since either wrong arguments were supplied or something beyond your control happened (file not found on disk say). Then, return $Failed or use exceptions (but be sure to use tagged exceptions and catch them in the outer - public- functions). \nThe function does not know what to do with the input, but there is a chance that the input may evaluate to something meaningful at some later point.  Then, returning unevaluated may make more sense.\n\nGenerally, functions which do not return anything and whose results are some performed actions, tend to be candidates for 1. or 2., while functions returning expressions are more often candidates for 3. But these are just general guidelines, and one has to develop the intuition to know when to follow these rules and when to break them. \n", "Change syntax from other programs to mathematica syntax": "\nThere is support for TeX files built in to the Import function. For example:\nNotebookPut[Import[\"http://www.math.wisc.edu/computing/tex/sample.tex\"]]\n\nWill load the sample TeX file located at that URL into a Mathematica notebook. You can of course replace the URL with a path to a file on your computer.\nThe TeX file is imported with \"structure\" intact (I suppose we'd expect this from Mathematica), so you can play around with how exactly it is formatted.\nAs for other computer algebra systems, it would surprise me if there was an easy way to translate syntax in general--but you can use StringReplace for simple syntax modifications, as in this example:\nToExpression[StringReplace[\"Sin(x)+Cos(y)\", {\"(\" -> \"[\", \")\" -> \"]\"}]]\n\n", "programming - Sum over n variables": "\nYou can write a few helper functions to help you. The following can probably be streamlined...\nvars[s_String, n_Integer?Positive] := Table[Symbol[s <> ToString[i]], {i, 1, n}]\nvars[sym_Symbol, num_] := vars[SymbolName[sym], num]\n\nnestedRange[vars_List, min_, max_] /; min <= max := \n Transpose@{vars, ConstantArray[min, Length[vars]], Append[Rest@vars, max]}\n\nnestedSum[f_, vars:{__Symbol}, min_, max_] /; min <= max := \n With[{r = Sequence @@ Reverse@nestedRange[vars, min, max]}, Sum[f, r]]\nnestedSum[f_, {var:(_String|_Symbol), num_Integer?Positive}, \n min_, max_] /; min <= max := nestedSum[f, vars[var, num], min, max]\n\nThen, for example \nnestedSum[f[a, b, c], {a, b, c}, 0, Infinity] // TraditionalForm\n\nproduces \nA larger sum is\nIn[]:= nestedSum[Total@vars[i, 4], {i, 4}, 1, 20] // Timing\nOut[]= {0.016001, 371910}\n\nwhich can be compared with evaluating the same thing using Boole\nIn[]:= v = vars[i, 4];\n       With[{r = Sequence@@Table[{n, 1, 20}, {n, v}]}, \n            Sum[Boole[LessEqual@@v] Total@v, r]] // Timing\nOut[]= {0.056003, 371910}\n\n", "graphics - ListPlot: Plotting large data fast": "\nMany posters already suggested good answers. I am just adding some explanation behind this behavior. Also, I have to warn that this is my understanding, and I couldn't find any reference. So, please take it with grain of salt. I am more than happy to stand corrected, if found wrong.\nProblem\nIt is a rendering issue. And it is in fact Windows' GDI+ related issue (and probably Apple too). I tried my best, but couldn't find related Microsoft KB (which I know there is...).\nAnyway, this is what is roughly happening. If you have lines defined by Line[{pt1, pt2, ...}], system graphics API treat it as a single path (with multiple segment). Now, in a single path case, the API, especially the rasterizer is trying to see whether each pixel is intersected by multiple segments. The reason? Because of the opacity. Compare these two images (very exaggerated, but the idea is there).\npts = {{0, 0}, {1, 1}, {1, 0}, {0, 1}};\n\n{Graphics[{Thickness[.1], Opacity[.3], Line[{{0, 0}, {1, 1}, {1, 0}, {0, 1}}]}],\n Graphics[{Thickness[.1], Opacity[.3], Line[Partition[pts, 2, 1]]}]}\n\n\nIf you don't treat the self-intersection, what you end up getting is something like the second result (transparency accumulated in self-intersection points). Which is very bad for many cases. Now it shouldn't be a problem when opacity is 1, but unfortunately if you use anti-aliasing, then you are in effect introducing a different opacity, this should be dealt. This is no problem with multi-path case (like the second image), since in that case, you can just accumulate pixel values at each pixel.\nTo prove it, compare the following point configuration and speed difference:\n\nThe same number of points, but the rendering of the second one is much faster.\nNow, back to our problem. When we are using ListLinePlot without any options (or just PlotRange->All), the process is very close to what Leonid's myListPlot is doing. Which means that it will generate a long chain of Line[{pt1, pt2, ...}] and the self-intersection routine will kick in. If you see the original result closely, you will see that in fact, the resulting graphics has a lot of self-intersection in pixel-res space (it does computation on pixel-level).\nSolutions\nIn fact, Mr.Thomas already got his own answers.\n\nTuring off anti-aliasing (by Style[..., AntiAliasing->False]). This way, the rasterizer spend a lot less time processing intersections, thus much much faster.\nSub-sampling. There are multiple ways, MaxPlotPoints is one, Thomas' code is another, and much more.\nCheating by making multiple paths:\n\nWell, this solution isn't going to give you super boost. Just in case you absolutely need anti-aliasing, and also need to use all the points. Look at a part of my first example:\nLine[Partition[pts, 2, 1]]\n\nYou will see that we are essentially turning Line[{pt1, pt2, pt3, pt4, ...}] into Line[{{{pt1, pt2}}, {{pt2, pt3}}, {{pt3, pt4}}, ...}]. As long as the opacity remains 1, the result should be about the same (except JoinedForm, but in our case it is no concern). The benefit of the second form is that now it is not considered to be a single path. So, the rasterizer will think that it is multiple-path, and no self-intersection treatment.\nI modified Lenoid's myListPlot a bit so that it does this task.\nClearAll[myListPlot2];\nOptions[myListPlot2] = {AspectRatio -> GoldenRatio^(-1), Axes -> True,\n    AxesOrigin -> {0, 0}, PlotRange -> {All, All}, \n   PlotRangeClipping -> True, \n   PlotRangePadding -> {Automatic, Automatic}};\n\nmyListPlot2[pts_List, opts : OptionsPattern[]] :=\n Module[{pts1, pts2},\n  pts1 = Developer`ToPackedArray@\n    Transpose[{N@Range[Length[pts]], pts}];\n  pts2 = Partition[pts1, 2, 1];\n  Graphics[{{{}, {}, {Hue[0.67, 0.6, 0.6], Line[pts2]}}}, \n   FilterRules[{opts, Options[myListPlot]}, Options[Graphics]]]]\n\nNow, time to prove the theory. With the same data set rv, here is the timing comparison between myListPlot and myListPlot2 (myListPlot is faster than ListLinePlot so it is enough).\n\nWell, about twice as fast. Frankly, it is not that practical, just theoretical interest :)\nAddendum\nSzabolcs found some bundling going on at 500 (Not sure it is Windows specific or number is exactly that, but bundling is true), which makes me experimenting with different segmenting--instead of just 2, partitioning it at 3, 4, ... etc. And I got all different speed result (getting faster, then slower again). If you use Partition it drops the tail (and I personally am still learning all complex syntax, so...), but it shouldn't make that much of difference, in my opinion.\nSo, the problem is probably not just affected by the self-intersection, but also the bundling. It gets more interesting / complex :)\n", "options - How to find out which method Mathematica selected?": "\nI think you can actually see (most of) what Mathematica is doing by using Trace[..., TraceInternal -> True].\nFor example, \nSelect[Flatten[\n  Trace[NDSolve[y'[x] == x && y[0] == 0, y, {x, 0, 6}], \n   TraceInternal -> True]], ! FreeQ[#, Method | NDSolve`MethodData] &]\n\nshows the DE was evaluated using NDSolve`LSODA and Newton's method. (I think)\nAnd\nSelect[Flatten[\n  Trace[NDSolve[{Derivative[1][x][t]^2 + x[t]^2 == 1, x[0] == 1/2}, \n    x, {t, 0, 10 Pi}, SolveDelayed -> True], \n   TraceInternal -> True]], ! FreeQ[#, Method | NDSolve`MethodData] &]\n\nused NDSolve`IDA.\n\nAs an aside, here's something I just learnt from Trott's Mathematica guidebook for numerics, to see all of the methods and suboptions for NDSolve \n{#, First /@ #2} & @@@ \n Select[{#, Options[#]} & /@ (ToExpression /@ \n   DeleteCases[Names[\"NDSolve`*\"],(* PDE method only *) \"NDSolve`MethodOfLines\"]), \n   (Last[#] =!= {}) &]\n\n", "interactive - Get a \"step-by-step\" evaluation in Mathematica": "\nFor differentiation at least, old versions of Mathematica had a demonstration function called WalkD[] that holds your hand and shows what is done at each stage up until the final answer.\nIn general, however...\n\nYou should realize at the outset that while knowing about the\n  internals of Mathematica may be of intellectual interest, it is\n  usually much less important in practice than you might at first\n  suppose.\nIndeed, one of the main points of Mathematica is that it provides an\n  environment where you can perform mathematical and other operations\n  without having to think in detail about how these operations are\n  actually carried out inside your computer. \n...\nParticularly in more advanced applications of Mathematica, it may\n  sometimes seem worthwhile to try to analyze internal algorithms in\n  order to predict which way of doing a given computation will be the\n  most efficient. And there are indeed occasionally major improvements\n  that you will be able to make in specific computations as a result of\n  such analyses.\nBut most often the analyses will not be worthwhile. For the internals\n  of Mathematica are quite complicated, and even given a basic\n  description of the algorithm used for a particular purpose, it is\n  usually extremely difficult to reach a reliable conclusion about how\n  the detailed implementation of this algorithm will actually behave in\n  particular circumstances.\nA typical problem is that Mathematica has many internal\n  optimizations, and the efficiency of a computation can be greatly\n  affected by whether the details of the computation do or do not allow\n  a given internal optimization to be used.\n\nPut another way: how Mathematica does things doesn't necessarily correspond to \"manual\" methods.\n\nHere's my modest attempt to (somewhat) modernize WalkD[]:\nFormat[d[f_, x_], TraditionalForm] := DisplayForm[RowBox[{FractionBox[\"\\[DifferentialD]\",\n                                                  RowBox[{\"\\[DifferentialD]\", x}]], f}]];\n\nSpecificRules = {d[(f_)[u___, x_, v___], x_] /;\n                 FreeQ[{u}, x] && FreeQ[{v}, x] :> D[f[u, x, v], x],\n                 d[(a_)^(x_), x_] :> D[a^x, x] /; FreeQ[a, x]};\n\nConstantRule = d[c_, x_] :> 0 /; FreeQ[c, x];\n\nLinearityRule = {d[f_ + g_, x_] :> d[f, x] + d[g, x],\n                 d[c_ f_, x_] :> c d[f, x] /; FreeQ[c, x]};\n\nPowerRule = {d[x_, x_] :> 1, d[(x_)^(a_), x_] :> a*x^(a - 1) /; FreeQ[a, x]};\n\nProductRule = d[f_ g_, x_] :> d[f, x] g + f d[g, x];\n\nQuotientRule = d[(f_)/(g_), x_] :> (d[f, x]*g - f*d[g, x])/g^2;\n\nInverseFunctionRule = d[InverseFunction[f_][x_], x_] :>\n                      1/f'[InverseFunction[f][x]];\n\nChainRule = {d[(f_)^(a_), x_] :> a*f^(a - 1)*d[f, x] /; FreeQ[a, x],\n             d[(a_)^(f_), x_] :> Log[a]*a^f*d[f, x] /; FreeQ[a, x],\n             d[(f_)[g__], x_] /; ! FreeQ[{g}, x] :>\n             (Derivative[##][f][g] & @@@ IdentityMatrix[Length[{g}]]).(d[#, x] & /@ {g}),\n             d[(f_)^(g_), x_] :> f^g*d[g*Log[f], x]};\n\n$RuleNames = {\"Specific Rules\", \"Constant Rule\", \"Linearity Rule\", \"Power Rule\",\n              \"Product Rule\", \"Quotient Rule\", \"Inverse Function Rule\", \"Chain Rule\"};\n\ndisplayStart[expr_] := CellPrint[\n  Cell[BoxData[MakeBoxes[HoldForm[expr], TraditionalForm]], \"Output\", \n   Evaluatable -> False, CellMargins -> {{Inherited, Inherited}, {10, 10}}, \n   CellFrame -> False, CellEditDuplicate -> False]]\n\ndisplayDerivative[expr_, k_Integer] := CellPrint[\n  Cell[BoxData[TooltipBox[RowBox[{InterpretationBox[\"=\", Sequence[]], \"  \", \n       MakeBoxes[HoldForm[expr], TraditionalForm]}], $RuleNames[[k]], \n     LabelStyle -> \"TextStyling\"]], \"Output\", Evaluatable -> False, \n   CellMargins -> {{Inherited, Inherited}, {10, 10}}, \n   CellFrame -> False, CellEditDuplicate -> False]]\n\nWalkD[f_, x_] := Module[{derivative, oldderivative, k}, \n        derivative = d[f, x]; displayStart[derivative];\n        While[! FreeQ[derivative, d],\n            oldderivative = derivative; k = 0;\n            While[oldderivative == derivative,\n                      k++;\n                      derivative = derivative /. \n                              ToExpression[StringReplace[$RuleNames[[k]], \" \" -> \"\"]]];\n            displayDerivative[derivative, k]];\n        D[f, x]]\n\nI've tried to make the formatting of the derivative look a bit more traditional, as well as having the differentiation rule used be a tooltip instead of an explicitly generated cell (thus combining the best features of WalkD[] and RunD[]); you'll only see the name of the differentiation rule used if you mouseover the corresponding expression.\n\n", "implementation details - How to check for Mathematica\u2019s definition of XY?": "\nSince there are two parts to your question. I will address the one directly dealing with Binomial.\nFor the purposes of discrete mathematics, the binomial is defined through its generating function:\n$$\n   (1+x)^{\\alpha} = \\sum_{m=0}^\\infty \\binom{\\alpha}{m} x^m\n$$\nIt makes evaluations of sums using generating functions much easier if the sum were to run over all integers. So it is natural, in this context, to set $\\binom{\\alpha}{m} = 0$, $\\forall m \\in \\mathbb{Z}_{< 0}$. \nAnd this convention is indeed adopted in two books you link to, at the expense of breaking the symmetry $\\binom{\\alpha}{m} = \\binom{\\alpha}{\\alpha-m}$, as explicitly emphasized in \"Concrete Mathematics\".\nIn Mathematica, Binomial[z,w] is a defined over $\\mathbb{C} \\times \\mathbb{C}$, and the aforementioned symmetry holds almost everywhere, justifying automatic evaluation\nIn[62]:= Binomial[n, n - 3]\n\nOut[62]= 1/6 (-2 + n) (-1 + n) n\n\nBut the symbolic polynomial above does not give zero for $n \\in \\mathbb{Z}_{\\leqslant -1}$, so we have an inconsistency.\nIn order to fix all the sums for $c^r_n$ one may use Boole (also known as Iverson bracket). In fact it seems that this particular sum requires Boole even in version 7:\n\n", "front end - How to force neat linewrapping in Print?": "\nThe option ImageSize with the value Scaled should give better results, and it will adapt to the size of the notebook window. You will still need to define the value of Scaled to allow for likely widths of the label in the first column.\nPrint[\"test line 1...............: \", {1, 2, 3}, \"\\n\", \n  \"test line 2...............: \", \n  Pane[Table[\"testestestestestestestestest\", {10}], \n   ImageSize -> Scaled[0.5]], \"\\n\", \n  \"test line 3...............: \", {1, 2, 3}];\n\n\nI agree that Grid is a better option here. But if you stick with Print, for example because you want to keep this output as a side effect of evaluation, you might also want to consider wrapping that long table output in TableForm.\n", "plotting - Using ListPointPlot3D to simulate 2D plots moving in time": "\nThanks to all for the answers. After looking more into this, I think I found a method that works for me. I thought I describe it here. \nThe idea is to use ListPlot3D with DataRange->All. But to use this, I needed to modify my data structure a little to make each entry in the list as {x,time,u(x,t)}. Not a big problem for me to do that. The following diagram shows the data structure used\n\nHere is an animation of some made up function in time, showing the 3D view of the solution in time with the normal 2D view on the side. Below that I post the example code which generated this:\n\nCode: (just for illustration of the method)\nMake up the data:\nf1 = .05;\nf2 = .2;\nsimulationTime = 20;\nu = Table[\n       Table[{x,t,Exp[-.01 t] Cos[f1 t x] Sin[ f2 t x]},{x,-2 Pi,2 Pi,.2}], \n       {t, 0, simulationTime, .1}\n    ];\n\nDo the animation:\nGrid[{\n  {\n   Animate[ListPlot3D[u[[1 ;; i]],\n     AxesLabel -> {\"x\", \"time\", \"u(x,t)\"},\n     PlotLabel -> Row[{\"u(x,t) at time \", u[[i]][[1, 2]], \" sec\"}],\n     MaxPlotPoints -> 10,\n     PlotRange -> {{-2 Pi, 2 Pi}, {0, simulationTime}, {-1, 1}},\n     DataRange -> All,\n     PerformanceGoal -> \"Quality\",\n     Mesh -> Automatic\n     ], {i, 2, Length[u], 1}\n    ]\n   ,\n   Animate[ListPlot[u[[i, All, {1, 3}]],\n     AxesLabel -> {\"x\", Row[{\"u(x) at time \", u[[i]][[1, 2]], \" sec\"}]},\n     PlotRange -> {{-2 Pi, 2 Pi}, {-1, 1}},\n     Joined -> True,\n     Mesh -> All\n     ], {i, 2, Length[u], 1}\n    ]\n   }\n  }]\n\nNote:\nJust an implementation note. I have been testing the above method in my main demo, and so far, it is working well. But since I need to save in memory each frame to get this method to work (each time I plot, I plot all the frames from t0 to current time, so I need to keep them all in memory), what I did is the following:\n\nPre-allocate using Table the slots for as many frames I need.\nDo not generate a frame for each time step, as it will consume too much memory, and the demo will become too slow very quickly. So what I do is make one frame each $n$ time steps, where $n$ is something I am trying to decide a good value for, as it depends on the length of the simulation and the size of the grid and such. I try to make it show not less than 100 or so frames for the whole simulation time each time. This way, it runs fast, and the memory usage for this is kept low. \nIn MATLAB, I did this differently, since MATLAB has a command called holdon. \nI wish Mathematica had such a command; it would make life so much easier. This command works like this: One can make a plot to the graphic window, and then say holdon which means the next plot to the same window will not erase what is on the window but add to it whatever is being plotted. So, when I did this same simulation in MATLAB, I did not have to keep track myself of all the frames, but only the current one. This made the simulation much simpler, as me, the user did not need to manage and keep lots of frames in my own buffer, all the time and then re-plot them all each time.\n\nSo in summary, this is how the simulation works in Mathematica:\nallocate array for simulation frames\nLOOP\n    time = time + delt\n    generate solution \n    IF need to generate new plot  --- do this every N steps to save memory\n      add current frame to buffer    \n      plot frames 1..current    \n    END IF\nEND LOOP\n\nIn MATLAB, I would do\nLOOP\n    time = time + delt\n    generate solution    \n    Plot current frame\n    holdon\nEND LOOP\n\nYou can see it makes the simulation simpler as everything is pushed to the graphics buffer instead of user having to manage it.\nI hope future version of Mathematica will add such a feature to its graphics, as I like the way graphics look in Mathematica more. If there is a trick to do now in Mathematica, I'd love to know about it.\n\nUpdate:\nI've implemented the above method for showing the solution of few simple PDE's in a demo I am writing. I think it helps in the visualization of the solution, but the problem is that it takes a lot of memory as I have to save many frames, but still, it seems to work OK.\nHere is one example, an animation of the solution of the convection-diffusion 1D PDE (diffusion with drift). In the 2D plot, the red curve is the initial condition, and the blue is the current concentration.  Then the 3D view of the same solution.\n \nI think Mathematica is really nice for doing simulations with (It just needs faster rendering. I think that is the slowest part. Hard to get very high FPS from it, but may be I am still not doing something the right way somewhere.\n", "import - Importing videos in Mathematica": "\n64-bit Windows only\n\nNote for Mathematica 11.3: There is a potential conflict between MathMF and the built-in MediaTools package. See here for details and here for an example of how to use MediaTools in place of MathMF.\n\n\u00a0\n\nNote for Mathematica version 10: The Wolfram Library has been updated in version 10 and you will need to recompile the MathMF DLL. This is most easily accomplished by evaluating \"MathMF\"//FindLibrary//DeleteFile prior to loading the package.\n\nLink to package on GitHub\nI have written a package called MathMF which uses a LibraryLink DLL to do frame-by-frame video import and export with Windows Media Foundation. It should be able to read a reasonable variety of movie files, including AVI, WMV and MP4. Exporting is currently limited to WMV and MP4 formats (AVI encoding is not natively supported by Media Foundation)\nHere is the sort of code you can write with it. The code first opens a video file for reading, and creates a new video file for writing to. It then runs a loop in which each frame is sequentially read from the input stream, processed in Mathematica and then written to the output stream. So Mathematica is effectively being used as a video filter.\n{duration, framerate, width, height} =\n MFInitSourceReader[\"C:\\\\Users\\\\Simon\\\\Desktop\\\\test1.wmv\"];\n\nMFInitSinkWriter[\"C:\\\\Users\\\\Simon\\\\Desktop\\\\filtered.wmv\", \n width, height, \"FrameRate\" -> framerate]\n\nWhile[\n  (image = MFGrabFrame[\"RealImage\"]) =!= EndOfFile,\n  MFSendFrame @ GradientFilter[image, 2]\n  ] ~Monitor~ image\n\nMFFinaliseSink[]\n\nThe package can be downloaded from the GitHub link at the top of this post, it is too large to include in full here.\nThe package includes the library source code, and on first use will attempt to compile the library locally. I believe the compilation should work if you have Visual Studio 2010 or later installed, and probably won't work if you use a different compiler. There is a pre-built DLL available if the compilation fails (see the readme on GitHub for more details)\nI hope some people find this useful, it has been hovering in my mind as something to try to do for quite some time, hindered mainly by my total lack of experience with C++ and COM programming.\n", "How to find out the (current) free memory on the system?": "\nYou might be able to use JLink along with some undocumented behaviour of the Java class java.lang.management.ManagementFactory to get the information you seek:\nNeeds[\"JLink`\"]\nInstallJava[];\nLoadJavaClass[\"java.lang.management.ManagementFactory\"];\nJavaBlock[\n  {#, java`lang`management`ManagementFactory`getOperatingSystemMXBean[]@#[]} & /@\n  { getName\n  , getArch\n  , getVersion\n  , getCommittedVirtualMemorySize\n  , getFreePhysicalMemorySize\n  , getFreeSwapSpaceSize\n  , getTotalPhysicalMemorySize\n  , getTotalSwapSpaceSize\n  , getProcessCpuTime\n  , getAvailableProcessors\n  , getSystemLoadAverage\n  } // Grid\n]\n\nThis works on Windows 7 (Mathematica 8, 64-bit):\nOut[368]= getName                        Windows Vista\n          getArch                        amd64\n          getVersion                     6.1\n          getCommittedVirtualMemorySize  102449152\n          getFreePhysicalMemorySize      5997510656\n          getFreeSwapSpaceSize           14498115584\n          getTotalPhysicalMemorySize     8587284480\n          getTotalSwapSpaceSize          17172676608\n          getProcessCpuTime              6068438900\n          getAvailableProcessors         4\n          getSystemLoadAverage           -1.\n\nI don't have Mac or Linux boxes to hand at the moment to test whether it works there as well.\n", "front end - What are the most common (usual) ways to make palettes with non-trivial functionality?": "\nAll palette state (i.e., variables which affect the palette and should be remembered between sessions) should be vectored through the palette's TaggingRules option, and its initialization should be done in the palette's NotebookDynamicExpression option.  That, plus context isolation of any kernel functions you need to define should solve all of the points you raise, excepting the documentation issue.\nAn example palette which demonstrates these principles:\nCreatePalette[\n Column[{Button[\"Print opener state\", \n    MyPalette`Private`DoSomething[\n     \"The opener is \" <> \n      If[CurrentValue[EvaluationNotebook[], {TaggingRules, \"opener\"}],\n        \"open\", \"closed\"]]],\n   OpenerView[{\"Group of buttons\", Column[{Button[1], Button[2]}]}, \n    Dynamic[CurrentValue[\n      EvaluationNotebook[], {TaggingRules, \"opener\"}, False]]]}],\n NotebookDynamicExpression :> \n  Refresh[MyPalette`Private`DoSomething[MyPalette`Private`x_] := \n    Print[MyPalette`Private`x], None]]\n\n\nLet's hit the items raised in this code one by one...\n\nThe palette uses a kernel-defined function which is in NotebookDynamicExpression. The code is wrapped in Refresh[_,None] to ensure that it evaluates once only when the notebook is opened. The code is context isolated by hand. Note that Begin and End won't work here, although they would work inside of a package, or if you wrapped the code in ToExpression (e.g., Begin[\"foo`\"];ToExpression[\"code\"];End[]).\nA palette-wide state variable is stored in the palette's TaggingRules, which can be accessed by using CurrentValue[EvaluationNotebook[],{TaggingRules,\"opener\"}]. Because \"opener\" is a string, no symbols are introduced into any context.\nState variables will typically need to be initialized. I could do that in various standard ways, but I used the undocumented third argument to CurrentValue which sets it to False if it doesn't already have a value.\nOnce the palette is installed, the TaggingRules setting will persist between instances of the palette, even if you quit Mathematica. Mathematica automatically serializes an installed palette's TaggingRules settings when you close it by storing the value into the global option PalettesMenuSettings.\nIf you have multiple versions of the palette open, they'll each operate using independent state variables because the state variable is attached to the palette notebook. If multiple versions of the palette are installed under different names then the PalettesMenuSettings trick will store the TaggingRules separately.\n\n", "How do you efficiently return all of a List but one element?": "\nYou can use Most[list] to do this if you want to drop last element, Rest[list] to drop the first element, and Delete[list, n] to drop the $n^\\mathrm{th}$ element.\nI verified that none of these unpack packed arrays, so performance should be good.  Drop and Take don't unpack either, so the performance of those should be similar too, at least for packed arrays.\n", "How to find the position of elements in a list satisfying criteria": "\nPosition[{2, 4, 6, 8, 10}, _?(# > 7 &)] does the job. Apply Flatten[] if need be.\n\nAs noted by Dan in a comment alluding to Brett's answer, using the level-specification argument of Position[] might sometimes be needed, if the numbers are not Reals, Rationals or Integers.\n", "notebooks - How to avoid spaces between numbers when displaying TagBox(es)": "\nWhy not use ToBoxes (or MakeBoxes) to construct boxes, instead of doing it yourself?\nDisplayForm[\n ToBoxes[Row[List[0, 1, Superscript[2, 3], Superscript[1, 2], a]]]]\n\n\n", "graphics - Transparent textures don't show": "\nGo into the option inspector, and try the different settings for Graphics Options > RenderingOptions > \"Graphics3DRenderingEngine and see if that has any effect.\nEdit This option can be set on a per-graphic basis, say by using Style:\nAbsoluteTiming[\n   Rasterize[\n    Style[Graphics3D[{Opacity[0.1], \n       Sphere[{0, 0, 0}, #] & /@ Range[20]}, ImageSize -> 200], \n     RenderingOptions -> {\"Graphics3DRenderingEngine\" -> #}]]] & /@\n{\"BSPTree\", \"HardwareDepthBuffer\"}\n\n\n", "list manipulation - What is the most efficient way to add rows and columns to a matrix?": "\nArrayFlatten is much faster than combination of Join and Transpose:\nm = RandomVariate[NormalDistribution[], {1000, 1000}];\nv = RandomVariate[NormalDistribution[], 1000];\n\nCheck that ArrayFlatten gives the same output:\n(* In[54]:=*) ArrayFlatten[{{Transpose[{v}], m}}] == \n Transpose[Join[{v}, Transpose[m]]]\n\n(* Out[54]= True *)\n\n(* In[57]:= *) ArrayFlatten[{{Transpose[{v}], m}}] == \n MapThread[Prepend, {m, v}]\n\n(* Out[57]= True *)\n\nSee the timing:\n(* In[55]:= *) Do[\n  ArrayFlatten[{{Transpose[{v}], m}}], {10^3}] // AbsoluteTiming\n\n(* Out[55]= {4.330433, Null} *)\n\n(* In[58]:= *) Do[MapThread[Prepend, {m, v}], {10^3}] // AbsoluteTiming\n\n(* Out[58]= {11.766177, Null} *)\n\n(* In[56]:= *) Do[\n  Transpose[Join[{v}, Transpose[m]]], {10^3}] // AbsoluteTiming\n\n(* Out[56]= {16.700670, Null} *)\n\n", "performance tuning - Is there an NDSolve`ProcessEquations analog for NIntegrate?": "\nNIntegrate performs a certain symbolic processing of the integrand to detect discontinuities, singularities, to determine the method to choose and so on. \nIf you know the integrand pretty well, the way to reduce the overhead is to set the method explicitly, set its SymbolicProcessing suboption to 0 (to allow to time spent on the preprocessing), and to add points of discontinuities to the path explicitly.\nThis can make a significant difference in timing:\nIn[66]:= Do[\n  NIntegrate[Piecewise[{{x^2, x <= 1}}, 1/1 + x], {x, 0, 1, 2}, \n   Method -> {\"GaussKronrodRule\", \n     \"SymbolicProcessing\" -> 0}], {10^3}] // AbsoluteTiming\n\nOut[66]= {1.542154, Null}\n\nIn[67]:= Do[\n  NIntegrate[\n   Piecewise[{{x^2, x <= 1}}, 1/1 + x], {x, 0, \n    2}], {10^3}] // AbsoluteTiming\n\nOut[67]= {15.063506, Null}\n\n", "evaluation - How can I test properties of a symbol from the string name without the symbol completely evaluating": "\nI usually use \nToExpression[\"symbol\",  InputForm, ValueQ]\n\nToExpression will wrap the result in its 3rd argument before evaluating it.\n\nGenerally, all functions that extract parts (Extract, Level, etc.) have such an argument.  This is useful when extracting parts of held expressions.  ToExpression acts on strings or boxes, but both the problem with evaluation control and the solution is the same.  I thought this was worth mentioning here.\n", "graphics - Antialiasing in 3D - Mathmatica Stack Exchang": "\nThis needs specific support from your graphics card.  My own graphics card is very old, and does not support it, so the slider does nothing on my machine.\n\nBut the good news is that there are workarounds, and I even made an antialiasing palette (code at the end of the post -- evaluate it, pop out the palette, and if you prefer, save it using Palettes -> Install Palette...).\nThis is the core antialiasing function I use:\nantialias[g_, n_: 3] := \n  ImageResize[Rasterize[g, \"Image\", ImageResolution -> n 72], Scaled[1/n]]\n\nIt simply renders a large image, and it downscales it.  The results can be better than with a better graphics card's built-in antialiasing, so it's worth a look even if you have a good graphics card.\nProblems with this method:\n\nFonts can be blurrier than what you'd like\nWith a high scaling factor, it may expose bugs in your graphics driver, and show some unusual results (I had problems with opacity in more complex graphics)\nTick marks don't scale properly (I think this is a bug), so they are barely visible on the antialiased version.\n\n\nThis is the palette code.  Usage: select a 3D graphic and press the button.  It'll insert an antialiased image below.\nBegin[\"AA`\"];\n\nPaletteNotebook[DynamicModule[\n  {n = 3},\n  Column[{\n    SetterBar[\n     Dynamic[n], {2 -> \"2\\[Times]\", 3 -> \"3\\[Times]\", \n      4 -> \"4\\[Times]\", 6 -> \"6\\[Times]\"}, Appearance -> \"Palette\"],\n    Tooltip[\n     Button[\"Antialias\", antialiasSelection[SelectedNotebook[], n], \n      Appearance -> \"Palette\"], \n     \"Antialias selected graphics using the chosen scaling factor.\\nA single 2D or 3D graphics box must be selected.\"]\n    }],\n  Initialization :> (\n    antialias[g_, n_Integer: 3] := \n     ImageResize[Rasterize[g, \"Image\", ImageResolution -> n 72], \n      Scaled[1/n]];\n\n    antialiasSelection[doc_, n_] := Module[{selection, result},\n      selection = NotebookRead[doc];\n      If[MatchQ[selection, _GraphicsBox | _Graphics3DBox],\n       result = \n        ToBoxes@Image[antialias[ToExpression[selection], n], \n          Magnification -> 1];\n       SelectionMove[doc, After, Cell];\n       NotebookWrite[doc, result],\n\n       Beep[]\n       ]\n      ]\n    )\n  ],\n TooltipBoxOptions -> {TooltipDelay -> Automatic}, \n WindowTitle -> \"Antialiasing\"\n ]\n\nEnd[];\n\n\nDemonstration:\n \n", "Image levels: how to alter 'exposure' of dark and light areas?": "\nTwo things. \nFirst, a minor point: if you rewrite your compiled function as\ntweakC = Compile[{{pixel, _Real, 1}},\n  Module[{m},\n   m = Mean[pixel];\n   Which[\n    m <= 0.3, pixel*1.5,\n    m >= 0.85, pixel*0.8,\n    True, pixel]\n   ]\n  ]\n\nthen the ImageApply bit is 20 times faster (due to not having to use external calls). It's also a bit cleaner.\nIf you have v8 and a C compiler, you can speed it up by another factor of 2 by using CompilationTarget->\"C\".\nSecond, and more important, is that your tone curve looks like this:\n\nthe jumps at .35 and .8 lead to harsh transitions. So I thought I'd use a smoother curve which you can interactively manipulate (horrible code, but seems to do the job):\nimage1 = Image[\n   ReliefPlot[\n    Table[i - 3 Sin[i^2 + j^2], {i, -4, 4, .03}, {j, -4, 4, .03}]]];\nDynamicModule[\n {pts = {{0, 0}, {.25, .25}, {.5, .5}, {.75, .75}, {1, 1}}}, Dynamic[];\n LocatorPane[\n  Dynamic[pts],\n  Dynamic[\n   curve = InterpolatingPolynomial[pts, x];\n   image2 = ImageAdjust[\n     ImageApply[Function[{x}, Evaluate@curve], image1, \n      Interleaving -> False]];\n   Dynamic[\n    Plot[curve, {x, 0, 3}, PlotRange -> {{0, 1}, {0, 1}}]]\n   ],\n   LocatorAutoCreate -> True\n  ]\n ]\nGraphicsGrid[\n {{image1, Dynamic[image2]}}\n ]\n\nit looks like this:\n\nThe idea is, you define a curve by moving the locators, and the image on the right bottom reflects that transformation. The whole thing is interactive. You may add more locators by alt-clicking on windows and linux, cmd-clicking on OS X.\nNote that I have little understanding of Dynamic etc, so this is probably badly written in terms of dynamic interactivity.\n", "graphics - Why is the Locator snapping back to the original coordinates? How can I prevent this?": "\nIt seems using an EventHandler to simulate a locator will be smooth on my computer ( press Shift instead of press mouse button to active the locator ):\np = {3, 3};\nEventHandler[\n EventHandler[\n  Graphics[Circle[{5, 5}, 5], Epilog -> Locator[Dynamic[p]], \n   Axes -> True, GridLines -> {{3}, {3}}],\n  \"MouseMoved\" :> Null,\n  PassEventsUp :> CurrentValue[\"ShiftKey\"]],\n \"MouseMoved\" :> (p = MousePosition[\"Graphics\"])\n ]\nDynamic[p]\n\nUpdate:\nI think it's the AlignmentGuidesEnabled feature which causes the snapping.\nHere are another two examples which display the problem:\n\nPutting the Locator in the \"main part\" of Graphics instead of in Epilog:\np = {3, 3};\nGraphics[{Circle[{5, 5}, 5], Locator[Dynamic[p]]}, Axes -> True, \n GridLines -> {{3}, {3}}]\n\nOn my computer, the snapping occurs near the borders of the Graphics but not near {3, 3} anymore.\nDifferent Locator actions in one Graphics:\nDynamicModule[{v1 = {2, 0}, v2 = {-1, 1}},\n Dynamic@Graphics[{\n    Line[{{0, 0}, v1}],\n    Locator[Dynamic[v1]],\n    Locator[Dynamic[v2]]\n    }, PlotRange -> 3, Frame -> True]]\n\nOn my computer (Windows 7 x64, Mathematica 8.0.4), the Locator v1 which linked to the Line moves smooth, but the Locator v2 remains snapping.\n\nSo it looks like the behavior of AlignmentGuidesEnabled. Use Ctrl+D open the \"Drawing Tools\" palette, there is a button at the bottom-left, toggle the AlignmentGuidesEnabled option off, the snapping will gone.\n", "front end - How to work with characters from CJK Unified Ideographs Extension B correctly?": "\nReposting John Fultz\u2019s comment above as a \u201ccommunity wiki\u201d answer for everyone to improve:\n\nMathematica simply has no support for non-plane-0 characters. That it\n  appears to temporarily work should not fool you into thinking that M--\n  knows anything about such values. Those who saw the R&D keynote at the\n  2011 Tech Conference may remember my relating the story of the pain we\n  have experienced from the fact that we were extremely early adopters\n  of Unicode, well before it was baked into OSes and the concept of\n  Unicode planes had been fully developed. It affects every part of the\n  system, and will be difficult and expensive to fix when we finally do\n  fix it.\n\n", "performance tuning - Adaptive sampling for slow to compute functions in 2D": "\nUpdate: I described an alternative approach based on built in plotting functions in this answer.  That approach is not very practical here though because I need to be able to handle points at arbitrary positions while built in functions work with a rectangle-based mesh.  I am still looking for improvements.\n\nI came up with this very naive approach and implementation (I know that the implementation is not optimal at all):\nFirst let's define a test function (same one as in the question):\nfun[{x_, y_}] := 1/(1 + Exp[10 (Norm[{x, y}] - 3)])\n\nThese functions will subdivide lines in the Delaunay triangulation of the points if 1. the points are further apart than a threshold (i.e. the resolution is controlled) and 2. the function values in the two points also differ by more than another threshold.\n<< ComputationalGeometry`\n\nmakeLines[tri_] := Union[Sort /@ Flatten[Thread /@ tri, 1]]\n\nsubdivision[points_, values_, valueThreshold_, distanceThreshold_] :=\n Module[\n  {tri, lines, linesToDivide},\n  tri = DelaunayTriangulation[points];\n  lines = makeLines[tri];\n  linesToDivide = \n   Pick[lines, (Abs[values[[#1]] - values[[#2]]] > valueThreshold && \n        Norm[points[[#1]] - points[[#2]]] > distanceThreshold ) & @@@ lines];\n  Mean /@ (linesToDivide /. n_Integer :> points[[n]])\n  ]\n\nLet's define an initial point grid to compute the function in:\npoints = Tuples[Range[0, 5, 1], 2];\n\nWe can iterate this function to add more and more points and recursively subdivide the grid (evaluate the following commands together repreatedly):\nvalues = fun /@ N[points];\nnewpoints = subdivision[points, values, 0.1, 0.1];\n\nListDensityPlot[Flatten /@ Thread[{points, values}], \n InterpolationOrder -> 0, Mesh -> All, ColorFunction -> \"MintColors\", \n Epilog -> {PointSize[Large], Point[points], Red, Point[newpoints]}]\n\npoints = Join[points, newpoints];\n\n\n\n\n\nThe result after several iterations:\nvalues = fun /@ N[points];\nListDensityPlot[Flatten /@ Thread[{points, values}], \n InterpolationOrder -> 0, Mesh -> All, ColorFunction -> \"MintColors\"]\n\n\n\nOpen question:  My aim is to minimize the number of points I need to compute while getting a precise approximation.  This is probably not the best subdivision method for it.  What are some easy-to-implement better methods?\nI think ideally the decision for refining the grid should be made based on some sort of curvature.  Take for example the following function:\nContourPlot[Erf[1/(1 + 20 x^2) - y], {x, -3, 3}, {y, -3, 3}]\n\n\nUsing a valueThreshold of 0.3 and distanceThreshold of 0.1, and a starting grid with a spacing of 0.5 produces this:\n\nLet's turn on interpolation (because I can't turn interpolation off in DensityPlot) and compare it with a DensityPlot made using similar options (PlotPoints -> 12, MaxRecursion -> 15):\n\nThe curvature-based DensityPlot (right) is clearly much better.  Furthermore, my method won't properly detect \"fjord-like\" structures (similar to the one in this example).  It tend to \"jump\" over them, this is why some artefacts are visible in the middle of the plot.\n\nThanks to @ruebenko for the hints and ideas he sent me!\n", "graphics - How can I extract the maximum value from a Histogram?": "\nAs mentioned by others, use HistogramList.  You can even use the resulting information to generate the plot without recomputing the information:\n{bins, heights} = HistogramList[returns, 300, \"PDF\"];\nmaxFreq = Max[heights];\nHistogram[returns, {bins}, heights &, \n Epilog -> {{Thick, Darker[Green], \n    Line[{{\u03bc, 0}, {\u03bc, maxFreq + 2}}]}}]\n\n\n", "How to export and import Graphs with additional data?": "\nI think it must be an oversight in the graph export code (it also happens when exporting to graph formats other than Graphlet). If you use explicit labels in Mathematica, it gets exported properly, just the implicit VertexLabels -> \"Name\" does not.\nNote that since the export formats do not have an equivalent of VertexLabels -> \"Name\", you'd expect the export/import cycle to yield explicit VertexLabels.\nSo, I guess you should submit a bug report to Wolfram Research.\nIn the meantime, the work around of using explicit labels should not be too onerous; e.g.,\nGraph[{1 -> 2, 2 -> 3, 3 -> 1}, VertexLabels -> Table[i -> i, {i, 3}],\n  VertexStyle -> Purple, VertexShapeFunction -> \"Diamond\"]\n\n\nThis can be automated in Export by using something like\nExportGraph[file_String, g_Graph, opts___] :=\n If[Flatten[{PropertyValue[g, VertexLabels]}] === {\"Name\"},\n  Export[file, SetProperty[g,\n         VertexLabels -> Table[i -> i, {i, VertexList[g]}]], opts],\n  Export[file, g, opts]]\n\n", "performance tuning - How can I ensure that I am constructing patterns in the most efficient way possible?": "\nSome pitfalls in pattern-construction\nYou should ask several questions:\n\nWill your pattern involve frequent invocation of the evaluator (this happens if it contains Condition and / or PatternTest, and is tested many times). If yes, this will slow down the pattern-matcher.\n\nHere is an example taken from this answer\nrandomString[]:=FromCharacterCode@RandomInteger[{97,122},5];\nrstest = Table[randomString[],{1000000}];\n\nIn[102]:= MatchQ[rstest,{__String}]//Timing\nOut[102]= {0.047,True}\n\nIn[103]:= MatchQ[rstest,{__?StringQ}]//Timing\nOut[103]= {0.234,True} \n\n\nWill your pattern make the pattern-matcher perform many a-priori doomed matching attempts (and thus, underutilize the runs of the pattern-matcher)? If yes, this will slow it down a lot. Patterns with BlankSequence or BlankNullSequence are notorious for that, particularly in combination with ReplaceRepeated.\n\nFor example, this list sorting is very inefficient:\nlist//.{left___,x_,y_,right___}/;x>y:>{left,y,x,right}\n\nHowever, there are cases where such patterns are very efficient as well, such as in this answer.\n\nWill your pattern lead to excessive copying of parts? This happens also for patterns like x___, because the rule like {x_,y___}:>{y} will copy the entire sequence (array) y during the match. This is because lists are implemented as arrays in Mathematica.\n\nAs in example here, consider the following implementation of mergeSort, taken from my answer in this thread:\nClear[merge]; \nmerge[x_List, y_List] := \n Block[{merge}, \n   Flatten[merge[x, y] //. {\n    merge[{a_, b___}, {c_, d___}] :> \n      If[a < c, \n         {a, merge[{b}, {c, d}]}, {c, merge[{a, b}, {d}]}\n      ], \n      merge[{}, {a__}] :> {a}, \n      merge[{a__}, {}] :> {a}}]]  \n\nThis one is very slow. The detailed analysis is in the same answer I linked to, but here is the version based exclusively on ReplaceRepeated, but made efficient because it uses linked lists:\nClear[toLinkedList]; \ntoLinkedList[x_List] := Fold[{#2, #1} &, {}, Reverse[x]]; \nModule[{h, lrev}, \n  mergeLinked[x_h, y_h] := \n    Last[{x, y, h[]} //. {\n        {fst : h[hA_, tA_h], sec : h[hB_, tB_h], e_h} :> \n              If[hA > hB, {tA, sec, h[hA, e]}, {fst, tB, h[hB, e]}], \n        {fst : h[hA_, tA_h], h[], e_h} :> {tA, h[], h[hA, e]}, \n        {h[], sec : h[hB_, tB_h], e_h} :> {h[], tB, h[hB, e]}}]; \n\n  lrev[set_] := Last[h[set, h[]] //. h[h[hd_, tl_h], acc_h] :> h[tl, h[hd, acc]]]; \n\n  sort[lst_List] := \n     Flatten[Map[h[#, h[]] &, lst] //. \n         x_List :>       \n           Flatten[{toLinkedList@x, {}} //.\n            {{hd1_, {hd2_, tail_List}}, accum_List} :> \n               {tail, {accum, lrev@mergeLinked[hd1, hd2]}}], \n         Infinity, h]]; \n\nJust only due to the use of linked lists and resulting from them memory/run-time savings, this implementation recovers the correct n log n asymptotic complexity of the merge sort angorithm, even though ReplaceRepeated is used all over. The benchmarks can be found in the quoted post.\n\nDoes your pattern lead to accidental unpacking of packed arrays, even when that is not necessary? This can slow things down significantly. In this answer, I discussed some possible work-arounds to avoid such situtations.\n\nSummary and recommendations:\n\n\nBe careful with __ and ___\nBe careful with ReplaceRepeated\nTry to construct patterns such as to minimize failed pattern-matching attempts.\nAvoid Condition and PatternTest whenever possible, and use syntactic patterns\nWatch out for unpacking during the pattern-matcher\nIn place of __ and ___, try using linked lists when you can\n\n", "Asynchronous evaluation: Is it possible?": "\nBy using the ideas of @Szabolcs, I've managed to write a convenient function which almost does what you want (edit: there is a better version of this function in the third edit, that does exactly what you want):\nClearAll[AsynchronousEvaluate];\nSetAttributes[AsynchronousEvaluate, HoldAll];\nAsynchronousEvaluate[exp_] := DynamicModule[{eval, display},\n  display = EventHandler[\n    eval= ParallelSubmit[exp],\n    {\"MouseClicked\" :> (display = WaitAll[eval])}];\n  Parallel`Developer`QueueRun[];\n  Dynamic[display]]\n\nWhat this function does is put the expression you want to evaluate in the queue, and makes it run in the background. In the mean while it displays the EvaluationObject that the function ParallelSubmit outputs, and you are free to perform other operations in the same Mathematica notebook.\nOnce the evaluation of the expression is complete, all you have to do is click the EvaluationObject, and it will be replaced by the result.  \nOf course it would be better if the EvaluationObject would be automatically replaced by the result when the evaluation finishes, but I don't know how to do that. If anyone thinks of way - feel free to edit my answer and add it (edit: I already found a way, see below).\nEdit: By using $Pre = AsynchronousEvaluate; you can get Mathematica to automatically apply the function AsynchronousEvaluate to every expression you evaluate, saving you some time and making the notebook look neater.\nEdit #2: Be careful when assigning a function to $Pre though, the only way to change it back is to restart Mathematica, since trying to evaluate $Pre=. will result in sending the command to one of the parallel kernels :)\nEdit #3: OK here it is, the same function, only now it automatically replaces the EvaluationObject by the result when the evaluation finishes. In order for it to work you need to have a scheduled task running in the background:\nqRunTask = CreateScheduledTask[Parallel`Developer`QueueRun[]];\nStartScheduledTask[qRunTask];\n\nKeeping the default interval of one second for the scheduled task seems reasonable. Now the AsynchronousEvaluate function:\nClearAll[AsynchronousEvaluate];\nSetAttributes[AsynchronousEvaluate, HoldAll];\nAsynchronousEvaluate[exp_] := DynamicModule[{eval,display},\ndisplay = eval = ParallelSubmit[exp];\nDynamic[\n  If[MatchQ[eval[[4]],\n    Parallel`Developer`finished[_]], display = eval[[4]][[1]]]; display]]\n\nThat's it!\nIf you're not using this function for a while, you can stop the scheduled task (though it doesn't cause any slow down in my experience):\nStopScheduledTask[qRunTask];\n\nEdit #4: I improved the function to fix a problem where the results did not persist after restarting Mathematica. Now they do.\n", "How to combine images with the same dimensions in a grid?": "\nWhat you're looking for is ImageAssemble:\nc1 = Import[\"http://i.stack.imgur.com/2SRcD.png\"];\nc2 = Import[\"http://i.stack.imgur.com/zL8id.png\"];\nImageAssemble[{c1, c2}]\n\n\nIt can also assemble vertically and horizontally:\nImageAssemble[{{c1, c1}, {c2, c2}}]\n\n\n", "image processing - Tuning ParallelMap when IO and computationally bound": "\nIn this case, you would want to favor Method->FinestGrained, not Method->CoarsestGrained.\nFinestGrained is more useful when the workload has items that may take a very long time to process, or which may have wildly varying computation times.\nCoarsestGrained is useful when the workload consists of many fast, easy to compute items. You don't want to have heavy synchronization and dispatch when you're adding 1 to 10^10 numbers, do you? \nI'll add some real examples shortly. But in general:\n\nFinestGrained: Computation bound or varying completion time\nCoarsestGrained: Fast computations. Really fast ones. Communication is expensive so you want to limit it.\n\nYou can really view it the two options as tradeoffs between TComm (cost of communication) vs TComp (cost of computation. In other words:\nIf[TComm > TComp,\n    Method->\"CoarsestGrained\",\n    Method->\"FinestGraned\"]\n\n\nIf you want some more control over the grain, you can utilize Method->ItemsPerEvaluation->n. In this case, we hand out n items to each kernel when they come for work. You can use this to further tweak how fine Mathematica grains your calculations.\nAs a note, the default option of Method->Automatic (which is implicit any time you use Parallel*) performs load balancing we may be expensive to perform if your workload is better suited to fine or coarse grained.\nRemember though -- Always measure!\n", "front end - What is the most effective way to setup a Notebook with transparent background but solid contents?": "\nOn Mac this works (but apparently only with WindowFrame->\"PopupMenu\"):\nSetOptions[InputNotebook[], Background -> Opacity[.75, Red], \n WindowFrame -> \"PopupMenu\"]\n\nThis is different than WindowOpacity.\n", "evaluation - How to simplify expression and use HoldForm at the same time?": "\nWhy don't you use HoldForm only on the part that actually needs to be held? For example:\nf[c_] := Module[{}, \n  c HoldForm[D[\"u\"[\"x\", \"t\"], {\"x\", 2}]] == \"f\"[\"x\", \"t\"]]\n\n\n", "notebooks - Setting up TextStyle with initialization cells in Mathematica 6+": "\nJust use SetOptions[Graphics, BaseStyle -> {...}].  For example\nSetOptions[Graphics, BaseStyle -> {Large, Red, FontFamily -> \"Times\", Italic}];\nGraphics[{Circle[], Text[\"test\"]}]\n\n\nNote that the Text inherits its BaseStyle from the surrounding Graphics.\nThe Text function also takes a BaseStyle option, but for some reason it doesn't seem to do anything (in Mma v8.0.4) - this might be a bug. For example:\nSetOptions[Text, BaseStyle -> {Large, \"Color\" -> Green}]\n{Text[\"test\"], Text[\"test\"]//Graphics}\n\n\nHowever explicit BaseStyle options passed to Text do work:\nGraphics[{Circle[], Text[\"test\", BaseStyle -> {Large, \"Color\" -> Green}]}]\n\n\n", "output formatting - Easiest Way to Use ShowGroupOpener in Mathematica": "\nUnless you want group openers for all groups -- which you probably don't, since that would put one at the very top level for the entire notebook -- then you can edit the notebook's style sheet, select the kind of cell (Section, Subsection, e.g.) for which you want the group opener, and then use the Option Inspector on that cell in the style sheet to include ShowGroupOpener.\nYou could do this either for a particular notebook by using the menu command Format > Edit StyleSheet or you could make a copy of a standard style sheet, modify that, and then select it as the style sheet for whatever notebooks you choose. (I'd advise against directly modifying any of the Wolfram-supplied style sheets.)\nI can give a more detailed explanation if you like. \n", "Implementing local complements of graphs": "\nFor your two examples\ng1 = {1 <-> 2, 2 <-> 3, 3 <-> 1}; g2 = {1 <-> 2, 2 <->3, 3 <-> 4, 4 <-> 1};\n\nyour function LocalComplement[_,_] gives the results:\nEdgeList[LocalComplement[Graph[g1], 1]] (*  gives {1 <-> 2, 3 <-> 1} *)\n\nand\nEdgeList[LocalComplement[Graph[g2], 1]] (* gives {1 <-> 2, 2 <-> 3, 2 <-> 4, \n     3 <-> 4, 4 <-> 1}\n\nwhich are both correct.\nFor pictures, using\n gplt:={Graph[#, VertexShapeFunction -> \"Name\"], \n   Graph[EdgeList[LocalComplement[Graph[#], 1]],VertexShapeFunction -> \"Name\"]} &\n\nfor the two examples,  I get\n gplt@g1  (* gives *)\n\n\nand \ngplt@g2  (* gives *)\n\n\nEDIT: Graph is introduced with version 8.0, and specific details of \"over 500\" fixes and improvements from V8.0 to V8.0.4 has not been released. Since your function works fine in V8.0.4 but gives incorrect results in V8.0, it is likely that you are seeing the effect of a bug that has been fixed in 8.0.4.  \n", "front end - Is it possible to cause a notebook to be hidden when pressing the close button?": "\nNot a perfect solution, but it works for some extent. It definitely needs some further foolproofing though.\nnb = CreateDocument[{}, WindowTitle -> \"Log\", \n   WindowFrameElements -> {}, NotebookEventActions -> {\n     \"WindowClose\" :> DialogReturn[],\n     \"EscapeKeyDown\" :> (\n       SetOptions[EvaluationNotebook[], Visible -> False];\n       )}];\n\nButton[\"Show\", SetOptions[nb, Visible -> True]]\n\nI used the hack Heike provided to remove the closebox from the window frame, since no matter how hard I tried to integrate the hiding functionality under \"WindowClose\" instead of \"ExcapeKeyDown\" without actually closing the window, it was always closed. Now the window is kept hidden if Esc is hit, and it is Alt+F4 that really terminates the window. If hidden, the provided \"Show\" button can be used to unhide the notebook.\n", "front end - Move the cursor in a notebook using the keyboard": "\nThere are some known bugs where the caret can get, as you say, \"trapped\" when using the up/down arrow keys.  I.e., further presses of the up/down key at certain points in typesetting cells can just do nothing.  However, it has always been my experience that left/right arrow will continue to work, and that usually one or two presses will get you to a point that the up/down arrow keys begin working again.\nAlso, important to note, that you can traverse the notebook more quickly with the arrow keys by popping the selection out to the cell bracket.  You can, of course, select the cell bracket using the mouse, but you can also select it from the keyboard by repeatedly pressing Ctrl+period (or Cmd+period on Mac) to move the structured selection outwards until it hits the cell bracket.  At that point, using the up/down arrow keys will never get trapped, and it will also be very efficient if you're looking to skip through content cell by cell.\n", "programming - Updating Wagon's FindAllCrossings2D[] function": "\nHere is my latest code for this function, from Chapter 12 of the third edition of \"Mathematica in Action\". It is pretty short, but I will let you work out if it is faster or more robust than yours. Note the PlotPoints option for difficult cases.\nFindRoots2D::usage = \n  \"FindRoots2D[funcs,{x,a,b},{y,c,d}] finds all nontangential solutions to\n   {f=0, g=0} in the given rectangle.\"; \n\nOptions[FindRoots2D] = {PlotPoints -> Automatic, MaxRecursion -> Automatic}; \n\nFindRoots2D[funcs_, {x_, a_, b_}, {y_, c_, d_}, opts___] := Module[\n  {fZero, seeds, signs, fy}, \n  fy = Compile[{x, y}, Evaluate[funcs[[2]]]]; \n\n  fZero = Cases[Normal[\n     ContourPlot[\n        funcs[[1]] == 0, \n        {x, a-(b-a)/97, b+(b-a)/103}, {y, c-(d-c)/98, d+(d-c)/102}, \n        Evaluate[FilterRules[{opts}, Options[ContourPlot]]]]], \n     Line[z_] :> z, Infinity]; \n\n  seeds = Flatten[(\n     (signs = Sign[Apply[fy, #1, {1}]]; \n      #1[[1 + Flatten[Position[Rest[signs*RotateRight[signs]], -1]]]]) &\n     ) /@ fZero, 1];\n  If[seeds == {}, {}, \n     Select[\n        Union[({x, y} /.\n           FindRoot[{funcs[[1]], funcs[[2]]}, {x, #1[[1]]}, {y, #1[[2]]}, \n              Evaluate[FilterRules[{opts}, Options[FindRoot]]]] & ) /@ seeds, \n           SameTest -> (Norm[#1 - #2] < 10^(-6) & )], \n        a <= #1[[1]] <= b && c <= #1[[2]] <= d & ]]]\n\n", "list manipulation - Efficient way to combine SparseArray objects?": "\nArrayFlatten[{{sa11, sa12}, {sa21, sa22}}] seems to be what you need. It automatically merges everything into one big SparseArray[].\n", "algorithm - How to get actual triangles from DelaunayTriangulation[]?": "\nIt might be easier to use TriangularSurfacePlot3D to find the Delaunay triangulation of the points. For example, \nNeeds[\"ComputationalGeometry`\"];\ntriangles[points_] := Module[{pl},\n  pl = TriangularSurfacePlot[ArrayPad[points, {{0, 0}, {0, 1}}]];\n  Cases[pl, Polygon[a_] :> Flatten[(Position[points, #[[{1, 2}]]] & /@ a)], \n    Infinity]]\n\nGraphics[GraphicsComplex[points, {EdgeForm[Black], FaceForm[],    \n  Polygon[triangles[points]]}]]\n\nproduces this:\n\n\nIf we use the approach in the original question, each valid triangle should appear exactly trice in the list, so a way to extract the triangles from the result of DelaunayTriangulation would be\nNeeds[\"ComputationalGeometry`\"];\ntriangles2[points_] := Module[{tr, triples},\n  tr = DelaunayTriangulation[points];\n  triples = Flatten[Function[{v, list},\n      Switch[Length[list],\n        (* account for nodes with connectivity 2 or less *)\n        1, {},\n        2, {Flatten[{v, list}]}, \n        _, {v, ##} & @@@ Partition[list, 2, 1, {1, 1}]\n      ]\n    ] @@@ tr, 1];\n  Cases[GatherBy[triples, Sort], a_ /; Length[a] == 3 :> a[[1]]]]\n\nEdit \nI've moved Needs[\"ComputationalGeometry`\"] outside of the function definition of triangles. As Szabolcs correctly remarked in his comments, putting Needs[\"ComputationalGeometry`\"] inside the definition will cause shadowing problems because of the creation of the symbol Global`DelaunayTriangulation\nEdit 2\nApparently ListDensityPlot uses a Delaunay triangulation as well, and is much faster than TriangularSurfacePlot, so the first part of this answer could be made much more efficient by rewriting it according to\ntriangles1[points_] := Module[{pl},\n  pl = ListDensityPlot[ArrayPad[points, {{0, 0}, {0, 1}}]];\n  Cases[pl, Polygon[a_] :> a, Infinity][[1]]]\n\nNote that since ListDensityPlot returns a GraphicsComplex and it keeps the order of the points the same, the index lists for the polygons can extracted directly from the plot without having to lookup the indices of the vertices in points.\n", "evaluation - Reassign values to symbols": "\nThis seems to work:\na = 1; b = 2; c = 3; d = 4;\nScan[Function[p, p = 5, HoldAll], Hold[a, b, c, d]]\n\nNow, try evaluating {a, b, c, d}.\nHere's the version with slots:\nScan[Function[Null, # = 5, HoldAll], Hold[a, b, c, d]]\n\n", "networking - How do you use ssh-keys instead of a password to run a remote-kernel over ssh?": "\nMathematica by default uses its own ssh implementation. You can see it in the dialog of the remote kernel configuration dialog in the advanced options: `java` -jar `mathssh`. As far as I know, you can safely replace that with the local ssh command (most likely /usr/bin/ssh). You have to select the \"Advanced Options\" radiobutton to do that (if you first add all the standard options, the rest of the command is already filled in correctly).\nEdit: By default, Mathematica uses the launch command\n`java` -jar \"`mathssh`\" user@hostname math -mathlink \n       -LinkMode Connect -LinkProtocol TCPIP -LinkName \"`linkname`\" \n       -LinkHost `ipaddress`\n\nto invoke ssh, where user and hostname are filled in via text boxes above. To use the local ssh command, you need to change the above command to\nssh user@hostname \"math -mathlink -LinkMode Connect -LinkProtocol TCPIP \n                        -LinkName `linkname` -LinkHost `ipaddress`\"\n\nThis appears to have one flaw, killing the remote kernel via the front-end no longer kills the processes on the remote server. So, that will have to be done by hand.\n", "What are recommended guidelines for developing packages?": "\nPart of what you are asking is of course a matter of taste and habits, but here are my 2 cents:\n1) if you want Mathematica to find your package files with a Needs or Get their context names must agree with the hierarchy of directories and filenames. I don't see any good reasons to diverge from that standard convention. For complex packages with many files you will also typically have a Kernel-subdirectory with an init.m, but I think these things are relatively well documented.\n2) My personal opinion is that using symbols for option names is asking for exactly these kind of problems. Obviously at least some of the WRI personnel thinks the same, since in later versions there are more and more options that accept strings as names and the new way to work with options also full supports this. If you are worried about cluttering your code with too many pairs of \"\", note that this will work alright:\nOptions[f] = {\"Verbose\" -> False}\n\nf[OptionsPattern[]] := (If[OptionValue[\"Verbose\"], \n   Print[\"I'm so verbose!\"]]; RandomReal[])\n\nf[Verbose -> True]\n\nor even:\nf[someothercontext`Verbose -> True]\n\nWhat you loose is the possibility to have a usage message bound to the option name, but as you have noticed if there are more than one function using the same option name, the usage message is of limited use anyway and the details must be explained in the documentation of the function, not the option. WRI has the same problem, obviously: At least I don't think that this usage is of very much help:\n?Method\n\nMethod is an option for various algorithm-intensive functions that specifies what internal methods they should use.\n3) Introducing sub-contexts is useful when things get more complex and parts of the whole can be split up in more or less independent parts. Of course giving these parts names that make it easy to recognize what they provide is a good idea, but I think that's so obvious that I doubt I fully understand that part of your question. If you want these parts to be loadable without the other parts, you must split them in different files, otherwise it's up to you from the technical viewpoint. From the code organization point of view I would think that if it makes sense to split your packages in separate contexts, it usually is also a good idea to split them into separate files. That becomes even more important if several people work on the various parts, but I feel there is not much Mathematica code written that way (except within WRI). Of course it's not necessary to include a Common.m, but as you have mentioned it's a good approach to collect all symbols that the various parts share into one common context/file, and Common.m (myPackage`Common`) is a common convention that is also used by WRI, so I'd stick with it. On the other hand I would consider it as a good design of your package when you don't need a Common.m, since then you obviously managed to really split your package in independent parts.\n", "How to xport larg graphics? - Mathmatica Stack Exchang": "\nFirst, some clarifications:\n\npure image size: pixels \u00d7 pixels\nMathematica ImageSize: the distance x distance of the image, defined as a multiple of 1/72'', which is approximately 0.353 mm (1/72'' is called a printer's point)\nprinting size: distance \u00d7 distance on the printing media\nprinter resolution (dpi): depends on printer characteristics; it's the number of small drops it can place in a linear inch; nowadays, above 1000 dpi; generally, due to the mechanical characteristics of the printer, it can put more points in a \"horizontal\" line than in a vertical line; some printers allow this value to be changed for ink economy. \nimage resolution printing output (dpi): the amount of pixels defined on the image that will be placed in a 1 inch row or column, on the sheet of paper\nMathematica ImageResolution: a way to specify how many pixels to generate on the exported file, etc.\n\nSo, let's suppose you have a 1000 \u00d7 1000 pixels image file. What is the resolution of your image? If it is not shown, neither on the screen, nor on paper, it has no resolution (sure your image software can register in a file a specific value for the resolution, but this value has absolutely no impact on your image, see it as something like the date on a digital photograph.)\n(I'm sure someone from the \"printing\" business would not agree with some of the words I used, but let's use this as my personal practical definition)\nIf you print that 1000 \u00d7 1000 pixels image on a 4\" \u00d7 4\" size paper, it will have a image resolution printing output of 1000/4\"= 250 dpi. If you printed with a printer resolution of 2500 \u00d7 2500 dpi, then your printer placed 10 \u00d7 10 drops of ink to render each pixel of your digital image (this also allows for a correct color rendering from just 3 or 5 different ink recipients).\nIf you display the same 1000 \u00d7 1000 image on your screen, with a 100 % zoom (where each pixel of the image occupies exactly one pixel on your screen), most likely, your image will measure 1000/72\" (if you use a ruler), since most screens have a resolution of 72 dpi (recent laptops may have substantially higher resolution).\nSo, another important question is: What should be my image resolution printing output?\nWhen printing, you should have an image resolution printing output adapted to the distance at which the image will be seen. It is common to say that someone with a 20/20 sight is able to distinguish 0.3 to 0.4 arc minutes at maximum. Considering the value 0.3, we could say that, for the printing to be perfect, the image resolution printing output, in dpi, should be (360/(0.3/60))/(2 d*Pi), where d stands for the distance of viewing (in inches).\nNevertheless, I'll add here my personal experience on printed results (where, for obvious reasons, things aren't so perfect as on perfectly geometrical displays): below 150 dpi, you will start to easily see the pixels on your printed support; above 300 dpi, only with very precise printers, and looking closely, will you see a difference to the same image at 300 dpi. Out of curiosity, these practical limits correspond on a perfect vision to a distance between 1 to 2 meters.\nFor your example, a 3' \u00d7 5' print, I think that 200 dpi image resolution printing output is more than enough, since it is probably a print that will be observed from a certain distance. Everyone farther than 1,5 m will be beyond physical capability to distinguish pixels; and I would add that up to 1/4th of this distance, the image will still be perfectly acceptable (after-all, we have been living pretty happy with 72/96 dpi displays up to not so long ago...)\nThis means you would need 3 \u00d7 12 \u00d7 200 by 5 \u00d7 12 \u00d7 200 = 7200 \u00d7 12000 pixels on your file.\nHow to generate this on Mathematica?\nThere are a lot of different ways. I will show you a couple of examples.\nThe following creates an image of 100 \"printer points\" (horizontal), meaning 100*1/72'', which corresponds to approximately 36 mm.\na = Plot[x^2, {x, 0, 1}, ImageSize -> 100]\n\nUnfortunately, what that means is a little hard to understand, since the size that image will occupy on your screen is probably not 36 mm. It depends on the Magnification, the difference between your screen true resolution and what Mathematica reads of it (not always match), etc. Nevertheless, if you activate the ruler (Windows->Show Rules), you will see that it matches. So, think of it more like a meta information...\nThe following exports the previously generated image with the default value of ImageResolution, which is 72 dpi. This means that you jpg file will have (100*1/72'')*72 dpi = 100 horizontal pixels.\nExport[\"a.jpg\", a]\n\nThe following exports a 200 horizontal pixel size image (it changes your original option, defined on the Plot)\nExport[\"a.jpg\", a, ImageSize->200]\n\nAnd with the following you specify the ImageResolution for the Export function. This is  probably what you are looking for.\nExport[\"a.jpg\", a, ImageResolution->200]\n\nSo, I recommend that you play around with ImageSize, to get a good looking image on your screen (the texts on the correct size, etc), and then Export it specifying the ImageResolution to get the 7200 \u00d7 12000 pixels file.\n(See JPEG specifications to get it into a reasonable file size.)\n", "How to represent and manipulate abstract indexed vector (or tensor) expressions?": "\nOn this wikipedia page you find a collection of Tensor software and Mathematica has the biggest section. \nThe package Ricci, which username acl pointed out in his answer is there, and I personally have used xAct. It looks like this\nhttp://img692.imageshack.us/img692/211/pic1ni.png\nAnd yes, as you suggest in your question, for smaller computation in specific dimensions you can also work in components directly. For me, this usually looks something like this (only have a screenshot atm.).\nhttp://img835.imageshack.us/img835/5023/bild4go.png\nAlthough the expression $de_\\mu$ makes me think the package variant is best suited for you.\n", "programming - Creating Mathematica packages": "\nPackage creation is a large topic indeed. I will still attempt to give a minimal clarification of the encapsulation mechanism behind packages, since in my experience it pays off to understand it.\nWhat constitutes a package\nBasically, a piece of Mathematica code (usually containing a number of variable \nand function definitions), which is placed inside\nBegin[someContext]\n\ncode\n\nEnd[]\n\ncan be called a package. Usually, however, at least some more structure is present. In particular, to separate interface from implementation, the typical package looks like\nBeginPackage[someContext]\n\npublic-functions-usage-messages \n\nBegin[\"`Private`\"]\n\ncode\n\nEnd[]\n\nEndPackage[]\n\nContexts and symbol names\nThe context here is a namespace. The convention is that context name is a string ending with \"`\". At any given moment, the value for the current working namespace is stored in the system variable $Context, and can also be queried by calling Context[]. Begin[\"test`\"] will simply add the current context to the context stack, and then change it to \"test`\", while End[] will exit the current context by making the previous one current. \nEvery symbol must belong to some context. The system commands belong to the \"System`\" context, and the default working context for interactive FrontEnd sessions is \"Global`\". When mma code is parsed, the symbols are given their \"true\" (long) names, which contain both a symbol name and a context where the symbol is. For example, Map is really System`Map, and if I define a function f[x_]:=x^2 in the FE session, it will be Global`f. For any symbol, one can call Context[symbol] to determine the context where that symbol belongs. To \"export\" a symbol defined in a package, it is sufficient to simply use it in any way in the \"public\" part of the package, that is, before \"`Private`\" or other sub-contexts are entered. Usage messages is just one way to do it, one in principle could just write sym; and the sym would be created in the main package context just the same (although this practice is discouraged).\nEvery symbol can be referenced by its long name. Using the short name for a symbol is acceptable if the context where it belongs belongs to the list of contexts currently on the search path, stored in a variable $ContextPath. If there is more than one context on the $ContextPath, containing the symbol with the same short name, a symbol search ambiguity arises, which is called shadowing. This problem should be avoided, either by not loading packages with conflicting public (exported) symbols at the same time, or by referring to a symbol by its long name. I discussed this mechanics in slightly more detail in this post.\nContexts can be nested. In particular, the \"`Private`\" above is a sub-context of the main context someContext. When the package is loaded with Get or Needs,only its main context is added to the $ContextPath. Symbols created in sub-contexts are therefore inaccessible by their short names, which naturally creates the encapsulation mechanism. They can be accessed by their full long names however, which is occasionally handy for debugging.\nStoring and loading packages\nPackages are stored in files with \".m\" extension. It is recommended that the name of the package coincides with the name of the package context. For the system to find a package, it must be placed into some of the locations specified in the system variable $Path. As a quick alternative (useful at the development stage), $Path can be appended with the location of a directory that contains a package. \nWhen the Needs or Get command are called, the package is read into a current context. \nWhat is meant  by this is that the package is read, parsed and executed, so that the definitions it contains are added to the global rule base. Then, its context name is added to the current $ContextPath. This makes the public symbols in a package accessible within the current working context by their short names. If a package A is loaded by another package B, then generally the public symbols of A will not be accessible in the context C which loads B - if needed, the A package must generally be explicitly loaded into C. \nIf the package has been loaded once during the work session, its functions can be accessed by their long names even if it is not currently on the $ContextPath. Typically, one would just call Needs again - if the package has been loaded already, Needs does not call Get but merely adds its context name to the $ContextPath. The internal variable $Packages contains a list of currently read in packages.\nThe case at hand\nHere is how a package might look like:\nBeginPackage[\"SimpleArithmetic`\"]\n\nAddTwo::usage = \"AddTwo[a, b] returns a+b\";\nAddThree::usage = \"AddThree[a, b, c] returns a+b+c\";\nTimesTwo::usage = \"TimesTwo[a, b] returns a*b\";\nTimesThree::usage = \"TimesThree[a, b, c] returns a*b*c\";\n\nBegin[\"`Private`\"]\n\nplus[args___] := Plus[args];\ntimes[args___] := Times[args]\n\nAddTwo[a_, b_] := plus[a, b];\nAddThree[a_, b_, c_] := plus[a, b, c];\nTimesTwo[a_, b_] := times[a, b];\nTimesThree[a_, b_, c_] := times[a, b, c];\n\nEnd[]\nEndPackage[]\n\nThe functions AddTwo, AddThree, TimesTwo,TimesThree are public because these symbols were used in the public part of the package. Their long names would be then SimpleArithmetic`AddTwo, SimpleArithmetic`AddThree, SimpleArithmetic`TimesTwo, SimpleArithmetic`TimesThree. The functions plus and times are private to the package, since they are in the sub-context `Private`, which is not added to the ContextPath when the main package is loaded. Note that this is the only reason they are private. Should I call AppendTo[$ContextPath,SimpleArithmetic`Private`], and they'd become as \"public\" as the main functions (practice that should of course be discouraged by which should clarify the encapsulation mechanism).\nWith regards to splitting a package into several packages, this is a normal practice, but usually an individual mma package contains much more functionality than say a typical Java class, more like Java package. So, in the case at hand, I'd not split it until you get a much more functionality in it.\nOf course, I only discussed here a very small subset of things related to packages. I will hopefully update this tutorial soon. An excellent reference for writing packages is a book of Roman Maeder \"Programming in Mathematica\". It is pretty old, but still one of the most (if not the most) useful accounts on the matter.   \n", "function construction - SetAttributes[f,Flat]: Why the order dependence?": "\nOk, I'm going to try to explain my best conjuecture as to how this happens, and don't even try to answer why. \nThere are three reasons for this behaviour:\nSetDelayed left hand side evaluation\nAs others have mentioned, even though SetDelayed has attributes that indicate it holds the lhs, it does evaluate the head and the arguments of it, just not the expression as a whole.\nHow the Attribute Flat affects the final evaluation of the expression\nOk, so the evaluator is now trying to transform the expression (with head Flat) as a whole. It has already evaluated the head and arguments, or not, as it was supposed to. It has already flattened everything. It has already tried the UpValues, nothing fit.\nNow it checks, in order, one DownValue at a time:\n1* If it matches the expression as is, we're good. It applies the transformation rule.\n2* If it doesn't, then it modifies the expression, gathering arguments. Tries combinations of head[prev__, head[some__], aft__] with args being different subsequences of arguments taken from expression. If some subexpression fits the pattern, it transforms it and restarts the process.\nExample\nIn[27]:= ClearAll[f];\nSetAttributes[f, {Flat, HoldAll}];\nf[b, c] := 8;\nf[a, b, c, d]\n\nOut[30]= f[a, 8, d]\n\n3* If it doesn't then IT TRIES TO MATCH THE EXPRESSION head[] WITH NO ARGUMENTS. If it succeeds, then IT PREPENDS THE UNEVALUATED TRANSFORMATION OF head[] TO THE EXPRESSION AND RESTARTS THE EVALUATION PROCESS\nSome examples:\nIn[18]:= ClearAll[f1, f2, f3, f4];\nSetAttributes[{f1, f2, f3, f4}, Flat];\nf1[2, 2, 2, 2] := \"Yeahh\";\nf1[2] = \"bo\";\nf1[] := (Print[\"here\"]; 2);\n\nf2[2] = \"bo\";\nf2[2, 2, 2, 2] := \"Yeahh\";\nf2[] := (Print[\"here\"]; 2);\n\nf3[] := (Print[\"here\"]; 2);\nf3[2, 2, 2, 2] := \"Yeahh\";\nf3[2] = \"bo\";\n\nf4[2, 2, 2, 2] := \"Yeahh\";\nf4[] := (Print[\"here\"]; 2);\nf4[2] = \"bo\";\n\nIn[32]:= Scan[Print[DownValues[#][[All, 1]]] &, {f1, f2, f3, f4}]\n\nDuring evaluation of In[32]:= {HoldPattern[f1[2,2,2,2]],HoldPattern[f1[2]],HoldPattern[f1[]]}\n\nDuring evaluation of In[32]:= {HoldPattern[f2[2]],HoldPattern[f2[2,2,2,2]],HoldPattern[f2[]]}\n\nDuring evaluation of In[32]:= {HoldPattern[f3[]],HoldPattern[f3[2,2,2,2]],HoldPattern[f3[2]]}\n\nDuring evaluation of In[32]:= {HoldPattern[f4[2,2,2,2]],HoldPattern[f4[]],HoldPattern[f4[2]]}\n\nIn[33]:= f1[2]\nf2[2]\nf4[2]\n\nOut[33]= \"bo\"\n\nOut[34]= \"bo\"\n\nDuring evaluation of In[33]:= here\n\nDuring evaluation of In[33]:= here\n\nDuring evaluation of In[33]:= here\n\nOut[35]= \"Yeahh\"\n\nSo, in our case, when the expression f[n_Integer] fails to match the pattern f[x___Real], it evaluates f[] to get {}, and tries matching f[{}, f[n_Integer]], which doesn't match so it loops infinately.\nIf this is a case, then a good tip would be to always take care that all definitions of Flat symbols that match without arguments should go last...\nHow the order of setting attributes matter\nFlat affects evaluation in 3 different moments:\n\nAfter evaluating the arguments of an expression, it automatically\nflattens it's head\nChanges the pattern-matching (more on this later)\nChanges what the evaluator does when an expression didn't match a DownValue\n\nThe 1.th and 2.th part seems to only care about Flat being set at the time of evaluation.\nBut 3., it seems that that peculiar behaviour (see 2* and 3* above) of the evaluator trying to match the no-arguments version is PER DOWNVALUE, and it seems to me that, at the time the DownValue is set, MMA records somewhere if Flat was or not set at the time.\nSo, the previous f3 example that looped infinitely wouldn't loop infinitely if the no argument version was defined while the Flat attribute wasn't set.\nClearAll[f3];\nf3[] := (Print[\"here\"]; 2);\nSetAttributes[{f1, f2, f3, f4}, Flat];\nf3[2, 2, 2, 2] := \"Yeahh\";\nf3[2] = \"bo\";\n\nIn[65]:= f3[2]\n\nOut[65]= \"bo\"\n\nThe previous f4 example would also differ. You don't even need to set the Flat attribute back up in the end for the behaviour to remain\nIn[66]:= ClearAll[f4];\nSetAttributes[f4, Flat];\nf4[2, 2, 2, 2] := \"Yeahh\";\nClearAttributes[f4, Flat];\nf4[] := (Print[\"here\"]; 2);\nSetAttributes[f4, Flat];\nf4[2] = \"bo\";\n\nIn[73]:= f4[2]\n\nOut[73]= \"bo\"\n\nThe same actually applies to (see 2*) the evaluator testing the different combinations of gathered arguments... So\nIn[37]:= ClearAll[f];\nSetAttributes[f, {Flat, HoldAll}];\nf[b, c] := 8;\nClearAttributes[f, Flat];\nf[e, g] := 9;\nf[a, b, c, d]\nf[a, e, g, d]\n\nOut[42]= f[a, 8, d]\n\nOut[43]= f[a, e, g, d]\n\nExtra for less incompleteness\nFlat also affects the pattern matcher.\nWhen the pattern matcher finds itself comparing arguments of an expression whose head (let's call it head) has attribute Flat, it behaves differently: patterns of length one (_, r_, Conditions, PatternTests) trigger the pattern matcher to automatically wrap a head around the respective arguments of the expression so both the expression and the pattern have the same number of arguments (could also be a single argument, but it never leaves it as is. Don't know the purpose). In cases where more than one option is possible due to having __s as arguments, it just starts trying one way and if it doesn't match, tries the next).\nIn[47]:= ClearAll[f]; SetAttributes[f, {Flat, HoldAllComplete}];\n         Cases[Hold@f[1], Hold@f[i_] :> Hold[i], {0}]\n         Cases[Hold@f[1, 2, 3, 4], Hold@f[1, i_, 4] :> Hold[i], {0}]\n         Cases[Hold@f[1, 2, 3, 4], Hold@f[i_, __] :> Hold[i], {0}]\n         Cases[Hold@f[1, 2, 3, 4], \n            Hold@f[i_, j__ /; Length[{j}] === 2] :> Hold[i], {0}]\n\nOut[48]= {Hold[f[1]]}\n\nOut[49]= {Hold[f[2, 3]]}\n\nOut[50]= {Hold[f[1]]}\n\nOut[51]= {Hold[f[1, 2]]}\n\nConclusion\nThe problem is: Will the evaluation of f[n_Integer] in our definition of g trigger an infinite loop or not? It does evaluate because of the peculiar evaluation rules of Set functions.\nf[n_Integer] doesn't match the only DownValue it has at the time: f[x___Real]. In the 2 cases that work, that DownValue wasn't defined while f had the attribute Flat, so it just returns unevaluated. However, in the third case, the DownValue was defined while the symbol had Flat. So after failing, it tries to evaluate f[], returning {} and now reevaluates the whole expression as f[{}, n_Integer]\n", "performance tuning - How do you determine the optimal autocompilation length on your system": "\nYou should note that you are actually controlling the compiling and the array packing is just coupled to that and AFAIK can't be controlled independently (anymore). You can verify this with e.g. this uncompilable table body which generates the same result:\nDeveloper`PackedArrayQ[Table[i /. x_ /; x > 300 :> RandomReal[], {i, 1, 251}]]\nFalse\n\nI would expect that the compiling dominates over the array packing concerning runtime overhead and thus that the dependence on the actual body of the table is much stronger than that of the system you are on. If that expectation isn't completely wrong an optimization with regards to the system might be rather useless. Here are examples to demonstrate this:\nSetSystemOptions[\"CompileOptions\" -> {\"TableCompileLength\" -> \\[Infinity]}];\nuncompiled = Map[\n   Function[x, Timing[Do[With[{y = RandomReal[]},\n         Table[\n          Abs[i - y]/(Exp@Sin[y*i]*i^2 + 1 - 0.5*(i + y)^23), {i, x}]\n         ], {1000}];][[1]]],\n   Range[1, 50]\n   ];\n\nSetSystemOptions[\"CompileOptions\" -> {\"TableCompileLength\" -> 1}];\ncompiled = Map[\n   Function[x, Timing[Do[With[{y = RandomReal[]},\n          Table[\n           Abs[i - y]/(Exp@Sin[y*i]*i^2 + 1 - 0.5*(i + y)^23), {i, x}]\n          ], {1000}];][[1]]],\n    Range[1, 50]\n   ];\n\nListLinePlot[{compiled, uncompiled}]\n\n\nSetSystemOptions[\"CompileOptions\" -> {\"TableCompileLength\" -> \\[Infinity]}];\nuncompiled = Map[\n    Function[x, Timing[Do[\n        With[{y = RandomReal[]}, Table[i + y, {i, x}]],\n        {5000}];][[1]]],\n   Range[60, 180]\n   ];\n\nSetSystemOptions[\"CompileOptions\" -> {\"TableCompileLength\" -> 1}];\ncompiled = Map[\n   Function[x, Timing[Do[\n        With[{y = RandomReal[]}, Table[i + y, {i, x}]],\n        {5000}];][[1]]],\n   Range[60, 180]\n  ];\n\nListLinePlot[{compiled, uncompiled}]\n\n\nIf you compare the two plots you will see that for these two cases the optimal compile length is very different.\nTo get most out of your system, you would need to adopt these settings to the problem at hand (and of course change them for another).\nThis of course assumes that you are talking about runtime efficiency, although array packing is just as well (or even in the first place) about memory efficiency.\n", "packages - Strategies for avoiding and handling shadowing": "\nWhen this is unavoidable, I just refer to full contexts.  This happens all the time when using Combinatorica, which defines Graph objects that conflict with V8's new built in Graph object.  Here's a sample session (presented as an image to show highlighting and such):\n\n", "performance tuning - How to collect result continuously (interruptible calculation) when running parallel calculations?": "\nRegarding using Sow instead of AppendTo, you may find this trick useful:\nLast[Last[Reap[CheckAbort[Do[Pause[0.1]; Sow[x], {x, 30}], ignored]]]]\n\n(Try running this and aborting it partway through. It runs for 3 seconds due to the Pause[0.1] commands.)\nDo is used instead of Table, and the results are returned with Sow. The CheckAbort catches when you abort your computation partway through and does the useful tidying up (in this case, returning something, anything, to the enclosing Reap).\nYou can combine this with a version of Sow that always run on the master kernel:\nSetSharedFunction[ParallelSow];\nParallelSow[expr_] := Sow[expr]\n\n(Tangentially related blog post I did: http://blog.wolfram.com/2011/04/20/mathematica-qa-sow-reap-and-parallel-programming/)\nThen you could use this parallelized version:\nIn[3]:= Last[\n Last[Reap[\n   CheckAbort[ParallelDo[Pause[0.1]; ParallelSow[x], {x, 30}], \n    ignored]]]]\n\nOut[3]= {6, 1, 7, 2, 8, 3, 9, 4, 10, 5, 16, 11, 17, 12, 18, 13, 19, \\\n14, 20, 15, 21, 26, 22, 27, 23, 28, 24, 29, 25, 30}\n\nHowever, as you can see, the results come in in an unpredictable order so something slightly cleverer is in order. Here is one way (probably not the best but the first thing I thought of):\nIn[5]:= Catch[\n Last[Last[\n   Reap[CheckAbort[\n     Throw[ParallelTable[Pause[0.1]; ParallelSow[x], {x, 30}]], \n     ignored]]]]]\n\nOut[5]= {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, \\\n18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30}\n\nThe Throw is used to jump outside the Reap if the ParallelTable finishes. (Getting messy!)\nTo be safe this should be wrapped up in a function and tags (a.k.a. the optional second argument) should be used on the Throw, Catch, Sow, Reap.\n", "Constructing functions with variable number of output arguments": "\nAs you have mentioned there are other more standard ways to provide some variaty in your return value so I don't think that this is something that you should do. If you provide code using something like it you should have good reasons for doing so. Just being used to it because matlab has it probably is just not convincing enough. \nThat said, it can be done along these lines:\nClearAll[f, ff]\nf /: Set[arg_Symbol, f[x_]] := Block[{nargout = 1}, arg = ff[x]];\nf /: Set[args_List, f[x_]] := Block[{nargout = Length[args]}, args = ff[x]];\nf[arg_] /; FreeQ[Stack[], Set] := Block[{nargout = 1}, ff[arg]];\nff[x_] := (Table[x, {nargout}]);\n\nyou can now use it like this:\nIn[101]:= f[5]\nOut[101]= {5}\nIn[102]:= a=f[5]\nOut[102]= {5}\nIn[104]:= {a,b}=f[5]\nOut[104]= {5,5}\nIn[105]:= {a,b,c}=f[5]\nOut[105]= {5,5,5}\n\nThis is not tested well and could have many pitfalls. I see it rather as a proof of concept and probably something for your own convenience. So use with care, especially if you are uncertain about all the details (as I am: I can't remember I ever had the need to use Stack). \nBrett already found one pitfall. Actually that is a case where one could be argueing what the expected return value should be. If we fall back to the one argument case for everything that is not an explicit Set it is easy to solve, but I can see other problems already :-):\nf[arg_] /; Not[MatchQ[Stack[],{___,Set,f,___}]]:=Block[{nargout=1},ff[arg]];\n\n", "optics - Drawing graphics part by part": "\nWhat you want is done by\nGraphics[Table[Circle[{a, 1}, 1], {a, 1, 2}] ~Append~ Text[\"It's finished\", {0, 0}]]\n\n\nHere's another approach, with minimal changes to your code:\nGraphics[\n  {\n     a = 1;\n     Label[tag];\n     If[a < 3,\n        {Sow @ Circle[{a, 1}, 1], a = a + 1; Goto[tag];},\n        {Sow @ Text[\"It's finished\", {0, 0}]}]\n  } // Reap // Last // Last\n]\n\nEDIT: I'm afraid I am not sure what that is supposed to look like, but does this\nManipulate[\n Graphics[\n  {\n   \u03b1 = ArcSin[H/R];\n   p = Sqrt[R^2 - H^2];\n   {Red, Thick, Line[{{-2, H}, {p, H}}]},\n   {Blue, Opacity[.5], Disk[{0, 0}, R, {0, Pi/2}]},\n   If[\n    H < R/n,\n    {\n     l = (R^2 n)/(Sqrt[R^2 - H^2] n - Sqrt[R^2 - H^2 n^2]);\n     {Red, Thick, Line[{{p, H}, {l, 0}}]}\n     },\n    Last@Last@Reap[\n       {\n        novo = H;\n        k = 2;\n        Sow@Text[\u03b8, {10, 5}], Text[\u03b1, {10, 7}], \n        Text[k, {10, 9}],\n        Label[oznaka];\n        s = R Cos[\u03b1] - novo/Tan[2 \u03b1];\n        If[s <= R,\n         Sow@{{Red, Thick, Line[{{p, novo}, {s, 0}}]}},\n         {\u03b8 = (2 k + 1) \u03b1 - k Pi;\n          f = R Cos[\u03b8];\n          h = R Sin[\u03b8];\n          k = k + 1;\n          Sow@Line[{{{p, novo}, {f, h}}}], novo = h;\n          p = f;\n          Goto[oznaka];}]}\n       ]\n    ]\n   }\n  ],\n {{H, 9.45991`, \"Vertikalna udaljenost upadne zrake\"}, 0.0001, \n  R - 0.0001, \n  Appearance -> \"Labeled\"}, {{n, 1.5, \n   \"Koeficijent prelamanja stakla\"}, 1.001, 2, \n  Appearance -> \"Labeled\"}, {{R, 10, \"Poluprecnik prizme\"}, 0, 10, \n  Appearance -> \"Labeled\"}]\n\nwork?\n\n", "histograms - Elegantly pairing up mismatched lists": "\nYou can use InterpolationOrder for the plot itself to generate the same behavior. I'm assuming here you want the plot you posted in an easier way, not the data handling itself.\n{bins, counts} = HistogramList[...];\nListLinePlot[\n    {bins, Append[counts, 0]} // Transpose, \n    InterpolationOrder -> 0\n]\n\n\n(You may want to prepend one value to the finished list so that the histogram goes down to zero on the left side as well.)\n", "configuration - what is the command to make Mathematica beep each time there is an error even for the same command?": "\nHeike figured out what was going on. \nHowever, if you want a command that will make your Simplify[expr] beep everytime, you need to turn of the symbolic part of the cache using\nSetSystemOptions[\"CacheOptions\" -> {\"Symbolic\" -> False}]\n\n", "options - How can I work out which functions work with SetOptions?": "\nI don't know the direct answer to the specific question on SetOptions, but if we look at the purpose of (re)setting options globally, I have some alternative suggestion. A need to set options globally means that you need some persistent configuration of options which you'd like to be applied many times, without extra effort on your side. This can be achieved by creating such option(s) configuration and then always passing options locally (explicitly). It is possible to create helper functions / macros, which would automate this process for you and make it look and feel (almost) as if you have set your options globally.\nI have implemented a simplistic options configuration manager, and a lexically scoped construct withOptionConfiguration, which can be wrapped around your code containing a function call of interest. One can also implement dynamically-scoped environments, for which the option-passing will happen also for all code called from the code within a construct. To my mind, this will save a lot of hassle even if / when you get the exhaustive answer to your direct question, since with the approach I suggest, you don't have at all to remember which functions work with SetOptions and which don't.\n", "numerics - Combined numerical minimization and maximization": "\nThis is a rather common issue that comes up with many numerical functions (FindRoot, NIntegrate, FindMaximum, NMaximize, etc.)  It is also explained in this Wolfram Knowledge Base article. Sometimes you want to pass these functions an expression that has a symbolic parameter, and compute the result for different values of that parameter.\nExample:\nfun[a_] := Block[{b}, b /. NMinimize[(a^2 + b)^2, {b}][[2]]]\n\nThis will work nicely if you call it with a numeric argument: fun[3].  But it will cause an error in NMinimize if you call it with a symbolic parameter: fun[a] (for obvious reasons).\nThe solution is:\nClear[fun]\nfun[a_?NumericQ] := Block[{b}, b /. NMinimize[(a^2 + b)^2, {b}][[2]]]\n\nNMaximize[fun[a], {a}]\n\n(Be sure to evaluate Clear[...] to get rid of the previous definition of fun!)\nThis ensures that fun will only evaluate for numerical arguments, i.e. fun[a] won't evaluate inside NMaximize before NMaximize actually substitutes a number for a.\nAnd this is also the answer to your specific question: make the inner NMinimize expression a separate function, and make sure it only evaluates for numerical arguments.\n\nRequested edit\nAn important related point is: how can we match only numerical quantities using a pattern?  One might think of using _Real (as in the comment below).  The problem with this is that it will only match numbers whose Head is Real.  This excludes integers (such as 1,2,3), rationals (2/3, 4/5), constants (such as Pi or E), or expressions like Sqrt[2].\nThe only robust solution is using NumericQ[] (x_ ? NumericQ in a pattern).  NumericQ will return True for anything that gives a number when N[] is applied to it.\nThere's another related function, NumberQ[], which gives True only for objects with Integer, Rational, Real or Complex, but not for constant or expressions (Pi or Sin[3]).\n", "programming - How do I evaluate only one step of an expression?": "\nI believe I have found the solution I was seeking.  It returns the first step that transforms the entire expression, and it does so without further evaluation.  \nThe P = (P = part is to skip the untransformed expression.\nSetAttributes[step, HoldAll]\n\nstep[expr_] :=\n  Module[{P},\n    P = (P = Return[#, TraceScan] &) &;\n    TraceScan[P, expr, TraceDepth -> 1]\n  ]\n\nI hope that this function will be as helpful to others as I expect it will be to me.\n", "options - How can I set Grid alignments using numbers?": "\nIt seems that the handling of the Alignment option is not consistent for all functions using it. Panel for instance seems to support numeric values for this option\nManipulate[\n Panel[\"\\[Times]\", ImageSize -> {100, 50}, Alignment -> {x, y}],\n {x, -1, 1},\n {y, -1, 1}\n]\n\nwhile with Grid this is not supported.\nKnowing this, you could check functions you're interested in with something simple like\nSetAttributes[AlignmentTest, HoldAll];\nAlignmentTest[func_] := Row[{\n   Manipulate[\n    Append[func, Alignment -> {x, y}],\n    {x, -1, 1},\n    {y, -1, 1}\n    ],\n   Manipulate[\n    Append[func, Alignment -> {x, y}],\n    {x, {Left, Center, Right}},\n    {y, {Bottom, Center, Top}}\n    ]\n   }]\n\nYou see that in many cases numeric values for the Alignment option can be used\nAlignmentTest[\n Button[\"Click Here\", Print[10!], ImageSize -> {100, 100}]]\n\nAlignmentTest[\n Manipulate[Plot[Sin[x (1 + a x)], {x, 0, 6}], {a, 0, 2}, \n  ContentSize -> {500, 500}]]\n\nAlignmentTest[\n Grid[{{\"\\[Times]\", \"\\[Times]\", \"\\[Times]\"}, {\"\\[Times]\", \"\\[Times]\", \n    \"\\[Times]\"}}, Frame -> All, ItemSize -> {10, 10}]]\n\nAlignmentTest[Overlay[{Graphics[{Disk[]}], Slider2D[]}, All, 2]]\n\n", "boolean computation - Prenex and Skolem normal forms": "\ntutorial/RealPolynomialSystems claims \"Reduce, Resolve, and FindInstance always put real polynomial systems in the prenex normal form, with quantifier-free parts in the disjunctive normal form...\"\nFor obtaining Skolem form from prenex, possibly could proceed as described at\nhttp://demonstrations.wolfram.com/Skolemization/\nor\nhttp://mathworld.wolfram.com/SkolemFunction.html\nEdit:\nAlso there is a non-System` context function of interest (I learned this via grep). I'll illustrate with the example provided in a comment.\nee = ForAll[x, P[x] \\[Implies] Q[x]] \\[Implies] (ForAll[x, P[x]] \\[Implies] ForAll[x, Q[x]]);\n\nWe'll need to put into a normal for; conjunctive or disjunctive will suffice. I'll use LogicalExpand to get a dnf.\nff = LogicalExpand[ee]\n\n\nExists[x,  !Implies[P[x], Q[x]]] || Exists[x,  !P[x]] || ForAll[x, Q[x]]\n\n\nReduce`ToPrenexForm[ff]\n\n\nExists[{C[1], C[2]}, ForAll[{C[3]}, (P[C[1]] &&  !Q[C[1]]) ||  !P[C[2]] || Q[C[3]]]]\n\n\nI've no idea whether this is the sort of result wanted. But it does seem to have all quantifiers at the front.\n", "calculus and analysis - Implementing discrete and continuous Hilbert transforms": "\nHere's a direct implementation of the formula\n$$\\mathcal H(u)(t) = \\frac1{\\pi} -\\hspace{-1.1em}\\int_{-\\infty}^\\infty \\frac{u(\\tau)}{t-\\tau}\\, \\mathrm d\\tau$$\nhilbertTransform[f_, u_, t_] :=\n       FullSimplify[Convolve[f, 1/u, u, t, PrincipalValue -> True]/\u03c0]\n\nTry it out:\nhilbertTransform[#, v, w] & /@ {Sin[v], Cos[v], 1/(1 + v^2), Sinc[v], DiracDelta[v]}\n   {-Cos[w], Sin[w], w/(1 + w^2), (1 - Cos[w])/w, 1/(\u03c0 w)}\n\n\nFor the discrete Hilbert transform, here is a Mathematica routine:\nhilbert[data_?VectorQ] := Module[{fopts = FourierParameters -> {1, -1}, e, n},\n   e = Boole[EvenQ[n = Length[data]]]; \n   Im[InverseFourier[Fourier[data, fopts] * \n                     PadRight[ArrayPad[ConstantArray[2, Quotient[n, 2] - e], {1, e}, 1], n],\n                     fopts]]] /; And @@ Thread[Im[data] == 0]\n\n(making everything completely analogous to FourierTransform[] and Fourier[]). The algorithm is based on the routine in Marple's paper, and is essentially the same algorithm used by the function hilbert() in MATLAB's Signal Processing Toolbox.\nExamples:\nhilbert[{1, -2, 1}]\n   {1.73205, 0., -1.73205}\n\nhilbert[{1, -2, 1, 2}]\n   {2., 0., -2., 0.}\n\n", "plotting - On coloring the faces of a surface differently with parameter-dependent colors": "\nMy friend C.H. enlightened me, that in current version of M. ColorFunction defines vertex colors which in turn define polygon colors. Because vertexes cannot have 2 different colors for different sides of a surface, so can\u2019t polygons. \nI will show two solutions.\nSo here is one solution. We can extract images from ColorData:\n\nand just use textures - if you want to call ParametricPlot3D only once. You can easily map different textures on different sides of a surface, use Specularity and Opacity with them.\nParametricPlot3D[{Cos[u] (3 + Cos[v]), Sin[u] (3 + Cos[v]), \n  Sin[v]}, {u, 0, 1.5}, {v, -3.5, 2}, \n TextureCoordinateFunction -> ({#4, #5} &), \n PlotStyle -> \n  Directive[Specularity[White, 50], \n   FaceForm[Texture[ColorData[\"BrightBands\", \"Image\"]], \n    Texture[ColorData[\"DarkRainbow\", \"Image\"]]]], Axes -> False, \n Lighting -> \"Neutral\", Mesh -> None, Boxed -> False]\n\n\n\nAnother solution, as you mentioned, is to put 2 surfaces together. I really like it, it's light and zippy. I will mention it here for completeness of example. In M. we can make surface (its polygons) to be transparent if you look from one side and colored from the other with help of FaceForm[None , {}]. Clearly demonstrated below with M\u00f6bius strip:\nParametricPlot3D[{Cos[t] (3 + r Cos[t/2]), Sin[t] (3 + r Cos[t/2]), \n  r Sin[t/2]}, {r, -1.5, 1.5}, {t, 0, 2 Pi}, Mesh -> {10, 60}, \n PlotStyle -> FaceForm[None, Orange], Boxed -> False]\n\n\nYou can also do things like PlotStyle -> FaceForm[None, Directive[Orange, Opacity[.5]]] We will uses this. Each graphics one surface\u2019s side is effectively turned off, so shifting the two surfaces with respect to each other is not needed.\nShow[\n ParametricPlot3D[{(2 + Cos[v]) Cos[u], (2 + Cos[v]) Sin[u], \n   Sin[v]}, {v, -Pi/1, Pi/1.5}, {u, 0, Pi/1.5}, Boxed -> False, \n  Axes -> False, Mesh -> False, \n  ColorFunction -> (ColorData[\"DarkRainbow\"][#5] &), \n  PlotPoints -> 30,\n  PlotStyle -> FaceForm[{}, None] ],\n\n ParametricPlot3D[{(2 + Cos[v]) Cos[u], (2 + Cos[v]) Sin[u], \n   Sin[v]}, {v, -Pi/1, Pi/1.5}, {u, 0, Pi/1.5}, Boxed -> False, \n  Axes -> False, Mesh -> False, \n  ColorFunction -> (ColorData[\"BrightBands\"][#5] &), \n  PlotPoints -> 30,\n  PlotStyle -> FaceForm[None, {}] ]\n]\n\n\n======================== Reply to 1st Comment ========================\nTrimming anyhow color maps will work:\nParametricPlot3D[{Cos[u] (3 + Cos[v]), Sin[u] (3 + Cos[v]), \n  Sin[v]}, {u, 0, 1.5}, {v, -3.5, 2}, \n TextureCoordinateFunction -> ({#4, #5} &), \n PlotStyle -> \n  Directive[Specularity[White, 50], \n   FaceForm[\n    Texture[ImageTake[\n      ColorData[\"BrightBands\", \"Image\"], {0, 31}, {85, 250}]], \n    Texture[ImageTake[\n      ColorData[\"DarkRainbow\", \"Image\"], {0, 31}, {85, 250}]]]], \n Axes -> False, Lighting -> \"Neutral\", Mesh -> None, Boxed -> False]\n\n\n", "syntax - Convenient string manipulation": "\nI suggest an approach based on creating lexical and / or dynamic environments (custom scoping constructs if you wish), inside which the rules of our \"universe\" will be altered. I will illustrate with a dynamic environment:\nClearAll[withStringManipulations];\nSetAttributes[withStringManipulations, HoldAll];\nwithStringManipulations[code_] :=\n  Internal`InheritedBlock[{Take, Drop, Position, Join, Append, \n        Prepend, Length, Part, Plus},\n   Unprotect[Take, Drop, Position, Join, Append, Prepend, Length, Part, Plus];\n   Take[s_String, pos_] := StringTake[s, pos];\n   Drop[s_String, pos_] := StringDrop[s, pos];\n   HoldPattern[Part[s_String, n_]] := StringTake[s, {n, n}];\n   Join[ss__String] := StringJoin[ss];\n   Append[s_String, ss_String] := StringJoin[s, ss];\n   Prepend[s_String, ss_String] := StringJoin[ss, s];\n   Length[s_String] := StringLength[s];\n   Plus = \n    Function[Null, \n      If[MatchQ[{##}, {__String}],\n        StringJoin[##],\n        (* else *)\n        Module[{result, ov = OwnValues[Plus]},\n          Unprotect[Plus];\n          OwnValues[Plus] = {};\n          result = Plus[##];\n          OwnValues[Plus] = ov;\n          Protect[Plus];\n          result]]];\n   Protect[Take, Drop, Position, Join, Append, Prepend, Length, Part, Plus];\n   code\n];\n\nThis is not a complete set of things you can do, just an example. Because I used Internal`InheritedBlock, the global versions of functions Part etc are never modified, so this is safe in the sense that it does not have system-wide effects. With Plus, I had to go through some pain, since it has an Orderless attribute and I did not want to alter that, but wanted to avoid sorting when arguments are strings.\nSome examples:\nIn[31]:= withStringManipulations[\"a\"+\"b\"+\"c\"]\nOut[31]= abc\n\nIn[32]:= withStringManipulations[1+2+3]\nOut[32]= 6\n\nIn[34]:= withStringManipulations[With[{s = \"abc\"},Table[s[[i]],{i,Length[s]}]]]//InputForm\nOut[34]//InputForm=\n {\"a\", \"b\", \"c\"}\n\nwithStringManipulations[Append[\"abc\",\"d\"]]\nOut[37]= abcd\n\nAs I said, this is just an example to illustrate the idea. Anyone interested can create their own environments by setting their own rules. This is IMO a very cheap and powerful way to reuse the system functions' syntax to one's liking, without endangering the system. \nBe aware, however, that the above environment is dynamic (in terms of scoping), and so not suitable for example to create higher-order functions which would accept some arbitrary user's code (unless the user knows exactly what the consequences will be, but in practice you as a package-writer can not depend on the user much), since these functions (Part etc) will be also behaving differently in that code. It is also possible to create lexical environments, where the changes will only affect the code literally present inside the environment.\n", "evaluation - Context unique to each group at a specified level": "\nNow, with v9, I can undelete this answer :)\nYou could set a context dependent on a certain counter value. \nAdd to your stylesheet, to the \"Input\" style, the following option\nCellContext:>\"Section\"<>ToString@CurrentValue[{\"CounterValue\", \"Section\"}]<>\"`\"\n\nand in my few tests you get a context dependent on the last section number. It can very probably be expanded to add a title counter and a notebook id\n", "Functions with Options - Mathmatica Stack Exchang": "\nThe main change since that time seems to be that the modern way of using options is associated with  OptionsPattern[] -  OptionValue commands. A typical way of defining a function would be:\nOptions[f] = {FirstOption -> 1, SecondOption -> 2};\nf[x_, y_, opts : OptionsPattern[]] :=\n   Print[{x, y, OptionValue[FirstOption], OptionValue[SecondOption]}]\n\nThe OptionsPattern[] is a pattern which is similar to ___?OptionQ in its purpose, but has subtle differences, some of which are discussed in this question. In the same question, it is discussed what are the major differences and advantages / disadvantages of old and new approaches. You can still use the old way though. The OptionValue command is a rather magical function, which knows which function you are in, so that you often don't have to supply the function name explicitly. However, you can always do so, since OptionValue has forms with more arguments. What you can not do is to mix the two approaches: if you declare options as ___?OptionQ, then OptionValue won't work.\nThe second difference is that there is new built-in functions  FilterRules, which can be used to filter options. Previously, there was a package by Maeder called FilterOptions, which provided similar functionality, but was not in the widespread use, just because not everyone knew about it. The typical options filtering call looks like\ng[x_, y_, opts : OptionsPattern[]] :=\n   f[x, y, Sequence@@FilterRules[{opts}, Options[f]]]\n\nFiltering options is a good practice, so this addition is quite useful.\nIf you wanted to pass options that belong to other functions (e.g. functions that are called inside your function g) you would do something like this, and it would work even if useQ was actually an option of the function p:\ng[x_, y_, opts : OptionsPattern[{g, f, p, q}]] :=\n  Module[\n    {s = If[OptionValue[useQ], q[y, FilterRules[q]], p[x, FilterRules[p]]]},\n    f[x, s, Sequence@@FilterRules[{opts}, Options[f]]] \n  ]\n\n", "VertexSize doesn't scale with Graph layout?": "\nDoes the following do what you want?\nWeightedGraph[edges_, weights_, options___]:=\n  Block[{maxweight=Max[#[[2]]&/@weights]},\n    Graph[edges,VertexSize->((#[[1]]->0.9*#[[2]]/maxweight)&/@weights),options]]\n\nWeightedGraph[{1 \\[UndirectedEdge] 2, 2 \\[UndirectedEdge] 3,\n               3 \\[UndirectedEdge] 1, 3 \\[UndirectedEdge] 4},\n   (*weights:*) {1 -> 1.1, 2 -> 1.2, 3 -> 1.3, 4 -> 1.4}]\n\n\nThe second line is basically your Graph call, except that it uses WeightedGraph instead of Graph, and the weights don't have VertexSize-> in front of them.\n", "syntax - Clear complains that a subscripted variable is not a symbol or a string?": "\nYour code reveals exactly why Clear complains: Subscript[x, r] is not a Symbol nor a String. When you assign a value to it, you're setting a DownValue not an OwnValue; in other words, you're setting the value of a function not a variable. To use $x_r$ as a symbol, use the Notation` package's function, Symbolize. I'd recommend using it from the palette directly, as it has all of the intricacies already set up for you.  \n", "graphics - Antialiasing option behaves weird (polygon edges visible in ContourPlot)": "\nI believe that forcing anti-aliasing renders the edges of the polygons with alpha transparency, and that where two of these adjoin there is a region that remains partially transparent, through which the background shows.  Example:\nStyle[plot, Antialiasing -> True, Background -> Magenta]\n\n\n", "graphics - Inconsistent GraphicsRow behaviour": "\nGraphicsRow puts both plots into one GraphicsBox, which means they have to be rendered together.  Since the DensityPlot contains VertexColors it has to be rendered (on some platforms) using the 3D graphics renderer, whose support for Antialiasing is highly hardware dependent.\nContourPlot output normally renders with a 2D graphics engine.  DensityPlot normally renders with a 3D graphics engine.  When you group the two together (via GraphicsRow in this case) it forces them both to render with the 3D graphics engine, and that causes the ContourPlot to have a slightly different appearance.\nTake a look at this example, containing only the ContourPlot.  This code forces the ContourPlot to be drawn with a 2D renderer (in my case Quartz, since I'm using a Mac) in one window and a 3D renderer (OpenGL) in another window.  Observer the difference in appearance (at full size):\ng = ListContourPlot[\n   Table[Sin[i + j^2], {i, 0, 2, 0.05}, {j, 1.2, 2, 0.05}], \n   ColorFunction -> ColorData[\"AvocadoColors\"], Contours -> 10, \n   Mesh -> False, ImageSize -> 400];\n\nCreateDocument[g, CacheGraphics -> False, \n  \"NotebookRenderingEngine\" -> \"Quartz\"];\n\nCreateDocument[g, CacheGraphics -> False, \n  \"NotebookRenderingEngine\" -> \"OpenGL\"];\n\n\n", "plotting - Using GraphHighlight interactively": "\nThe reason why it fails is because of GraphHighlight. If you're highlighting a single vertex, then it expects an atom and not a list. In other words, it needs to be something like GraphicsHighlight -> 1 instead of GraphicsHighlight -> {1}. However, this is not the case for edges, where even a single edge can be supplied wrapped in a list. \nSo the culprit here is the {#2} in VertexShapeFunction -> (...), and all you need to do to fix it is remove the {}. The following code works.\nDynamicModule[{selection = {}},\n Dynamic[Graph[{1 \\[UndirectedEdge] 2, 2 \\[UndirectedEdge] 3, \n    3 \\[UndirectedEdge] 1}, PlotLabel -> selection,\n   VertexShapeFunction -> (EventHandler[Disk[#1, .1], \n       \"MouseClicked\" :> (selection = #2;)] &),\n   EdgeShapeFunction -> (EventHandler[Arrow[#1, .1], \n       \"MouseClicked\" :> (selection = #2;)] &), \n   GraphHighlight -> selection, GraphHighlightStyle -> \"Thick\", \n   ImageSize -> 200]]\n ]\n\n\n", "remote access - Are later versions of the Front-End compatible with older Kernels?": "\nThe best thing to do is to test whether you can make the connection manually:\nStart Mathematica on your local machine. \nOn the toolbar, navigate to Evaluation \u25ba Kernel Configuration Options.\nAdd a new kernel and configure it. In the dialog, click on Add ... and a Kernel Configuration dialog appears.\nEnter an appropriate name for your remote kernel.\nUnder Basic Options, verify that Launch On is set to Local machine. Additionally, clear the field, Kernel program.\nClick on the Advanced Options switch. In the text field called Arguments to MLOpen, enter:\n-LinkMode Listen -LinkProtocol TCPIP\n\nClick OK and open up a new Mathematica notebook.\nOn the toolbar, navigate to Evaluation \u25ba Notebook's Kernel and click on the name of the kernel that you just created.\nEvaluate the command:\n$Version\n\ninside the notebook. Instead of printing\nMathematica's version number, a message box appears:\nMathLink Alert\nLink created on:\n\nAfter this message is a string of characters. This string of characters is a linkname. Record the linkname so that you can use it later, and click OK to close the dialog.\nThe title bar of the notebook should still say Running... at the top.\nWhile, the local machine is still running that notebook, connect to the remote machine and launch the Mathematica kernel. Inside the kernel, run the command:\n$ParentLink = LinkConnect[\"linkname\", LinkProtocol->\"TCPIP\"]\n\nWhere \"linkname\" is the linkname you recorded earlier in quotation marks. For example, if the linkname you saw was:\nport1@machine.domain.com,port2@machine.domain.com\n\nYou would run:\n$ParentLink = LinkConnect[\n                \"port1@machine.domain.com,port2@machine.domain.com\",\n                LinkProtocol->\"TCPIP\"]\n\nThe notebook that is open on the local machine prints out the version of Mathematica you remotely connected to. This indicates that the local machine is successfully using the remote kernel.\n", "curated data - Why is Neptune missing from AstronomicalData?": "\nAstronomicalData was updated to remove Pluto, so you don't need to anymore.\nIn[27]:= AstronomicalData[\"Planet\"]\n\nOut[27]= {\"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\"}\n\n", "Correct way to handle mysterious NaN` result from MathLink function": "\nNaN (or Not-a-Number is used in floating point arithmetic to represent values that are undefined or unrepresentable, such as $0/0,\\ \\infty/\\infty$, etc. Mathematica typically returns Indeterminate for these, but several other languages return NaN.\nTo work with NaNs, you must load the ComputerArithmetic package as <<ComputerArithmetic` prior to calling your external function. If you don't do so, then Mathematica will treat the NaNs like any other symbol (or perhaps with other, unknown consequences depending on the setup). Loading the package will give you the results as expected, and pattern matching is pretty straightforward too.\n\n", "graphics - Visualizing Rubik's Graph": "\nI am not sure this is what you need.  Please see if it helps.  The little cubes are clickable, but not rotatable.  We could put nicely formatted edge labels as well, but I didn't want to do that now as it would slow it down even more.\nconf = solved;\n\nDynamic@Graph[\n  Join[\n   (conf -> twist[#, conf] &) /@ basic,\n   (twist[#, conf] -> conf &) /@ inv /@ basic\n   ],\n\n  VertexShapeFunction -> (Inset[\n      Button[Graphics3D[#2, Boxed -> False], conf = #2, \n       Appearance -> None], #1, {0.5, 0.5}, #3] &), VertexSize -> 1, \n  EdgeStyle -> Black]\n\n\nFor others than the OP reading this:\nYou need to download the source of the demonstration, copy everything from the Initialization :> ( ... ) section of the Manipulate, and evaluate it.  The code is very well written and very easy to work with.\n", "programming - What's the purpose of the Unique function?": "\nProbably the most common use of Unique is in situations when you need a large number of local variables (and sometimes a variable number of local variables) so using Module is either inconvenient or impossible. In that case you can use the construction:\nvars= Table[Unique[x],{n}] or something of this kind. You can find a few examples in the archives of the MathGroup. One that I remember being quite pleased with myself can be found here:\nhttp://mathforum.org/kb/thread.jspa?forumID=79&threadID=1185003&messageID=3868818\n", "functions - How to find range in which a number falls, from given list of numbers?": "\nInterpolation\nI propose using Interpolation.\nlist = Prime ~Array~ 3000;\nintf = Interpolation[\n         {list, Range@Length@list}\\[Transpose],\n         InterpolationOrder -> 0\n       ];\n\nThen, for point x:\nx = 12225.4;\n\nWhich[\n x < First@list , {-\u221e, First@list},\n x > Last@list  , {Last@list, \u221e},\n True           , list[[#-1 ;; #]]& @ intf @ x\n]\n\n\n{12211, 12227}\n\n\n\nThis could all be done inside Interpolation as well:\nintf2 =\n  Interpolation[\n    Join[\n      {{First@list, {-\u221e, 2}}},\n      Thread[{Rest@list, Partition[list, 2, 1]}],\n      {{Last@list + 1, {Last@list, \u221e}}}\n    ],\n    InterpolationOrder -> 0\n  ];\n\nintf2[12225.4]\n\n\n{12211, 12227}\n\n\n\nOrdering\nThe method above was written from the perspective of repeated searching within the same list, and as noted in the comments it is assumed that the input list is sorted and free of duplicates.\nIf these assumptions do not hold other methods become appealing.  After a review of others answers seeking inspiration, including those by kglr, celtschk and Leonid, I find Leonid's use of UnitStep to have great promise but his function is hobbled by the comparatively slow function Position.  We can replace it with a use of Ordering. \n\nThis function requires a sorted list as input, but including the overhead of Sort I still find it faster than other methods I tried such as a separate application of Ordering in an earlier revision of this answer.\nI use an explicit Subtract for performance.\n\nCode:\nseekOrdered[x_, list_] /; x < First @ list := {-\u221e, First @ list}\n\nseekOrdered[x_, list_] /; x >= Last @ list := {Last @ list, \u221e}\n\nseekOrdered[x_, list_] := \n  list[[# ;; # + 1]] & @@ Ordering[UnitStep @ Subtract[x, list], -1]\n\nHere are comparative timings including Leonid's getInterval, celtschk's function, and a variation of kglr's interval2 using Replace rather than ReplaceList to return a single interval (in the case of ambiguous matches) for somewhat better performance. (Credit to Ali Hashmi for noting this.)\nThe various functions I am comparing take slightly different interpretations of the end point behavior requested therefore output does not precisely match.  It should be possible to change the behavior of my function with a bit of tinkering should that be required for a particular application.\nThe other functions as I will be timing them:\ngetInterval[ints_List, num_] := \n  Position[UnitStep[ints - num], 1, 1, \n    1] /. {{{1}} -> {-Infinity, First@ints}, {} -> {Last@ints, Infinity}, {{n_}} :> \n     ints[[n - 1 ;; n]]};\n\nceltsF[x_, list_List] := \n Module[{pos = Last@Ordering@Ordering[Append[list, x]]}, \n  Which[pos == 1, {-Infinity, First@list}, \n   pos == Length[list] + 1, {Last@list, Infinity}, True, list[[{pos - 1, pos}]]]]\n\ninterval2fast[x_, list_List] := \n Replace[#, {___, a_, x, b_, ___} :> {a, b}] &@\n  Join[{-Infinity}, Sort[Join[list, {x}]], {Infinity}]\n\nBenchmark 1:\nlist = Prime ~Array~ 3000;\n\nxs = RandomInteger[{-100, 30000}, 5000];\n\ninterval2fast[#, list] & /@ xs;  // RepeatedTiming // First\ngetInterval[list, #] & /@ xs;    // RepeatedTiming // First\nceltsF[#, list] & /@ xs;         // RepeatedTiming // First\nseekOrdered[#, list] & /@ xs;    // RepeatedTiming // First\n\n\n1.25\n0.5890\n0.224\n0.114\n\nWith a packed input list:\nlist = Developer`ToPackedArray @ list;\n\n(* other code the same *)\n\n\n1.16\n0.5370\n0.129\n0.0689\n\nWith Reals rather than Integers for the search elements:\nxs = RandomReal[{-100, 30000}, 5000];\n\n(* other code the same *)\n\n\n1.54\n0.5674\n0.855\n0.0981\n\nWith Reals rather than Integers for the list:\nlist = Sort @ RandomReal[27000, 3000];\n\n(* other code the same *)\n\n\n1.88\n0.552\n0.129\n0.0895\n\nOf course for this repeated application Interpolation is faster still:\nintf2 /@ xs; // RepeatedTiming // First // Quiet\n\n\n0.0112\n\n", "sorting - How to generate Intervals from a given list?": "\nMaybe\nPartition[Sort@list, 2, 1]\n\ngiving\n\n{{1, 3}, {3, 4}, {4, 5}, {5, 7}}\n\n", "trigonometry - How to express trigonometric equation in terms of of given trigonometric function?": "\nThis is a new version of my answer in response to the edited question (the first version is here). \nIt is based on the same idea, but the Weierstrass substitution rules are now generated by Mathematica (instead of entered by hand) and results with $\\pm$ solutions are correctly returned.\nFirst, generate the Weierstrass substitution rules\n$TrigFns = {Sin, Cos, Tan, Csc, Sec, Cot};\n(WRules = $TrigFns == (Through[$TrigFns[x]] /. x -> 2 ArcTan[t] // \n      TrigExpand // Together) // Thread)\n\nThen, Partition[WRules /. Thread[$TrigFns -> Through[$TrigFns[x]]], 2] // TeXForm returns\n$$\n\\begin{align}\n \\sin (x)&=\\frac{2 t}{t^2+1}\\,, & \\cos (x)&=\\frac{1-t^2}{t^2+1}\\,, \\\\\n \\tan (x)&=-\\frac{2 t}{t^2-1}\\,, & \\csc (x)&=\\frac{t^2+1}{2 t}\\,, \\\\\n \\sec (x)&=\\frac{-t^2-1}{t^2-1}\\,, & \\cot (x)&=\\frac{1-t^2}{2 t} \\ .\n\\end{align}\n$$\nThen, we invert the rules using \ninvWRules = #[[1]] -> Solve[#, t, Reals] & /@ WRules\n\nwhich we can finally use in the convert function:\nconvert[expr_, (trig : Alternatives@@$TrigFns)[x_]] := \n Block[{temp, t},\n  temp = expr /. x -> 2 ArcTan[t] // TrigExpand // Factor;    \n  temp = temp /. (trig /. invWRules) // FullSimplify // Union;\n  Or @@ temp /. trig -> HoldForm[trig][x] /. ConditionalExpression -> (#1 &)]\n\nNote that the final line has HoldForm to prevent things like 1/Sin[x] automatically being rewritten as Csc[x], etc...\nHere are some test cases - it is straight forward to check that the answers are correct (but don't forget to use RelaseHold):\nIn[6]:= convert[Sin[x], Cos[x]]\nOut[6]= - Sqrt[1 - Cos[x]^2] || Sqrt[1 - Cos[x]^2]\n\nIn[7]:= convert[Sin[x]Cos[x], Tan[x]]\nOut[7]= Tan[x]/(1 + Tan[x]^2)\n\nIn[8]:= convert[Sin[x]Cos[x], Cos[x]]\nOut[8]= -Cos[x] Sqrt[1 - Cos[x]^2] || Cos[x] Sqrt[1 - Cos[x]^2]\n\nIn[9]:= convert[Sin[2x]Cos[x], Sin[x]]\nOut[9]= -2 Sin[x] (-1 + Sin[x]^2)\n\nIn[10]:= convert[Sin[2x]Tan[x]^3, Cos[x]]\nOut[10]= 2 (-2 + 1/Cos[x]^2 + Cos[x]^2)\n\n\nA couple of quick thoughts about the above solution:\n\nIt assumes real arguments for the trig functions. It would be nice if it didn't do this and could be extended to hyperbolic trig and exponential functions.\nWhen two solutions are given, it should return the domains of validity - or combine the appropriate terms using Abs[].\nIt should be extended to handle things like convert[Sin[x], Cos[2x]].\n\nIf anyone feels like implementing any of these things, please feel free!\n", "performance tuning - Can a Trie be implemented efficiently?": "\nUPDATE\nSince version 10, we have Associations. Here is the modified code for trie building and querying, based on Associations. It is almost the same as the old code (which is below):\nClearAll[makeTreeAssoc];\nmakeTreeAssoc[wrds : {__String}] := Association@makeTreeAssoc[Characters[wrds]];\nmakeTreeAssoc[wrds_ /; MemberQ[wrds, {}]] := \n    Prepend[makeTreeAssoc[DeleteCases[wrds, {}]], {} -> {}];\nmakeTreeAssoc[wrds_] := \n   Reap[\n     If[# =!= {}, Sow[Rest[#], First@#]] & /@ wrds, \n     _, \n     #1 -> Association@makeTreeAssoc[#2] &\n   ][[2]]\n\nYou can see that the only difference is that Association is added to a couple of places, otherwise it's the same code. The lookup functions also are very similar:\nClearAll[getSubTreeAssoc];\ngetSubTreeAssoc[word_String, tree_] := Fold[Compose, tree, Characters[word]]\n\nClearAll[inTreeQAssoc];\ninTreeQAssoc[word_String, tree_] := KeyExistsQ[getSubTreeAssoc[word, tree], {}]\n\nThe tests similar to the ones below (for entire dictionary) show that the lookup based on this trie (Associations - based) is about 3 times faster than the one based on rules, for a trie built from a dictionary. The new implementation of getWords is left as an exercise to the reader (in fact, that function could be optimized a lot, by storing entire words as leaves in the tree, so that one doesn't have to use StringJoin and combine the words).\n\nA combination of rules and recursion is able to produce rather powerful solutions. Here is my take on it:\nClearAll[makeTree];\nmakeTree[wrds : {__String}] := makeTree[Characters[wrds]];\nmakeTree[wrds_ /; MemberQ[wrds, {}]] := \n     Prepend[makeTree[DeleteCases[wrds, {}]], {} -> {}];\nmakeTree[wrds_] := \n    Reap[If[# =!= {}, Sow[Rest[#], First@#]] & /@ \n       wrds, _, #1 -> makeTree[#2] &][[2]]\n\nClearAll[getSubTree];\ngetSubTree[word_String, tree_] := Fold[#2 /. #1 &, tree, Characters[word]]\n\nClearAll[inTreeQ];\ninTreeQ[word_String, tree_] :=  MemberQ[getSubTree[word, tree], {} -> {}]\n\nClearAll[getWords];\ngetWords[start_String, tree_] :=\n  Module[{wordStack = {}, charStack = {}, words},\n    words[{} -> {}] :=\n      wordStack = {wordStack, StringJoin[charStack]};\n    words[sl_ -> ll_List] :=\n      Module[{},\n        charStack = {charStack, sl};\n        words /@ ll;\n        charStack = First@charStack;\n      ];\n    words[First@Fold[{#2 -> #1} &, getSubTree[start, tree], \n         Reverse@Characters[start]]\n    ];\n    ClearAll[words];\n    Flatten@wordStack];\n\nThe last function serves to collect the words from a tree, by performing a depth-first tree traversal and maintaining the stack of accumulated characters and words. \nHere is a short example:\nIn[40]:= words = DictionaryLookup[\"absc*\"]\nOut[40]= {abscess,abscessed,abscesses,abscessing,abscissa,abscissae,abscissas,\n   abscission,abscond,absconded,absconder,absconders,absconding,absconds}\n\nIn[41]:= tree = makeTree[words]\nOut[41]= {a->{b->{s->{c->{e->{s->{s->{{}->{},e->{d->{{}->{}},s->{{}->{}}},\n      i->{n->{g->{{}->{}}}}}}},i->{s->{s->{a->{{}->{},e->{{}->{}},s->{{}->{}}},\n        i->{o->{n->{{}->{}}}}}}},o->{n->{d->{{}->{},e->{d->{{}->{}},r->{{}->{},s->{{}->{}}}},\n       i->{n->{g->{{}->{}}}},s->{{}->{}}}}}}}}}}\n\nIn[47]:= inTreeQ[#,tree]&/@words\nOut[47]= {True,True,True,True,True,True,True,True,True,True,True,True,True,True}\n\nIn[48]:= inTreeQ[\"absd\",tree] \nOut[48]= False\n\nIn[124]:= getWords[\"absce\", tree]\nOut[124]= {\"abscess\", \"abscessed\", \"abscesses\", \"abscessing\"}\n\nI only constructed here a bare-bones tree, so you can only test whether or not the word is there, but not keep any other info. Here is a larger example:\nIn[125]:= allWords =  DictionaryLookup[\"*\"];\n\nIn[126]:= (allTree = makeTree[allWords]);//Timing\nOut[126]= {5.375,Null}\n\nIn[127]:= And@@Map[inTreeQ[#,allTree]&,allWords]//Timing\nOut[127]= {1.735,True}\n\nIn[128]:= getWords[\"pro\",allTree]//Short//Timing\nOut[128]= {0.015,{pro,proactive,proactively,probabilist,\n    <<741>>,proximate,proximately,proximity,proxy}}\n\nIn[129]:= DictionaryLookup[\"pro*\"]//Short//Timing\nOut[129]= {0.032,{pro,proactive,proactively,probabilist,<<741>>,\n    proximate,proximately,proximity,proxy}}\n\nI don't know which approach has been used for the built-in functionality, but the above implementation seems to be generally in the same calss for performance. The slowest part is due to the top-level tree-traversing code in getWords. It is slow because the top-level code is slow. One could speed it up considerably by hashing words to integers - then it can be Compiled. This is how I'd do that, if I were really concerned with speed.\nEDIT\nFor a really nice application of a Trie data structure, where it allows us to achieve major speed-up (w.r.t. using DictionaryLookup, for example), see this post, where it was used it to implement an efficient Boggle solver.\n", "performance tuning - Fastest square number test": "\nHere's an idea similar to Carl Woll's that's a little faster:\nsQ[n_] := FractionalPart@Sqrt[n + 0``1] == 0;\nsQa = FractionalPart@Sqrt[# + 0``1] == 0 &; (* @Roman's suggestion *)\n\n@Roman reports the pure function is 10% faster. I find on several runs of timeRun[] below, the variation in the timings cause them to overlap, with sQa sometimes timed slower than sQ. The median for sQa is around 5\u20136% faster. If I change AbsoluteTiming to Timing in timeRun[], sQ and sQa finish in a dead heat, \u00b12% of each other. Theoretically, I would expect pure functions to have less overhead, but it would be a small difference compared to the time Sqrt[n + 0``1] will take.  Maybe %5 is about right. It's difficult to time computations in a multiprocess environment like my laptop. The upshot is that sQa appears to be a bit faster.\n\nHere are some timing runs similar to @fgrieu's:\ntimeRun[f_] := Module[{a, m},\n  a = (2^1024 - 3^644)^2;\n  m = (2^1024 - 3^644)^2 + 9;\n  First@ AbsoluteTiming@ Do[f[n], {n, m - 200000, m}]\n  ]\n\ntimeRun2[f_] :=\n  First@ AbsoluteTiming[\n   Do[\n    f /@ (n^2 + {-2, -1, 0, 1, 2}),\n    {n, 2^1357, 0, -Floor[2^1357/99]}]\n   ];\n\nTests of a long sequence of consecutive integers about single large square number:\ntimeRun[sQ]\ntimeRun[SqQ]\ntimeRun[sqQ1]\ntimeRun[SquareQ2]\ntimeRun[SquareQ08]\n(*\n  0.626601  sQ\n  0.789668  SqQ (@fgrieu)\n  1.11774   sqQ1 (@CarlWoll)\n  1.63489   SquareQ2 (@Mr.Wizard)\n  3.39258   SquareQ08 (@KennyColnago)\n*)\n\nTests of short sequences of consecutive integers about many small to large square numbers:\ntimeRun2[sQ] \ntimeRun2[SqQ] \ntimeRun2[sqQ1] \ntimeRun2[SquareQ2] \ntimeRun2[SquareQ08] \n(*\n  0.002639   sQ\n  0.003289   SqQ\n  0.0039     sqQ1\n  0.005791   SquareQ2\n  0.01749    SquareQ08\n*)\n\nA test of just smaller numbers:\naa = 1; bb = 10^6;\nAbsoluteTiming@Do[sQ@(n), {n, aa, bb}]\nAbsoluteTiming@Do[SqQ@(n), {n, aa, bb}]\nAbsoluteTiming@Do[sqQ1@(n), {n, aa, bb}]\nAbsoluteTiming@Do[SquareQ2@(n), {n, aa, bb}]\nAbsoluteTiming@Do[SquareQ08@(n), {n, aa, bb}]\n(*\n  {2.34658, Null}\n  {3.2571,  Null}\n  {3.18561, Null}\n  {3.42899, Null}\n  {3.25997, Null}\n*)\n\n\nIf you want to verify its accuracy, you can test it against other solutions like this:\naa = 10^20 - 100; bb = aa + 10^3;\nTable[sQ[n], {n, aa, bb}] === Table[IntegerQ@Sqrt[n], {n, aa, bb}]\n(*  True  *)\n\naa = 1; bb = 10^6;\nTable[sQ[n], {n, aa, bb}] === Table[IntegerQ@Sqrt[n], {n, aa, bb}]\n(*  True  *)\n\n", "numerics - How to guarantee that NDSolve correctly detects abrupt changes in parameters?": "\nThere is an (undocumented?) feature of NDSolve which is handy for exactly this purpose: You can add more than just the start and end of the integration interval and enforce that these points will be met. The result is like you would run NDSolve on each of the corresponding intervals with the starting conditions given by the end point of the previous interval. This would do what you want for your example: \nvariation[x_?NumericQ] := Which[\n   x < 10, 1, x < 15, 0, x < 15.1, 10, x < 20, 0, x < 30, 1, True,0\n];\npoints = {};\nans = accumulation /. \n  Flatten[NDSolve[{accumulation'[x] == variation[x], \n     accumulation[0] == 0}, \n     accumulation, {x, 0, 10, 15, 15.1, 20, 30, 40}, \n     StepMonitor :> AppendTo[points, {x, accumulation[x]}]]];\n\nShow[\n Plot[ans[x], {x, 0, 40}],\n ListPlot[points, PlotStyle -> Red]\n]\n\n\n", "front end - Saving a notebook as PDF, preserving syntax highlighting": "\nThe default style sheets set ShowSyntaxStyles -> False for the \"Printout\" environment.\nYou could change the notebook to use a style sheet that doesn't set this.  Probably the easiest way is to copy the definition from Default.nb, and modify it:\nCell[StyleData[All, \"Printout\"],\n ShowSyntaxStyles->True]\n\n", "debugging - Inspecting non-variable state from a breakpoint in Workbench": "\nYou can enter arbitrary expressions in the Expressions debugging view:\n\nThe function VariableValue must be used in such expressions in order to access any active variables.\nIf the Expressions view is not visible, you can open it from the Workbench main menu using Window / Show View... / Expressions.\n", "output formatting - Converting a large floating-point number to a single-line string": "\nAdmittedly hackish, but you could use\nnumbers = RandomReal[10^10, 3]\n\nToString[ToString[#, CForm] & /@ numbers]\n\nor\nToString[ToString[#, FortranForm] & /@ numbers]\n\nIt gives\n{3.672422352722051e9, 8.491123505444411e9, 1.7587409493599138e9} \n\nMathematica usually likes to wrap long lines.  This won't happen here because by default ToString uses PageWidth -> Infinity\n", "notebooks - How to export to HTML and not lose Grid Frame in the generated HTML?": "\nFollowing my comment on your question, if you add\ntable\n{\nborder-collapse:collapse;\n}\ntable, td, th\n{\nborder:1px solid black;\n}\n\nat the beginning of the css file, you will get:\n\n", "parallelization - How can we implement \"Sleep Sort\"?": "\nHere is an implementation that uses the scheduled tasks in version 8:\nsleepSort[l_, t_:0.1] :=\n  Scan[RunScheduledTask[Print[#];RemoveScheduledTask[$ScheduledTask], {t #}]&, l]\n\nIn a notebook environment, output will appear in the messages window.  The time interval is specified as the optional second argument, defaulting to 1/10th of a second (I'm impatient).  Don't set it too low, though -- the vagaries of the timing might produce results out of order.\n", "document creation - Generating a table of contents": "\n\nA bit of warning from the OP: this code locked-up my Mathematica session, so be sure to save everything before you try this. Update: Problem seems to be related to a problem MMA has with paginating a particular notebook of mine (see comments).\n\nThis code creates a separate TOC for a notebook saved at the location bookUrl. It works by iterating over all the cells in the book. If a cell is encountered whose type is in typeList, a tag is added to the cell and a line is written to the TOC notebook. We use CounterBox[\"Page\", {bookUrl, tag}] to print the appropriate page number. \nNote that due to the nature of CounterBox, the page numbers are only shown in the TOC is the notebook of the book is open and ShowPageBreaks -> True is set, but you should be able to print the TOC to a pdf.\ncreateToc[bookUrl_, typeList_] :=\n  Module[{toc, book, createCell, counter, cell, type, tag},\n\n    (*create TOC file and open book*)\n    toc = CreateDocument[];\n    book = NotebookOpen[bookUrl];\n    SetOptions[book, ShowPageBreaks -> True];\n\n    (* helper file for creating cell *)\n    createCell[text_, tag_, level_] := Cell[BoxData[\n         TagBox[GridBox[{{\"\", text, CounterBox[\"Page\", {bookUrl, tag}]}},  \n           GridBoxAlignment -> {\"Columns\" -> {Left, Left, Right}}, \n           GridBoxItemSize -> {\"Columns\" -> {2 level - 1, 35 - 2 level, 5}}], \n          \"Grid\"]], \"Text\"];\n\n    (* iterate over cells to set tags and write lines to TOC *)\n    Scan[(counter[#] = 0) &, typeList];\n    SelectionMove[book, Before, Notebook];\n    SelectionMove[book, Next, Cell];\n    While[(cell = NotebookRead[book]) =!= {},\n      If[Length[cell] >= 2,\n       type = cell[[2]];\n       If[MemberQ[typeList, type],\n        counter[type] += 1;\n        tag = type <> ToString[counter[type]];\n        SetOptions[NotebookSelection[book], \n         CellTags -> Union[Flatten[{Options[NotebookSelection[book], \n           CellTags][[1, 2]], tag}]]];\n        SelectionMove[book, All, CellContents];\n        NotebookWrite[toc, \n         createCell[NotebookRead[book], tag, \n          Position[typeList, type][[1, 1]]]]];\n       SelectionMove[book, Next, Cell]]];\n    SetSelectedNotebook[toc]];\n\nTo see the code in action, lets create a very simple document with 2 sections and 3 subsections on 3 pages\nbook = CreateDocument[];\nNotebookWrite[book, Cell[\"This is section 1\", \"Section\"]];\nNotebookWrite[book, Cell[\"This is a subsection\", \"Subsection\"]];\nNotebookWrite[book, Cell[\"This is some text\", \"Text\"]];\nNotebookWrite[book, \n  Cell[\"Another section which begins on a new page\", \"Section\", \n   PageBreakAbove -> True]];\nNotebookWrite[book, \n  Cell[\"Subsection 2.1\", \"Subsection\", PageBreakBelow -> True]];\nNotebookWrite[book, Cell[\"Subsection 2.2\", \"Subsection\"]];\nbookUrl = ExpandFileName[\"book1.nb\"];\nNotebookSave[book, bookUrl];\n\nThen createToc[bookUrl, {\"Section\", \"Subsection\"}] creates something like this\n\n", "numerics - How to use NDSolve to track equilibrium?": "\nThis approach finds equilibrium by checking that all derivatives up to the order of the differential equation are below a threshold. Following the template (defined below) suggested by the OP, here is an example for a damped harmonic oscillator:\nNeeds[\"DifferentialEquations`InterpolatingFunctionAnatomy`\"];\n\neqns1 = {a''[t] == Pi^2/2500 - (Pi^2*a[t])/2500 - 0.02*a'[t], \n         a[0] == 0., a'[0] == 0};\n\nsteps1 = {};    \nsol1 = equilibriumNDSolve[eqns1, {a}, {t, 0, 1000}, a, \n                          equilibriumThreshold -> 1*^-5, \n                          equilibriumStepMonitor :> AppendTo[steps1, t]];\n\nend1 = InterpolatingFunctionDomain[a /. sol1[[1]]][[1, 2]];\nPlot[a[t] /. sol1, {t, 0, end1}, PlotRange -> {0, 2}, \n     Prolog -> {Thin, Dashed, Line[{{#, 0}, {#, 2}}] & /@ steps1[[1 ;; -1 ;; 2]]}, \n     PlotStyle -> Thick, AxesLabel -> {t, a[t]}]\n\nstops early (t=656.59), giving\n\nThe dashed vertical lines show the step monitor times. That is a 2nd order differential equation. The OP's example is a first order differential equation:\neqns2 = {Derivative[1][a][t] == -a[t] - 0.2` a[t]^2 + 2.1` b[t], Derivative[1][b][t] == a[t] + 0.1` a[t]^2 - 1.1` b[t], a[0] == 0.5`, b[0] == 0.5`};\n\nsteps2 = {};\nsol2 = equilibriumNDSolve[eqns2, {a, b}, {t, 0, 1000}, a + b, \n                          equilibriumThreshold -> 1*^-3, \n                          equilibriumStepMonitor :> AppendTo[steps2, t]];\nend2 = InterpolatingFunctionDomain[a /. sol2[[1]]][[1, 2]];\nPlot[Evaluate[{a[t], b[t]} /. sol2], {t, 0, end2}, PlotRange -> Automatic, \n     Prolog -> {Thin, Dashed, Line[{{#, 0}, {#, 1100}}] & /@ steps2}, \n     PlotStyle -> Thick, AxesLabel -> {t, Row[{a[t], \", \", b[t]}]}]\n\nuses a threshold of 1*^-3, and stops at t=465.234:\n\nHere is the definition of equilibriumNDSolve[]:\nClear[equilibriumNDSolve];\nOptions[equilibriumNDSolve] = {equilibriumThreshold :> 1*^-5, equilibriumStepMonitor -> None};\nequilibriumNDSolve[eqns_, vars_, {t_, start_, finish_}, equilibriumexpr_, opts : OptionsPattern[]] := \n  Module[{threshold, order},\n    threshold = OptionValue[equilibriumThreshold];\n    order = Max[Cases[eqns, Derivative[n_][_][_] :> n, Infinity]];\n    NDSolve[eqns, vars, {t, start, finish}, Method -> {\"EventLocator\", \n      \"Event\" -> And @@ ((Distribute@Abs[Through[\n         Distribute[Derivative[#][equilibriumexpr]][t], Plus]] <threshold) & /@    Range[order])}, \n      StepMonitor :> OptionValue[equilibriumStepMonitor]]]\n\nThe key part is the \"EventLocator\" method of NDSolve, as pointed out by Sjoerd and Szabolcs. \nThe function expects the stopping criterion (equilibriumexpr) to involve at most the addition of the NDSolve variables (more complicated expressions do not work as-is). The transformation of equilibriumexpr into an Event is not clean (i.e., not easy to follow), and may not be robust, but it works for the two cases above.\n", "front end - Programmatically copy code so that all output is commented out": "\nThis is inspired by Rolfs answer, but uses the \"Copy As Input\" functionality as the starting point. My impression is that using that approach will keep more of the original formatting (concerning linebreaks) but it still isn't perfect in that concern. To see the problems, I didn't change what it does to the its own code (it added some empty lines). \nOther differences are that it will look at the current selection instead of using all the content of the selected notebook. And it adds the spaces at the begining of each line so it will directly be recognized as code when pasted into the edit window. \nIt can't handle correctly anything except input and output cells that have an In/Out tag, otherwise the splitting in input and output cells will not work (although I think it will create something that's not completely useless in those cases...). \nCreatePalette[\n Tooltip[\n  Button[\n   \"Copy for MSE\",\n   FrontEndTokenExecute[SelectedNotebook[], \"CopySpecial\", \n    \"InputText\"];\n   Map[\n    CreateDocument[TextCell[#, \"Text\", FontFamily -> \"Courier\"]] &,\n    Cases[\n     NotebookGet[ClipboardNotebook[]],\n     Cell[c_String, ___] :> \"    \" <> StringReplace[\n        StringJoin[Riffle[\n          StringReplace[\n\n           StringTrim[\n            StringSplit[\n             c, (\"In\" | \"Out\") ~~ \"[\" ~~ DigitCharacter .. ~~ \"]\"]], {\n\n            StartOfString ~~ \":=\" ~~ WhitespaceCharacter ~~ input__ :>\n              input,\n\n            StartOfString ~~ \"=\" ~~ WhitespaceCharacter ~~ output__ :>\n              \"(*\\n==> \" <> output <> \"\\n*)\"\n            }\n           ],\n          \"\\n\\n\"\n          ]],\n        \"\\n\" -> \"\\n    \"\n        ],\n     Infinity\n     ]\n    ],\n   Method -> \"Queued\"\n   ],\n  \"Copy formatted for use in MSE\"\n  ],\n   Saveable -> False\n ]\n\n", "numerics - Strategies to avoid LessEqual::nord in NMinimize?": "\nI think you have to do the same as in many such cases: protect your arguments to be strictly numerical:\nf[a_?NumericQ, b_?NumericQ] := Abs[(a + I b)^(3/2)];\n\nAnd  then no problems:\nNMinimize[f[a,b],{a,b}]\n\n(*\n ==>  {1.11868*10^-26,{a->3.9489*10^-18,b->3.07007*10^-18}}\n*)\n\nEdit:\nThe following function automatically packs the expression into a function with _?NumericQ pattern arguments:\nNOptimize[optfunc_,expr_,vars_,options___]:=\n  Module[{f,\n          varlist=If[ListQ[vars],vars,{vars}],\n          expression=If[ListQ[expr],First@expr,expr],\n          conditions=If[ListQ[expr],Rest@expr,{}]},\n    Evaluate[f@@(Pattern[#,_?NumericQ]&/@varlist)]=expression;\n    optfunc[{f@@varlist}~Join~conditions,vars,options]]\n\nIt can be used as follows:\nNOptimize[NMinimize, a^2, a, AccuracyGoal->0.01]\n(*\n--> {2.39829*10^-33,{a->4.89724*10^-17}}\n*)\n\nor with constraints:\nNOptimize[NMinimize, {a^2, a>3}, a, AccuracyGoal->0.01]\n(*\n--> {9.,{a->3.}}\n*)\n\nThe following shows that it indeed solves the problem with LessEqual::Nord:\nNOptimize[NMinimize,Abs[(a+I b)^(3/2)],{a,b}]\n(*\n--> {9.06219*10^-27,{a->4.31982*10^-18,b->4.8223*10^-19}}\n*)\n\n", "numerics - What determines the value of $MaxNumber?": "\nIf you calculate  Log[2,Log[2,$MaxNumber]], you'll get 29.999999828017338886225739 which is remarkably close to 30. Therefore I conclude that Mathematica calculates with a 31-bit exponent (1 bit for the exponent's sign). Which means that if Mathematica uses the same ordering as IEEE floats (i.e. first sign bit, then exponent, then mantissa), the first 32 bits (i.e. exactly 4 bytes) of a Mathematica floating point number contain the sign and the exponent.\n", "import - Operations on online files via public URL access": "\nHere's one approach, though it's hard to say without knowing the site and what additional information you want for the files.\nImport[\"http://kaurov.com\", {\"HTML\", \"Images\"}]\n\n\nThere are several other items you can ask for (including what elements you can ask for!)\nIn[53]:= Import[\"http://kaurov.com\", {\"HTML\", \"Elements\"}]\n\nOut[53]= {\"Data\", \"FullData\", \"Hyperlinks\", \"ImageLinks\", \"Images\",\n\"Plaintext\", \"Source\", \"Title\", \"XMLObject\"}\n\nIn[54]:= Import[\"http://kaurov.com\", {\"HTML\", \"ImageLinks\"}]\n\nOut[54]= {\"http://kaurov.com/wordpress/wp-content/uploads/2011/10/masterimagelfss.jpg\",            \n   ...\n   \"http://kaurov.com/wordpress/wp-content/uploads/2009/11/life-death-spinner.gif\"}\n\n", "graphics - How can I share objects with dynamic content with non-Mathematica users?": "\nYou do not need to export an applet to be able to share things with non-Mathematica users. If you save your stuff as a CDF then other non-Mathematica people will be able to use it both on their desktops or view it in webpages (if you choose to embed your CDFs in a webpage). You can do this via File > Deploy\n\nSee also ref/format/CDF in the documentation center and the How To that is linked at the bottom.\nAlso some additional things that may help you:\n#1\n#2\n#3\n", "mathlink or wstp - Is it possible to use C# LINQ from Mathematica using .NET/Link?": "\nYes, it is, but it's cumbersome (at least as of Mathematica 8). The hardest part is that you have to manually do a lot of the juggling required to work with .NET generics and extension methods.\nFor example, let's translate a straightforward solution to Project Euler's Problem #1 (\"Add all the natural numbers below one thousand that are multiples of 3 or 5.\") from LINQ:\nEnumerable.Range(1, 999)\n.Where(x => x % 5 == 0 || x % 3 == 0)\n.Sum();\n\nTo .NET/Link:\n(* Load stuff. *)\n<< NETLink`;\nInstallNET[];\nLoadNETType[\"System.Linq.Enumerable\"];\n\n(* Create our enumerable list of numbers. *)\nnumbers = Enumerable`Range[1,999];\n\n(* Create the filter that we're going to apply. *)\nenumerableType = GetTypeObject[LoadNETType[\"System.Linq.Enumerable\"]];\nmeths = enumerableType@GetMethods[];\nwhereMethod = First[Select[meths, #@Name == \"Where\" && Length[#@GetParameters[]] == 2&]];\nintTypeParams = {GetTypeObject[LoadNETType[\"System.Int32\"]]};\nintWhereMethod = whereMethod@MakeGenericMethod[intTypeParams];\ndivisibleByThreeOrFive[n_] := Or[Mod[n, 3] == 0, Mod[n, 5] == 0];\nwhereCondition = NETNewDelegate[\"System.Func`2[System.Int32,System.Boolean]\", divisibleByThreeOrFive];\n\n(* Apply the filter to the list. *)\nfilteredNumbers = intWhereMethod@Invoke[Null, {numbers, whereCondition}];\n\n(* Pump all the results through the filter and Sum. *)\nEnumerable`Sum[filteredNumbers]\n\n", "string manipulation - What's a robust way to insert another extension into a filename?": "\nHere's my non-regex solution (but it does use a \"String Pattern\", which is equivalent to regex). I think it is robust.\ninsertExtension[fn_String, piece_String] := \n Module[{split = FileNameSplit[fn], temp},\n  temp = Insert[StringSplit[Last[split], \".\"], piece, 2];\n  temp = StringJoin[Riffle[temp, \".\"]];\n  FileNameJoin[Append[Most[split], temp]]]\n\nTest:\nIn[]:= insertExtension[\"/home/me.em/dir.ab/nomnom.tar.gz\", \"123\"]\n\nOut[]= \"/home/me.em/dir.ab/nomnom.123.tar.gz\"\n\n", "Is it possible to import dates and times directly as AbsoluteTime and by pass DateLists?": "\nThe data in the file test.xls are\n\n03/Jan/2000   45.46\n  04/Jan/2000   43.92\n  05/Jan/2000   44.38\n  06/Jan/2000   42.9\n  07/Jan/2000   43.46\n  10/Jan/2000   43.78\n  11/Jan/2000   42.65\n  12/Jan/2000   41.26\n  13/Jan/2000   42.04\n  14/Jan/2000   43.78\n\n\nAn alternative approach is to exploit the fact that Office documents are zipped collections of XML files. So, \nStep 1: rename the source file by adding .zip to the file name: test.xlsx.zip.\nStep 2: Import the appropriate xml file in the zip file, extract the data elements and re-format:\n Cases[Import[\"C:\\\\ your directory \\\\test.xlsx.zip\", {\"ZIP\", \"xl\\\\worksheets\\\\sheet1.xml\"}], \n  XMLElement[\"v\", {}, {value_}] :> value, Infinity] \n  // Partition[#, 2] &\n\nThis gives:\n\n{{\"36528\", \"45.46\"}, {\"36529\", \"43.92\"}, {\"36530\", \"44.38\"}, {\"36531\",\n     \"42.9\"}, {\"36532\", \"43.46\"}, {\"36535\", \"43.78\"}, {\"36536\", \n    \"42.65\"}, {\"36537\", \"41.26\"}, {\"36538\", \"42.04\"}, {\"36539\", \n    \"43.78\"}}\n\nwhere the first entry in each sublist is Excel's DATEVALUE (serial date number that counts the number of days from 1/1/1900). \nPuzzle: I would expect that converting Excel's DATEVALUE to Mathematica's AbsoluteTime (number of seconds from 1/1/1900) would be as simple as multiplying the former by 24*60*60. But doing that with:\n  excelDateValues = {\"36528\", \"36529\", \"36530\", \"36531\", \"36532\", \"36535\", \"36536\", \"36537\", \"36538\", \"36539\"}\n\nand \n  DateList /@ (24*60*60*ToExpression@excelDateValues)\n\ngives\n\n{{2000, 1, 5, 0, 0, 0.}, {2000, 1, 6, 0, 0, 0.}, {2000, 1, 7, 0, 0, 0.}, \n  {2000, 1, 8, 0, 0, 0.}, {2000, 1, 9, 0, 0, 0.}, {2000, 1, 12,  0, 0, 0.}, \n  {2000, 1, 13, 0, 0, 0.}, {2000, 1, 14, 0, 0, 0.}, {2000, 1, 15, 0, 0, 0.}, \n  {2000, 1, 16, 0, 0, 0.}}\n\n\nwhich is off by two days. Hopefully, there is a less naive approach to the get the right conversion factor to go from excel Datevalues to Mma AbsoluteTime so that a modified version of Cases[] above gives the desired result. \nPuzzle resolved:  Thanks to Mr.Wizard's reference, the historical background to the two-day discrepancy is explained beautifully in Joel Spolsky's great story  . So, unless your data does contain dates going back early 1900's for most cases just subtracting 2 from final output dates should be ok. But ... things can get more complicated considering possible excel date system settings and varying defaults accross OSs. (see XL 1900 and 1904 date systems)\nEDIT: Import uses the filename extension if no format is provided as the second argument. For zip files it returns the filenames in the zipped archive. For the example case\n   Import[\"C:\\\\ your directory \\\\test.xlsx.zip\"]\n\nreturns\n\n {\"[Content_Types].xml\", \"_rels\\\\.rels\",\"xl\\\\_rels\\\\workbook.xml.rels\", \"xl\\\\workbook.xml\", \"xl\\\\styles.xml\",  \"xl\\\\worksheets\\\\sheet1.xml\", \"xl\\\\theme\\\\theme1.xml\", \"customXml\\\\item1.xml\", \"customXml\\\\_rels\\\\item1.xml.rels\", \"customXml\\\\_rels\\\\item2.xml.rels\", \"docProps\\\\app.xml\", \"customXml\\\\itemProps2.xml\", \"customXml\\\\item2.xml\", \"customXml\\\\itemProps1.xml\", \"docProps\\\\core.xml\"}\n\n\n", "computational geometry - Intersecting graphics": "\nHow about RegionPlot?\nRegionPlot[\n  {\n   (x - 0.2)^2 + y^2 < 0.5 && 0 < x < 1 && 0 < y < 1,\n   (x - 0.2)^2 + y^2 < 0.5 && ! (0 < x < 1 && 0 < y < 1),\n   ! ((x - 0.2)^2 + y^2 < 0.5) && 0 < x < 1 && 0 < y < 1\n  }, \n   {x, -1, 1.5}, {y, -1, 1.5}, \n   PlotStyle -> {Red, Yellow, Blue}\n]\n\n\nEDIT in response to Szabolcs's comment:\nPointInPoly[{x_, y_}, poly_List] := \n Module[{i, j, c = False, npol = Length[poly]}, \n  For[i = 1; j = npol, i <= npol, j = i++, \n   If[((((poly[[i, 2]] <= y) && (y < \n             poly[[j, 2]])) || ((poly[[j, 2]] <= y) && (y < \n             poly[[i, 2]]))) && (x < (poly[[j, 1]] - \n             poly[[i, 1]])*(y - poly[[i, 2]])/(poly[[j, 2]] - \n              poly[[i, 2]]) + poly[[i, 1]])), c = \u00ac c];];\n  c]\n\n(from an answer I gave in MathGroup)\nRegionPlot[{\n   PointInPoly[{x, y}, {{1, 3}, {3, 4}, {4, 7}, {5, -1}, {3, -3}}] && \n   PointInPoly[{x, y}, {{2, 2}, {3, 3}, {4, 2}, {0, 0}}], \n   PointInPoly[{x, y}, {{1, 3}, {3, 4}, {4, 7}, {5, -1}, {3, -3}}] &&\n   \u00ac PointInPoly[{x, y}, {{2, 2}, {3, 3}, {4, 2}, {0, 0}}],\n   \u00ac PointInPoly[{x, y}, {{1, 3}, {3, 4}, {4, 7}, {5, -1}, {3, -3}}] &&\n   PointInPoly[{x, y}, {{2, 2}, {3, 3}, {4, 2}, {0, 0}}]}, \n  {x, 0, 6}, {y, -4, 8}, \n  PlotPoints -> 100, PlotStyle -> {Red, Yellow, Blue}\n]\n\n\n", "coding style - Placement of Condition /; expressions": "\nI prefer the Condition to appear on the left-hand-side and outside the square brackets for several reasons.\nType signature\nI often think of the condition as (part of) the analog of the signature in a typed language, so it should go on the left hand side.\nOrder of operations\nI like that the elements of the function definition appear in the order in which I want them to happen:\nf[x_] /; x > 0 := Sqrt[x]\n\n\nLook for f[x_].\nCheck that x > 0.\nReturn Sqrt[x].\n(Optional) Check any postcondition (see below).\n\nFunction contract\nWhen an argument-checking definition of the form\nf[else___] := Throw[\"Error in f.\"]\n\nappears, a left-hand-side Condition often plays the role of a precondition in the sense of Design By Contract. A Condition can also appear on the right-hand-side and this plays the role of a postcondition:\nf[x_] /; x > 0 := Sqrt[x] /; Sqrt[x] > 0\n\nConsistency of appearance\nI prefer f[x_] /; x > 0 to the alternative f[x_ /; x > 0] for consistency, because sometimes placing the Condition inside the square brackets is not possible, such as when the Condition depends on multiple arguments:\nf[x_, y_] /; x > y := 1/(x - y)\n\nUpdate: Rationale\nI think Brett's preference of putting the Condition as close as possible to the quantity to which it applies is equally good so I want to explain why I ended up with my slightly different preference.\nBasically I was writing a sequence of definitions like this, following Brett's guideline:\nf[x_ /; c1[x], y_] := this\nf[x_, y_ /; c2[y]] := that\nf[x_, y_] /; c3[x, y] := other\n\nNote that all of these define f[x, y]. So there are two things I didn't like about that:\n\nThe key difference between each LHS is the different conditions on x and y, and these are difficult to read quickly here because they all start at different places and are mixed in with f[x_, y_].\nWhen a condition needs to change such that it suddenly starts or stops depending on x or y, I need to move it from inside the square brackets to outside or vice versa.\n\nNow compare:\nf[x_, y_] /; c1[x] := this\nf[x_, y_] /; c2[y] := that\nf[x_, y_] /; c3[x, y] := other\n\nOf course, what would make even more sense would be to adhere to Brett's guideline except in special cases like above! Maybe I will try that now ...\n", "list manipulation - Unexpected behavior from GatherBy in version 7": "\nWe can compare the results of the two forms of GatherBy for varying data set sizes:\nRandomSeed[1];\nListPlot @ Table[\n  RandomInteger[4,{n,3}] /.\n  set_ :> { n\n         , Boole @ SameQ[\n             GatherBy[set, Sort]\n           , GatherBy[set, (\"x\";Sort@#)&]\n           ]\n       }\n, {n, 1, 300}\n]\n\nThe x-axis shows the set size and the y-axis shows 1 where the GatherBy results match and 0 where they do not.  The chart shows the set size on the x-axis and The results for Mathematica 7 show a problem when there are 100 or more elements:\n\nMathematica 8 does not show this problem:\n\nFollowing @ruebenko's suggestion, let's take a look for a compiler option with the magic number 100:\nCases[\"CompileOptions\" /. SystemOptions[], HoldPattern[_ -> 100]]\n\n\n{FoldCompileLength->100, MapCompileLength->100, NestCompileLength->100}\n\nSome experimentation demonstrates that MapCompileLength is the culprit:\nSetSystemOptions[\"CompileOptions\" -> \"FoldCompileLength\" -> 100];\nSetSystemOptions[\"CompileOptions\" -> \"MapCompileLength\" -> 50];\nSetSystemOptions[\"CompileOptions\" -> \"NestCompileLength\" -> 100];\n\nRecreating the chart after reducing MapCompileLength to 50 produces:\n\nIt appears we have a compiler bug involving the compilation of an internal use of Map -- a bug that seems to be fixed in Mathematica 8.\nIncreasing MapCompileLength to Infinity appears to correct the problem.\n", "programming - How do you set attributes on SubValues?": "\nYour question really is about how to make attributes of f affect also the evaluation of other groups of elements, like y and z in f[x___][y___][z___]. To my knowledge, you can not do it other than using tricks like returning a pure function and the like. \nThis is because, the only tool you have to intercept the stages of evaluation sequence when y and z are evaluated, is the fact the heads are evaluated first. So, anything you can do to divert the evaluation from its standard form (regarding y and z), must be related to evaluation of f[x], in particular substituting it by something like a pure function. Once you pass that stage of head evaluation, you have no more control of how y and z will be evaluated, as far as I know.   \nGenerally, I see only a few possibilities to imitate this: \n\nreturn a pure function with relevant attributes (as discussed in the linked answer)\nreturn an auxiliary symbol with relevant attributes (similar to the first route)\nplay with evaluation stack. An example of this last possibility can be found in my answer here\n\nHere is another example with Stack, closer to those used in the question:\nClearAll[f];\nf := \n  With[{stack = Stack[_]},\n   With[{fcallArgs =\n      Cases[stack, HoldForm[f[x_][y_]] :>\n         {ToString[Unevaluated[x]], ToString[Unevaluated[y]]}]},\n      (First@fcallArgs &) & /; fcallArgs =!= {}]];\n\nAnd:\nIn[34]:= f[1 + 2][3 + 4] // InputForm\nOut[34]//InputForm=  {\"1 + 2\", \"3 + 4\"}\n\nPerhaps, there are other ways I am not aware of. The general conclusion I made for myself from considering cases like this is that the extent to which one can manipulate evaluation sequence is large but limited, and once you run into a limitation like this, it is best to reconsider the design and find some other approach to the problem, since things will quickly get quite complex and go out of control.\n", "interoperability - Interfacing Mathematica with MINE using JLink": "\nYou don't need JLink for this, because MINE program (Java version) seems to not be able to transmit the results by any data transfer protocol. Rather, you launch it from the command line, as a Java executable (jar file). It takes the name of the input data file as one of the command line parameters, and it writes its output into another file. \nI will illustrate the steps needed to run it from Mathematica on Win7, but they should be similar on other systems.\n1.Download MINE.jar and an example file (say Spellman.csv), and save them in some directory. I saved them in a directory C:\\Temp\\MINE\n2.Find out the location of the Java runtime coming with Mathematica. One way to do this is to run \nNeeds[\"JLink`\"]\nInstallJava[]\n\n(* \n-->\n\nLinkObject[\"C:\\Program Files\\Wolfram Research\\Mathematica\\8.0\\SystemFiles\\Java\\\nWindows-x86-  64\\bin\\javaw\" -classpath ...\"]\n\n*)\n\n3.Define these directories:\n$MINEDir = \"C:\\\\Temp\\\\MINE\";\n$JavaDir = \"C:\\\\Program Files\\\\Wolfram Research\\\\Mathematica\\\\8.0\\\\SystemFiles\n\\\\Java\\\\Windows-x86-64\\\\bin\";\n\n4.Set the current directory to be the one with Java installation:\nSetDirectory[$JavaDir]\n\n5.Run this command (for example - this corresponds to an example they show):\nstringify[s__String] := StringJoin[\"\\\"\", s, \"\\\"\"]\n\nRun@StringJoin[\n  \"javaw -jar \",\n  stringify@FileNameJoin[{$MINEDir, \"MINE.jar\"}],\n  \" \",\n  stringify@FileNameJoin[{$MINEDir, \"Spellman.csv\"}],\n  \" 0 cv=0.7\"\n]\n\nIn practice, the string with parameters you will build dynamically, from the parameter values, of course. Since I don't have a good grasp on possible parameters and their values, I refrained from implementing this, but this is straightforward to do.  Note that stringify is only needed for Windows (probably), to prevent the Windows shell from mis-interpreting spaces. It should return 0 if executed correctly, and you should also see a command-line window popping up and floating for a second or two, that it takes to compute.\n6.This shows the data files:\nIn[8]:= (dataFiles = FileNames[\"*.csv\",{$MINEDir}])//InputForm\nOut[8]//InputForm=\n{\"C:\\\\Temp\\\\MINE\\\\Spellman.csv\", \n \"C:\\\\Temp\\\\MINE\\\\Spellman.csv,mv=0,cv=0.7,B=n^0.6,Results.csv\"}\n\nThe first one is the original data set. The last one contains the results. It should be possible to automate the identification of which is which.\n7.Import the results:\nIn[9]:= Import[\"C:\\\\Temp\\\\MINE\\\\Spellman.csv,mv=0,cv=0.7,B=n^0.6,Results.csv\"]//Short[#,3]&\n\nOut[9]//Short= {{X var,Y var,MIC (strength),MIC-p^2 (nonlinearity),MAS (non-monotonicity),\nMEV (functionality),MCN (complexity),Linear regression (p)},<<4380>>,{time,<<6>>,0.00775905}}\n\nIt should be possible to automate all that, this is just to show the basic steps. I must add that the program does not contain an awful lot of documentation, so figuring out the parameters etc may be not completely trivial.\n", "coordinate transformation - Plotting an implicit polar equation": "\nSince ContourPlot[] returns a GraphicsComplex, you could also replace the point list of the plot with g @@@ pointlist where g is the coordinate transformation. For example\nf[r_, th_] := th^2 - (3 Pi/4)^2 Cos[r]\ng[r_, th_] := {r Cos[th], r Sin[th]} \n\npl = ContourPlot[f[r, th] == 0, {r, 0, 8 Pi}, {th, 0, 2 Pi}, PlotPoints -> 30];\npl[[1, 1]] = g @@@ pl[[1, 1]];\n\nShow[pl, PlotRange -> All]\n\nwhich produces\n\nThe advantage of this method is that it also works for coordinate transformations for which the inverse transformation is hard to find.\n", "algebraic manipulation - How do I replace a variable in a polynomial?": "\nThe reason why the replacement doesn't work is that replacement rules are not mathematical replacements, but pure structural replacements. Therefore the replacement z^2->x just looks for occurrences of the pattern z^2 and replaces that with x. Now z^4 doesn't match that pattern.\nAlso note that rules operate on the internal form, which doesn't always match the displayed form. For example, one would expect a-2b /. 2b->c to result in a-c, but it actually results in a-2b again, because internally the expression reads Plus[a, Times[-2, b]] (you can see that by applying FullForm), while 2b is Times[2,b].\nTo do the replacement wanted, one has to use a method which is aware of the mathematics instead of just the structure. One possibility is\nSolve[p==z^4+z^2+4 && x==z^2, {p}, {z}]\n\nwhich means \"Solve the equations given for p while eliminating z\". The result then is\n{{p->4+x+x^2}}\n\nNote that the curly braces around z are mandatory because otherwise Mathematica interprets it as domain, resulting in an error message because z is of course no valid domain. Also note that the documentation page of Solve omits the possibility of giving a list of variables to eliminate as third argument (at least I didn't find it). However, you'll find it in a Mathematica tutorial on eliminating variables (but there they use the third argument without braces, which at least for me results in an error message, as written above).\n", "functions - What are the use cases for different scoping constructs?": "\nYou will find a lot of information in this answer. I will add a few personal notes.\nModule\nUse Module when you want to localize variables inside your function's body, and those variables will potentially acquire and/or change their values during the computation.\nBasic use\nFor example:\nf[x_]:=Module[{y=x^2},y=y+x;{x,y}]\n\nHere, a local mutable variable (symbol) y is local to the Module, and is, indeed, a symbol with a unique name. This is the closest you have in Mathematica to, say, local variables in C.\nAdvanced uses\nModule also has advanced uses. One of them is to create closures - functions with a persistent state. My third post in this thread illustrates many cases of that and has further references. One example I will steal from there:  the following function will produce the next Fibonacci number on demand, and yet it will be as fast as the iterative loop implementation for generation of consecutive Fibonacci numbers (since Module is invoked only once, when the function is defined):\nModule[{prev, prevprev, this}, \n   reset[] := (prev = 1; prevprev = 1); \n   reset[]; \n   nextFib[] := (this = prev + prevprev; prevprev = prev; prev = this)\n];\n\n \nreset[]; \nTable[nextFib[], {1000}]; // Timing \n\n(* \n  ---> {0.01, Null} \n*)\n\nOne problem with persistence created with Module-variables is that one should not generally serialize such state (definitions), for example by saving the state via Save or DumpSave. This is because, the uniqueness of names for Module-generated symbols is guaranteed only within a single Mathematica session.\nModule also allows one to create local functions, which With does not (except pure functions). This is a very powerful capability. It is particularly useful for writing recursive functions, but not only. In the link mentioned above, there were examples of this. One problem with local functions created by Module is that these symbols won't be automatically garbage-collected when Module finishes (if they have DownValues, SubValues or UpValues. OwnValues are fine), and so may lead to memory leaks. To avoid that, one can Clear these symbols inside Module before returning the result.\nWith\nUse With to define local constants, which can not be changed inside the body of your function.\nBasic use\nFor example,\nf[x_,y_]:=With[{sum = x+y},{sum *x, sum *y}]\n\nIt is instructive to trace the execution of f. You will notice that sum gets replaced by its value very early on, before the body starts evaluating. This is quite unlike Module, where variable entries get replaced by their values in the process of evaluation, just as it would normally happen were the variables global.\nAdvanced uses\nOn an advanced level, With can be used to inject some evaluated code deep into some expression which is otherwise unevaluated:\nWith[{x=5},Hold[Hold[x^2]]]\n\n(*\n    Hold[Hold[5^2]]\n*)\n\nand is thus an important meta-programming tool. There are lots of uses for this feature, in particular one can use this to inject code into Compile at run-time right before compilation. This can extend the capabilities / flexibility of Compile quite a bit. One example can be found in my answer to this question.\nThe semantics of With is similar to that of rule substitutions, but an important difference is that With cares about inner scoping constructs (during variable name collisions), while rules don't. Both behaviors can be useful in different situations.\nModule vs With\nBoth of these are lexical scoping constructs, which means that they bind their variables to lexical their occurrences in the code. Technically, the major difference between them is that  you can not change the values of constants initialized in With, in the body of With, while you can change values of Module variables inside the body. On a deeper level, this is because With does not generate any new symbols. It does all the replacements before the body evaluates, and by that time no \"constant symbols\" are at all present, all of them replaced with their values. Module, OTOH, does generate temporary symbols (which are normal symbols with an attribute Temporary), which can store a mutable state.\nStylistically, it is better to use With if you know that your variables are in fact constants, i.e. they won't change during the code execution. Since With does not create extra (mutable) state, the code is cleaner. Also, you have more chances to catch an occasional erroneous attempt in the code to modify such a constant.\nPerformance-wise, With tends to be faster than Module, because it does not have to create new variables and then destroy them. This however usually only shows up for very light-weight functions. I would not base my preference of one over another on performance boosts.\nBlock\nBasic use\nBlock localizes the value of the variable. In this example, a does not refer to i literally inside Block, but still uses the value set by Block.\na:=i\nBlock[{i=2},a]\n{a,i}\n\nBlock therefore affects the evaluation stack, not just the literal occurrences of a symbol inside the code of its body. Its effects are much less local than those of lexical scoping constructs, which makes it much harder to debug programs which use Block extensively. It is not much different from using global variables, except that Blockguarantees that their values will be restored to their previous values once the execution exits Block (which is often a big deal). Even so, this non-transparent and non-local manipulation of the variable values is one reason to avoid using Block where With and / or Module can be used. But there are more (see below).\nIn practice, my advice would be to avoid using Block unless you know quite well why you need it. It is more error-prone to use it for variable localization than With or Module, because it does not prevent variable name collisions, and those will be quite hard to debug. One of the reasons people suggest to use Block is that they claim it is faster. While it is true, my opinion is that the speed advantage is minimal while the risk is high. I elaborated on this point here, where at the bottom there is also an idiom which allows one to have the best of both worlds. In addition to these reasons, as noted by @Albert Retey, using Block with the Dynamic - related functionality may lead to nasty surprises, and errors resulting from that may also be quite non-local and hard to find.\nOne valid use of Block is to temporarily redefine some global system settings / variables. One of the most common such use cases is when we want to temporarily change the value of $RecursionLimit or $IterationLimit variables. Note however that while using Block[{$IterationLimit = Infinity}, ...] is generally okay, using  Block[{$RecursionLimit = Infinity}, ...] is not, since the stack space is limited and if it gets exhausted, the kernel will crash. A detailed discussion of this topic and how to make functions tail-recursive in Mathematica, can be found e.g. in my answer to this question.\nIt is quite interesting that the same ability of Block can be used to significantly extend the control the user has over namespaces/symbol encapsulation. For example, if you want to load a package, but not add its context to the $ContextPath (may be, to avoid shadowing problems), all you have to do is\nBlock[{$ContextPath}, Needs[Your-package]]\n\nAs another example, some package you want to load modifies some other function (say, System`SomeFunction), and you want to prevent that without changing the code of the package. Then, you use something like\nBlock[{SomeFunction}, Needs[That-package]]\n\nwhich ensures that all those modifications did not affect actual definitions for SomeFunction  - see this answer for an example of this.\nAdvanced uses\nBlock is a very powerful metaprogramming device, because you can make every symbol (including system functions) temporarily \"forget\" what it is (its definitions and other global properties), and this may allow one to change the order of evaluation of an expression involving that symbol(s) in non-trivial ways, which may be hard to achieve by other means of evaluation control (this won't work on Locked symbols). There are many examples of this at work, one which comes to mind now is the LetL macro from my answer to this question.\nAnother more advanced use of Block is to ensure that all used variables would be restored to their initial values, even in the case of Abort or exception happening somewhere inside the body of Block. In other words, it can be used to ensure that the system will not find itself in an illegal state in the case of sudden failure. If you wrap your critical (global) variables in Block, it will guarantee you this.\nA related use of Block is when we want to be sure that some symbols will be cleared at the end. This question and answers there represent good examples of using Block for this purpose.\nVariable name conflicts\nIn nested scoping constructs, it may happen that they define variables with the same names. Such conflicts are typically resolved in favor of the inner scoping construct. The documentation contains more details.\nBlock vs Module/With\nSo, Block implements dynamic scoping, meaning that it binds variables in time rather than in space. One can say that a variable localized by Block will have its value during the time this Block executes (unless further redefined inside of it, of course). I tried to outline the differences between Block and With/Module (dynamic vs lexical scoping) in this  answer.\nSome conclusions\n\nFor most common purposes of variable localization, use Module\nFor local constants, use With\nDo not ordinarily use Block for introducing local variables\nAll of the scoping constructs under discussion have advanced uses. For Module this is mostly creating and encapsulating non-trivial state (persistent or not). For With, this is mostly injecting inside unevaluated expressions. For Block, there are several advanced uses, but all of them are, well, advanced. I'd be worried if I found myself using Block a lot, but there are cases when it is indispensable.\n\n", "graphics - Undocumented form for FilledCurve[]": "\nThe first element in the triples seems to indicate the type of curve used for the segment where 0 indicates a Line, 1 a BezierCurve, and 3 a BSplineCurve. I haven't figured out yet what 2 does.\nEdit: When the first element of the triple is 2, the segment will be a BezierCurve similar to option 1 except that with option 2, an extra control point is added to the list to make sure that the current segment is tangential to the previous segment.\nThe second digit indicates how many points to use for the segment, and the last digit the SplineDegree. To convert the FilledCurve to a list of Graphics primitives, you could therefore do something like\nconversion[curve_] :=\n   Module[{ff},\n\n       ff[i_, pts_, deg_] :=\n           Switch[i,\n               0, Line[Rest[pts]],\n               1, BezierCurve[Rest[pts], SplineDegree -> deg],\n               2, BezierCurve[\n                   Join[{pts[[2]], 2 pts[[2]] - pts[[1]]}, Drop[pts, 2]], \n                   SplineDegree -> deg],\n               3, BSplineCurve[Rest[pts], SplineDegree -> deg]\n               ];\n\n       Function[{segments, pts},\n               MapThread[ff,\n                   {\n                       segments[[All, 1]],\n                       pts[[Range @@ (#1 - {1, 0})]] & /@\n                           Partition[Accumulate[segments[[All, 2]]], 2, 1, {-1, -1}, 1],\n                       segments[[All, 3]]\n                       }\n                   ]\n               ] @@@ Transpose[List @@ curve]\n       ]\n\nThen for the example in the original post, \ncurve = FilledCurve[{{{1, 4, 3}, {1, 3, 3}, {1, 3, 3}, {1, 3, 3}}}, \n  {{{10.9614, 7.40213}, {10.9614, 10.2686}, {8.51663, 12.3137}, \n   {5.79394, 12.3137}, {3.05663, 12.3137}, {0.641063, 10.2686}, \n   {0.641063, 7.40213}, {0.641063, 4.53319}, {3.05663, 2.48813}, \n   {5.79394, 2.48813}, {8.53125, 2.48813}, {10.9614, 4.51856}, \n   {10.9614, 7.40213}}}];\ncurve2 = conversion[curve]\n\ngives\n{BezierCurve[{{10.9614, 7.40213}, {10.9614, 10.2686}, {8.51663, \n    12.3137}, {5.79394, 12.3137}}, SplineDegree -> 3], \n BezierCurve[{{5.79394, 12.3137}, {3.05663, 12.3137}, {0.641063, \n    10.2686}, {0.641063, 7.40213}}, SplineDegree -> 3], \n BezierCurve[{{0.641063, 7.40213}, {0.641063, 4.53319}, {3.05663, \n    2.48813}, {5.79394, 2.48813}}, SplineDegree -> 3], \n BezierCurve[{{5.79394, 2.48813}, {8.53125, 2.48813}, {10.9614, \n    4.51856}, {10.9614, 7.40213}}, SplineDegree -> 3]}\n\nand Graphics[curve2] produces\n\n", "notebooks - How can I set a fixed cell height?": "\nThe cell dimensions are set by the option CellSize -> {width, height} which can be found in the category Cell Options > Inline Cell Options of the options inspector. One way to get there is to right-click on a cell bracket and select Properties near the bottom of the pop-up menu.\nEdit\nThis is what the cell looks like in my version of Mathematica (8.0.1 on OS X) after setting CellSize -> {Automatic, 50} of the output cell in the options inspector. The little blue square attached to the bottom of the bracket of the output cell is the resize handle. \n\n", "equation solving - Figuring when the minute and hour hand coincide on a clock": "\nI don't think it's necessary to use all the apparatus of Solve or Reduce here.\nWhen you think about it, at one o'clock, the hour hand is on the 1, which corresponds to five minutes. So the hands meet a little after five past one. The solution is therefore that $m = 60  (\\frac{h}{11})$. Someone else might show how this can be solved explicitly.\nHere is a short piece of code that finds the correct times and formats them nicely as \"HH:MM:ss.    \nDateString[{2012, 1, 23, #, 60. (# )/11}, {\"Hour12\", \":\", \"Minute\", \n\":\", \"Second\"}] & /@ Range[0, 11]\n\n\n{\"12:00:00\", \"01:05:27\", \"02:10:54\", \"03:16:21\", \"04:21:49\",\n  \"05:27:16\", \"06:32:43\", \"07:38:10\", \"08:43:38\", \"09:49:05\",\n  \"10:54:32\", \"12:00:00\"}\n\nEdit to include equation solving approach\nTo do this in a more complex situation that actually involves Solve, something along these lines would work:\nsoln = m /. First@Solve[30 h - 11 m /2 == 0, m, Reals]\n\n\n(60 h)/11\n\nAll the solutions are actually in the correct domain of $m$ when $h \\in\\{1,...,11\\}$, but here is what you would need to do to check this.\ntimes = Select[Table[{h, N@soln}, {h, 0, 11}], 0 .<= #[[2]] <= 60. &]\n\nConvert to date strings:\nstrings = DateString[Join[{2012, 1, 23}, #], {\"Hour12\", \":\", \"Minute\"}] & /@ \n  times\n\n\n{\"12:00\", \"01:05\", \"02:10\", \"03:16\", \"04:21\", \"05:27\", \"06:32\",\n  \"07:38\",\n  \"08:43\", \"09:49\", \"10:54\", \"12:00\"}\n\nConvert to the necessary angle units.\ndegrees = {1, -6 Degree}*# & /@ times\n\n\n{{0, 0.}, {1, -0.571199}, {2, -1.1424}, {3, -1.7136}, {4, -2.28479},\n  {5, -2.85599}, {6, -3.42719}, {7, -3.99839}, {8, -4.56959},\n  {9, -5.14079}, {10, -5.71199}, {11, -6.28319}}\n\n Graphics[{Circle[{0, 0}, 0.85], \n  MapThread[\n   Text[#1, {Cos[#2 + Pi/2], Sin[#3 + Pi/2]}] &, {strings, \n    degrees[[All, 2]], degrees[[All, 2]]}]}, ImageSize -> 250]\n\n\n", "list manipulation - Why don't * and ^ work as I expected on matrices?": "\nMatrices in Mathematica are nothing but a specific type of list of lists \u2014 specifically, a two dimensional list of lists.\n* is the short form for the Times function, which threads over lists elementwise, and this is what you'd use if you wanted to take the Hadamard product of two matrices. So when you say A*B, you're actually saying Times[A, B].\n. on the other hand, is short form for Dot, which lets you take the usual matrix products. So A.B is equivalent to Dot[A, B]. Both of these are different and it just boils down to understanding and remembering the short forms and the functions they represent.\nIf you're coming from a language like MATLAB, you might be confused at first, because * and ^ indeed do behave the way you described in that language. Although one should familiarize themselves with each language's differences, this might help you in remembering it \u2014 * and ^ behave exactly like .* and .^ respectively in MATLAB, in that they operate element wise.\nWhether it is intuitive or not depends on your personal preferences (and experience with other languages). In the same vein, you could also ask why Infix is ~, when MATLAB treats it as the not operator or throwaway variable, depending on how you use it :)\n", "programming - Distributing PlusMinus consistently": "\nHere's my shot, haven't tested it much yet, but it's pretty weird.\nFlattens out in NumericFunctions, I thought that made sense.\nClearAll[PlusMinus];\nModule[{PlusMinusList},\n SetAttributes[PlusMinus, {Flat, OneIdentity, NumericFunction}];\n SetAttributes[PlusMinusList, {Flat, OneIdentity}];\n PlusMinus[a_] := PlusMinusList[a, -a];\n PlusMinus[a_, b_] := PlusMinusList[a + b, a - b];\n PlusMinusList /: \n  h_Symbol?(MemberQ[Attributes[#], NumericFunction] &)[b___, \n   pm_PlusMinusList, a___] := \n  Block[{PlusMinusList}, h[b, #, a] & /@ pm];\n PlusMinusList[exp___] := {exp} /; Length@Stack[] === 4;\n PlusMinusList /: \n  h_?(Head[#] =!= Symbol || ! \n        MemberQ[Attributes[#], NumericFunction] &)[bef___, \n   PlusMinusList[pm___], aft___] := \n  h[bef, {pm}, aft];\n ]\n\nThe idea is that it splits the results not in a regular List but in a PlusMinusList, which flattens itself out. With UpValues, it distributes over NumericFunctions. Then I put a couple of weird definitions to turn the PlusMinusList into a List in two cases: when it's already in the highest level of the stack, and when it is wrapped up by a non numeric function.\nBut I'm already seing that it doesn't Flatten properly nested PlusMinus because it doens't have the NumericFunction Attribute\nEDIT\nI added the attribute NumericFunction to PlusMinus, and removed the condition \"/; h =!= PlusMinusList;\" which I think serves no purpose. Also added a line to consider the single argument case PlusMinus[x]\n", "programming - How can you give a Module a context and have its local variables and Modules belong to that context?": "\nHere is an idea:\nSetAttributes[account, HoldAll ]\n\nmakeAccount[ initBalance_ ] :=\n Module[ { balance = initBalance },\n  account[ balance ]\n  ]\n\naccount /: balance[ account[ bal_ ] ] := bal\n\naccount /: deposit[ account[ bal_ ], newBal_ ] := ( bal += newBal )\n\naccount /: withdraw[ account[ bal_ ], amount_ ] := ( bal -= amount ) /; \n  amount <= bal\naccount /: withdraw[ account[ bal_ ], amount_ ] := \n Print[ \"Save some cash first\" ] /; amount > bal\n\nFormat[ acc_account  /; ValueQ[ balance[ acc ] ] ] := \"-account-\"\n\nThen use this as:\na1 = makeAccount[100]\na2 = makeAccount[150]\n\nbalance[a1]\n\n100\ndeposit[a1, 100]\n\n200\nbalance[a1]\n\n200\nbalance[a2]\n\n150\nThis works because of the unique symbol:\nFullForm[a1]\n\nEdit:\nHere is a version without SetAttributes\nmakeAccount1[ initBalance_ ] :=\n\n Module[ { balance = initBalance , withdraw, deposit, amount, \n   dispatch},\n\n  withdraw[ amount_ ] :=\n   Module[ {},\n    If[ balance >= amount,\n     balance -= amount; balance,\n     Print[ \"Insufficient funds\" ] \n     ]\n    ];\n\n  deposit[ amount_ ] :=\n   Module[ {},\n    balance += amount; \n    balance\n    ];\n\n  amount[ amount_ ] :=\n   Module[ {},\n    balance\n    ];\n\n  dispatch[m_] :=\n   Which[\n    StringMatchQ[ m, \"withdraw\" ], withdraw,\n    StringMatchQ[ m, \"deposit\" ], deposit,\n    StringMatchQ[ m, \"amount\" ], amount,\n    (* else *)\n    True, Print[\"Unknown request -- MAKE_ACCOUNT \", m]\n    ];\n\n  Return[ dispatch ];\n  ]\n\nUse as follows:\nacc = makeAccount1[ 100 ] \nacc2 = makeAccount1[ 200 ] \n\ndispatch$99\ndispatch$100\nacc[  \"withdraw\" ][ 10 ]\n\n90\nacc2[ \"withdraw\" ][ 60 ]\n\n140\nacc2[\"amount\"][]\n\n140\n", "performance tuning - Function that caches when it returns unevaluated": "\nThe following definition of f uses an auxiliary symbol to cache all results, whether they meet the required condition or not:\nlongCalculation[x_] := (Print[\"calculating value for \", x]; x)\n\nModule[{cache}\n, m:cache[x_] := m = longCalculation[x]\n; f[x_] := Module[{r = cache[x]}, r /; r < 8]\n]\n\nHere is a sample use:\nIn[61]:= f /@ Mod[2Range[20], 10]\nDuring evaluation of In[61]:= calculating value for 2\nDuring evaluation of In[61]:= calculating value for 4\nDuring evaluation of In[61]:= calculating value for 6\nDuring evaluation of In[61]:= calculating value for 8\nDuring evaluation of In[61]:= calculating value for 0\nOut[61]= {2,4,6,f[8],0,2,4,6,f[8],0,2,4,6,f[8],0,2,4,6,f[8],0}\n\n", "programming - Is it possible to use Begin and End inside a Manipulate?": "\nShort answer: yes, it is possible.\nThe problem is that parsing is done line-by-line only for the top-level code. For code inside some head(s), it is first parsed as a whole. Therefore, your f is parsed to Global`f, and this is why that symbol is used. Here is what you can do, schematically:\nDynamicModule[{x = 5},\n With[{def = MakeBoxes[f[y_] := y^2 + 1;], ff = MakeBoxes[f]},\n   Block[{$ContextPath},\n     BeginPackage[\"obj`\"];\n     ReleaseHold[MakeExpression@ff];\n     Begin[\"`Private`\"];\n     ReleaseHold[MakeExpression@def];\n     End[];\n     EndPackage[]]\n ];\n {x, Date[], obj`f[1]}]\n\nWhat we do here is to delay the parsing (or, more precisely, the last stage of it)  of our definition until run-time, converting it first to boxes and thus preventing its premature parsing. I used a similar technique in my answer in this thread. We could have converted to strings, but I prefer boxes as being still \"on this side of Mathematica\".\nNote that a side effect of this code is that a symbol f is still created in the context which is current when the code executes (Global` here). If you want to avoid that, you could insert Remove[f]  before Block. I went all the way to use `Private` sub-context, to avoid polluting the current context with some auxiliary symbols created during assignments.\nYou can also automate this code with some meta-programming.\n", "equation solving - Why is FindInstance finding non-instances?": "\nYour understanding of Exists is wrong. Maybe the best way to explain Exists is by an example:\nFindInstance[Exists[y,x==y^2], x, Reals]\n(*\n--> {{x -> 0}}\n*)\n\nThis means you seek values of $x$ for which there exists a value for $y$ whose square equals $x$. Obviously $x=0$ is such a value because for $y=0$, we have $x=y^2$. However, $x=-1$ would not be such a value because there's no real number whose square is $-1$. Note especially that in the first argument of Exists, there are variables whose values you don't seek for ($y$ in my example).\nTo solve your problem, just remove the Exists:\nFindInstance[x > 1 && y > 1 && x > Sqrt[x + y], {x, y}]\n(*\n--> {{x -> 2, y -> 3/2}}\n*)\n\n", "number theory - Why does Mathematica claim there is no even prime?": "\nNote: I am not particularly knowledgable in the field of this question, so what I write below may well be wrong.\nI don't know whether or not this should be considered a bug, but to my mind this is an instance of a clash of programming and mathematical functionality. To put it differently, predicates (functions ending with Q) seem to be a wrong match for things like FindInstance or Resolve, because of their evaluation semantics. Functions suitable for mathematical transformations tend to return unevaluated when they don't know what to do, which gives the outer functions a chance to further transform them as expressions. OTOH, predicates will always return False immediately when they can not establish the the condition they check is True. \nBy using Trace[Exists[n,EvenQ[n]&&PrimeQ[n]]//Resolve, TraceInternal->True], one can see that at some point, both EvenQ and PrimeQ evaluate to False, and this is the reason for the result. Moreover, even a simpler request \nExists[n,EvenQ[n]]//Resolve\n(*  \n  -->  False\n*)\n\nHowever, this will work:\nFindInstance[IntegerPart[n/2]*2==n && n>1 &&n<4 ,n,Integers]\n\n(* \n --> {{n->2}}\n*)\n\nI wasn't able to make the original request work (I tried using Divisors, but no luck). But my point is that recasting the condition as a set of equations and/or inequalities may increase the chances of success here, because their evaluation semantics is that of the mathematical rather than programming functionality. The borderline seems to be quite blurred, but I think it is there.\n", "packages - Future-proofing access to packed array tools": "\nI don't think that Developer` is going to go away; there is too much (also internal) stuff depending on it. What I do at the beginning of a package:\npack = Developer`ToPackedArray;\npackedQ = Developer`PackedArrayQ;\n\nthen only use those; if anything changes then it's only one place I need to change it. On the other hand a re-factoring: of Developer`ToPackagedArray is not the end of the world.\nConcerning moving this to the kernel: unlikely. It has not been done in the past (for probably good reasons), why should it happen now. I don't think there is generally a way to classify stability of packages; if it is in the kernel, it is more stable than if it is in a package that you have to explicitly load.\n", "How to generate random directed acyclic graphs?": "\nNote that @halmir's solution does the same thing as described below, but much more concisely. I recommend using that approach.\n\nThe idea is that the graph is acyclic if and only if if there exists a vertex ordering which makes the adjacency matrix lower triangular\u00b9. It's easy to see that if the adjacency matrix is lower triangular, then vertex $i$ can only be pointing to vertex $j$ if $i<j$.\nSo let's generate a matrix which has zeros and ones uniformly distributed under the diagonal:\nvertexCount = 10;\nedgeCount = 30;\n\nelems = RandomSample@\n  PadRight[ConstantArray[1, edgeCount], \n   vertexCount (vertexCount - 1)/2]\n\nadjacencyMatrix = \n  Take[\n    FoldList[RotateLeft, elems, Range[0, vertexCount - 2]],\n    All,\n    vertexCount\n  ] ~LowerTriangularize~ -1\n\n(Thanks to @Mr.Wizard for the code that fills the triangular matrix!)\n\ngraph = AdjacencyGraph[adjacencyMatrix]\n\nAcyclicGraphQ[graph]\n\n(* ==> True *)\n\nLayeredGraphPlot will show you the acyclic structure in a \"convincing\" way:\n\n\nYou did not say it explicitly, but I assume you need a connected graph.  Unfortunately I have no algorithm that gives you a connected one, but you can keep generating them until you find a connected one by accident (brute force).  If the connectance is very low, and you get very few connected ones, you can try generating graphs with a slightly higher vertex count than the required one until the largest connected component has the required vertex count.\n\nPacked into a function for convenience:\nrandomDAG[vertexCount_, edgeCount_] /; \n  edgeCount < vertexCount (vertexCount - 1)/2 :=\n Module[\n   {elems, adjacencyMatrix},\n   elems = RandomSample@\n     PadRight[ConstantArray[1, edgeCount], vertexCount (vertexCount - 1)/2];\n   adjacencyMatrix = \n     Take[\n       FoldList[RotateLeft, elems, Range[0, vertexCount - 2]],\n       All,\n       vertexCount\n     ] ~LowerTriangularize~ -1;\n   AdjacencyGraph[adjacencyMatrix]\n ]\n\n\n\u00b9 You can find the ordering that makes the adjacency matrix triangular using a topological sort.\n", "Is the communication protocol underlying MathLink user-customizable?": "\nSeems entirely possible. I'd start by writing a stub for each end whose entire purpose is to echo MathLink traffic over your custom channel. Without doing any measurement, my first guess would be that you should use the existing shared memory protocol for the stub to connect to the MathLink peer on either end.\nAs I think about it more, the stubs don't really even need to understand the MathLink protocol at all. If you use TCP/IP on either end, and you have a way to tunnel TCP/IP over your custom channel (a la SSH port forwarding), you're all set and don't have to write any code.\n", "mathlink or wstp - Connecting to and disconnecting from a continuously running kernel, on demand": "\nWhy MathLink or webMathematica? (both quite time-consuming once you do something nontrivial)\nKeep it simple:\nOn Windows: Use Remote Desktop to connect to your server (where you started the FrontEnd, starting the parallel calculation).\nOn Linux: Use TightVNC or NX or some such.\n", "import - Plotting data with exponentials": "\nYou should be able to use ReadList on the string contents of each sublist. Here I'm just creating a small list containing three elements identical to the one you provided. The result can be plotted using ListPlot for example.\nIn[20]:= in = {{\"   7.9080000e+01   1.9283193e+04\"}, \n               {\"   7.9080000e+01   1.9283193e+04\"}, \n               {\"   7.9080000e+01   1.9283193e+04\"}};\n\nIn[22]:= Table[ReadList[StringToStream@First[i], Number], {i, in}]\n\nOut[22]= {{79.08, 19283.2}, {79.08, 19283.2}, {79.08, 19283.2}}\n\nEDIT: \nDue to the comments I should point out that this Table is going to produce an array that is not packed.  This means that the evaluator isn't aware ahead of time that all of the values are a particular type (namely real in this case) and so it is going to lean toward more general methods and is going to consume more memory to store the table. \nAs the documentation for Developer`ToPackedArray points out, using Developer`ToPackedArray will not change results generated by Mathematica, but can enhance speed of execution and reduce memory usage.\nIn order to pack the result we can simply use ruebenko's suggestion placing Developer`ToPackedArray@ in front of our Table.\nTESTING EDIT:\nI decided to test whether ImportString proposed by Mr. Wizard or the ReadList approach might be faster. In fairness I separated the ExportString out presuming that the string would already be saved somewhere for importing.  It appears that ReadList is much faster at least for the fabricated example I've created here.  I'd be curious to see if this is true for 500's data.\nIn[21]:= data = Table[\"   7.9080000e+01   1.9283193e+04\", {5000}];\n\nIn[22]:= Export[\"numbers.txt\", data];\n\nIn[23]:= in = Partition[ReadList[StringToStream@Import[\"numbers.txt\", \n              \"Plaintext\"], Record], 1];\n\nIn[24]:= (andyr = Table[ReadList[StringToStream@First[i], Number]\n                   , {i, in}]); // AbsoluteTiming\n\nOut[24]= {0.0780015, Null}\n\nIn[25]:= str = ExportString[in, \"Table\"];\n\nIn[26]:= (mrwiz = ImportString[str, \"Table\"]); // AbsoluteTiming\n\nOut[26]= {4.1340795, Null}\n\nIn[27]:= andyr === mrwiz\n\nOut[27]= True\n\nI should also point out that this comparison is only fair if we assume that the data is already in memory.  If not, the cost for Importing should be factored in to the ReadList approach.\n", "plotting - 1 Plot, 2 Scale/Axis": "\nThis can be done with Overlay if the ImagePadding and the horizontal range for each plot is the same. For example,\nplot1 = ListLinePlot[\n    Accumulate[RandomReal[{0, 1}, {100}]],\n    PlotStyle -> Blue,\n    ImagePadding -> 25,\n    Frame -> {True, True, True, False},\n    FrameStyle -> {Automatic, Blue, Automatic, Automatic}\n]\n\n\nplot2 = ListLinePlot[\n    Accumulate[RandomReal[{0, 100}, {100}]],\n    PlotStyle -> Red,\n    ImagePadding -> 25,\n    Axes -> False,\n    Frame -> {False, False, False, True},\n    FrameTicks -> {{None, All}, {None, None}},\n    FrameStyle -> {Automatic, Automatic, Automatic, Red}\n]\n\n\nOverlay[{plot1, plot2}]\n\n\nEdit: Cleared up which axis is which using FrameStyle.\n", "export - How to embed fonts when exporting Mathematica graphics as PDF": "\nWhat Verbeia said in her answer is not entirely correct \u2014 Mathematica indeed does embed the font, regardless of whether a particular font weight/slant exists or not. The real culprits are the PDF viewers on Macs, which do not use the base font if the specified weight is not available. It took some digging around to get to the reason though. The clues that led to my reasoning are as follows:\n\nMathematica knows what font it used when you re-import\nThis was the first clue. Executing Import[\"~/Desktop/Graphics.PDF\"] will correctly display the graphics in Papyrus font, albeit without the bold option (which, as Verbeia noted, doesn't exist in all fonts). So the information had to be in the file somewhere.\n\nThe binary file shows Papyrus embedded in it\nOpening the pdf in vim under hex mode, you find the font info embedded in it. What you see in the readable text on the right is the full copyright info, which they'd have to include only if it were embedded.\n\nIt opens correctly on linux systems\nPapyrus is not a font that comes installed by default with linux systems. The above file opens with the correct font (but not weight) on RHEL 6 and Ubuntu 11.10, which can only mean that the font is embedded in the pdf. Below is a screenshot in RHEL 6, with the same file opened in Adobe reader (left) and evince (right). \n\nHey, it opens perfectly in Adobe Reader!\nBelow is a screenshot of the same file opened in Adobe reader (left) and Preview.app (right). You can see that Adobe sure does know which font to use.\n\n\nSo you can see here that the problem is most likely with the PDF viewers on macs (other than Adobe reader). My guess is that they don't stay true to Adobe's specifications, and instead rely on OSX's Quartz framework for rendering the file, which is why you don't see the right font. \nEither that, or they don't like the fact that Mathematica uses PDF v1.4 to export its files. v1.4 is pretty old (2001), and it is worth mentioning (since you're embedding non-standard fonts) that PDF v1.4 does not support embedding \"Open Type\" fonts. That was introduced only in v1.6, and if you're working with such fonts, you might want to keep this in mind.\n", "functions - Error checking and trapping techniques with Throw and Catch": "\nI have answered almost exactly this question (somewhat more general one, if we interpret this one as being concerned only with Throw and Catch)  here. Since you asked a more narrow one, I feel it may be appropriate to borrow a part of my answer, to have it here.\nThe method\n\nThis method is IMO almost never appropriate for the top-level functions that are exposed to the user. Mathematica exceptions are not checked (in the sense of say checked exceptions in Java), and mma is not strongly typed, so there is no good language-supported way to tell the user that in some event exception may be thrown. However, it may be very useful for inner functions in a package. Here is a toy example:\nClearAll[ff, gg, hh, failTag];\nhh::fail = \"The function failed. The failure occured in function `1` \";\n\nff[x_Integer] := x^2 + 1;\nff[args___] := Throw[$Failed, failTag[ff]];\n\ngg[x_?EvenQ] := x/2;\ngg[args___] := Throw[$Failed, failTag[gg]];\n\nhh[args__] :=\n  Module[{result},\n   Catch[result = \n     gg[ff[args]], _failTag, (Message[hh::fail, Style[First@#2, Red]];\n      #1) &]];\n\nand some example of use:\nIn[219]:= hh[1]\nOut[219]= 1\n\nIn[220]:= hh[2]\nDuring evaluation of In[220]:= hh::fail: The function failed.\nThe failure occured in function gg \nOut[220]= $Failed\n\nIn[221]:= hh[1,3]\nDuring evaluation of In[221]:= hh::fail: The function failed. \nThe failure occured in function ff \nOut[221]= $Failed\n\nIt is important to never use a single-argument Throw - always use exception tags. I would go even further and say that in my opinion, the possibility to use Throw without a tag is a defect of the language.\nI found this technique very useful, because when used consistently, it allows to locate the source of error very quickly. This is especially useful when using the code after a few months, when you no longer remember all details.\nMeta-programming and automation\n\nYou may have noticed that lots of error-checking code is repetitive (boilerplate code). A natural thing to do seems to try automating the process of making error-checking definitions. I will give one example to illustrate the power of mma meta-programming by automating the error-checking for a toy example with internal exceptions discussed above.\nHere are the functions that will automate the process:\nGeneral::interr = \n \"The function `1` failed due to an internal error. The failure occured in function `2`\";\n\nClearAll[setConsistencyChecks];\nAttributes[setConsistencyChecks] = {Listable};\nsetConsistencyChecks[function_Symbol, failTag_] :=\n    function[___] := Throw[$Failed, failTag[function]];\n\n\nClearAll[catchInternalError];\nAttributes[catchInternalError] = {HoldAll};\ncatchInternalError[code_, f_, failTag_] :=\n  Catch[code, _failTag,\n    Function[{value, tag},\n      Message[General::interr , Style[f, Red], Style[First@tag, Red]];\n      value]]; \n\nThis is how our previous example would be re-written:\nClearAll[ff, gg, hh];\nModule[{failTag},\n  ff[x_Integer] := x^2 + 1;\n  gg[x_?EvenQ] := x/2;\n  hh[args__] := catchInternalError[gg[ff[args]], hh, failTag];\n  setConsistencyChecks[{ff, gg}, failTag]\n];\n\nYou can see that it is now much more compact, and we can focus on the logic, rather than be distracted by the error-checking or other book-keeping details. The added advantage is that we could use the Module- generated symbol as a tag, thus encapsulating it (not exposing to the top level). Here are the test cases:\nIn[34]:= hh[1]\nOut[34]= 1\n\nIn[35]:= hh[2]\n\nDuring evaluation of In[35]:= General::interr: The function hh failed \n    due to an internal error. The failure occured in function gg\nOut[35]= $Failed\n\nIn[36]:= hh[1,3]\n\nDuring evaluation of In[36]:= General::interr: The function hh failed \n    due to an internal error. The failure occured in function ff\nOut[36]= $Failed\n\nMany error-checking and error-reporting tasks may be automated in a similar fashion. For a more complete discussion of the error-checking, see the original answer I linked to.\nApplicability\n\nNow, why would you choose exceptions over, say, returning $Failed, or perhaps, some custom return codes which can be analyzed? One good reason to use exceptions is when you have long chain of function calls. Without exceptions,  we would need to  propagate $Failed or some other error codes through the entire chain of functions until we reach one which is in a position to make decision and / or execute some recovery code. This may add a lot of needless complexity to the code.\nAnother good reason is that since Mathematica is a functional programming language and emphasizes immutable code, functions normally don't have much state. Therefore, abrupt jump within an execution stack, which is what exception is, does not usually lead to system getting into an invalid state. In other world, most functions we write in Mathematica don't require any clean-up code to be executed when exception is thrown.\nYet another feature of this error-checking method, which I consider good, is that it takes a zero-tolerance approach to errors. If you use it consistently, any error inside the code will lead to a program failure, during the development stage. This makes code self-testing to a large degree. A similar effect can be achieved with assertions. If you are disciplined enough, it is best not to use exceptions in places where assertions  can and should be used. However, the two methods can complement each other, because you can only use assertions on rather specific conditions, while exceptions can be used as catch-all ones, and can also catch cases you missed when designing the assertions.\nIn some cases, returning $Failed is still more appropriate. In particular, this is so when there is a well-defined procedure of what to do on failure, and the chain of function calls from the place where error happens to the actual error-handling function is not long.\n", "graphics - Character edge finding": "\nI think there is a neat solution. We have curios function ListCurvePathPlot:\npic = Thinning@Binarize[GradientFilter[Rasterize[Style[\"\\[Euro]\", \nFontFamily -> \"Times\"], ImageSize -> 200] // Image, 1]];\n\npdata = Position[ImageData[pic], 1];\n\nlcp = ListCurvePathPlot[pdata]\n\n\nNow this is of course Graphics containing Line with set of points \nlcp[[1, 1, 3, 2]]\n\n\nSo of course we can do something like \nGraphics3D[Table[{Orange, Opacity[.5],Polygon[(#~Join~{10 n})&\n/@ lcp[[1, 1, 3, 2, 1]]]}, {n, 10}], Boxed -> False]\n\n\nI think it works nicely with \"8\" and Polygon:\npic = Thinning@Binarize[GradientFilter[\nRasterize[Style[\"8\", FontFamily -> \"Times\"], ImageSize -> 500] //Image, 1]]; \npdata = Position[ImageData[pic], 1]; lcp = ListCurvePathPlot[pdata]\n\n\nAnd you can do polygons 1-by-1 extraction:\nGraphics3D[{{Orange, Thick, Polygon[(#~Join~{0}) & /@ lcp[[1, 1, 3, 2, 1]]]},\n  {Red, Thick, Polygon[(#~Join~{1}) & /@ lcp[[1, 1, 3, 3, 1]]]},\n  {Blue, Thick, Polygon[(#~Join~{200}) & /@ lcp[[1, 1, 3, 4, 1]]]}}]\n\n\n=> To smooth the curve set ImageSize -> \"larger number\" in your pic = code.\n=> To thin the curve to 1 pixel wide use Thinning:\n Row@{Thinning[#], Identity[#]} &@Binarize[GradientFilter[\n Rasterize[Style[\"\\[Euro]\", FontFamily -> \"Times\"], \n ImageSize -> 200] // Image, 1]]\n\n\nYou can do curve extraction more efficiently with Mathematica. A simple example would be\ntext = First[\n   First[ImportString[\n     ExportString[\n      Style[\"\\[Euro] 9 M-8 \", Italic, FontSize -> 24, \n       FontFamily -> \"Times\"], \"PDF\"], \"PDF\", \n     \"TextMode\" -> \"Outlines\"]]];\n\nGraphics[{EdgeForm[Black], FaceForm[], text}]\n\n\n", "graphics - How can all those tiny polygons generated by RegionPlot be joined into a single FilledCurve?": "\nYou could start by extracting the Line primitives from the normalized GraphicsComplex:\na=36;\n\ng=RegionPlot[Mod[Sqrt[x^2+y^2]-7/2 ArcTan[x,y]+Sin[x]+Cos[y],Pi]<Pi/2,\n {x,-a,a},{y,-a,a},PlotPoints->100];\n\nlines=Cases[Normal[g], _Line, Infinity];\n\nThe lines can then be directly included in a FilledCurve:\nGraphics[{\n  EdgeForm@Directive[Black, Thickness[Medium]], \n  FaceForm@Directive[Opacity[1/2], Orange], \n  FilledCurve[List /@ lines]\n}]\n\n\nThis renders noticeably faster even within Mathematica (for example during resizing).\nThe structure of the FilledCurve must follow the FilledCurve[{{Line[...]}, {Line[...]}, ...}] pattern in order for the holes to show correctly.  Each line must be included in a separate sublist.\n\nIf each Line is included in a separate FilledCurve, then the holes will be missing:\nGraphics[FilledCurve/@lines]\n\n\nIf we use the FilledCurve[{Line[...], Line[...], ...}] structure, the lines will be effectively concatenated into one continuous line, causing artefacts:\nGraphics[FilledCurve[lines]]\n\n\n", "output formatting - Printing a string in a Mathematica script": "\nAnother option is to set FormatType -> OutputForm on the $Output stream:\nSetOptions[ $Output, FormatType -> OutputForm ];\nPrint[\"Hello\"];\n\nOr call OutputForm on the string itself:\nPrint[ OutputForm[\"Hello\"] ];\n\n", "dynamic - Usage Examples for DynamicWrapper": "\nSuppose we have a Graphics object which depends on some parameters and a controller with which we want to control these parameters. This could be done easily enough using the second argument of Dynamic, for example\ngr[pts_, col_, radius_] := Graphics[{col, Disk[#, radius] & /@ pts}, \n   PlotRange -> {{0, 3}, {0, 3}}, ImageSize -> 200];\n\ncontrl = {1, radius};\ncol = Blue; radius = .1;\npts = RandomReal[3, {10, 2}];\n\nGrid[{{Dynamic[Framed[gr[pts, col, radius]]], \n  Slider2D[Dynamic[cntrl, \n   (cntrl = #; col = Blend[{Red, Blue}, cntrl[[1]]]; radius = cntrl[[2]])&]]\n}}]\n\nHowever, suppose that we also want a switch which switches the coupling between the controller and the plot on and off. With DynamicWrapper this can be done by doing something like this\nGrid[{{Dynamic[Framed[gr[pts, col, radius]]], \n  Slider2D[Dynamic[cntrl]], \n  Toggler[\"Off\", {DynamicWrapper[\"On\", \n      col = Blend[{Red, Blue}, cntrl[[1]]]; radius = cntrl[[2]]], \n     \"Off\"}]\n }}]\n\n\nBy clicking on the label of the slider you can then toggle between coupling or no coupling. The same effect can be achieved without using DynamicWrapper for example\nDynamicModule[{state = \"Off\"}, \n  Grid[{{Dynamic[Framed[gr[pts, col, radius]]], \n    Labeled[Slider2D[Dynamic[cntrl,(cntrl = #; \n         If[state === \"On\", col = Blend[{Red, Blue}, cntrl[[1]]]; \n         radius = cntrl[[2]]]) &]], \n     Toggler[Dynamic[state], {\"On\", \"Off\"}], Top]\n  }}]\n]\n\nbut imho the DynamicWrapper solution is more elegant in this case.\n", "programming - How to close the front end so I can clear all Global variables?": "\nFrom your description you seem to have an open window containing Dynamic content, which is what prevents some variables being cleared by simply quitting the kernel (or rather they get redefined again). \nSo why don't you just close all windows containing any Manipulates or Dynamic and then use Quit[] (or Quit Kernel from the Evaluation menu) ? \nThe only menu command to quit the Front End is the \"Quit Mathematica\" menu item in the Mathematica menu, which will indeed work (in a rather radical way) until you reopen the same notebooks that caused the problem to start with. \n", "packages - Why is JLink loaded every time I start Mathematica?": "\nAs far as I know, JLink is used at least in PacletManager`, for operations like loading data on demand etc. The documentation system also uses Java. Perhaps, other uses as well. I don't think that Java is used a lot for the core language though. \nThis code can make it a bit more quantitative:\nallNames = Flatten[Names[#<>\"*\"]&/@Contexts[]];\nQuiet@Select[\n  Select[allNames,!StringMatchQ[Context[#],\"JLink`\"~~___]&],\n  MemberQ[\n    Union@Cases[\n             ToExpression[#,InputForm,DownValues],\n             s_Symbol/;!MatchQ[Unevaluated[s],HoldPattern[Symbol[_]]]:>Context[s],\n             Infinity,\n             Heads->True\n    ],\n    c_String/;StringMatchQ[c,\"JLink`\"~~___]\n  ]&\n]//Short[#,5]&\n\nOut[59]//Short= {com`wolfram`documentationsearch`DocumentationSearcher`closeSearcher,\ncom`wolfram`documentationsearch`DocumentationSearcher`closeSearchers,\ncom`wolfram`documentationsearch`DocumentationSearcher`getParser,   \n <<291>>,PacletManager`Utils`Private`DumpPacletSites, Assert,SystemInformation}\n\nAnd this is only in contexts that were loaded in my session, plus probably the ReadProtected functions were not searched, and I only looked at DownValues. Some of these names are names for symbols that JLink generates to map to Java classes, but others are true Mathematica functions. So, I think one can safely say that Mathematica critically depends on Java.\n", "deployment - How to install packages?": "\nNote: This answer was originally written with package authors in mind, aiming to provide a user-friendly way to distribute packages and provide installation instructions. If your aim is user convenience, today you should be using paclets instead.\n\nI think that the menu item File -> Install... is very convenient, even for power users.  The only problem is that there is no uninstall option.  However, if the package consists of a single file, upgrading is easy: the old file will be overwritten with the new file.\nYou can write some simple instructions for users:\n\nOpen the .m file you sent them\nChoose File -> Install...\nChoose Type -> Package, Source -> (the open notebook), Install Name -> SomePackage\nLoad the package by evaluating <<SomePackage` .\n\nThe only thing that can go wrong is that they mistype the install name.\nThe Install... menu item will put the package into\nFileNameJoin[{$UserBaseDirectory, \"Applications\"}]\n\nwhich on Windows is\n%appdata%\\Mathematica\\Applications\n\n(Press Win-R and type the above to get to that directory.)\nWhen necessary, the package file can be deleted from that directory.\nThis is the usual way I install and upgrade palettes myself.\n\nPutting packages into the Mathematica installation directory is not really advantageous because they will get lost when Mathematica is upgraded (for example, from 8.0.1 to 8.0.4).  Instead they can be put into $BaseDirectory/Application (for all users) or $UserBaseDirectory/Application (for the current user).  This is what the Install... menu item does.\n\nIt seems that the Install... menu item can deal with multi-file packages too.  \"Type of Item to Install\" should be set to \"Applications\", \"Source\" -> \"From File...\" and the package files need to be inside an archive (.zip file).  I have not used this personally, so I have no experience with it (e.g. about what happens on upgrade).\n\n@AlbertRetey noted below that the Wolfram Player Pro does not have this menu item at all.  The only way to install packages into it is to do it manually or create a script that does it.\n", "mathlink or wstp - Specifying the ports used by LinkCreate or LinkLaunch": "\nIf you want to use port forwarding, you'll need to know that for every MathLink connection, two different ports are used.  The full syntax for TCPIP link names looks like this:\nLinkCreate[\"8000@1.2.3.4,8001@1.2.3.4\", LinkProtocol -> \"TCPIP\"]\n\n8000 and 8001 are the port numbers while 1.2.3.4 is your IP address.  You can pass only a single port number to LinkCreate as the link name: in this case it will return a LinkObject containing the full name and the other port will be automatically selected.\n\nHowever, if you want to use SSH port forwarding, I strongly recommend using the Remote Kernel Strategies package.  It will save you a lot of trouble.  For example, it will automatically forward ports for all three links that Mathematica needs for Front End - Kernel communication ($ParentLink, MathLink`$PreemptiveLink and MathLink`$ServiceLink).  The other two links are created by the kernel when the front end connects to it by executing the code in the file SystemFiles/FrontEnd/TextResources/GetFEKernelInit.tr.\nPlease see the presentation I linked to for more information on how the connection is made and why three links are needed.\n", "Code Golf: Least Common Multiple": "\nI am not sure how this compares in terms of length but it does not throw errors and isn't even obfuscated:\nlcm[ls__] := \n Fold[Denominator[Together[Unique[x]/#1 + Unique[x]/#2]] &, \n  First[{ls}], Rest[{ls}]\n\nJust to check it works:\nf = RandomInteger[{1, 100}, 200];\n\nlcm @@ f == LCM @@ f\n\n\nTrue\n\n\n", "programming - Using NETLink.MathKernel.Compute() for graphics results fails with GraphPlot[]": "\nI think your problem is that Graph will actually not evaluate to a Graphics but only be rendered as something like that by the FrontEnd. You could look at ToBoxes[yourgraph] to learn some details and try to extract something that can be transfered to .NET. I don't have any experience with NETLink, but I remember that at least older versions of JLink would return graphics as rastered images anyway, so a more simple approach could be to use \nRasterize[GraphPlot[{1 -> 2, 2 -> 1, 3 -> 1, 3 -> 2, 4 -> 1, 4 -> 2, 4 -> 4}]]\n\nYou might want to finetune this with the options of Rasterize to meet your needs.\n", "front end - How to Keep Input Cells Hidden After Evaluating Notebook": "\nAutoCollapse[] function\nPlease try this code, based on Sasha's adaption of my own answer to this question.\nAutoCollapse[] := (\n  If[$FrontEnd =!= $Failed, \n   SelectionMove[EvaluationNotebook[], All, GeneratedCell];\n   FrontEndTokenExecute[\"SelectionCloseUnselectedCells\"]])\n\nThen in a new cell:\n2 + 2\nAutoCollapse[]\n\nAlways place AutoCollapse[] as the last line of an Input cell.\nStylesheets\nTo get the behavior without having to include AutoCollapse[] in each cell you can use Stylesheets and CellEpilog.  For example to create an InputHidden style use menu Format > Edit Stylesheet... and then add a Cell with the following code (use Ctrl+Shift+E to edit Cell code):\nCell[StyleData[\"InputHidden\", StyleDefinitions -> StyleData[\"Input\"]],\n CellEpilog :> (SelectionMove[EvaluationNotebook[], All, GeneratedCell]; \n   FrontEndTokenExecute[\"SelectionCloseUnselectedCells\"]),\n MenuSortingValue -> 1510\n , MenuCommandKey -> \"8\"\n]\n\n\nThis creates a new style that behaves like Input but which auto-collapses when evaluated.  MenuCommandKey -> \"8\" lets it be quickly applied using Alt+8; change or remove this line as desired.\n\nI may be reading more into your question than is there.  As Heike points you can close the input cells manually by deselecting menu Cell > Cell Properties > Open but I assumed you knew this already and provided the soluition(?) above.  If all you need is a hidden cell that generates output, use the menu.  If you need something a little more flexible that automatically hides after you make your changes I hope you will find the methods above useful.\n", "programming - How to eliminate the need to double evaluate a Manipulate so that a Module in its Initialization section works?": "\nStill not sure whether this is what you intended, but if you keep initialization stuff within the Initialization things seem to behave well:\nManipulate[x;\n get[obj],\n Button[\"run\", x++],\n {x, None},\n {{obj, None}, None},\n TrackedSymbols :> {x},\n Initialization :> (\n   makeObj[] := Module[{obj, u},\n     init[obj] ^:= u = {1, 2, 3};\n     get[obj] ^:= {obj, u, Date[]};\n     obj\n     ];\n   obj = makeObj[];\n   init[obj];\n   )\n ]\n\nI have seen that Faysal Aberkane has given an explanation what goes wrong in the first place. I just had prepared a piece of code which shows you in which order the various parts are evaluated, so I thought I'll share it, although it doesn't add anything new:\nManipulate[\n WriteString[$Output, \"body\\n\"];\n x,\n Button[\"run\", x++],\n {x, None},\n {{obj, Print[\"var. init\"]}, None},\n TrackedSymbols :> {x},\n Initialization :> {\n   Print[\"Initialization option\"]\n   }\n ]\n\nHere is another try which only uses frontend owned variables:\nManipulate[x;\n \"init\"[obj];\n \"get\"[obj],\n Button[\"run\", x++],\n {x, None},\n {u, None},\n {obj, None},\n TrackedSymbols :> {x},\n Initialization :> (\n   obj =.;\n   \"init\"[obj] ^:= u = {1, 2, 3};\n   \"get\"[obj] ^:= {obj, Hold[u], u, Date[]};\n   )\n ]\n\n", "plotting - I'd like to display field lines for a point charge in 3 dimensions": "\nThis is something I have used for my classes. Over time, I've tried to make it more and more user friendly, but that's also made it a little longish. I'll post the complete set of functions, with apologies if it's a bit unwieldy...\nAs you'll see, I found it does indeed work better in my use cases if I normalize the field, so that we advance along the field lines in more balanced steps. The hardest part in applying these functions is to choose the appropriate seed points.\nfieldSolve::usage = \n  \"fieldSolve[f,x,x0,\\!\\(\\*SubscriptBox[\\(t\\), \\(max\\)]\\)] \\\nsymbolically takes a vector field f with respect to the vector \\\nvariable x, and then finds a vector curve r[t] starting at the point \\\nx0 satisfying the equation dr/dt=\\[Alpha] f[r[t]] for \\\nt=0...\\!\\(\\*SubscriptBox[\\(t\\), \\(max\\)]\\). Here \\[Alpha]=1/|f[r[t]]| \\\nfor normalization. To get verbose output add debug=True to the \\\nparameter list.\";\n\nfieldSolve[field_, varlist_, xi0_, tmax_, debug_: False] := Module[\n  {xiVec, equationSet, t},\n  If[Length[varlist] != Length[xi0], \n   Print[\"Number of variables must equal number of initial conditions\\\n\\nUSAGE:\\n\" <> fieldSolve::usage]; Abort[]];\n  xiVec = Through[varlist[t]];\n  (* Below, Simplify[equationSet] would cost extra time \n    and doesn't help with the numerical solution, so   don't try to simplify. *)\n\n  equationSet = Join[\n    Thread[\n     Map[D[#, t] &, xiVec] == \n      Normalize[field /. Thread[varlist -> xiVec]]\n     ],\n    Thread[\n     (xiVec /. t -> 0) == xi0\n     ]\n    ];\n  If[debug, \n   Print[Row[{\"Numerically solving the system of equations\\n\\n\", \n      TraditionalForm[(Simplify[equationSet] /. t -> \"t\") // \n        TableForm]}]]];\n  (* This is where the differential equation is solved. \n  The Quiet[] command suppresses warning messages because numerical precision isn't crucial for our plotting purposes: *)\n\n  Map[Head, First[xiVec /.\n     Quiet[NDSolve[\n       equationSet,\n       xiVec,\n       {t, 0, tmax}\n       ]]], 2]\n  ]   \n\nfieldLinePlot[field_, varList_, seedList_, opts : OptionsPattern[]] :=\n   Module[{sols, localVars, var, localField, plotOptions, \n    tubeFunction, tubePlotStyle, postProcess = {}}, \n   plotOptions = FilterRules[{opts}, Options[ParametricPlot3D]];\n   tubeFunction = OptionValue[\"TubeFunction\"];\n   If[tubeFunction =!= None,\n    tubePlotStyle = Cases[OptionValue[PlotStyle], Except[_Tube]];\n    plotOptions = \n     FilterRules[plotOptions, \n      Except[{PlotStyle, ColorFunction, ColorFunctionScaling}]];\n    postProcess = \n     Line[x_] :> \n      Join[tubePlotStyle, {CapForm[\"Butt\"], \n        Tube[x, tubeFunction @@@ x]}]\n    ];\n   If[Length[seedList[[1, 1]]] != Length[varList], \n    Print[\"Number of variables must equal number of initial \\\nconditions\\nUSAGE:\\n\" <> fieldLinePlot::usage]; Abort[]];\n   localVars = Array[var, Length[varList]];\n   localField = \n    ReleaseHold[\n     Hold[field] /. \n      Thread[Map[HoldPattern, Unevaluated[varList]] -> localVars]];\n   (*Assume that each element of seedList specifies a point AND the \\\nlength of the field line:*)Show[\n    ParallelTable[\n     ParametricPlot3D[\n         Evaluate[\n          Through[#[t]]], {t, #[[1, 1, 1, 1]], #[[1, 1, 1, 2]]}, \n         Evaluate@Apply[Sequence, plotOptions]\n         ] &[fieldSolve[\n        localField, localVars, seedList[[i, 1]], seedList[[i, 2]]\n        ]\n       ] /. postProcess, {i, Length[seedList]}\n     ]\n    ]\n   ];\n\nOptions[fieldLinePlot] = \n  Append[Options[ParametricPlot3D], \"TubeFunction\" -> None];\n\nSyntaxInformation[fieldLinePlot] = {\"LocalVariables\" -> {\"Solve\", {2, 2}}, \n   \"ArgumentsPattern\" -> {_, _, _, OptionsPattern[]}};\n\nSetAttributes[fieldSolve, HoldAll];\n\nThe main function is fieldLinePlot, but I split it into two functions to be more modular. Also, the problem of where to start drawing the field lines is treated separately because it depends a lot on the particular application.\nfieldSolve[f,x,x0,Subscript[t, max]] symbolically takes a vector field f with respect to the vector variable x, and then finds a vector curve r[t] starting at the point x0 satisfying the equation dr/dt = \u03b1 f[r[t]] for t=0...tmax. Here \u03b1 = 1/|f[r[t]]| for normalization. To get verbose output add debug=True to the parameter list.\nfieldLinePlot[field,varlist,seedList] plots 3D field lines of a vector field (first argument) that depends on the symbolic variables in varlist. The starting points for these variables are provided in seedList.\nEach element of seedList={{p1, T1},{p2, T2}...} is a tuple where pi is the starting point of the $i^\\mathrm{th}$ field line and Ti is the length of that field line in both directions from Pi.\nHere are some examples:\n1) Coulomb field of two opposite charges at $\\vec{r} = \\vec{0}$ and $\\vec{r} = (1, 1, 1)$:\nLook at the form of seedList to see how the field line starting points and lengths are specified.\nseedList = \n  With[{vertices = .1 N[PolyhedronData[\"Icosahedron\"][[1, 1]]]}, \n   Join[Map[{#, 2} &, vertices], \n    Map[{# + {1, 1, 1}, -2} &, vertices]]];\n\nShow[fieldLinePlot[{x, y, z}/\n    Norm[{x, y, z}]^3 - ({x, y, z} - {1, 1, 1})/\n    Norm[{x, y, z} - {1, 1, 1}]^3, {x, y, z}, seedList, \n  PlotStyle -> {Orange, Specularity[White, 16], Tube[.01]}, \n  PlotRange -> All, Boxed -> False, Axes -> None], \n Background -> Black]\n\n\n2) Magnetic field of an infinite straight wire:\nWith[{seedList = Table[{{x, 0, 0}, 6.5}, {x, .1, 1, .1}]\n  },\n Show[fieldLinePlot[{-y, x, 0}/(x^2 + y^2), {x, y, z}, \n   seedList, PlotStyle -> {Orange, Specularity[White, 16], Tube[.01]},\n    PlotRange -> All, Boxed -> False, Axes -> None], \n  Graphics3D@Tube[{{0, 0, -.5}, {0, 0, .5}}], Background -> Black]]\n\n\n\nEdit: added variable line thickness to represent field strength\nThe field lines can be given a color that scales with the field strength (the norm of the vector field along the lines), by specifying a ColorFunction in fieldLinePlot. For example, if the vector field has been defined as a function f2 of variables x,y,z, then you could add the option ColorFunctionScaling -> False, ColorFunction -> Function[{x,y,z,u}, Quiet@Hue[Clip[ Norm[f2[x,y,z]],{0,20}]/20]] as I mention in the comment section.\nIn this new edit, I added the ability to encode the field strength in the thickness of the field lines instead. This required adding a new option \"TubeFunction\" which works similarly to ColorFunction. It is a function of the three coordinates x,y,z and returns the radius of the tube representing the field line at that point. To calculate this radius in the examples below, I take the (unscaled) value of the field and get its Norm. Then I scale and constrain it to a reasonable range so that the thickness variations of the field lines don't look too grotesque:\n3) Same Coulomb field as above, but with varying field line thickness\nf2[x_, y_,z_] := {x, y, z}/Norm[{x, y, z}]^3 - ({x, y, z} - {1, 1, 1})/\n   Norm[{x, y, z} - {1, 1, 1}]^3\n\nseedList = \n  With[{vertices = .1 N[PolyhedronData[\"Icosahedron\"][[1, 1]]]}, \n   Join[Map[{#, 2} &, vertices], \n    Map[{# + {1, 1, 1}, -2} &, vertices]]];\n\nfieldLinePlot[f2[x, y, z], {x, y, z}, seedList, \n PlotStyle -> {Orange, Specularity[White, 16]}, PlotRange -> All, \n Boxed -> False, Axes -> None, \n \"TubeFunction\" -> \n  Function[{x, y, z}, Quiet[Clip[Norm[f2[x, y, z]], {2, 40}]/200]], \n Background -> Black]\n\n\n4) Same magnetic field as above, this time with varying line thickness\nf3[x_, y_, z_] := {-y, x, 0}/(x^2 + y^2)\n\nWith[{seedList = Table[{{x, 0, 0}, 6.5}, {x, .1, 1, .1}]}, \n Show[fieldLinePlot[f3[x, y, z], {x, y, z}, seedList, \n   PlotStyle -> {Cyan, Specularity[White, 16]}, PlotRange -> All, \n   Boxed -> False, Axes -> None, \n   \"TubeFunction\" -> \n    Function[{x, y, z}, Quiet[Clip[Norm[f3[x, y, z]], {1, 40}]/200]]],\n   Graphics3D@Tube[{{0, 0, -.5}, {0, 0, .5}}], Background -> Black]]\n\n\n", "What is the purpose of tags like :Name:, :Context:, etc. in packages?": "\nOld versions of Mathematica featured the package Utilities`Package`. This had the function Annotation[] that read those commented lines in packages so that one could see those annotations without having to explicitly open those packages in the front end.\nNeeds[\"Utilities`Package`\"]\n\nAnnotation[\"Statistics`NonlinearFit`\"]\n{\"Title\", \"Context\", \"Name\", \"Author\", \"Summary\", \"Copyright\", \"Package Version\", \"Mathematica Version\", \"History\", \"Keywords\", \"Sources\", \"Discussion\", \"Warning\", \"Example\", \"Example\", \"Example\"}\n\nAnnotation[\"Statistics`NonlinearFit`\", \"Mathematica Version\"]\n{\"(* :Mathematica Version: 5.0 *)\"}\n\nIf you want to still use this function, it's available here. I would say those specific delimiters allowed the package to pick out annotations instead of code comments.\n", "graphics - Ideas on how to improve the rendering of the letter B in this 3D region plot?": "\nThe reason the B appears incorrectly is not because of the shape of G, but rather because the horizontal length of G is less than the vertical length of B, resulting in B being decapitated. Here's how the letters look at present when one is laid on top of the other at 90\u00ba:\n\nNotice that in the actual GEB logo, they use a squarish font, which solves this problem. So a possible solution, in the absence of a square font, is to set the aspect ratio of each of the letter shapes to 1, so that they sit well with each other. \nHere is a solution that uses Vitaliy's solution for extracting the outlines from letters.\nletter[s_String] := ImageData@ Binarize@Graphics[{EdgeForm[None], FaceForm[Black], \n     First[First[ImportString[ExportString[Style[s, FontSize -> 24], \"PDF\"], \n        \"PDF\", \"TextMode\" -> \"Outlines\"]]]}, AspectRatio -> 1, ImageSize -> 100]\n\nNow you can see that the shapes now line up correctly:\n\nProceeding with your RegionPlot3D code, but with slight modifications, \n{g, e, b} = letter /@ {\"G\", \"E\", \"B\"};\nRegionPlot3D[\n g[[Round[i], Round[j]]] == 0 && e[[Round[i], Round[k]]] == 0 && \n  b[[Round[j], Round[k]]] == 0, {i, 1, 100}, {j, 1, 100}, {k, 1, 100}]\n\nwe get a nice and pretty GEB logo that reproduces the B and all the other letters correctly.\n\n\n\n", "programming - Functions vs. patterns": "\nsquare = Function[x, x^2];\nsquare1 = #^2 &;\nsquare2[x_] := x^2;\n\nDownValues[square]\nDownValues[square1]\nDownValues[square2]\n\n{}\n{}\n{HoldPattern[square2[x_]] :> x^2}\n\nTwo differences that immediately come to mind are that:\n1) functions with down values won't autocompile when you use them in Table, Map, Nest etc. so therefore are less efficient when used that way. e.g.\ndata = RandomReal[{0, 10}, {10000}];\n\nTiming[Developer`PackedArrayQ[Map[square, data]]]\nTiming[Developer`PackedArrayQ[tmp1 = Map[square1, data]]]\nTiming[Developer`PackedArrayQ[tmp2 = Map[square2, data]]]\n\n{0.001404, True}\n{0.001498, True}\n{0.022324, False}\n\ndespite tmp1 being packed and tmp2 being unpacked they are equal\ntmp1==tmp2\nTrue\n\nbut using the pure function gives you a packed list which means faster evaluations and less memory for storage:\nN@ByteCount[tmp2]/ByteCount[tmp1]\n3.49456\n\nThis example used Map but you would observe the same thing with Table, Nest, Fold and so on. As to why this is the case (@Davids question) the only answer I have is the circular one that autocompilation using functions with down values hasn't been implemented. I haven't found out what the difficulties are in implementing this, i.e. whether it hasn't been done because it can't be or because it just hasn't been. Someone else may know and can comment.\n2) functions with down values may (in all likelihood will) cause a security warning when present in an embedded CDF.\nI'm sure others will be able to expand on this and add many more differences.\n", "performance tuning - With versus Function": "\nTo my mind, the differences are significant if obscure. The very big difference in evaluation was described already by @Sal. Here are several more subtle ones, which may however bite you. So, functions go first. \nFunctions\n\nCan be in two forms, Function[x,x^2] or Function[#^2] (the last is equivalent to #^2&), which are not always equivalent. Differences:\n\nFunctions with named arguments are scoping constructs, and as such, perform variable collision resolution by renaming variables in inner scoping constructs, if needed. Functions with Slot-s are not quite (are in some respects but not others. Example of the difference is below), and because of that have some  speed advantage.\nFunctions with named arguments represent a leaky functional abstraction (see at the bottom of that answer). This matters because you can never be sure that you won't run into trouble when passing such a function as an argument. Functions with slots are ok, but can not always be nested.\nFunctions with slots have a form which takes arbitrary number of arguments, such as Function[Null, Plus[##]]. Functions with named arguments don't have such form.\nFunctions with slots can be made recursive, which can be a very powerful tool in some cases.\n\nFunctions with slots, not being full - fledged scoping constructs,  have the substitution semantics similar to replacement rules, in that they won't care about inner scoping constructs and possible name collisions.\n\nExample:\nWith[{x=a},x+#]&[x]\n\n(*\n  ==> 2 a\n*)\n\nbut\nFunction[{inj},With[{x=a},x+inj]][x]\n\n(*\n   ==>  a+x\n*)\n\n(we could have used Module or another Function in place of With here). Which behavior is preferred depends on the situation, but more often than not the former one is used not intentionally and leads to subtle bugs. In any case, one should be aware of this. \n\nAs mentioned, Function - s with slots can take arbitrary number of arguments\nFunctions can carry attributes. For example, this function will sort its arguments: Function[Null, {##}, Orderless]\nBecause functions can carry attributes, they can hold arguments passed to them, for example: Function[expr,Head[Unevaluated[expr]],HoldAll], and also inject unevaluated arguments in their body. Functions with slots can do that for an arbitrary number of arguments as well, here is an example\nBecause of their SubValue - looking form of invokation: Function[x,x^2][y], and the fact that SubValues can not be forced to hold outer groups of arguments, Function call semantics for Function-s with Hold-arguments can not be easily emulated by other means. This tells us that Function-s are very special objects, for which probably an exception was made in the main evaluation sequence semantics.\nBecause Function-s can carry Hold-attributes, they can implement pass-by-reference semantics. In particular, they can change values of variables passed to them: a=1; Function[x,x=2,HoldAll][a];a.\nBecause of their evaluation semantics (elaborated by @Sal), Function-s can be used to implement currying.\n\nWith\nOk, now time for With:\n\nWith is always a scoping construct. This means it cares about inner scoping constructs and renames their variables in cases of conflicts. This is a good feature most of the time, but when it is not, there are ways to disable renaming\nWith normally does evaluate the r.h.sides of its variable declarations. I recently learned (from @Szabolcs) that there is a syntax which will keep them unevaluated: With[{a := Print[1]}, Hold[a]], but it is undocumented and it is not clear if it is reliable.\nBy its nature, With will always require a fixed number of arguments\nWith can not normally change the values of its \"variables\" (constants really), unless again an undocumented form of it is used: a=1;With[{b := a}, b = 3];a.\nIn principle, the core With functionality  is nothing special in the sense that it can be emulated with a top-level code.\nWith can be used as a r.h.s. of delayed rules. This usage allows it to share variables between its body and condition, e.g. x_:>With[{y=x^2},{x,y}/;y<10]. This is a powerful feature, and one variation  of it (Trott-Strzebonski technique, a reference to the original source and some explanation can be found  e.g. here) is a particularly powerful device in rule-based programming. This is a language feature, and can not be easily emulated (well, perhaps unless one uses RuleCondition) . Function-s can not be used in a similar fashion. \n\nSome conclusions\nWhile Function and With have somewhat similar semantics regarding the way they bind their variables, these construct are different. Even within Function-s themselves, functions with slots are substantially different from functions with named arguments, the main difference being that the former is not really a full-fledged scoping contsruct (more of a macro, as was also noted in other answers), while the latter is.  \nReturing to With vs Function, viewed as injecting devices - the sets of such use cases for both do have a significant overlap. In other words, in many such cases they can be used interchangeably. However, my personal inclanation is to mostly use With as an injecting device, while I use Function for such purposes in relatively special circumstances. One should also keep in mind differences outlined above, sometimes those effects can lead to subtle errors.\nFinally, from the viewpoint of a programming paradigms, With plays well both with functional programming and with rules, while Function plays well with functional programming constructs, so With seems to have somewhat wider domain of applicability.\n", "numerics - Using Mathematica to help to determine the consistency of and numerically solve systems of non-linear equations": "\nYour system is very large and what you're asking is quite general. So I guess only collection of general tips or links can help for now. If you provide a more specific smaller example - it would be easier to address. Generally there is an extensive documentation with many examples on \"Constrained Optimization\":\n\nRead sectioned online\nDownload PDF\n\nAn example of a flexible approachs to a solution of a nonlinear system was already posted here:\nUpdating Wagon's FindAllCrossings2D[] function\nList of some relevant interactive Demonstrations with free source code that solve a nonlinear system:\n\nHertzian Contact Stress \nSemenov's Algorithm for Solving Systems of Nonlinear Equations\nIterations of Newton's Method for Two Nonlinear Equations\n\n", "Does there exist any way to add type annotations?": "\nYou could use UpValues:\nmylist = {\"Alice\", \"Bob\", \"Carol\"};\nnumlist = {1, 2, 5, 3};\n\nSetAttributes[NETType, HoldAll]\n\nNETType[mylist] ^:= String\nNETType[numlist] ^:= Integer\n\n{NETType[mylist], NETType[numlist]}\n\n(* Returns:\n{String, Integer}\n*)\n\nOf course, this does not perform any checks that the elements in the list actually are of the type claimed.\n", "plotting - Visualizing 3\u00d73 spectrahedra": "\nIf the desire is to not have a surface appear when the region hits the boundary of the plot range, you could use something like:\nShow[RegionPlot3D[Evaluate[cons], {x, -3, 3}, {y, -3, 3}, {z, -3, 3}, \n  PlotRangePadding -> None, Mesh -> 5, PlotStyle -> Opacity[.7], \n  PlotPoints -> 10], PlotRange -> 2.9]\n\nto truncate the plot range to an area inside the boundary.\n\n", "reference request - What is the best Mathematica tutorial for young people?": "\nMathematica is the best tutorial. It is a discovery tool - just start from something that he knows a bit already and you both take one little step at a time. Just try things.\n\n1st Thing - Try this Link => Hands-on Start to Mathematica\nI personally would recommend engaging with him in a project of making an application and submitting it to the Wolfram Demonstrations Project. \n\nhttp://demonstrations.wolfram.com/\nCheck out stuff for kids: Link => Especially this\nIt could be something simple, but because it is interactive - he may find it fun to play with. I suggest you guys design and make a game. When teens have precise goals it is easier to set them on track especially if it is fun. You can also look through demonstrations and try to figure out how they work. Taking thinks apart - kids like that ;-)\n\nThere are many videos here:\n\nhttp://www.wolfram.com/broadcast/\n\nBut, again, Mathematica is the tutorial itself. It has some magic called \"free form linguistic input\". Basically you type in plane English and it gives you back the code or data. This is very cool for kids and teens. They can see how a concept is getting turned into code. You can find a few examples here:\n\nLink => Virtual talk video\nLink => Virtual talk notebook\nThis maybe a little bit adult level, but you can find some tricks how to teach him.\n\nI generally recommend all talks here - videos & notebooks:\n\nhttp://www.wolfram.com/events/virtual-conference/2011/presentations/\n\nMathematica Documentation is full of neat examples.\nIf he does not have Mathematica he can try using Wolfram|Alpha - it is free:\n\nhttp://www.wolframalpha.com/\nI very much like the idea of teaching programming to children. Below are a standard references for students:\nM10: A Student's First Course in Mathematica\nWolfram Education Portal\n", "graphics - $\\LaTeX$ and Mathematica": "\nThere are a few different parts to your question. I'll just answer the part about using psfragand pdflatex.\nThere's a package called pstool that automates the whole process of using psfrag with pdflatex.\nFor example, here's a graphics created in Mathematica 8\nplot = Plot[Sin[Exp[x]], {x, -Pi, Pi}, AxesLabel -> {\"e\", \"s\"}]\nExport[NotebookDirectory[] <> \"plot.eps\", plot]\n\n\nNote the use of the single character names for the axes. This was discussed in the stackexchange question \nMathematica 8.0 and psfrag.\nYou can use psfrag on this image and compile straight to pdf using the following latex file\n\\documentclass{article}  \n\\usepackage{pstool}\n\\begin{document}\n\\psfragfig{plot}{%\n\t\\psfrag{e}{$\\epsilon$}\n\t\\psfrag{s}{$\\Sigma$}}  \n\\end{document} \n\nCompile it using pdflatex --shell-escape filename.tex. You can optionally include a file plot.tex in the same directory which can contain all the psfrag code for plot.eps so that your main .tex file is tidier and the plot is more portable.\nHere's a screenshot of the graphics in the pdf file:\n\n", "front end - Revert FullForm-ed text to prettyprinted": "\nThe fastest method keystroke-wise that I have found is:\n\nCreate new empty cell\nPress Ctrl+Shift+E to get Cell[BoxData[\"\"], \"Input\"]\nPaste your expression into that one replacing the \"\" inside of BoxData.\nPress Ctrl+Shift+E again.\n\nAlternatively, plaste your expression into this and evaluate:\nFrontEndExecute@FrontEnd`CellPrint[\n  (* expression here *)\n]\n\n", "front end - Fontsize is too small": "\nI might as well post my comment to Szabolcs as an answer. As Szabolcs noted, the default screen resolution in Mathematica is set to 72 dpi which might not agree with the actual resolution. \nYou can change the screen resolution in the Option Inspector which can be found in the Format menu.  Set \"Show option values\" to \"Global preferences\" to change Front End settings permanently or set it to \"Selected Notebook\" to apply them to only the current notebook.  Then just search for ScreenResolution in the search box. The relevant option is the one called \"ScreenResolution\" with quotation marks. You can also find it via Formatting Options > Font Options > FontProperties > \"ScreenResolution\". It's set to 72 by default as Szabolcs figured out. \nBy the way, I found that on OS X at least, to change a value in the option inspector I need to click on the value and hover over the selection with my mouse cursor for a few seconds until it goes into edit mode, but it might be different on Windows. \n\nYou can try out using the system dpi temporarily by evaluating:\nSetOptions[$FrontEndSession, FontProperties -> {\"ScreenResolution\" -> Automatic}]\n\n(This will revert to the previous value after the Front End is closed.)\nYou do this for the current notebook using\nSetOptions[EvaluationNotebook[], \n     FontProperties -> {\"ScreenResolution\" -> Automatic}]\n\n\nAlternatively, If it's just the \"Text\" style that is too small, you could change the default text font in the style sheet you're using. In order to do this, go to Format > Edit Stylesheet... and type Text in the text field. Select the newly created cell, change the size in Format > Size to whatever you want, and close the stylesheet editor. All text cells in your notebook should now use the updated font size by default.\n", "graphics - Tile image on specific location without space between them": "\nOne can in fact use the (once documented) third argument of Rectangle[] to tile images. Here's an example I cooked up:\nimgs = {ExampleData[{\"TestImage\", \"Clock\"}], \n   ExampleData[{\"TestImage\", \"Elaine\"}], \n   ExampleData[{\"TestImage\", \"JellyBeans\"}], \n   ExampleData[{\"TestImage\", \"Lena\"}], \n   ExampleData[{\"TestImage\", \"Mandrill\"}], \n   ExampleData[{\"TestImage\", \"Peppers\"}], \n   ExampleData[{\"TestImage\", \"Splash\"}], \n   ExampleData[{\"TestImage\", \"Tiffany\"}], \n   ExampleData[{\"TestImage\", \"U2\"}]};\n\nmat = Partition[RandomSample[Range[9]], 3];\nGraphics[Table[Rectangle[{j, k}, {j + 1, k + 1}, imgs[[mat[[j + 1, k + 1]]]]],\n               {j, 0, 2}, {k, 0, 2}]]\n\n\nThe idea is that, you have nine images to distribute on a 3\u00d73 grid; you thus partition some permutation of the numbers $1$ to $9$ in groups of three (that is, mat), have the indices of Table[] map to a corresponding entry of mat, and then that entry of mat has a corresponding index in the list imgs. The extension to any number of images to be arranged in a grid should be straightforward.\n", "front end - Create shortcut in Mathematica for \"Equal Symbol Aligned Math Cell\"": "\nWith a little help from\nhttp://web.ift.uib.no/~szhorvat/mmatricks.php\nI came up with (having no idea why I could not use F3, on Windows, but F4 works) :\nItem[KeyEvent[\"F4\"], FrontEndExecute[FrontEnd`NotebookWrite[FrontEnd`InputNotebook[],\n    Cell[TextData[Cell[BoxData[FormBox[GridBox[{{GridBox[{{\"\\[Placeholder]\"}},\n    GridBoxAlignment->{\"Columns\" -> {{\"=\"}}}]}},\n    GridBoxItemSize->{\"Columns\" -> {{Scaled[0.96]}}}], TraditionalForm]]]], \"Text\"], After]; \n    FrontEnd`NotebookFind[FrontEnd`InputNotebook[], \"\\[Placeholder]\", Previous,CellContents]]]\n\nwhich I inserted at the end of KeyEventTranslations.tr\nMaybe it is a good idea to make a backup-copy of your KeyEventTranslations.tr, and remember:\nthe copy should not end with .tr\n", "linear algebra - How to enter matrices in block matrix format?": "\nYou're looking for ArrayFlatten. For your example matrices,\n R = ArrayFlatten[ {{A, {t}\\[Transpose]},{0, 1}} ]\n (*\n => {{1, 0, 0, 1}, {0, 0, 1, 1}, {0, -1, 0, 1}, {0, 0, 0, 1}}\n *)\n\nThe construct {t}\\[Transpose] is necessary for ArrayFlatten to treat t as a column matrix. \n\nThen to find $\\boldsymbol{R}^{-1}$, you run \nInverse[R]\n(* \n=> {{1, 0, 0, -1}, {0, 0, -1, 1}, {0, 1, 0, -1}, {0, 0, 0, 1}}\n*)\n\n", "version 8 - Typography messed up in prints": "\nFirst, I cannot reproduce your issue on Mathematica 8.0.1.0 on 64-bit Linux (CentOS 5.8). But I compare what you obtain and what I see, and I think I have an idea.\n\nThe notebook does not specifically require fonts, and as such, the font for e.g. your title cell is system-dependent. On my Mac, it uses a bold Helvetica in size 36, while on my Linux box it substitutes it by a Nimbus Sans L. As the latter is a free Helvetica substitute, it works fine even though it does not strictly have the same metrics. When exported to PDF, the font used is \"Helvetica-Bold\", which is not embedded because it's a standard PDF font.\nIn your case, the display font substitution is what is going wrong. Compare your display (top) and print (bottom) versions:\n\n\nYou can see the display font is not a good substitute for Helvetica: the characters are different (see the endings of the s and a) and it's definitely wider. I suspect this difference in metrics is where the awful character positioning is coming from.\nSo, why is your display font not Helvetica or a substitute? If you have a decent substitute installed, I don't know why Mathematica isn't using it, but font handling in X11 is a hairy topic. Maybe you'll get better results at debugging this on AskUbuntu.\nAnd what can you do to fix it? Well, if it's a problem of fonts missing from you system, try installing Freefont if you haven't already (package ttf-freefont), or MS Core fonts (package ttf-mscorefonts-installer). If it's an X11 issue, then I'm afraid I can't help more\u2026\n\n\nEdit. I actually have another suggestion for a workaround: have you tried other fonts on your system (non-default fonts) to see if it works better?\n", "front end - How to work around Column cutting off a pixel row from images?": "\nThis seems to be due to a small rounding issue on Windows.\nHere is a test Manipulate:\nManipulate[\n matrix = ArrayFlatten[Table[DiamondMatrix[size], {x}, {y}]];\n image = Image[matrix /. {0 -> {0, 0, 0}, 1 -> {255, 255, 255}},\n  \"Byte\", ColorSpace -> \"RGB\", Interleaving -> True];\n Column[{\"test\", Image[image, Magnification -> 1], \"test\"}],\n {size, 1, 20, 1},\n {x, 1, 20, 1},\n {y, 1, 20, 1}\n]\n\nUnder certain settings the top row of pixels in the image is cut off:\n\n", "output formatting - Way to improve \"show me this decimal number to M places, don't use scientific notation\"?": "\nYou can express any fraction/number to arbitrary decimal places by using a backtick followed by number of digits required. For example:\nIn[1]:= 4/3`20\nOut[1]= 1.3333333333333333333\n\nThis is the same as N[4/3, 20]. Now combine this with AccountingForm, which never uses scientific notation to get the output that you desire.\nAccountingForm[1/998001`2994]\nOut[2]//AccountingForm= 0.0000010020030040050060070080090100110120130140...\n\nHowever, be aware that AccountingForm uses parentheses for negative numbers:\nAccountingForm[-1/998001`2994]\nOut[3]//AccountingForm= (0.00000100200300400500600700800901001101201301401501601....\n\n\nDaniel Lichtblau has a good point that although using `instead of N might be shorter in this case, in general, it might not give the same result \u2014 for example, compare the digits of Log[2`50] and N[Log[2],50]. You'll see that they differ in the last couple of digits. However, for small use cases, the difference might be insignificant.\n", "sparse arrays - Efficient by-element updates to SparseArrays": "\nIf you need a batch update, then the answer is in my comment you linked. If you need element-by-element, then there are two cases: \n\nMost of values you update are non-zero (or, generally, not equal to default element). In this case, I believe the answer of @Mr. Wizard is optimal, and you should expect  update of a single element to be constant time.\nMost (or at least a sizable fraction) of these elements are initially zero (or, default element). Then, you are out of luck. I gave a brief answer to a similar request in this thread. Basically, SparseArray object keeps lists of non-zero elements and their positions in packed arrays. Therefore, a transition from zero to non-zero for an element requires insertion in the middle of them, which is O(n) operation, where n is the current number of non-zero elements. So, this is the same situation as building a list with Append, and it will lead to a quadratic complexity. \n\nThis tidbit is not well-known, so I'd like to emphasize it again: element-by-element update for the SparseArray generally has complexity ~ updates * nzero, where updates is the number of updates, and  nzero is the final non-zero elements.\nIf you can organize your elements into batches which can be updated at the same time, you win big. Then, I suggest that you use the function I described in the cited answer. A main obstacle in a batch approach would be if you need the current state of your array to be used for something, say matrix multiplication, in between single element updates. If this is not the case, I think you should be able to use the batch update method.\n", "programming - How can I speed up SQL queries in Mathematica?": "\nAdding a database index is very important when SELECTing data from a big table. Once you add the index, MySQL will take care of keeping it updated. The disadvantage of indices is that your database now takes more space in your HD and that your INSERTs are now slower.\nNote that you created a multiple-column index that speeds up you SELECTs when you lookup by:\n\nticker, whichprice and date\nticker and whichprice\nticker\n\nIf you do a SELECTs by whichprice or date or (whichprice and date) will still be slow. \nLastly, if this is a read-only table you could use the MyISAM storage engine and maybe even move to MariaDB (a mysql fork) for better performance.\n", "evaluation - How to create symbols from strings and set values for them?": "\nOne solution is to use the third argument of ToExpression:\nWith minimal modification, a working version of your code would look like this:\nTable[\n  ToExpression[\n  mmsignalnames[[i]], \n  InputForm, \n  Function[name, \n    name = Extract[ToExpression[celfilenames[[i]]], mmammindices[[j]]],\n    HoldAll]],\n {i, Length[mmsignalnames]}, {j, Length[mmammindices]}]\n\n(Untested because I don't have your data;  but see below for the main idea and a small demonstration.)\nThe core of the method is this:\nToExpression[\"a\", InputForm, Function[name, name = 1, HoldAll]]\n\nToExpression will wrap the result into its third argument before evaluating it.  We can make the third argument a function that sets a value to the symbol (in this simple example it always sets the value to 1).  HoldAll is needed to make sure the symbol won't evaluate when it is passed to the function.\n\nYou might find all the evaluation control I'm using here a bit confusing.  To learn how to work with unevaluated expressions, I recommend reading\n\nWorking with Unevaluated Expressions by Robby Villegas\n\nIt is one of the best tutorials on the matter.\n\nFinally, after answering your actual question, I'd like to suggest you use a hash table instead of symbols:\nInstead of creating symbols from the strings \"a\", \"b\", \"c\", ..., and assigning to them, you could assign to myTable[\"a\"], myTable[\"b\"], ...  This will make programmatic access to this data trivial.  You won't need to bother with evaluation control nearly as much.  And more importantly, you can avoid accidental name collisions with existing symbols.  Here's an example:\n(myTable[#] = 1) & /@ {\"a\", \"b\", \"c\"}\n\n", "graphics - How can I specify the arrowhead size in printers points?": "\nYou could create a custom arrowhead using Offset coordinates, which are in terms of printer's points:\narrow = Graphics[\n   Polygon[{{0, 0}, Offset[{-10, 5}, {0, 0}], Offset[{-5, 0}, {0, 0}],\n      Offset[{-10, -5}, {0, 0}]}]];\n\nTable[Graphics[{Arrowheads[{{0.1, 1, arrow}}], \n   Arrow[{{0, 0}, {1, 1}}]}, ImageSize -> s], {s, Range[25, 150, 25]}]\n\n\n", "graphics - Plot Ellipse based on EigenSystem": "\nYou can use Rotate to draw the ellipse too. Note that knowing the eigenvectors is the same as knowing the orientation of the ellipse, so there is no necessity to favour GeometricTransformation over Rotate. So, to orient your ellipse along the first eigenvector (corresponding to the largest eigenvalue), it is as simple as:\nGraphics[Rotate[Disk[meanVec, eigVals], ArcTan @@ eigVecs[[1]]]]\n\n\nwhere meanVec is the mean (here, I've taken it to be {0,0})\n\nGoing by your comment under rcollyer's answer, here's a example reproducing your desired figure with simple shifting (change the center of the disk) and rotation of the disk. This approach will be simpler to follow (as the transformations are spelled out), if you do not understand what GeometricTransformation does. Modifying rcollyer's module,\nModule[{mat = #, avg = Mean@fixations, eigVals, eigVecs},\n   {eigVals, eigVecs} = Eigensystem@mat;\n   Graphics[{{Black, Disk[#, .5] & /@ fixations}, \n      {Directive[Opacity[0.1], Red, EdgeForm[Gray]], \n          Rotate[Disk[avg, eigVals/5], ArcTan @@ eigVecs[[1]]]}\n   }]\n]&@covMatrice\n\n\n", "list manipulation - Flatten at a certain level": "\nOk, I will give it a shot, although what follows is mostly a guess, and I also may be wrong.\nWhy this does not work (a guess)\nI think, what you ask can not be achieved with just Flatten. And the reason for this is that there seems to be no way for the syntax you propose to coexist with the syntax explained in the question you linked. So, the problem is, that while e.g. this code is ligitimate:\nFlatten[{{{1, 2, 3}, {6, 7}}, {{4, 5}, {8, 9, 10}}, {11, 12}}, {1}]\n\n(*\n  ==>  {{{1, 2, 3}, {6, 7}}, {{4, 5}, {8, 9, 10}}, {11, 12}}\n*)\n\nthe syntax we used there means not what you'd like it to be in this case. I can only guess that this design decision was motivated by considering this possibility to be easily implemented using Map (for those who need it), while the one that currently is there for this syntax to be less trivial and not easily replicated.\nMaking it work through custom environments\nIf you want to frequently use Flatten with the semantics you mentioned, I suggest to create a lexical or dynamic environment where you will replace the existing semantics with this one. Here is a dynamic environment which will do that:\nClearAll[withListableFlatten];\nSetAttributes[withListableFlatten, HoldAll];\nwithListableFlatten[code_] :=\n  Internal`InheritedBlock[{Flatten},\n    Unprotect[Flatten];\n    Flatten[lst_, levspec_List] := Map[Flatten, lst, levspec];\n    Protect[Flatten];\n    code];\n\nand now:\nwithListableFlatten[\n  Module[{\n     test = {{{1, 2, 3}, {4, 5}, 11}, {{6, 7}, {8, 9, 10}, 12}},\n     levSpec = {1}},\n    Flatten[test, levSpec]\n  ]]\n\n(* \n  ==> {{1, 2, 3, 4, 5, 11}, {6, 7, 8, 9, 10, 12}}\n*)\n\nwhere I used Module to illustrate that the new syntax will take effect for an arbitrary code enclosed in this wrapper, and all the way down the execution stack in this code. A lexical environment will be much easier to write in this case:\nClearAll[withListableFlattenLex];\nSetAttributes[withListableFlattenLex, HoldAll];\nwithListableFlattenLex[code_] :=\n  ReleaseHold[\n     Hold[code] /. HoldPattern[Flatten[l_, lev_]] :> \n         Map[Flatten, l, lev]]\n\nand you can check that it will give the same result for the above example. The difference is that in this case, only the explicit entries of Flatten in code will be affected.\nAs a side note, a good thing about dynamic environments is that they can be easily combined / nested, with rather predictable behavior in terms of how they interact, because they change behavior at run-time only (which is a late stage). The bad thing about them is that they affect all the code down the execution stack, and this makes them less suitable for writing say higher-order functions, or any functions which accept arbitrary user's code. Lexical environments are safer in this respect, but so far Mathematica lacks a genuine macro system which would both be natural to use, and will make their composition easier.\n", "How to create a group action table with Mathematica?": "\nMMA v.8 provides support for (finite) Group Theory, however this answer will not make use of that functionality.\nWe shall use the ** (NonCommutativeMultiply) command present in MMA, which allows us to create semigroups quite easily. \nIn a fresh MMA session:\nUnprotect[NonCommutativeMultiply];\nGroupAction[g_, s_] := (g ** #) & /@ s\n1 is the identity:\ng_ ** 1 := g\n1 ** g_ := g\nElements relations\na ** a ** a := 1\nb ** b := 1\nb ** a ** a := a ** b\nThen\nG = {1, a, a ** a, b, b ** a, b ** a ** a}\n\nS = Subsets[G, {3}]\n\nCheck some products:\na ** 1 ** b ** q\na ** 1 ** b ** b ** q\na ** 1 ** b ** a ** a ** b ** q\np ** a ** a ** a ** q\n(p and q are generic group elemants) as you see MMA uses the associative (Flat) property of NonCommutativeMultiply to parse and simplify the expressions in all possible ways.\nNow this is your table:\nTable[GroupAction[g, s], {s, S}, {g, G}] // MatrixForm\nNicely formatted:\nGrid[Prepend[Table[GroupAction[g, s], {s, S}, {g, G}], G], \n Background -> {None, {Lighter[Blue, .9], {White, \n     Lighter[Blend[{Blue, Green}], .8]}}}]\nIf you are serious about Group Theory, you might want to check the functionalities offered by MMA v.8\n", "What are some useful, undocumented Mathematica functions?": "\n\nLongestCommonSequencePositions and LongestCommonSubsequencePositions  Their use is analogous to LongestCommon(Sub)sequence but they return the position of the first match instead.\nUpdate: These are documented since 10.2.\nClipboardNotebook[] can be used to access the clipboard.  NotebookGet@ClipboardNotebook[] will give a Notebook expression with the current contents of the clipboard.  I use this for pre-processing data before it is pasted (e.g. in the table paste palette).  I am not sure if this can be used for copying at all---I use the Front End's Copy function directly for that (through FrontEndTokenExecute)\nUpdate: Since version 8 we have some documented clipboard functions.\nPolynomialForm[] allows changing the order in which polynomial terms are printed by setting the option TraditionalOrder -> True\nIn[1]:= PolynomialForm[1+x+x^2, TraditionalOrder->True]\nOut[1]= x^2+x+1\n\nPOST request: In version 8 Import has experimental support for the POST HTTP request method.  Example usage for uploading an image to imgur:\nImport[\"http://api.imgur.com/2/upload\", \"XML\", \n       \"RequestMethod\" -> \"POST\", \n       \"RequestParameters\" -> {\"key\" -> apikey, \"image\" -> image}]\n\n(Of course you'll need to insert your API key and a properly encoded image, as shown in the answer I linked to above.)\nInternal`Deflatten[] will reconstruct higher dimensional tensor from a flat list.  Example:\nIn[1]:= arr = {{1, 2}, {3, 4}}\nOut[1]= {{1, 2}, {3, 4}}\n\nIn[2]:= flatArr = Flatten[arr]\nOut[2]= {1, 2, 3, 4}\n\nIn[3]:= Internal`Deflatten[flatArr, Dimensions[arr]]\nOut[3]= {{1, 2}, {3, 4}}\n\nWarning: If the dimensions passed to it don't match the length of the flat array, this will crash the kernel!\nUpdate: Version 9.0 introduced the documented equivalent ArrayReshape.\n\n\n\nImage capture start/stop IMAQ`StartCamera[] and IMAQ`StopCamera[] start and stop the webcam.\n\n\n\nUndocumented interesting contexts to dig through: Internal`, Experimental`, Language`, NotebookTools` (similar to what the AuthorTools package offers), IMAQ` (IMage AQcuisition)\nThere are lots of functions in these contexts, generally undocumented, but sometimes with self-explanatory names (e.g. Internal`RealValuedNumericQ seems obvious).  Note that these functions might change in later versions.  Some of the ones listed by ?Internal`* are even from old versions and no longer work in M- 8.\nSome functions from Language` are described here.\n\n\n\nSystemOptions[]  The functions to set and read these options are not undocumented, but the options themselves unfortunately are.\n\nExperimental`SystemOptionsEditor[]  In version 8 this gives a GUI for viewing/setting system options.\n\"TableCompileLength\" (and other similar options from the \"CompileOptions\") section set the length of a Table above which it attempts to compile its argument.\nExample: SystemOptions[\"CompileOptions\" -> \"TableCompileLength\"] will show that the default value is 250.\n\"SparseArrayOptions\" -> {\"TreatRepeatedEntries\" -> 1}\nSetting this option to 1 will cause repeated entries to be summed up when creating a sparse array.  See an example use and explanation here.\nIn[1]:= Normal@SparseArray[{2 -> 1, 4 -> 1}]\nOut[1]= {0, 1, 0, 1}\n\nIn[2]:= Normal@SparseArray[{2 -> 1, 4 -> 1, 2 -> 1}]\nOut[2]= {0, 1, 0, 1}\n\nIn[3]:= SetSystemOptions[\"SparseArrayOptions\" -> {\"TreatRepeatedEntries\" -> 1}]\n\nIn[4]:= Normal@SparseArray[{2 -> 1, 4 -> 1, 2 -> 1}]\nOut[4]= {0, 2, 0, 1}\n\n\n\n\nThis MathGroup thread has some interesting information too.\n", "How can one find undocumented options or option values in Mathematica?": "\nOne thing you can do is look for options which appear in a function's Options but do not have a ::usage message. Of course, some of the results actually are documented in the help, they just don't have a usage message. Here's a function to do it:\nundoc[x_Symbol]:=Select[Options[x],!StringQ@MessageName[Evaluate@First@#,\"usage\"]&];\nundoc[_] = {};\n\n(* e.g. *)\nundoc[Plot]\nOut[3]= {Evaluated->Automatic,ImageSizeRaw->Automatic}\n\nThe following runs this function on all symbols in System context, and presents the results in a grid. Some functions (like Cell) have huge lists of options with no usage message, these ones I skip over (just printing out the function name) to save space.\nGrid[Select[{#,undoc[Symbol[#]]}&/@Names[\"System`*\"],\nLast@#=!={}&&(Length@Last@#<10||Print@First@#)&],Frame->All]\n\n\n", "calculus and analysis - Series expansion of an inverse": "\nIs InverseSeries what you are looking for?\nInverseSeries[Series[ArcTan[Log[1 + x]/(1 + x)], {x, 0, 5}]]\n(*\nx+(3 x^2)/2+3 x^3+(149 x^4)/24+(68 x^5)/5+O[x]^6\n*)\n\nEDIT: looks reasonable:\nPlot[{\n  pl[x],\n  invs\n  },\n {x, -.3, .3},\n PlotStyle -> {{Dashed, Black}, Red}\n ]\n\n\nWho knows what the radius of convergence is, though.\n", "export - How well does Mathematica code exported to C compare to code directly written for C?": "\nA lot depends on how you write your code in Mathematica. In my experience, the rule of thumb is that the generated code will be efficient if the code inside Compile more or less resembles the code I would write in plain C (and it is clear why). Idiomatic (high-level) Mathematica code tends to be immutable. At the same time, Compile can handle a number of higher-level functions, such as Transpose, Partition, Map, MapThread, etc.  Most of these functions return expressions, and even though these expressions are probably passed to the calling function, they must be created. For example, a call to ReplacePart which replaces a single part in a large array will necessarily lead to copying of that array. Thus, immutability generally implies creating copies.\nSo, if you write your code in this style and hand it to Compile, you have to keep in mind that lots of small (or large) memory allocations on the heap, and copying of lists (tensors) will be happening.\nSince this is not apparent for someone who is used to high-level Mathematica programming, the slowdown this may incur may be surprising. See this and this answers for examples of problems coming from many small memory allocations and copying, as well as a speed-up one can get from switching from copying to in-place modifications.\nAs noted by @acl, one thing worth doing is to set the SystemOptions -> \"CompileOptions\" as\nSetSystemOptions[ \"CompileOptions\" -> \"CompileReportExternal\" -> True]\n\nin which case you will get warnings for calling external functions etc.\nA good tool to get a \"high-level\" but precise view on the generated code is the CompilePrint function in the CompiledFunctionTools` package. It allows you to print the pseudocode version of the byte-code instructions generated by Compile. Things to watch for in the printout of CompilePrint function:\n\nCalls to CopyTensor\nCalls to MainEvaluate (callbacks to Mathematica, meaning that something could not be compiled down to C)\n\nOne not very widely known technique of writing even large Compile-d functions and combining them from pieces so that there is no performance penalty, is based on inlining. I consider this answer very illustrative in this respect - I actually posted it to showcase the technique. You can also see this answer and a discussion in the comments below, for another example of how this technique may be applied.  \nIn summary - if you want your code to be as fast as possible, think about \"critical\" places and write those in \"low-level\" style (loops, assignments, etc) - the more it will resemble C the more chances you have for a speed-up (for an example of a function written in such a style and being consequently very fast, see the seqposC function from this answer). You will have to go against Mathematica ideology and use a lot of in-place modifications. Then your code can be just as fast as hand-written one. Usually, there are just a few places in the program where this matters (inner loops, etc) - in the rest of it you can use higher-level functions as well.\n", "plotting - Centering date labels over the year in a DateListPlot": "\nHere is a much simpler solution than Szabolcs's or Mike's. I've directly addressed your second bonus question and this can be easily extended to the first case. The following generates tick marks for the x-axis and incorporates your needs as per yours and Mike's comments below:\n\nThe quarter label is centered mid quarter\nThe year label is centered mid year\n\nIt is a wee bit wasteful in that I generate ticks for all months and then set the ones I don't want to be transparent. Of course, you can build upon the logic and generate/not generate for specific months/dates, but I'll let you decide if its worth it. \nxTicks[data_] := Module[{monthStr, date, color},\n    monthStr[m_] := Which[\n        MemberQ[{2, 5, 8, 11}, m], DateString[# + {0, 1, 0}, \"MonthNameInitial\"] &, \n        m == 7, DateString[#, {\"\\n\", \"Year\"}] &, True, \"\" &\n    ];\n\n    color[m_] := If[MemberQ[{4, 7, 10, 1}, m], Black, Transparent];\n    date[m_] := If[MemberQ[{2, 5, 8, 11}, m], 15, 1];\n\n    Table[MapAt[monthStr[m], {{y, m, date[m]}, {y, m, date[m]}, {0.0125, 0}, color[m]}, 2], \n        {y, Min[data[[All, 1, 1]]], Max[data[[All, 1, 1]]]}, {m, 1, 12}] ~Flatten~ 1\n]\n\nand now plot your FinancialData with ticks generated with the above as:\naapl = FinancialData[\"AAPL\", {2008}];\nDateListPlot[#, Joined -> True, FrameTicks -> {xTicks[#], Automatic, False, False}, \n    GridLines -> False]& @ aapl\n\n\n", "formatting - Outline Numbering for Mathematica Section/Subsection Cells": "\nThis question might help. \nIn short, to get an automatically numbered section or subsection you could edit the CellFrameLabels or the CellDingbat option of the relevant style definitions. \n\nOpen a new notebook, add a section cell, and select Edit Stylesheet... in the Format menu \nChoose Section from the drop down menu in the stylesheet editor and select the newly created cell \nCheck Show Expression in the Cell menu which \nAdd either the option CellFrameLabels-> {{spec, None}, {None, None}} or CellDingbat -> spec somewhere after the first argument where spec is the specifications for the section number. \nUncheck Show Expression. Sections in the should then be numbered automatically\nYou can install the updated stylesheet by pressing the Install Stylesheet... button in the stylesheet editor\n\nIn its simplest form the number specification would be something like \n Cell[TextData[{ CounterBox[\"Section\"]}]]\n\nfor a section or\nCell[TextData[{ CounterBox[\"Section\"], \".\", CounterBox[\"Subsection\"]}]]\n\nfor a subsection, but you can add your own styling to the numbering. For example for a notebook using the default stylesheet you could set the style definition of Section to something like\nCell[StyleData[\"Section\"],\n  CellFrameLabels->{{\n    Cell[TextData[{CounterBox[\"Section\"], \" \"}],\n    CellFrame -> {{0, 0}, {0, 1}}, \n    CellFrameMargins -> 4, \n    CellSize -> {30, Automatic}, \n    TextAlignment -> Right], \n   None}, {None, None}},\n  CellFrameLabelMargins->0\n]\n\nWhich would produce sections like this\n\n", "programming - How to make GraphicsGrid with content tight inside it?": "\nI prefer Framed. To improve labels just wrap TraditionalForm around it:\nTraditionalForm@Framed[title]\n\n\nIf you have many cells and if the whole point is to make a tight grid and have nice labels, you could improve labels in Grid, rather then improving spacing in GraphicsGrid:\nTraditionalForm[Grid[{{title}, {title}}, Frame -> All]]\n\n\nGraphicsGrid is to handle graphics. Just for the sake of completeness you could simply Rasterize your formula to Graphics to make GraphicsGrid work:\nGraphicsGrid[{{Rasterize@TraditionalForm[title]}}, Frame -> All]\n\n\n", "Functional style using lazy lists?": "\nA \"lazy list\", \"functional style\" solution to this problem might look something like this:\nsIntegers[] ~sMap~ Prime ~sFilter~ palindromicQ ~sTake~ 400 // sList\n\nNo such notation is built into Mathematica.  However, creating such notations is Mathematica's strong suit.  Let's do it.\nFirst, we need to define the notion of a \"stream\".  Streams are inherently lazy, so let's use HoldAll:\nSetAttributes[stream, {HoldAll}]\n\nA stream can be empty:\nsEmptyQ[stream[]] := True\n\n... or it can be non-empty, having two elements:\nsEmptyQ[stream[_, _]] = False;\n\nThe first element of the stream is called the \"head\":\nsHead[stream[h_, _]] := h\n\nThe remaining elements of the stream are called the \"tail\":\nsTail[stream[_, t_]] := t\n\nArmed with these definitions, we can now express an infinite stream of integers thus:\nsIntegers[n_:1] :=\n  With[{nn = n+1}, stream[n, sIntegers[nn]]]\n\nsIntegers[] // sEmptyQ                 (* False *)\nsIntegers[] // sHead                   (* 1 *)\nsIntegers[] // sTail // sHead          (* 2 *)\nsIntegers[] // sTail // sTail // sHead (* 3 *)\n\nInfinite streams are difficult to display in a notebook.  Let's introduce sTake which truncates a stream to a fixed length:\nsTake[s_stream, 0] := stream[]\nsTake[s_stream, n_] /; n > 0 :=\n  With[{nn = n-1}, stream[sHead[s], sTake[sTail[s], nn]]]\n\nLet's also introduce sList, which converts a (finite) stream into a list:\nsList[s_stream] :=\n  Module[{tag}\n  , Reap[\n      NestWhile[(Sow[sHead[#], tag]; sTail[#])&, s, !sEmptyQ[#]&]\n    , tag\n    ][[2]] /. {l_} :> l\n  ]\n\nNow we can inspect an integer stream directly:\nsIntegers[] ~sTake~ 10 // sList\n(* {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} *)\n\nsMap applies a function to every element of a stream:\nsMap[stream[], _] := stream[]\nsMap[s_stream, fn_] := stream[fn[sHead[s]], sMap[sTail[s], fn]]\n\nsIntegers[] ~sMap~ Prime ~sTake~ 10 // sList\n(* {2, 3, 5, 7, 11, 13, 17, 19, 23, 29} *)\n\nsFilter selects elements from a stream that satisfy a given filter predicate:\nsFilter[s_, pred_] :=\n  NestWhile[sTail, s, (!sEmptyQ[#] && !pred[sHead[#]])&] /.\n    stream[h_, t_] :> stream[h, sFilter[t, pred]]\n\nsIntegers[] ~sFilter~ OddQ ~sTake~ 15 // sList\n(* {1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29} *)\n\nWe now have almost all of the pieces in place to address the original problem.  All that is missing is a predicate that detects palindromic numbers:\npalindromicQ[n_] := IntegerDigits[n] /. d_ :> d === Reverse[d]\n\npalindromicQ[123] (* False *)\npalindromicQ[121] (* True *)\n\nNow, we can solve the problem:\nsIntegers[] ~sMap~ Prime ~sFilter~ palindromicQ ~sTake~ 400 // sList\n\n(* {2,3,5,7,11,101, ... ,3528253,3541453,3553553,3558553,3563653,3569653} *)\n\nThe stream facility we have defined here is very basic.  It lacks error checking, and further consideration should be given to optimization.  However, it demonstrates the power of Mathematica's symbolic programming paradigm.\nThe following listing gives the complete set of definitions:\nClearAll[stream]\nSetAttributes[stream, {HoldAll, Protected}]\n\nsEmptyError[] := (Message[stream::empty]; Abort[])\nstream::empty = \"Attempt to access beyond the end of a stream.\";\n\nClearAll[sEmptyQ, sHead, sTail, sTake, sList, sMap, sFilter, sIntegers]\n\nsEmptyQ[stream[]] := True\nsEmptyQ[stream[_, _]] = False;\n\nsHead[stream[]] := sEmptyError[]\nsHead[stream[h_, _]] := h\n\nsTail[stream[]] := sEmptyError[]\nsTail[stream[_, t_]] := t\n\nsTake[s_stream, 0] := stream[]\nsTake[s_stream, n_] /; n > 0 :=\n  With[{nn = n-1}, stream[sHead[s], sTake[sTail[s], nn]]]\n\nsList[s_stream] :=\n  Module[{tag}\n  , Reap[\n      NestWhile[(Sow[sHead[#], tag]; sTail[#])&, s, !sEmptyQ[#]&]\n    , tag\n    ][[2]] /. {l_} :> l\n  ]\n\nsMap[stream[], _] := stream[]\nsMap[s_stream, fn_] := stream[fn[sHead[s]], sMap[sTail[s], fn]]\n\nsFilter[s_, pred_] :=\n  NestWhile[sTail, s, (!sEmptyQ[#] && !pred[sHead[#]])&] /.\n    stream[h_, t_] :> stream[h, sFilter[t, pred]]\n\nsIntegers[n_:1] :=\n  With[{nn = n+1}, stream[n, sIntegers[nn]]]\n\n\n\npalindromicQ[n_] := IntegerDigits[n] /. d_ :> d === Reverse[d]\n\n", "interoperability - Are there any \"RLink\" like projects, which enable the interaction between R and Mathematica?": "\nErich Neuwirth on MathGroup mentioned a solution for Windows (free for non-commercial applications) that you can download here.\nHere is his example with small updates from Sasha and Mark Fisher. After downloading the R instalation and DCOM server stuff I tried it and it seems to work just fine.\nNeeds[\"NETLink`\"]\nmyR = CreateCOMObject[\"StatConnectorSrv.StatConnector\"]\nmyR@Init[\"R\"]\nmyR@SetSymbol[\"xxx\", 12321]\nresult1 = myR@GetSymbol[\"xxx\"]\nmyR@EvaluateNoReturn[\"randmat<-matrix(rnorm(100),10)\"]\nrmat = myR@GetSymbol[\"randmat\"]\nresult2 = myR@Evaluate[\"solve(matrix(1:4,2))\"]\n\n(*\n==> NETLink`Objects`NETObject$3810539581$1070974657101825\n*)\n\n(*\n==> 12321\n*)\n\n(*\n==> {{-0.2729702674, 1.803861976, 0.5813040979, 0.1600081953, \n  0.7538751951, 0.3923246778, 1.240256949, 2.143071289, -0.2112634412,\n   0.9417189228}, {-0.1815065752, 0.6340400316, \n  0.6235181836, -0.1729713552, -0.965223049, -0.8076688634, \n  0.6125102682, 0.8043927759, \n  0.2623272614, -0.7300377248}, {-0.1573784247, \n  1.745921499, -1.223295754, \n  0.7508255497, -1.437158433, -0.5431748169, \n  0.5224185732, -0.006148655396, -0.5381351892, -0.1264029232}, \\\n{-0.2285349193, 0.5978044841, \n  0.7099844671, -0.830220449, -0.5994523393, -0.1600179795, \n  0.2957343203, -0.2560352574, \n  1.45552903, -0.9763608981}, {-0.5509826168, 0.4205191323, \n  2.021672968, 0.4834619721, -0.6738896365, -1.782509979, 0.515151609,\n   0.6698301759, -1.914440159, 0.1741606405}, {1.199489342, \n  1.397342011, -0.08762926484, 0.3572575699, 0.1415520058, \n  0.2384566775, -0.598134357, -0.199506724, -0.4849505361, \n  0.1238990228}, {0.55417032, \n  0.4911786903, -0.2432415953, -1.270176719, \n  0.3143047255, -0.3256634613, 0.9347990095, \n  0.6459510591, -0.924018154, 1.091294398}, {-0.5705422396, \n  0.1740525789, -0.7607604118, -0.4584603394, -2.602648464, \\\n-0.08879130709, 1.550124853, 0.4472847015, 0.1335582644, \n  0.07635818615}, {1.301494963, 1.106258178, \n  0.3354845242, -1.45468913, -0.3581930843, \n  1.187368824, -0.1503588385, 0.1511637701, 2.236312191, \n  1.067101554}, {0.04525815419, 0.1181913247, \n  1.588764281, -0.7367518216, -1.79115224, -3.891936361, 2.463525431, \n  2.721622641, 0.8049086131, -0.1488657311}}\n*)\n\n(*\n==> {{-2., 1.5}, {1., -0.5}}\n*)\n\nmyR@Close[]\n\n", "performance tuning - Internal`Bag inside Compile": "\nI am somewhat reluctant to offer this as an answer since it is inherently difficult to comprehensively address questions on undocumented functionality. Nonetheless, the following observations do constitute partial answers to points raised in the question and are likely to be of value to anyone trying to write practical compiled code using Bags. However, caution is always highly advisable when using undocumented functions in a new way, and this is no less true for Bags.\nThe type of Bags\n\nAs far as the Mathematica virtual machine is concerned, Bags are a numeric type, occupying a scalar Integer, Real, or Complex register, and can contain only scalars or other Bags. They can be created empty, using the trick described in the question, or pre-stuffed:\n\nwith a scalar, using Internal`Bag[val] (where val is a scalar of the desired type)\nwith several scalars, using Internal`Bag[tens, lvl], where tens is a full-rank tensor of the desired numeric type and lvl is a level specification analogous to the second argument of Flatten. For compiled code, lvl $\\ge$ ArrayDepth[tens], as Bags cannot directly contain tensors.\n\nInternal`StuffBag can only be used to insert values of the same type as the register the Bag occupies, a type castable to that type without loss of information (e.g. Integer to Real, or Real to Complex), or another Bag. Tensors can be inserted after being flattened appropriately using the third argument of StuffBag, which behaves in the same way as the second argument of Bag as described above. Attempts to stuff other items (e.g. un-flattened tensors or values of non-castable types) into a Bag will compile into MainEvaluate calls; however, sharing Bags between the Mathematica interpreter and virtual machine has not been fully implemented as of Mathematica 8, so these calls will not work as expected. As this is relatively easy to do by mistake and there will not necessarily be any indication that it has happened, it is important to check that the compiled bytecode is free of such calls.\n\nExample:\ncf = Compile[{},\n Module[{b = Internal`Bag[{1, 2, 3}, 1]},\n  Internal`StuffBag[b, {{4, 5, 6}, {7, 8, 9}}, 2];\n  Internal`BagPart[b, All]\n ]\n]\n\ncf[] gives:\n{1, 2, 3, 4, 5, 6, 7, 8, 9}\n\nNested Bags\nThese are created simply by stuffing one Bag into another, and do not have any special type associated with them except the types of the registers containing the pieces. In particular, there is no \"nested Bag type\". Per the casting rules given above, it is theoretically possible to stuff Integer Bags into a Real Bag and later extract them into Integer registers (for example). However, this technique is not to be recommended as the result depends on the virtual machine version; for instance, the following code is compiled into identical bytecode in versions 5.2, 7, and 8, but gives different results:\ncf2 = Compile[{},\n Module[{\n    br = Internal`Bag@Most[{0.}],\n    parts = Most[{0.}],\n    bi = Internal`Bag@Most[{0}]\n   },\n  Internal`StuffBag[bi, Range[10], 1];\n  Internal`StuffBag[br, bi];\n  parts = Internal`BagPart[br, All];\n  Internal`BagPart[First[parts], All]\n ]\n]\n\nThe result from versions 5.2 and 7:\n{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n\nThe result from version 8:\n{1.}\n\nStuffing Bags of mixed Real and Integer types into a Real Bag produces even less useful results, since pointer casts are performed by Internal`BagPart without regard to the original type of each constituent Bag, resulting in corrupted numerical values. However, nesting bags works correctly in all versions provided that the inner and outer bags are of identical types. It is also possible to stuff a bag into itself to create a circular reference, although the practical value of this is probably quite limited.\nMiscellaneous\n\nCalling Internal`BagPart with a part specification other than All will crash Mathematica kernels prior to version 8.\nInternal`Bag accepts a third argument, which should be a positive machine integer. The purpose of this argument is not clear, but in any case it cannot be used in compiled code.\n\n", "variable definitions - How do I clear all user defined symbols?": "\nMaybe this ?\nClearAll[\"Global`*\"]\n\n", "symbols - Is there a way to separate variables between multiple notebooks?": "\nMay be this, I have not tried it, but it sounds like this is what you are looking for (if I understood you correctly):\nEvaluation menu -> Notebook's Default Context -> Unique to This Notebook.\n\nSo, you do the above for each notebook.\nI found this in the daily Mathematica tip webpage: http://twitter.com/mathematicatip\nUpdate\nIf you want to do it programatically from within a notebook, run SetOptions[EvaluationNotebook[], CellContext -> Notebook].\nUpdate 2\nTo set this automatically for all new notebooks, open the Options Inspector (Ctrl/Command+Shift+O), and change the scope to \"Global Preferences.\" Then, the option CellContext is found under Cell Options -> Evaluation Options. Change it to \"Notebook.\"\n", "performance tuning - MaxSteps and Computing time issue for Solving Differential equation in Mathematica": "\nNDSolve uses adaptive methods to obtain a good solution.  It dynamically changes the step size during integration.\nI recommend you take a look at the Advanced Numerical Differential Equation Solving tutorial (ODE section), which has a very detailed description of how NDSolve work, what methods are available, and how you can tweak them.\nYou can start with \nNDSolve[..., Method -> {\"FixedStep\", Method -> \"ExplicitEuler\"}, StartingStepSize ->  ... ]\n\nto figure out what is going on (this will likely not give you a precise solution though).  There's a good chance that your differential equation is very troublesome to solve, so automatic method selection will not work well.  In this case you'll need to study the methods available, and make a suitable choice yourself.\n", "plotting - ListPlot InterpolationOrder->0 datapoint centered": "\nThis uses Nearest to build a NearestFunction (nf) for your testdata. This is like InterpolationOrder -> 0 except that it is centered because it does as the name implies: gives the nearest value.\ntestdata = {{1, 3}, {3, 4}, {4, 3}, {5, 8}, {7, 6}, {9, 4}};\n\nnf = Nearest[Rule @@@ testdata];\n\n{min, max} = {Min@# - 1, Max@# + 1} &@testdata[[All, 1]];\n\nPlot[ nf[x], {x, min, max},\n  AxesOrigin -> {0, 0},\n  Epilog -> {PointSize[Large], Point[testdata]}\n]\n\n\n", "probability or statistics - Simultaneously fitting multiple datasets": "\nThis is an extension of Heike's answer to address the question of error estimates. I'll follow the book Data Analysis: A Bayesian Tutorial by D.S. Sivia and J. Skilling (Oxford University Press).\nBasically, any error estimate depends on the basic assumptions you make. The previous answers implicitly assume uniform normally distributed noise: $\\epsilon \\sim  N(0, \\sigma)$. If you know $\\sigma$ the error estimate is straightforward.\nWith the same definitions:\ndata1 = Table[{x, RandomReal[{-.1, .1}] + f[x, 1, 1, 1]}, {x, -4, 6, 0.25}];\ndata2 = Table[{x, RandomReal[{-.1, .1}] + f[x, .5, 1, 2]}, {x, -8, 10, 0.5}];\nf[x_, amplitude_, centroid_, sigma_] := amplitude Exp[-((x - centroid)^2/sigma^2)]\n\nAdd the variables:\nvars = {mu, au1, s1, au2, s2};\n\nThe variance of the error is (analytically, from the definition above):\nnoiseVariance = Integrate [x^2, {x, -0.1, 0.1}];\n\nThe log-likelihood of the model is: \nlogModel = -Total[ (data1[[All, 2]] - (f[#, au1, mu, s1] & /@ \n       data1[[All, 1]]) )^2 /noiseVariance]/2 - \n             Total[ (data2[[All, 2]] - (f[#, au2, mu, s2] & /@ \n       data2[[All, 1]]) )^2 /noiseVariance]/2;\n\nOptimize the log-likelihood (note the change of sign leading to a maximization instead of minimization)\nfit = FindMaximum[logModel, vars]\n\nThe fit will be the same, as the variance estimation doesn't affect the maximum,  so I won't repeat it here.\nFor the error estimates, the covariance matrix is found as minus the inverse of the hessian of the log-likelihood function, so (DA p.50): \n$$\r\n\\sigma_{ij}^2 = -[\\nabla \\nabla L]^{-1}_{ij}\r\n$$\nhessianL = D[logModel {vars, 2}];\nparameterStdDeviations =  Sqrt[- Diagonal@Inverse@hessianL];\n{vars,  #1 \\[PlusMinus] #2 & @@@ ({vars /. fit[[2]], \n   parameterStdDeviations}\\[Transpose]) }\\[Transpose] // TableForm\n\nIf $\\sigma$ is unknown the analysis is slightly trickier, but the results are easily implemented. If the error is additive guassian noise of unknown variance the correct estimator is (DA p. 67): \n$$\r\ns^2 = \\frac{1}{N-1} \\sum_{k=1}^N (data_k - f[x_k; model])^2\r\n$$\nestimatedVariance1 = Total[(data1[[All, 2]] - (f[#, au1, mu, s1] & /@ \n       data1[[All, 1]]) )^2] / (Length@data2 - 1);\nestimatedVariance2 = Total[(data2[[All, 2]] - (f[#, au2, mu, s2] & /@ \n       data2[[All, 1]]) )^2] / (Length@data2 - 1); \n\nAs stated above the magnitude of the variance won't affect our point estimates in the model, so we can use the same code above, and just inject the newly estimated variance into the log-likelihood function. This seems to be equivalent to the default behaviour of NonlinearModelFit.\nAs you seem to indicate that you are fitting spectra from a counting experiment, you might have better performance if you assume Poisson counting noise instead, then the variance for each channel is estimated as the number of counts in that channel:\n$$\r\n\\sigma^2_k \\approx data_k\r\n$$\nYou might also want to consider adding a background model (a constant background is a simple extension of the above), depending on the noise level.  \n", "variable definitions - Subscripts": "\nThis is because only symbols can be localized by Module.   It is not about assignment, but localization.\nSubscript[a, 1] is not a symbol, but a compound expression, so:\nModule[{Subscript[a, 1] = \"x\"}, 0] (* <-- not allowed *)\n\nModule[{}, Subscript[a, 1] = \"x\"]  (* <-- allowed but not localized *)\n\nI agree that the error you got may be a bit confusing.\nA somewhat ugly workaround is Module[{Subscript}, Subscript[a, 1] = \"x\"] or you may try to use the Notation` package to create symbol names with subscripts in them.  A word of warning though: in some cases, Module variables that have DownValues do not get destroyed when the Module finishes evaluating.  For more information, see the end of the Module section in this answer by Leonid Shifrin, and the comments on that answer.\n", "undocumented - Bags and non-standard evaluation": "\nThis is not related to evaluation. Internal`Bag, like many other special types, is an atomic object.  You can verify this using AtomQ[x].  This is despite its InputForm suggesting a structure. \nThis is no different from how Graph, Rational, Complex or SparseArray behave.  (Though for SparseArray, most list manipulation functions are implemented, so it's much more difficult to notice that it is atomic).\n\nA similar example using Rational:\nIn[206]:= rats={1/2,2/3}\nOut[206]= {1/2,2/3}\n\nIn[208]:= Head/@rats\nOut[208]= {Rational,Rational}\n\nIn[209]:= Depth/@rats\nOut[209]= {1,1}\n\nIn[210]:= FullForm[rats]\nOut[210]//FullForm= List[Rational[1,2],Rational[2,3]]\n\n", "How to solve this iteration in the functional programming way?": "\nIf I now understand your code this should do what you want.  I am using my own f function for concise repeatability.\nf = Tr@ToCharacterCode@ToString@# &;\n\ntemp = {d -> {d}, c -> {c, d}, a -> {a, c, d}, b -> {b, d}};\n\nrules = Fold[Append[#, #2[[1]] -> f@Replace[#2, #, {2}]] &, {}, temp]\n\ntemp = Replace[temp, rules, {3}]\n\n\n{d -> 619, c -> 853, a -> 1085, b -> 851}\n\n{d -> {619},\n c -> {853, 619},\n a -> {1085, 853, 619},\n b -> {851, 619}}\n\n\n\nThis is orders of magnitude faster than your original code on long rules lists because the complete rules list is not continually reprocessed:\nf = Tr@ToCharacterCode@ToString@# &;\n\nsyms = RandomSample@Array[var, 1000];\ndat = # -> {#, Sequence @@ RandomSample[syms, RandomInteger[5]]} & /@ syms;\n\n(temp = dat;\n  rules = {};\n  Do[rules = Append[rules, temp[[i, 1]] -> f@temp[[i]]];\n   r1 = temp = Replace[temp, rules, {3}];, {i, \n    Length@temp}]) // Timing // First\n\n\n39.219\n\n\n(temp = dat;\n  rules = \n   Fold[Append[#, #2[[1]] -> f@Replace[#2, #, {2}]] &, {}, temp];\n  r2 = temp = Replace[temp, rules, {3}]) // Timing // First\n\n\n 0.14\n\n\nr1 === r2\n\n\nTrue\n\n\n", "front end - Using DynamicModule variables outside the DynamicModule": "\nWhat you want to do (make this piece of GUI resistant to kernel quits) can be achieved simply like this:\nDynamicModule[\n  {x = True, tag = Unique[StringJoin[\"g\", ToString[\n            $SessionID]]]}, CreateDocument[{\"hello\"},\n     TaggingRules -> tag, Visible -> True];\n   Checkbox[Dynamic[x,\n       (x = #1; TrueQ[Select[Notebooks[],\n                 CurrentValue[#1, TaggingRules] === tag & ] /.\n               {b_NotebookObject} :> (CurrentValue[b,\n                      Visible] =  ! CurrentValue[b,\n                        Visible])]) & ]]]\n\nThe \"wormhole\" is a unique identitfier attached to TaggingRules.\n", "functions - How to add an interpolating point to InterpolatingFunction?": "\nWhen I told you that this was not possible, I was wrong.\nMy understanding is that you have points $(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)$ through which you construct an interpolating function $f$.  Now you need to add another point $(x_0, y_0)$, and construct a new interpolating function $f^*$ for which it is true that $f^*(x) = f(x)$ for all $x \\in [x_1, x_n]$.  I thought it was not possible to keep the function value unchanged in the interval $[x_1, x_n]$ when using higher value interpolation, but this is not the case.  See below:\nLet's make an interpolation function from cosine values between 0.1 and 1.0:\nifun = Interpolation@Table[{x, Cos[x]}, {x, .1, 1, .1}]\n\nIt looks like this:\n\nThe trick is that when we add an extra point at $x=0$, we need to keep all derivatives unchanged in $x = 0.1$ up to the order of interpolation.\nYou can get the order of interpolation like this:\nifun[\"InterpolationOrder\"]\n\n(* ==> 3 *)\n\nLet's get the derivative values in the first point:\nderivs = Table[\n  Derivative[i][ifun][ifun[\"Grid\"][[1, 1]]], \n  {i, 0, First@ifun[\"InterpolationOrder\"] - 1}]\n\n(* ==> {0.995004, -0.0995897, -1.00396} *)\n\nAnd inject them back into the function, while adding a new value $f(0) = 2$:\nifun2 = Interpolation@Join[\n          {{{0}, 2},\n           {ifun[\"Grid\"][[1]], Sequence @@ derivs}},\n          Rest@Thread[{ifun[\"Grid\"], ifun[\"ValuesOnGrid\"]}]\n        ]\n\nNotice that the function is unchanged for all values greater than 0.1:\nPlot[{ifun2[x], ifun[x]}, {x, 0, 1}, PlotRange -> All]\n\n\nIf you are wondering where I got this special API to InterpolatingFunction where we do things like ifun[\"Grid\"]: I simply looked into the DifferentialEquations`InterpolatingFunctionAnatomy` package that the other answers used.\n", "replacement - Replace expressions with symbols": "\nI'm not really clear on the scope of the question, but this might provide a start.\nIn[340]:= \nPolynomialReduce[1 - Cos[\u03b1], t[1] - \u03c0 (1 - Cos[\u03b1]), \n  Cos[\u03b1]][[2]]\n\nOut[340]= t[1]/\u03c0\n\n--- edit ---\nHere is your example. I change equations to expressions in effect by taking differences. I create a Groebner basis for the defining expressions; that might not be necessary in this example. I order variables so that the one to be eliminated, Cos[alpha-sub-max], is highest. Your Eliminate came close but I think you'd really need to use Cos[alpha...] instead of just the alpha.\nIn[348]:= \nvars = Join[{Cos[Subscript[\u03b1, max]]}, \n   Table[Subscript[t, i], {i, 1, 5}]];\npolys = Table[\n   Subscript[t, i] == Pi/i (1 - Cos[Subscript[\u03b1, max]]^i), {i, \n    1, 5}];\ngb = GroebnerBasis[polys, vars];\n\nNow we can use PolynomialReduce to rewrite the expression of interest, replacing wherever possible that cosine with variables lower in the term order.\nIn[351]:= \nPolynomialReduce[\n  1/3*Pi*(Subscript[v, y]^2*Cos[Subscript[\u03b1, max]]^3 - \n     2*Subscript[v, z]^2*Cos[Subscript[\u03b1, max]]^3 - \n     3*Subscript[v, y]^2*Cos[Subscript[\u03b1, max]] + \n     2*Subscript[v, z]^2 + 2*Subscript[v, y]^2), gb, vars][[2]]\n\nOut[351]= Subscript[t, 1]*Subscript[v, y]^2 - \n Subscript[t, 3]*Subscript[v, y]^2 + \n   2*Subscript[t, 3]*Subscript[v, z]^2\n\n--- end edit ---\n--- edit 2 ---\nI saw (but no longer can locate) a comment asking about situations where there are related variables such as Sin[Subscript[\u03b1, max]/2]. This poses two wrinkles. First is that one will need to work with the smallest fractional angle in order to have polynomial relations between all such angles that can be algebraically related. The second is that one must also add the obvious trig relations such as Sin[XXX]^2+Cos[XXX]^2-1 where XXX is this smallest fractional angle. (Actually I am not sure if this relation must be added, or if GroebnerBasis preprocessing will figure that out for you. Assume it must be added by hand and you won't go too far astray.)\n--- end edit 2 ---\n--- edit 3 ---\nElaborating on edit 2 using an example from a comment, we use more trig variables and relationship polynomials.\nIn[74]:= vars = \n  Join[{Sin[Subscript[\u03b1, max]/2], \n    Cos[Subscript[\u03b1, max]/2], Sin[Subscript[\u03b1, max]], \n    Cos[Subscript[\u03b1, max]]}, Table[Subscript[t, i], {i, 1, 5}]];\npolys = Join[{Cos[Subscript[\u03b1, max]]^2 + \n     Sin[Subscript[\u03b1, max]]^2 - 1, \n    Cos[Subscript[\u03b1, max]/2]^2 + \n     Sin[Subscript[\u03b1, max]/2]^2 - 1, \n    Cos[Subscript[\u03b1, \n       max]] - (Cos[Subscript[\u03b1, max]/2]^2 - \n       Sin[Subscript[\u03b1, max]/2]^2), \n    Sin[Subscript[\u03b1, max]] - \n     2*Cos[Subscript[\u03b1, max]/2]*\n      Sin[Subscript[\u03b1, max]/2]}, \n   Table[Subscript[t, i] - \n     Pi/i (1 - Cos[Subscript[\u03b1, max]]^i), {i, 1, 5}]];\ngb = GroebnerBasis[polys, vars];\n\nIn[66]:= p1 = \n  4/3*k^2*Sin[Subscript[\u03b1, max]/2]^4*(3*Pi - t[1])*\n   Subscript[v, y];\n\nIn[80]:= PolynomialReduce[p1, gb, vars][[2]]\n\nOut[80]= -((2*(-3*k^2*Pi*Subscript[t, 1]*Subscript[v, y] + \n       3*k^2*Pi*Subscript[t, 2]*\n              Subscript[v, y] + \n       k^2*Subscript[t, 1]*Subscript[v, y]*t[1] - \n            k^2*Subscript[t, 2]*Subscript[v, y]*t[1]))/(3*Pi))\n\nHere is another requested example. In this case preprocessing with TrigExpand causes a multiple angle trig term to disappear, allowing the polynomial replacement to work to its fullest capability.\nIn[91]:= p2 = \n  1/6*k^2 Pi*(8 - 9*Cos[Subscript[\u03b1, max]] + \n     Cos[3*Subscript[\u03b1, max]])*Subscript[v, y];\n\nIn[92]:= PolynomialReduce[p2 // TrigExpand, gb, vars][[2]]\n\nOut[92]= 2*(k^2*Subscript[t, 1]*Subscript[v, y] - \n   k^2*Subscript[t, 3]*Subscript[v, y])\n\n--- end edit 3 ---\n", "list manipulation - How to find rows that have maximum value?": "\nWith:\ndat = {{10, b, 30}, {100, a, 40}, {1000, b, 10}, {1000, b, 70}, {100, b, 20}, {10, b, 70}};\n\nPerhaps most directly:\nCases[dat, {_, _, Max@dat[[All, 3]]}]\n\nMore approaches:\n\nLast @ SplitBy[SortBy[dat, {#[[3]] &}], #[[3]] &]\nPick[dat, #, Max@#] &@dat[[All, 3]]\nReap[Fold[(If[#2[[3]] >= #, Sow@#2]; #2[[3]]) &, dat]][[2, 1]]\n\nOf these Pick appears to be concise and efficient, so it is my recommendation.\nEdit: Position and Extract are three times as efficient as Pick on some data.  Using Transpose is slightly more efficient on packed rectangular data.\n\ndat ~Extract~ Position[#, Max@#] & @ dat[[All, 3]]\ndat ~Extract~ Position[#, Max@#] & @ Part[dat\\[Transpose], 3]\n\nHere are some timings performed in version 7:\nSetAttributes[timeAvg, HoldFirst]\ntimeAvg[func_] := Do[If[# > 0.3, Return[#/5^i]] & @@ Timing@Do[func, {5^i}], {i, 0, 15}]\n\nSeedRandom[1]\ndat = RandomInteger[99999, {500000, 3}];\n\nCases[dat, {_, _, Max@dat[[All, 3]]}]                          // timeAvg\nLast@SplitBy[SortBy[dat, {#[[3]] &}], #[[3]] &]                // timeAvg\nPick[dat, #, Max@#] &@dat[[All, 3]]                            // timeAvg\nReap[Fold[(If[#2[[3]] >= #, Sow@#2]; #2[[3]]) &, dat]][[2, 1]] // timeAvg\ndat ~Extract~ Position[#, Max@#] &@dat[[All, 3]]               // timeAvg\ndat ~Extract~ Position[#, Max@#] &@Part[dat\\[Transpose], 3]    // timeAvg\n\n\n0.1278\n0.764\n0.0904\n0.904\n0.02996\n0.02496\n\n(In actuality I restarted the Kernel between each individual timing line as otherwise each run gets slower, unfairly biasing the test toward the earlier lines.)\nThese can be further optimized by using faster position functions for numeric data.\nMichael E2 recommended compiling (probably faster in versions after 7):\npos = Compile[{{list, _Real, 1}, {pat, _Real}}, Position[list, pat]];\ndat ~Extract~ pos[#, Max@#] & @ Part[dat\\[Transpose], 3] // timeAvg\n\n\n0.01372\n\nMy favorite method is SparseArray properties:\nspos = SparseArray[Unitize[#], Automatic, 1][\"AdjacencyLists\"] &;\ndat[[spos[# - Max@#]]] & @ Part[dat\\[Transpose], 3] // timeAvg\n\n\n0.002872\n\nThis is now about 30X faster than Pick, my original recommendation.\n", "front end - How do I add new menuitems to menus?": "\nI've never seen that command before but this does work at least in version 7 on Windows:\nFrontEndExecute[\n AddMenuCommands[\n  \"BackgroundDialog\", {Delimiter, \n   Item[\"L&inen\", Background -> RGBColor[0.980, 0.941, 0.902]], \n   Item[\"A&liceBlue\", Background -> RGBColor[0.941, 0.973, 1.0]], \n   Item[\"Min&tCream\", Background -> RGBColor[0.961, 1.0, 0.980]], \n   Item[\"Lig&htYellow\", Background -> RGBColor[1.0, 1.0, 0.878]], \n   Item[\"Smok&e\", Background -> RGBColor[0.961, 0.961, 0.961]], \n   Item[\"Mi&styRose\", Background -> RGBColor[1.0, 0.894, 0.882]]}]]\n\n\nThat comes from this MathGroup post. (Now improved; see comments.)\nFurther reading tells us:\n\nYou can completely reset the menus using...\nFrontEndExecute[FrontEnd`ResetMenusPacket[{Automatic}]]\n\n\n", "curated data - Is there a Mathematica API for the functions.wolfram site?": "\nHere is a shameless plug for my HTML parser posted here. The code is a bit long to reproduce here, the only change to it I'd do is to replace the function processPosList with this code:\nprocessPosList::unmatched = \"Unmatched lists `1` enountered!\";\nprocessPosList[{openlist_List, closelist_List}] := \n  Module[{opengroup, closegroup, poslist}, \n  {opengroup, closegroup} = groupPositions /@ {openlist, closelist};\n   poslist = Transpose[Transpose[Sort[#]] & /@ {opengroup, closegroup}];\n   If[UnsameQ @@ poslist[[1]], Return[(Message[\n       processPosList::unmatched , {openlist, closelist}]; {})], \n   poslist = Transpose[{poslist[[1, 1]], Transpose /@ Transpose[poslist[[2]]]}]]];\n\nwhich will issue a message when some parts can not be parsed instead of printing the details (as the original code does). I must warn that my parser for some reason can not fully parse the Wolfram Functions pages (either they are ill-formed or my parser contains bugs), but it will parse enough for our purposes. Here is a simple web-scraper based on it and on a few observations about the typical format of the page:\nClear[getForms];\ngetForms[url_String] := \n Quiet@ Cases[postProcess@parseText[Import[url, \"Text\"]],\n     pContainer[attribContainer[\" class='CitationInfo'\"], x__String] :> \n        StringJoin@x, Infinity] //. \n       x_String :>  StringReplace[ x, {\"&quot;\" | \"quot;\" :> \"\\\"\", \"&amp;\" :> \"\", \n             \"&lt;\" | \"&lt\" :> \"<\", \"&gt;\" | \"&gt\" :> \">\", \"\\n\" :> \" \"}];\n\n\nClear[formsOk, getInputForm, getStandardForm, getRuleForm];\nformsOk[forms_] := Length[forms] == 5;\ngetInputForm[forms_?formsOk] := ToExpression[forms[[1]], InputForm];\ngetStandardForm[forms_?formsOk] := ToExpression[First@ToExpression[forms[[2]]], StandardForm];\ngetRuleForm[forms_?formsOk] := ToExpression[First@ToExpression[forms[[4]]]];\ngetInputForm[__] = getStandardForm[__] = getRuleForm[__] = $Failed;\n\nI can not say how fragile this is, probably rather fragile. Here is an example of use:\nIn[277]:= \nforms = getForms[\"http://functions.wolfram.com/07.23.17.0084.01\"];\nThrough[{getInputForm,getStandardForm,getRuleForm}[forms]]\n\nOut[278]= {Hypergeometric2F1[a,b,-(1/2)+a+b,z]==((Sqrt[1-z]-Sqrt[-z])^(1-2 a) \n  Hypergeometric2F1[-1+2 a,-1+a+b,-2+2 a+2 b,2 z+2 Sqrt[-z+z^2]])/Sqrt[1-z]/;Re[z]>1/2,\n  Hypergeometric2F1[a,b,-(1/2)+a+b,z]==((Sqrt[1-z]-Sqrt[-z])^(1-2 a) \n  Hypergeometric2F1[-1+2 a,-1+a+b,-2+2 a+2 b,2 z+2 Sqrt[-z+z^2]])/Sqrt[1-z]/;Re[z]>1/2,\n  HoldPattern[Hypergeometric2F1[a_,b_,a_+b_-1/2,z_]]:>((Sqrt[1-z]-Sqrt[-z])^(1-2 a) \n  Hypergeometric2F1[2 a-1,a+b-1,2 a+2 b-2,2 Sqrt[z^2-z]+2 z])/Sqrt[1-z]/;Re[z]/2}\n\nI tested on about 10 different formulas, and this worked fine, but of course this is not an extensive test, so most likely this will not always work.\n", "boolean computation - Are there \"All\" and \"Any\" functions in Mathematica?": "\nBoth, And and Or should work for All and Any respectively. You may have to get creative in how you apply them, though. For instance,\nAnd @@ {True, False, True}\n\nworks just like you would expect \nAllOf @ {True, False, True}\n\nto without any additional work. Similarly,\nOr @@ {False, True, False}\n\nworks like AnyOf.\n", "How to import date (YYYY-MM-DD) data from a file?": "\nImport[(* file *), \"Table\", \"DateStringFormat\" -> {\"Year\", \"-\", \"Month\", \"-\", \"Day\"}] seems to work...\n\nAs a test:\nExport[\"test.dat\",\n       {{\"2010-05-19\", 17}, {\"2010-05-20\", 20}, {\"2010-05-21\", 19}},\n       \"FieldSeparators\" -> \" \"];\n\nImport[\"test.dat\", \"Table\",\n       \"DateStringFormat\" -> {\"Year\", \"-\", \"Month\", \"-\", \"Day\"}]\n{{{2010, 5, 19}, 17}, {{2010, 5, 20}, 20}, {{2010, 5, 21}, 19}}\n\n", "programming - How to make TraditionalForm display the same in the Manipulate output as in a notebook?": "\nThis is just a matter of different style (font here). This will produce identical output to what you get outside of Manipulate: \nManipulate[\n    Style[\n        TraditionalForm[-Derivative[2, 0][u][x, y] - Derivative[0, 2][u][x, y] == f[x, y]], \n        FontFamily -> \"Times\"\n    ], \n    {z, None}]\n\n", "image processing - How to make a drop-shadow for a Graphics3D objects?": "\nThis produces a 2D shadow. If you meant a 3D shadow (on the x-y plane), see code below.\nimage = Rasterize[Graphics3D[Sphere[], Boxed -> False]];\nshadow = Blur[RegionBinarize[ColorNegate[image], {{1, 1}}, 0.1], 20];\n\nimage = SetAlphaChannel[image, ColorNegate@Binarize[image, {1, 1}]];\n\nShow[{shadow, image}]\n\n\nThe position of the shadow has to be fine tuned manually.\nI also managed to construct it in 3D (rotatable), though I cannot make the bottom polygon transparent.\nshadow = Blur[\n   RegionBinarize[Graphics[Circle[], ImagePadding -> 60], {{1, 1}}, \n    0.1], 40];\nshadow = SetAlphaChannel[shadow, ColorNegate@shadow];\n\nGraphics3D[{\n  Sphere[],\n  EdgeForm@None, Opacity@.7, Texture@shadow, \n  Polygon[{{-1, -1, -2}, {1, -1, -2}, {1, 1, -2}, {-1, \n     1, -2}, {-1, -1, -2}}, \n   VertexTextureCoordinates -> {{0, 0}, {1, 0}, {1, 1}, {0, 1}}]\n  }, Boxed -> False]\n\n\n", "Finding a subsequence in a list": "\nI asked the same question on StackOverflow recently, and the answer that is now my favourite came from Jan P\u00f6schko (modified):\nfindSubsequence[list_, {ss__}] := \n  ReplaceList[list, {pre___, ss, ___} :> Length[{pre}] + 1]\n\nThis will find all positions of ss in list.  Example:\nfindSubsequence[Range[50] ~Mod~ 17, {4, 5, 6}]\n\n\n{4, 21, 38}\n\nDespite using patterns, this solution runs very quickly, even for packed arrays.  Please see the question I linked to for more possibilities.\n\nA potentially useful generalization to other heads may be had with:\nfindSubsequence[list : h_[__], _[ss__]] :=\n  ReplaceList[list, h[pre___, ss, ___] :> Length[{pre}] + 1]\n\nAllowing such forms as:\nx = Hold[1 + 1, 2 + 1, 3 + 1, 4 + 1, 2 + 1, 3 + 1, 1 + 1, 2 + 1, 3 + 1];\n\nfindSubsequence[x, Hold[2 + 1, 3 + 1]]\n\n\n{2, 5, 8}\n\n", "list manipulation - Combination and Permutation": "\nTake all subsets of length 10, then for each one find all splits into two sets of five such that the first of the ten is in the first part of the split.\nIn[29]:= Timing[\n msets = Subsets[Range[12], {10}];\n m2 = Flatten[\n   Map[With[{fst = First[#], subs = Subsets[Rest[#], {4}], mset = #}, \n      With[{s2 = Map[Join[{fst}, #] &, subs]}, \n       Map[{#, Complement[mset, #]} &, s2]]] &, msets], 1];]\n\nOut[29]= {0.07799999999999985, Null}\n\nIn[30]:= Length[m2]\n\nOut[30]= 8316\n\n", "plotting - Styling ticks, axes and other elements in a Plot of a step function": "\nFor the arrow heads on the axes, use an Epilog inside the Plot with the Arrow function, or use the techniques described in this post: https://stackoverflow.com/questions/5844790/arrows-for-the-axes.\nFor the tick labeling, use for each item in the list of x-tick and y-tick locations not just the number but a list that includes the number and the corresponding label:\nTicks -> {{{-3, -3 Q}, {-2, -2 Q}, {-1, -Q}, {1, +Q}, {2, 2 Q}, {3, \n3 Q}}, {-3, -2, -1, 1, 2, 3}}\n\nwhere I've done it just with the x-ticks. If you insist on having the \"+\" prefixes on the positive ones, you could change, say, {1,+Q} to:{1, TraditionalForm@HoldForm[+Q]} and similarly for the others.\nOf course you could write a little function that you would do all that with the ticks simply by applying it to the list of x-tick numbers and the list of y-tick numbers.\nBy default, as you've seen, tick marks are drawn only to the positive side of the axis and at a predetermined length. To change that to get each tick mark crossing the axis, use an option third entry for each tick: a list {plen,nlen} giving (as a fraction of the image size, I believe) how far the tick mark should extend in the positive and negative direction from the axis. For example:\nTicks -> {{{-3, -3 Q, {0.01, 0.01}...\n\nYou didn't say exactly what features of the displayed graphic you couldn't satisfactorily reproduce in Mathematica, but perhaps the size of the text, including tick labels, is an issue. In that case, you could use the BaseStyle-> option to Plot if you wanted to uniformly change all the text sizes, fonts, weights, etc. If, however, you want different treatment of different text elements, then you could modify each one by a Style treatment, e.g.:\nTicks -> {{{-3, -Style[3 Q, 24, Red, Bold, FontFamily -> \"Papyrus\"],...\n\n(My system has that font installed; yours may not.)\n", "plotting - Creating a data1 versus data2 plot?": "\nAssuming the name of the table is data \ndata =\n  {\n   {1, 2, 3, 4, 5, 6},\n   {2, 3, 4, 5, 6, 7},\n   {3, 4, 5, 6, 7, 8},\n   {4, 5, 6, 7, 8, 9}\n   };\n\nThe 3rd column would be data[[All,3]] and the 5th data[[All,3]]. All means: take all elements of the given index. Since we need to plot x against y we need a submatrix containing the 3rd and 5th column. Data[[All,{5,3}]] does that.\ndata[[All, {5, 3}]]\n\n(*\n==> {{5, 3}, {6, 4}, {7, 5}, {8, 6}}\n*)\n\nThere are many plot functions in Mathematica. In this case, ListPlot or ListLinePlot are appropriate.\nListPlot[data[[All,{5,3}]]]\n\n\nListLinePlot[data[[All,{5,3}]]]\n\n\nThere are many, many options to tune those plots. I suggest looking up those in the extensive electronic documentation in the Help menu or by selecting a command and pressing F1 (Windows)\nThings to look up:\n\nPart ( [[...]] ) \nManipulating Elements Of Lists\nGetting Pieces Of Lists\nThe data visualization overview page and its descendants\nThe function visualization overview page and its descendants\n\n", "functions - sprintf() or close equivalent, or re-implementation?": "\nI've had a need for such a function several times, and I found this implementation of C-style *printf functions, by Vlad Seghete. To use it, all you need to do is extract the files to $UserBaseDirectory/MathPrintF/ and you're all set.\nHere's an example once you've installed it:\n<<MathPrintF`\nsprintf[\"%d %s %d %s, %s %s %s %s\", \n    Sequence @@ Riffle[{1, 2, \"red\", \"blue\"}, {\"fish\"}, {2, -1, 2}]]\n\nOut[1]= 1 fish 2 fish, red fish blue fish\n\n\nAlso note the following caveat in the README\n\nLimited Functionality\nWhile we tried to mimic the C-standard as much as possible, only certain\n  features are implemented. These are mainly dictated by what we needed at\n  the time. In particular %d, %f, %e, %E and %s with most of their options\n  are implemented. \n\n", "graphics - How can I create a ColorFunction using Blend?": "\ndistance = {0.245, -0.235, 0.053, -0.048, -0.128, -0.007, -0.075, -0.067, -0.005, 0.082}\n\nShow[Function[attributes, \n   Graphics[{Blend[{{-Max[Abs[distance]], Red}, {0, LightRed}, {0, \n        LightGreen}, {+Max[Abs[distance]], Green}}, \n      distance[[attributes]]], \n     Rectangle[{If[distance[[attributes]] < 0, \n        distance[[attributes]]*10, 0], \n       attributes - 1}, {If[distance[[attributes]] < 0, 0, \n        distance[[attributes]]*10], attributes}], \n     PlotRange -> {{-5, 5}, {0, 10}}}, \n    Epilog -> {White, Line[{{0, 0}, {0, 11}}]}]] /@ Range[10], \n Frame -> True]\n\n\n", "list manipulation - On generalizing Partition[] (with offsets) to sublists of unequal length": "\nThis is a complete re-write\nThis is the original solution which was done in haste but i will leave here. It works in limited cases:\nmultisegment[lst_List, scts_List, offset_List] := \n Module[{acc, offs}, \n  offs = 1+Prepend[Accumulate[PadRight[offset, \n      1 + Ceiling[Length[lst]/Total[offset]], offset]], 0];\n  acc = PadRight[scts, Length[offs],scts];\n  acc = acc + offs - 1;\n  Inner[Take[lst, {#1, #2}] &, offs, acc, List]\n  ]\n\nmultisegment[Range[14], {4, 3}, {3, 1}]\n{{1, 2, 3, 4}, {4, 5, 6}, {5, 6, 7, 8}, {8, 9, 10}, {9, 10, 11, \n  12}, {12, 13, 14}}\n\nTo solve this you note that the starting position (for Part or Take) of the list depends solely on the offset list:\n{1,4,5,8,9,12}\n\nThe \"span to\" position is determined by adding the partition list\n{4,3,4,3,4,3}\n\nto the offset list (minus 1) to give\n{4,6,8,10,12,14}\n\nFrom there, proceed as before with Inner and use either Take or Part. So this becomes an exercise in generating the correct offset list. As earlier failed attempts have shown, this is dependent on both the total of the offsets and the length of the offsets (list).\nBut also you do not want your Take or \"span to\" range exceeding the length of your target list. I have taken the easy way out here but using DeleteCases. A more exact and possibly elegant, but maybe not faster (?), approach is to actually work this out based on the partition list.\nmultisegment[lst_List, scts_List, offset_List] := \n Module[{fin, offs, len = Length[lst], tot = Total[offset], len2 = Length[offset]}, \n  offs = 1 + Prepend[Accumulate[\n      PadRight[offset, Ceiling[len2*len/tot], offset]], 0];\n  fin = PadRight[scts, Length[offs], scts] + offs - 1;\n  fin = DeleteCases[Transpose[{offs, fin}], {_, x_ /; x > len}];\n  Take[lst, #] & /@ fin]\n\n (* case for no offsets *)\n multisegment[lst_List, scts_List] := multisegment[lst, scts, scts]\n\nI prefer to layout the code in steps rather than combine multiple steps into a one (or two) liner. Feel free to do that if you wish but I think this way makes it easier for people to check out what is happening.\nAlso a qualifier: checks and/or conditions should be added. you cannot have {0} for your partition or offset. Must be integers etc. as per Simon's comments.\nUsage. First the base case of an uneven partition with no offset\nmultisegment[Range[14], {3, 4}]\n{{1, 2, 3}, {4, 5, 6, 7}, {8, 9, 10}, {11, 12, 13, 14}}\n\nnow add an offset\nmultisegment[Range[14], {3, 4}, {1, 2}]\n{{1, 2, 3}, {2, 3, 4, 5}, {4, 5, 6}, {5, 6, 7, 8}, {7, 8, 9}, {8, 9, \n  10, 11}, {10, 11, 12}, {11, 12, 13, 14}}\n\nExamples that previously failed:\nmultisegment[Range[10], {5, 4}, {2, 3}]\n{{1, 2, 3, 4, 5}, {3, 4, 5, 6}, {6, 7, 8, 9, 10}}\n\nmultisegment[Range[100], {5, 4}, {2, 3}]\n{{1, 2, 3, 4, 5}, {3, 4, 5, 6}, {6, 7, 8, 9, 10}, {8, 9, 10, 11}, {11,\n   12, 13, 14, 15}, {13, 14, 15, 16}, {16, 17, 18, 19, 20}, {18, 19, \n  20, 21}, {21, 22, 23, 24, 25}, {23, 24, 25, 26}, {26, 27, 28, 29, \n  30}, {28, 29, 30, 31}, {31, 32, 33, 34, 35}, {33, 34, 35, 36}, {36, \n  37, 38, 39, 40}, {38, 39, 40, 41}, {41, 42, 43, 44, 45}, {43, 44, \n  45, 46}, {46, 47, 48, 49, 50}, {48, 49, 50, 51}, {51, 52, 53, 54, \n  55}, {53, 54, 55, 56}, {56, 57, 58, 59, 60}, {58, 59, 60, 61}, {61, \n  62, 63, 64, 65}, {63, 64, 65, 66}, {66, 67, 68, 69, 70}, {68, 69, \n  70, 71}, {71, 72, 73, 74, 75}, {73, 74, 75, 76}, {76, 77, 78, 79, \n  80}, {78, 79, 80, 81}, {81, 82, 83, 84, 85}, {83, 84, 85, 86}, {86, \n  87, 88, 89, 90}, {88, 89, 90, 91}, {91, 92, 93, 94, 95}, {93, 94, \n  95, 96}, {96, 97, 98, 99, 100}}\n\nExample showing it working with increasing offset list length\nmultisegment[Range[44], {3, 4}, {1, 3, 2}]\n{{1, 2, 3}, {2, 3, 4, 5}, {5, 6, 7}, {7, 8, 9, 10}, {8, 9, 10}, {11, \n  12, 13, 14}, {13, 14, 15}, {14, 15, 16, 17}, {17, 18, 19}, {19, 20, \n  21, 22}, {20, 21, 22}, {23, 24, 25, 26}, {25, 26, 27}, {26, 27, 28, \n  29}, {29, 30, 31}, {31, 32, 33, 34}, {32, 33, 34}, {35, 36, 37, \n  38}, {37, 38, 39}, {38, 39, 40, 41}, {41, 42, 43}}\n\nmultisegment[Range[44], {3, 4}, {1, 3, 2, 4}]\n{{1, 2, 3}, {2, 3, 4, 5}, {5, 6, 7}, {7, 8, 9, 10}, {11, 12, 13}, {12,\n   13, 14, 15}, {15, 16, 17}, {17, 18, 19, 20}, {21, 22, 23}, {22, 23,\n   24, 25}, {25, 26, 27}, {27, 28, 29, 30}, {31, 32, 33}, {32, 33, 34,\n   35}, {35, 36, 37}, {37, 38, 39, 40}, {41, 42, 43}}\n\nand so on, and so forth.\n", "notebooks - How to find pieces of code responsible for syntax errors?": "\nNew answer\nThere was actually an old post on mathgroup, Strange Syntax problem,\nthat looks like it was exactly the same problem you're experiencing. \nA power/superscript being associated with the closing parenthesis instead of the whole parenthesized expression (see the box forms presented in my original answer below for more details).\nUnfortunately, this problem was not resolved in the the mathgroup post.\nThe best I can suggest at the moment is to simply press the + button\n\nto get the expanded form\n\nThis should help narrow down the problem. \nNote the Syntax::bktmcp warning is talking about non-matching brackets, yet in the visible expression, all brackets are properly matched. So, the problem lies in the underlying box expression.\nAlternatively, if it is this particular problem, you could Show Expression, then search for the problematic code snippet SuperscriptBox[\")\". \nThen you can modify the box structure directly.\nThis is normally easiest if you paste it into a new input cell so that the Extend Selection mechanism works.\nOriginal answer\nThere is no \"hidden bad character\" in the cell that you posted. Rather, the box structure is crazy and can't be interpreted by Mathematica - I have trouble imagining how you managed to create it...\nHere's your cell\nCell[BoxData[\n RowBox[{\"(\", \n  RowBox[{\"k\", \"h\"}], \n  SuperscriptBox[\")\", \"2\"]}]], \"Input\"]\n\nand here is how it should look\nCell[BoxData[\n SuperscriptBox[\n  RowBox[{\"(\", \n   RowBox[{\"k\", \" \", \"h\"}], \")\"}], \"2\"]], \"Input\"]\n\nSo, your question does not really a work with the example you provided.\nHowever, a simple way to maybe clean your code (at least in this case) is to copy it as plain text or input text, both of which produce (k h)^2 when pasted.\n", "programming - Struct equivalent in Mathematica?": "\nUpdate:  Mathematica 10 has introduced Association, which can be used as a close equivalent of structs.\nparams = <| \"par1\" -> 1, \"par2\" -> 2 |>\n\nparams[\"par1\"]\n(* ==> 1 *)\n\nIn version 10 pure functions can have named arguments, and can be effectively used as expression templates where the slots can be populated from an association.  This is similar to the technique I describe in the original version of this post (below the line).\n#par1 + #par2 & [params]\n\nwill evaluate to 1 + 2 then to 3. \nThat said, my personal workflow still fits better with the approach described below the line (withRules).  The reason for this is that I tend to build up calculations interactively and incrementally.  This means that I do not start by writing the equivalent of an expression template (which would require thinking ahead...).  Instead I start with all the values explicitly written out, and later I replace them with a global variable.  This global variable can be simply Unset, and given a local value using withRules, then eventually changed into a function argument.\n\nQuoting the OP's comment:\n\nMost of the work I do involves constructing mathematical models and\n  then testing various scenarios against those models. I'd like to be\n  able to populate a particular scenario and then pass that scenario to\n  a model. I'd also like to be able to copy that scenario, modify one or\n  more parameters, and then pass the new scenario to the model.\n\nThe requirement, as I understand, is to be able to pass many parameter values around in a structured way.  Lists of rules are convenient for this:\nparams = {par1 -> 1, par2 -> 2, par3 -> {x,y,z}}\n\nThey can be extracted like this:\npar1 /. params\n\n(* ==> 1 *)\n\nOnce I wrote a function for substituting such parameter lists into bigger pieces of code:\nClearAll[withRules]\nSetAttributes[withRules, HoldAll]\nwithRules[rules_, expr_] :=\n  First@PreemptProtect@Internal`InheritedBlock[\n    {Rule, RuleDelayed},\n    SetAttributes[{Rule, RuleDelayed}, HoldFirst];\n    Hold[expr] /. rules\n]\n\nIt can be used like this:\nwithRules[params,\n  par1 + par2\n]\n\n(* ==> 3 *)\n\nwithRules can contain complex code inside, and all occurrences of par1, par2, etc. will be substituted with the values from the parameter list.\nWe can also write a function for easily modifying only a single parameter (from the whole list), and returning a new parameter list.  Here's a simple implementation:\nsetParam[paramList_, newRules_] :=\n DeleteDuplicates[Join[newRules, paramList], \n  First[#1] === First[#2] &]\n\nExample usage:\nsetParam[params, {par2 -> 10}]\n\n(* ==> {par2 -> 10, par1 -> 1, par3 -> {x, y, z}} *)\n\nAnother list which has a different value for par2 is returned.\n\nIf needed, this could be extended to support more complex, structured lists such as { par1 -> 1, group1 -> {par2x -> 10, par2y -> 20}}, much how like the built-in option-handling works.  \n\nAddendum by celtschk:  It's possible to extract a value from a list of rules using OptionValue as well: OptionValue[params, par1].\n", "syntax - Representing second derivatives with a double overdot": "\ng[x_] := Overscript[x, \"..\"]\nPrint[HoldForm[g[x]], \" == \", g[x]]\n\nYou could use AdjustmentBox to tweak the two dots, but maybe this is not necessary.\n", "graphics - Is there an equivalent of FullGraphics for Graphics3D?": "\nNo solution with 3D return, but you can \"vectorize\" 3D graphics by using the good ole ImportString[ExportString[...]] trick which results in a (large) 2D Graphicsexpression:\ng = Plot3D[Sin[x + y^2], {x, -3, 3}, {y, -2, 2}]\n\n\nvectorized2D = ImportString[ExportString[g, \"PDF\"], \"PDF\"][[1]]\n\n\nThis is now  a Graphics expression that you can use to extract certain features:\nCases[vectorized2D, _JoinedCurve, Infinity] // Graphics\n\n\nbut finding the right patterns for the stuff you might want to work with could take some effort. Also you have to live with the fact that some appearances will change more or less dramatically.\n", "custom notation - Can we use letter with a subscript as a variable in Mathematica?": "\nYes you can, with limitations.\nYou have at least three different ways to make an assignment to a subscripted symbol a0 :\n\nmake a rule for Subscript\nmake a rule for a\n\"symbolize\" a0 using the Notation package/palette\n\nIn each case below, when I write e.g. Subscript[a, 1] this can also be entered as a1 by typing a then Ctrl+_ then 1.\nWhen you write:\nSubscript[a, 1] = \"dog\";\n\nYou make an assignment to Subscript:\nDownValues[Subscript]\n\n\n{HoldPattern[a1] :> \"dog\"}\n\nYou make a rule for a by using TagSet:\na /: Subscript[a, 2] = \"cat\";\n\nUpValues[a]\n\n\n{HoldPattern[a2] :> \"cat\"}\n\nIf you use the Notation palette you mess with underlying Box forms behind the scenes, allowing for assignment to OwnValues:\n\nEach of these can be cleared with either Unset or TagUnset:\nSubscript[a, 1] =.\n\na /: Subscript[a, 2] =.\n\n\n", "version 8 - Problem with EllipticE documentation": "\nI just tried it with both Mathematica 7 and 8, and Mathematica 7 gives the result from the documentation, while Mathematica 8 indeed gives just EllipticE[z, m].\nTherefore I conclude Wolfram modified Integrate but forgot to update this piece of documentation.\n", "plotting - Is it possible to speed up ContourPlot on multi-core machines?": "\nI second @Verbeia's suggestion: compute the function on a mesh of points and use ListContourPlot.  The disadvantage is that ListContourPlot has no adaptive sampling, so it'd be preferable if we could do our own adaptive sampling somehow.  Adaptive sampling can give you a much better result while needing to compute the function in far less points---and the problem here is indeed computation time.  So ContourPlot with its adaptive sampling might give a better result in less time on a single CPU than ListContourPlot will with a high resolution mesh computed on many CPUs.\nAdaptive sampling is what I asked about (and solved) here:  Adaptive sampling for slow to compute functions in 2D\nThe method I implemented there is usable (I am using it for something very similar to what you describe) but it is not nearly as good as ContourPlot's own.  So one might still try to somehow make use of it.  I'm quoting one suggestion I received from Leonid Shifrin there (in a comment):\n\nYou probably can control the DensityPlot, although not directly. Since\n  it calls your function, you can simply Sow the values until some\n  criteria (which you define) is violated (or satisfied). Then, you stop\n  via throwing an exception, and catching it in the outer function, but\n  still inside Reap. Alternatively, you could just start fooling\n  DensityPlot by supplying faked values (perhaps, interpolated, or\n  whatever), and it will stop by itself, I guess. Not sure this will\n  work for you, but it may be worth trying.\n\nI have not tried to implement this before, but I think it could work if your function is sufficiently smooth (which mine is definitely not, but yours may be).\nHere's a quick sample implementation of how it could work:\nFirst, let's define a sample function to plot:\nfun[{x_, y_}] := 1/(1 + Exp[10 (Norm[{x, y}] - 3)])\n\nLet's divide both the $x$ and $y$ axes into 5 parts on the interval $[0,5]$ and generate a mesh of points:\ninitialDivision = Range[0, 5];\n\npoints = N@Tuples[initialDivision, {2}];\n\nCalculate function values on the intial mesh.  This can be parallelized (just use ParallelMap)\nvalues = fun /@ points;\n\nThis counter i will be used to control the maximal subdivisions in ContourPlot:\ni = 0;\n\nNow put the following code into a single cell, and evaluate it several times.  Each time a finer and finer approximation will be computed.  The points where function values have been computed will also be visualized.  Note that I fixed the plot points in ContourPlot to force it to use the same initial mesh that I used, and I also fixed the number of contours.\nif = Interpolation@ArrayFlatten[{{points, List /@ values}}]\n\n{plot, {newpoints}} = Reap[\n   ContourPlot[if[x, y], {x, 0, 5}, {y, 0, 5}, \n    Contours -> Range[0, 1, .1], MaxRecursion -> (++i), \n    PlotPoints -> Length[initialDivision], \n    EvaluationMonitor :> Sow[{x, y}]]\n   ];\nplot\n\nnewpoints = Complement[newpoints, points];\nnewvalues = fun /@ newpoints;  (* <-- this can be parallelized *)\npoints = Join[points, newpoints];\nvalues = Join[values, newvalues];\n\nGraphics[Point[points]]\n\nAfter a few iterations the contour plot and the point mesh will look like this (note that the code above only plots the contours for the previous step, not the current results):\n\n\nAfter 3 iterations, this method has computed the function value in 3809 points for this particular function.\nLet's compare this with a plain ContourPlot using the same parameters:\nContourPlot[fun[{x, y}], {x, 0, 5}, {y, 0, 5}, \n    PlotPoints -> 6, MaxRecursion -> 3]\n\n\nThe quality of the plot is about the same with a plain ContourPlot as well.\nHow many points did the plain CountoutPlot use?\nReap[ContourPlot[fun[{x, y}], {x, 0, 5}, {y, 0, 5}, PlotPoints -> 6, \n    MaxRecursion -> 3, EvaluationMonitor :> Sow[{x, y}]]][[2, 1]] // Length\n\n(* ==> 3790 *)\n\nIt uses almost the same number of points, so if the bottleneck is computing f, the method I described is going to be almost as fast as ContourPlot on a single core, with the advantage that it is parallelizable for multiple cores.\nThe next step would be packaging this up into a self-contained function, but seeing how the quality improves step by step is also valuable as you can make decisions about when to stop calculating (and avoid excessive computation times).\n\nI find it quite disappointing that all those nice and fast algorithms that plotting functions use (fast Voronoi cells, Delaunay trinagulation, adaptive sampling) are not directly accessible by users.  We either have to use hacks to access these algorithms or reimplement them.\n", "graphics - 2D Gaussian distribution of squares coordinates": "\nThis reproduces the image decently. It works by sampling without replacement from all the positions, and randomly coloring them with a built-in color scheme. \nsize = 41; \namountCovered = 0.40;\nnoSquares = Floor[amountCovered*size^2];\ntiles = Flatten[Table[{i, j}, {i, size}, {j, size}], 1];\nprobabilities = Flatten@GaussianMatrix[Floor[size/2]];\nsample = RandomSample[probabilities -> tiles, noSquares];\ncolors = RandomInteger[21, noSquares];\nmat = SparseArray[sample -> colors, {size, size}];\nArrayPlot[mat, Frame -> None, \n          ColorRules -> {0 -> RGBColor[{237, 233, 214}/255], \n                         x_ -> ColorData[54][x]}]\n\n\nFor black and white, just replace colors with 1, and remove the ColorRules rules:\nmat = SparseArray[sample -> 1, {size, size}];\nArrayPlot[mat, Frame -> None] \n\n\nChoice of colors\nChoosing randomly from a set of colors instead of the built in ColorData:\nlesCouleurs = {RGBColor[0.4, 0.4, 1], RGBColor[1, 0.5, 0.5], RGBColor[0, 0, 0]}\ncolors = RandomInteger[Length@lesCouleurs, noSquares];\nmat = SparseArray[sample -> colors, {size, size}];\nArrayPlot[mat, Frame -> None, \n          ColorRules -> {0 -> RGBColor[{237, 233, 214}/255], \n                          x_ :>  lesCouleurs[[x]]}]\n\nN.B. I was lazy in using GaussianMatrix for computing the probabilities, so only odd sizes work as expected.\n", "export - How do you get high resolution plots in applications using the Mathematica MathService?": "\nTry this.\n1) Open Automator and create a new Service.\n2) In the search box, type \"Run Apple Script\" and drag the action into the workflow space on the right. \n3) Replace the sample script (changing MyName appropriately) with:\non run {input, parameters}\nset inputResult to (input as string)\nset cmd to \" -run 'Export[\\\"~/Desktop/test.pdf\\\",\" & input & \"];Exit[]'\"\nset mathPath to POSIX path of file ((path to application \"Mathematica\" as text) & \"Contents:MacOS:MathKernel\")\n\n\ndo shell script mathPath & cmd\nset the clipboard to (alias \"Users:MyName:Desktop:test.pdf\") as \u00abclass furl\u00bb\n\ntell application \"System Events\"\nkeystroke \"v\" using {command down}\nend tell\n\nend run\n\n4) Hit the hammer icon to verify the code, then save the file to give the service a name.\n5) In TextEdit try something like \nPlot[Sin[x],{x,0,Pi},PlotStyle->{Dashed,Red},ImageSize->500]\n\nor\nStyle[TraditionalForm[Integrate[Gamma[Pi x]y[x],{x,0,2}]],FontSize->48]\n\nIt will embed a high quality PDF, saving the temp file to the desktop.\n", "programming - How to Text justify string that includes SubScriptBox in it?": "\nYou can also supply a Row to the TextCell where the elements in the row can be a mix of strings and other expressions, so you could split the whole text into string fragments and bits of maths like this\nTextCell[Row[{\"This is some text \",\n  HoldForm[Subscript[a, b]], \n  \". This is more text\"}], TextJustification -> 1]\n\nTo show that it works:\nPanel[Style[TraditionalForm[Grid[{\n    {\"Boundary Conditions\", SpanFromLeft},\n    {TextCell[\n       Row[{\"This is some text, this is some text, this is some text \", \n       HoldForm[Subscript[a, b]], \" this is more text.\"}], \n      TextJustification -> 1], SpanFromLeft},\n    {\"West\", HoldForm[u = \\[Alpha][y]], HoldForm[Subscript[u, n] = \\[Alpha][y]]}},\n   Frame -> All]],\n  15, FontFamily -> \"Times\"], \n ImageSize -> 250]\n\n\n", "front end - MouseAppearance and cursor problems": "\nHeike's answer has a strong virtue of simplicity, but it has two downsides. It strips the Graph-specific context menus, and it causes the output to not evaluate as a Graph if copied back to input. Here's a version which preserves those properties:\nStripGraphMouseAppearance[x_Graph] := \n RawBoxes[ToBoxes[x, StandardForm] /. \n   TagBox[contents_, MouseAppearanceTag[\"NetworkGraphics\"]] :> \n    contents]\n\nNow, simply apply StripGraphMouseAppearance whenever you want to strip the appearance in output.  E.g., the example in the question would be reformulated as:\nStripGraphMouseAppearance[\n Graph[{1 <-> 2, 2 <-> 3, 3 <-> 1}, ImageSize -> 200, \n  EdgeShapeFunction -> ({Black, AbsoluteThickness@2, Arrowheads@.1, \n      Arrow[#1, .1]} &), \n  VertexShapeFunction :> ({Hue[.6, .2, .8], Disk[#1, .1]} &)]]\n\nBasically, Graph typesets with the MouseAppearance built into it. My code looks for the box form of MouseAppearance and strips it out. One could conceivably rewrite MakeBoxes rules for Graph directly to do this, but doing so correctly would be a much more difficult exercise, as it would require reverse-engineering the rules we have now and carefully overriding them...and such a solution might not be stable across different Mathematica versions.\n", "front end - How to pipe a stream to another notebook?": "\nI am not sure that this is possible.  The $Output and $Messages variables hold the output stream to where the standard output (and the message output) from the kernel goes.  If you check these, you'll see that they're simply set to stdout.\nIf you remove ReadProtected from NotebookWrite, you'll see that it is passing data to the front end instead of writing to an output stream.\nAll this suggest that it's not possible to redirect an output stream to an arbitrary notebook.\n\nInstead of using output streams to switch the output \"device\", I'd suggest switching the output function.  You could have a function write which can be set to write = Write[outputChannel, #]& or to write = NotebookWrite[nb, #]&.\nIf you already have a lot of code using Write then it would be inconvenient to rewrite it to use an alternative write function.  But you can temporarily redefine Write using a block:\nBlock[{ Write = NotebookWrite[nb, #2]& },\n\n .... (* code called here *)\n\n]\n\nIf you need to temporarily redefine Write with something that itself uses Write, then you can use the trick described here to \"wrap\" it with extra code.\n\nNote: As @Heike said below, NotebookWrite[nb, Cell[BoxData[ToBoxes[#2]], \"Output\"]] & is better for writing into notebooks than the simple NotebookWrite[nb, #2]& I used above.\n", "bugs - How to Write into multiple files?": "\nThis is a bug and fixed in the development version. Thanks for pointing it out.\n", "formatting - Producing cleaner Mathematica output": "\nTry using semi-colons to suppress normal output and then use Print to print what you want exactly:\na = 1+1;\nb = 1+2;\nPrint[a,\", \",b];\n\nwhich gives:\n2, 3\n\n", "front end - How to improve the typesetting of mathematical contents": "\nTo format all your output expressions as TraditionalForm, you can set the $Post variable as:\n$Post = TraditionalForm;\n\nHere's how it would look:\nSin[x]/Cos[x + y]^3 + Integrate[Log[x], {x, 1, 2}] // HoldForm\n\n\nWithout HoldForm:\nSin[x]/Cos[x + y]^3 + Integrate[Log[x], {x, 1, 2}]\n\n\nTo clear the definition for $Post (if you need to), just evaluate $Post =. You can add this to your init.m if you'd like to make this apply to all notebooks henceforth, but I wouldn't suggest doing that.\n", "mathlink or wstp - Is it possible to set a timeout for LinkWrite[]?": "\nSetting up MathLink connections between kernels acting as peers (as opposed to in a master-slave arrangement) is sparsely documented, and the critical function you need to make this work, i.e. LinkActivate, is undocumented altogether (although, if you clear its ReadProtected attribute, you will see that it is merely a synonym for LinkConnect, which itself is a version of LinkOpen). In fact, LinkRead and LinkWrite both work with message queues and are not inherently blocking operations, but the behaviour you see is the result of the MathLink connection not having been initialized properly before writing.\nTo initialize the connection correctly, modify your code as follows:\nSetOptions[EvaluationNotebook[], Evaluator -> \"K2\"]\n\nlink = LinkCreate[\"alink\"]\n\n(* Evaluate only after calling LinkConnect/LinkActivate from K1 *)\nLinkActivate[link]\n\n(* No longer blocks *)\nLinkWrite[link, \"boo\"]\n\nand\nSetOptions[EvaluationNotebook[], Evaluator -> \"K1\"]\n\n(* Evaluate immediately after calling LinkCreate from K2. *)\nlink = LinkConnect[\"alink\"];\nLinkActivate[link] (* this call is blocking! *)\n\nLinkRead[link]\n\nWhy this is undocumented I do not know; to my knowledge the only place where this is described is the (rather specialist) book, MathLink: Network Programming with Mathematica by Chikara Miyaji and Paul Abbott. I discovered it when I was curious as to whether it was possible to write an MPI-style message-passing implementation in pure Mathematica. (The answer is yes; I posted some code on MathGroup here if you are interested.)\n", "programming - Suppressing negative roots in Mathematica": "\nOne way is to use Refine to filter out only the positive root. For example:\nassume = Z > 0 && a > 0 && n > 0;\nint = Integrate[n^2*Radial[1, 0, r]*r^2, {r, 0, \u221e}, Assumptions -> assume];\nsol = Solve[int == 1, n];\nIf[Refine[(n /. #) > 0, assume], #, ## &[]] & /@ sol\n\n\nI've changed N to n since the former is a built-in function. In general, it's good practice in Mathematica to never use single capital letters for variables or start functions with capital letters (since internal functions always start with uppercase). \nAnother way of doing it is by passing the assumptions directly to Solve, and getting back only the roots that satisfy those assumptions. However, it has been my experience in the past, with more complicated inequalities, that both Solve and Reduce tend to choke when you try to impose the requirements of the roots inside it (i.e., it solves the general case faster than the specific), and it's simpler to filter out the general solution with Refine. \nFor the sake of completeness, here's a solution with the constraints inside Solve and then further simplified using Simplify:\nSolve[int == 1 && assume, n] // Simplify[#, Assumptions -> assume] &\n\n", "string manipulation - How to express an integer number in English words?": "\nNested WolframAlpha approach, showing the intermediate steps:\nnumberString[a_, k_: 10] := \n FixedPointList[\n  StringReplace[#, \n    b : (DigitCharacter ..) :> \n     WolframAlpha[\"spell \" <> b, {{\"Result\", 1}, \"Plaintext\"}]] &, a, \n  k]\n\nnumberString[\"123456\"]\n\n(*\n==> {\"123456\", \"123 thousand and 456\", \"one hundred twenty-three \\\nthousand and four hundred fifty-six\", \"one hundred twenty-three \\\nthousand and four hundred fifty-six\"}\n*)\n\nnumberString[\"123456789123456789123456789\"]\n\n(*\n==> {\"123456789123456789123456789\", \"123 septillion, 456 \\\nsextillion, 789 quintillion, 123 quadrillion, 456 trillion, 789 \\\nbillion, 123 million, 456 thousand and 789\", \"one hundred \\\ntwenty-three septillion, four hundred fifty-six sextillion, seven \\\nhundred eighty-nine quintillion, one hundred twenty-three \\\nquadrillion, four hundred fifty-six trillion, seven hundred \\\neighty-nine billion, one hundred twenty-three million, four hundred \\\nfifty-six thousand and seven hundred eighty-nine\", \"one hundred \\\ntwenty-three septillion, four hundred fifty-six sextillion, seven \\\nhundred eighty-nine quintillion, one hundred twenty-three \\\nquadrillion, four hundred fifty-six trillion, seven hundred \\\neighty-nine billion, one hundred twenty-three million, four hundred \\\nfifty-six thousand and seven hundred eighty-nine\"}\n*)\n\n", "performance tuning - Memoization of Rounded inputs": "\nSince Dan's already taken my initial solution, here's another approach that additionally allows you to specify the precision:\nf[x_, tol_] := f[Round[x, tol]]\nf[x_] := f[x] = Total[Table[x, {100000}]]\n\n", "formatting - bar and hat only apply to certain letters": "\nYou can use the menu Palettes -> Basic Math Assistant and click the overscript button:\n\nThen you can type j, followed by the tab key, followed by ^.\nIt should be possible at this point to assign to this typesetting construct.\nAlso, in this same grid of buttons you will see a button with a black square and\na ^ already on top of it, which should save you one step. There is also a button\nfor the overbar construction.\n", "palettes - Some windows go off display": "\nManual approach: evaluate Notebooks[], and locate the palette in the resulting list.  Then evaluate the following, with a suitable value of $i$ filled in:\nSetOptions[Notebooks[][[i]], WindowMargins -> {{0, 0}, {0, 0}}]\n\n", "list manipulation - Efficient way to count the number of zeros at the (right) end of a very large number": "\nFor general large integers n, I don't know if there's a better method than Min[IntegerExponent[n, 5], IntegerExponent[n, 2]]. Or more compactly, IntegerExponent[n, 10] or IntegerExponent[n].\n", "compile - List of compilable functions": "\nYes, but this only exists in version 8 onwards and is undocumented:\nCompile`CompilerFunctions[] // Sort\n\ngiving, for reference:\n{Abs, AddTo, And, Append, AppendTo, Apply, ArcCos, ArcCosh, ArcCot, ArcCoth, ArcCsc,\n ArcCsch, ArcSec, ArcSech, ArcSin, ArcSinh, ArcTan, ArcTanh, Arg, Array, ArrayDepth,\n Internal`Bag, Internal`BagPart, BitAnd, BitNot, BitOr, BitXor, Block, BlockRandom, Boole,\n Break, Cases, Catch, Ceiling, Chop, Internal`CompileError, System`Private`CompileSymbol,\n Complement, ComposeList, CompoundExpression, Conjugate, ConjugateTranspose, Continue,\n Cos, Cosh, Cot, Coth, Count, Csc, Csch, Decrement, Delete, DeleteCases, Dimensions,\n Divide, DivideBy, Do, Dot, Drop, Equal, Erf, Erfc, EvenQ, Exp, Fibonacci, First,\n FixedPoint, FixedPointList, Flatten, NDSolve`FEM`FlattenAll, Floor, Fold, FoldList, For,\n FractionalPart, FreeQ, Compile`GetElement, Goto, Greater, GreaterEqual, Gudermannian,\n Haversine, If, Im, Implies, Increment, Inequality, Compile`InnerDo, Insert,\n IntegerDigits, IntegerPart, Intersection, InverseGudermannian, InverseHaversine,\n Compile`IteratorCount, Join, Label, Last, Length, Less, LessEqual, List, Log, Log10,\n Log2, LucasL, Map, MapAll, MapAt, MapIndexed, MapThread, NDSolve`FEM`MapThreadDot,\n MatrixQ, Max, MemberQ, Min, Minus, Mod, Compile`Mod1, Module, Most, N, Negative, Nest,\n NestList, NonNegative, Not, OddQ, Or, OrderedQ, Out, Outer, Part, Partition, Piecewise,\n Plus, Position, Positive, Power, PreDecrement, PreIncrement, Prepend, PrependTo, Product,\n Quotient, Random, RandomChoice, RandomComplex, RandomInteger, RandomReal, RandomSample,\n RandomVariate, Range, Re, ReplacePart, Rest, Return, Reverse, RotateLeft, RotateRight,\n Round, RuleCondition, SameQ, Scan, Sec, Sech, SeedRandom, Select, Set, SetDelayed,\n Compile`SetIterate, Sign, Sin, Sinc, Sinh, Sort, Sqrt, Internal`Square, Internal`StuffBag,\n Subtract, SubtractFrom, Sum, Switch, Table, Take, Tan, Tanh, TensorRank, Throw, Times,\n TimesBy, Tr, Transpose, Unequal, Union, Unitize, UnitStep, UnsameQ, VectorQ, Which,\n While, With, Xor}\n\nAs of Mathematica 10.0.2, there are also the following functions:\n{Gamma, Indexed, LogGamma, LogisticSigmoid, Internal`ReciprocalSqrt}\n\nAs of Mathematica 11, there are also the following functions:\n{Internal`Expm1, Internal`Log1p, Ramp}\n\nAs of Mathematica 11.2, there are also the following functions:\n{RealAbs, RealSign}\n\nAbout Tr:\nPlease note that Tr appears in this list, but cannot actually be compiled without a call to MainEvaluate[]. It is unclear if this is deliberate or a bug.\n\nEdit: additional functions\nI have just discovered the symbol Internal`CompileValues, which provides various definitions and function calls needed to compile further functions not in the list above. Using the following code,\nInternal`CompileValues[]; (* to trigger auto-load *)\nClearAttributes[Internal`CompileValues, ReadProtected];\nsyms = DownValues[Internal`CompileValues] /. \n    HoldPattern[Verbatim[HoldPattern][Internal`CompileValues[sym_]] :> _] :>\n        sym;\nComplement[syms, Compile`CompilerFunctions[]]\n\nwe get some more compilable functions as follows:\n{Accumulate, ConstantArray, Cross, Depth, Det, DiagonalMatrix,\nDifferences, NDSolve`FEM`FEMDot, NDSolve`FEM`FEMHold,\nNDSolve`FEM`FEMInverse, NDSolve`FEM`FEMPart, NDSolve`FEM`FEMTDot,\nNDSolve`FEM`FEMTotalTimes, NDSolve`FEM`FEMZeroMatrix, FromDigits,\nIdentity, IdentityMatrix, Inverse, LinearSolve, Mean, Median, Nand,\nNestWhile, NestWhileList, Nor, Norm, Ordering, PadLeft, PadRight,\nPermutations, Ratios, Signature, SquareWave, StandardDeviation,\nTally, Total, TrueQ, Variance}\n\nLooking at the definition of Internal`CompileValues[sym] for sym in the list above will provide some additional information about how these functions are compiled. This can range from type information (for e.g. Inverse), through to an implementation in terms of lower-level functions (e.g. NestWhileList). One can presumably also make one's own implementations of non-compilable functions using this mechanism, giving Compile the ability to compile a wider range of functions than it usually would be able to.\nAs of Mathematica 10.3, there are also the following functions:\n{DeleteDuplicates, Region`Mesh`SmallMatrixRank,\n Region`Mesh`SmallQRSolve, Region`Mesh`SmallSingularValues,\n Region`Mesh`SmallSingularValueSystem, Region`Mesh`SmallSVDSolve,\n NDSolve`SwitchingVariable}\n\nAs of Mathematica 11, there are also the following functions:\n{NearestFunction, RegionDistanceFunction, RegionMemberFunction, RegionNearestFunction}\n\n\nEdit 2: the meaning of the second list\nIn response to a recent question, I want to be clear that the presence of a function in the second list given above does not necessarily mean it can be compiled into a form free of MainEvaluate calls. If a top-level function is already highly optimized (as e.g. LinearSolve is), the purpose of Internal`CompileValues[func] may be solely to provide type information on the return value, assuming that this can be inferred from the types of the arguments or some other salient information. This mechanism allows more complex functions that call these highly-optimized top-level functions to be compiled more completely since there is no longer any question of what the return type may be and so further unnecessary MainEvaluate calls may be avoided. It does not imply that the use of MainEvaluate is unnecessary to call the function itself.\n", "list manipulation - Bug in LengthWhile?": "\nLooks like a bug in V8.0.0 that was fixed in V8.0.1.\nSeems to be triggered in part when the argument is a packed array:\n(* V8.0.0 *)\nIn[2]:= digits = Reverse@IntegerDigits[1000]; \n\nIn[3]:= LengthWhile[digits, 0 === #&]\n\nOut[3]= 0\n\nIn[4]:= LengthWhile[Developer`FromPackedArray[digits], 0 === #&]\n\nOut[4]= 3\n\nwhich would explain why it worked when you used Evaluate in Place.\n", "programming - FE`symbols that remain in notebook internals even after removing them and SaveDefinitions->True issue": "\nPlease try evaluating this in a copy of the Notebook with all the dynamic objects first deleted, then save and examine the Notebook file:\nSetOptions[EvaluationNotebook[],\n  PrivateNotebookOptions->{\"FileContents\"->{\"NotebookData\"}, \"FileOutlineCache\"->False}\n]\n\n", "performance tuning - Making sure that Timing[] isn't thrown off by caching": "\nCompletely restarting the kernel will of course work.  If we don't restart the kernel, then we need to clear all caches.\nThe caches used for symbolic and some numeric calculations can be cleared using ClearSystemCache[].  The documentation page of this function says:\n\nClearSystemCache can be useful in generating worst-case timing results\n  independent of previous computations.\n\nI do not know if there are any other caches as well, not affected by this.\n", "parallelization - Is it safe to launch/close kernels in the middle of a parallel calculation?": "\nActually it's safe to add a kernel, but if you close the kernel the calculation is working with, the calculation will never finish! I once had this problem. But I think adding a kernel when you are calculating shouldn't affect your answer.\nHope my answer helps you.\n", "streams - Why these (error) messages?": "\nThe documentation for $Messages clearly states:\n\n$Messages gives the list of files and pipes to which message output is sent.\n\nTherefore Block[{$Messages = {stream}}, ... ] is the correct syntax.\n", "caching - Built-in Mathematica data: are they cached? how to speed up the loading?": "\nInitializing is not the same as downloading:\n\nI believe you are witnessing the data being unpacked for use.\n", "Efficint imag Import - Mathmatica Stack Exchang": "\nMake your filenames unambiguously parsable, e.g. by consistently using some delimeters like underscores or something. A typical file name can look like \"Electric_B_3.png\". EDIT  If you have no control over the file names, use string patterns as described by other answers, but in the long-term you may benefit from creating your own robust naming scheme END EDIT \nThen write a function that would parse a single file name,  something like:\nfileNameParse[fname_String, delim_String: \"_\"] :=\n   StringSplit[FileBaseName[fname], delim]\n\nThen, Map it on FileNames[\"*.png\", {your-dir}]. \nFinally, apply your importOne on the level one:\nimportOne@@@Map[fileNameParse, FileNames[\"*.png\", {your-dir}]]\n\nSince you have the result of Map available as well, you can regroup them any way you want. You can, for example, Map a function {#, importOne@@#}&, rather than just using importOne@@@.... Then, you could use GatherBy or any other means to regroup and collect your images according to the parts of their filenames.\nEDIT \nHere is a self-contained example ( I use text files, but this doesn't matter):\nClearAll[fileNameParse, fileNameMake, importOne, $dir];\nfileNameParse[fname_String, delim_String: \"_\"] :=\n    StringSplit[FileBaseName[fname], delim];\n\nfileNameMake[pieces_List, delim_String: \"_\", ext_String: \".txt\"] :=\n    StringJoin[Append[Riffle[pieces, \"_\"], \".txt\"]];\n\nimportOne[set_, cat_, num_, dir_: $dir] :=\n    Import[FileNameJoin[{dir, fileNameMake[{set, cat, num}]}]];\n\nWe now create a temporary directory:\n$dir = FileNameJoin[{$TemporaryDirectory, \"ImportTest\"}];\nIf[! FileExistsQ[$dir], CreateDirectory[$dir]];\n\nCreate sample files:\nMapIndexed[\n   Export[#, \"Test\" <> ToString[#2], \"Text\"] &,\n   Flatten[\n     Outer[\n       FileNameJoin[{$dir, fileNameMake[{##}]}] &,\n       {\"Electric\"}, {\"A\", \"B\", \"C\"}, {\"1\", \"2\", \"3\"}\n     ]]];\n\nimport them:\nimported = Map[{#, importOne @@ #} &,  fileNameParse /@ FileNames[\"*.txt\", {$dir}]]\n\n(* \n  ==>\n\n     {{{\"Electric\", \"A\", \"1\"},  \"Test{1}\"}, {{\"Electric\", \"A\", \"2\"}, \"Test{2}\"}, \n      {{\"Electric\", \"A\", \"3\"},  \"Test{3}\"}, {{\"Electric\", \"B\", \"1\"}, \"Test{4}\"}, \n      {{\"Electric\", \"B\", \"2\"},  \"Test{5}\"}, {{\"Electric\", \"B\", \"3\"},  \"Test{6}\"}, \n      {{\"Electric\", \"C\", \"1\"},  \"Test{7}\"}, {{\"Electric\", \"C\", \"2\"},  \"Test{8}\"}, \n      {{\"Electric\", \"C\", \"3\"}, \"Test{9}\"}\n      }\n*)\n\nYou can now, for example, group them according to whatever parts of their file names you wish:   \nGatherBy[imported , #[[1, 2]] &][[1]]\n\n(* \n ==>\n\n{{{\"Electric\", \"A\", \"1\"}, \"Test{1}\"}, {{\"Electric\", \"A\", \"2\"}, \"Test{2}\"}, \n   {{\"Electric\", \"A\", \"3\"}, \"Test{3}\"}}\n\n*)\n\n", "probability or statistics - Which Distributions can be Compiled using RandomVariate": "\nTo my knowledge UniformDistribution and NormalDistribution are the only distributions that are directly compilable for RandomVariate.\nConsider that sampling from a UniformDistribution is what RandomReal was originally designed to do.  This code is likely written deep down in C and so compiles without any special effort.  In order to hook up RandomVariate for uniforms Compile just needs to recognize that this is really just a call to RandomReal.\nNow, sampling from a NormalDistribution is so common that it was considered worth the time investment to make it compilable.  Notice that the call to RandomVariate actually produces a call to RandomNormal which was almost certainly written for this purpose.\nAs for other distributions, special code would need to be written for each one in a similar fashion to RandomNormal for them to be \"supported\" by Compile. Since there are well over 100 of these, it would be a huge undertaking.  An argument could be made for doing this for a few distributions but who is to decide which ones are most important?\nThere is a sunny side. Most distributions have their own dedicated and highly optimized methods for random number generation. Often Compile is used under the hood when machine precision numbers are requested.\nBecause of this, even if they were directly compilable you probably wouldn't see much of a speed boost since the code is already optimized. \nFortunately Compile can happily handle arrays of numbers.  I typically just rely on the optimized code used by RandomVariate to generate the numbers and subsequently pass them in as an argument to the compiled function.\nIncidentally, everything I just said about RandomVariate is also true of distribution functions like PDF, CDF, etc. Obviously these are just pure functions (in the univariate case) and unless they are built with some exotic components they should compile assuming you evaluate them before putting them into your compiled function.\n", "Plotting piecewise function with distinct colors in each section": "\nHere's an alternative approach than Spartacus' answer. What he did is splitting up the piecewise function into many different functions valid in only a small domain; what I am doing here is directly plotting the piecewise function as given, while the coloring is done using ColorFunction.\nI'll use the same function as Spartacus,\nf = Piecewise[{{#^2, # <= 0}, {#, 0 < # <= 2}, {Log[#], 2 < #}}] &\n\nStep by step to the result\nNow let's create a ColorFunction that does the desired thing out of this. I'll do this using Part, i.e. double brackets [[ ]], which is not limited to lists only.\nFirst, create a copy of f.\ncolorFunction = f;\n\nNow we need to find out how many pieces there are in this function; for this we have to extract those into a list we can allpy Length to. Step by step:\ncolorFunction[[1]]\n\n\nPiecewise[{{#1^2, #1 <= 0}, {#1, Inequality[0, Less, #1, LessEqual, 2]}, {Log[#1], 2 < #1}}, 0]\n\n\nThat's the full function body. By applying another [[1]], we can get the first argument of Piecewise:\ncolorFunction[[1, 1]]\n\n\n{{#1^2, #1 <= 0}, {#1, 0 < #1 <= 2}, {Log[#1], 2 < #1}}\n\n\nFrom this matrix-shaped list, we'd like to get the length, leaving us with\npiecewiseParts = Length@colorFunction[[1,1]]\n\nAlright! Now make some colors out of that. The default plot colors are stored in ColorData[1][x], where x=1,2,3,4... is the usual blue/magenta/yellowish/green and so on.\ncolors = ColorData[1][#] & /@ Range@piecewiseParts\n\n\n{RGBColor[0.2472, 0.24, 0.6], RGBColor[0.6, 0.24, 0.442893], RGBColor[0.6, 0.547014, 0.24]}\n\n\nNow we need to take these color directives and inject them into the original function (that is, the colorFunction copy I've made in the beginning), so that it replaces squares and logarithms by reds and blues. This is some more Part acrobatics:\ncolorFunction[[1, 1, All, 1]] = colors\n\nDone! colorFunction is now identical to the original function f, only that the actual functions have been replaced by colors. It looks like this:\nPiecewise[{{RGBColor[...], # <= 0}, {RGBColor[...], 0 < # <= 2}, {RGBColor[...], 2 < #}}] &\n\nNow it's time to plot, see the completed code below.\nThe completed code\nf = Piecewise[{{#^2, # <= 0}, {#, 0 < # <= 2}, {Log[#], 2 < #}}] &;\n\ncolorFunction = f;\npiecewiseParts = Length@colorFunction[[1, 1]];\ncolors = ColorData[1][#] & /@ Range@piecewiseParts;\ncolorFunction[[1, 1, All, 1]] = colors;\n\nPlot[\n    f[x],\n    {x, -2, 4},\n    ColorFunction -> colorFunction, \n    ColorFunctionScaling -> False\n]\n\n\n(The option ColorFunctionScaling determines whether Mathematica scales the domain for the color function to $[0,1]$. Handy in some cases, not so much here, since our self-made colorFunction is constant in this domain.)\n", "formatting - Removing In/Out Labels before printing": "\nYou can set this in a style sheet so that it is done once and you don't have to do it again:\nCell[StyleData[All, \"Printout\"], ShowCellLabel -> False]\n\nor can you programmatically add this private style to your notebook:\nSetOptions[EvaluationNotebook[], \n StyleDefinitions -> \n  Notebook[{Cell[StyleData[StyleDefinitions -> \"Default.nb\"]], \n    Cell[StyleData[All, \"Printout\"], ShowCellLabel -> False]},\n   StyleDefinitions -> \"PrivateStylesheetFormatting.nb\"]\n ]\n\nIf you are unfamiliar with editing style sheets that latter option is probably the best.\n", "character encoding - How to \"Copy as Unicode\" from a Notebook?": "\nSince a native method is not forthcoming, I shall post my file based circumvention, for Windows.\nYou will need to have this utility in the command path (it apparently is stock with Windows 7).\ncopyUnicode[expr_] := Run[\"clip <\",\n   Export[\"$Clipboard.temp\", ToString[expr, InputForm],\n          \"Text\", CharacterEncoding -> \"Unicode\"] ];\n\nUsage:\nexpr = \\[Alpha]\\[Beta] + Mod[\\[Delta]\\[CapitalPsi], 2\\[InvisibleTimes]\\[Rho]^2];\n\ncopyUnicode[expr]\n\nThis leaves the following text in the Windows Clipboard:\n\n\u03b1\u03b2 + Mod[\u03b4\u03a8, 2*\u03c1^2]\n\n\n\nHere is a version of the function that holds (does not evaluate) the expression:\nSetAttributes[copyUnicode, HoldFirst]\n\ncopyUnicode[expr_, form_: InputForm] := \n  Run[\"clip <\", \n   Export[\"$Clipboard.temp\", ToString[Unevaluated@expr, form], \"Text\", \n    CharacterEncoding -> \"Unicode\"]];\n\nNow:\nPlot[\\[Alpha], {\\[Alpha], 0, 10}] // copyUnicode\n\nPuts in the Windows Clipboard:\n\nPlot[\u03b1, {\u03b1, 0, 10}]\n\n\n", "programming - Cleaning up a List of HTML Data to Render Usable Information": "\nFor the two strings in your first example, this seems to work \nImportString[string, \"HTML\"]\n\nFor the baseurl as in the original post, Import[baseUrl, \"Data\"] gives something like\ndata = Import[baseUrl, \"Data\"]\ndata[[2, ;; 4]]\n\n{{\"Item\", \"View Options\"}, {\n  1., \"1841-1869 (Province of Canada), number 195, 21 June 1845, page \\\n15\", \"GIF | PDF\"}, {\n  2., \"1841-1869 (Province of Canada), number 402, Extra, 16 May \\\n1849, page 4\", \"GIF | PDF\"}, {\n  3., \"1841-1869 (Province of Canada), number 405, 26 May 1849, page \\\n15\", \"GIF | PDF\"}}\n\nso it looks like data[[2, ;; ,2]] gives you the list you're after.\n", "linear algebra - NullSpace[_, Method->\"OneStepRowReduction\"] is sometimes wrong; how can I work out when this happens?": "\n$Version    \n(*  \"10.4.1 for Mac OS X x86 (64-bit) (April 11, 2016)\"  *)\n\nLet m = <pastebin monster>.\nns1 = NullSpace[m];\nns2 = NullSpace[m, Method -> \"OneStepRowReduction\"];\ndiff = ns1 - ns2;\n\n\nRootReduce[diff]\n(*  {{0, 0, 0, 0, 0, 0, 0, 0}}  *)\n\nSo they're equivalent in V10.4.1.\nUpdate: Checking correctness\nAfter many minutes, this returns the zero vector:\nm.First@ns1 // RootReduce\n\nAnd these all return a rank of 7:\nMatrixRank[m]\nMatrixRank[N[m]]\nMatrixRank[N[m, 32]]\n\nFinally, Dimensions[m] yields {880, 8}, all of which confirms the answer is correct.\n", "random - Generate a new output using Manipulate": "\nDo you actually need a Manipulate expression, or is this sufficient?\nDynamicModule[{x = Null}, Column[{\n   Button[\"Shuffle Images\", \n    x = ImageAssemble[\n      Partition[\n       RandomSample[\n        Flatten@{DarkBlueB, DarkBlueC, DarkBlueN, DarkBlueE}, 20], 5]]\n    ],\n   Dynamic[x]\n}]]\n\n", "front end - Can the position of Tooltips be changed?": "\nImprovised Tooltip using Text and Mouseover\nHere's one way to improvise a tooltip for graphics objects--in this case,\na list of points. It emulates a tooltip but does not leave a a drop shadow, and as Istv\u00e1n notes, has a few graphical shortcomings that make it less than ideal (clipping, under axes layer). Also, the code would need to be tweaked for objects displayed through functions other than Graphics.\n[Edit: The present version makes use of Heike's suggestion to use the third parameter of Text for the offset. As Heike notes, \"The units of the third argument of Text are scaled with respect to the bounding box of the first argument where {0,0} corresponds to the centre, {-1,-1} to the lower left corner, {1,1} to the upper right corner etc.\"]\nGraphics[{PointSize[Medium], \n    Table[Mouseover[Point[p], {Point[p], \n        Text[Framed[p, Background -> LightYellow], p, {1.25, 2}]}], \n    {p, RandomReal[1, {10, 2}]}]}, Frame -> True, \n    PlotRange -> {{0, 1}, {0, 1}}, ImagePadding -> {{100, 10}, {50, 5}}]\n\n\n", "front end - Invisible \\[Conjugate] glyph in the linux frontend": "\nYou need to make a backup and then modify the UnicodeFontMapping.tr file:\nFileNameJoin[{$InstallationDirectory, \"SystemFiles\", \"FrontEnd\", \n              \"TextResources\", \"UnicodeFontMapping.tr\"}]\n\nLook for the line\n0xF3C8      N       6       0xad        # \\[Conjugate]\n\nand modify it to something like\n0xF3C8      N       1       0x2a        # *\n\n\nThanks go to ragfield for providing this workaround on stackoverflow.\n\nAside: In February 2011, I contacted WRI tech support about two linux specific Mathematica 8 frontend bugs/regressions. The non-visible \\[Conjugate] discussed above and the bad typesetting in fractions. Here's images showing the latter\n\n\nThe helpful tech support response was simply:\n\nThese are known problems with the FrontEnd on Linux, which our developers\n  hope to address in a future release of Mathematica.\n\nand that I'll be \"notified when the issues are resolved\"...  \n\nBack to the aside:\nBoth of the Linux front-end bugs mentioned in the previous aside have been fixed in the first version 9 release. \n", "parallelization - Silence debug output from Parallelize?": "\nIt is the Check function which is throwing the error. Try using:\nParallelDo[\n Do[Quiet@Check[{i[[1]], j[[1]], \n     FindGeometricTransform[i[[2]], j[[2]], \n      Transformation -> \"Translation\"]}, {i[[1]], j[[1]], err}], {i, \n   files}],\n {j, files}]\n\nIf you leave off the Print command, it will silence all kernel outputs, and also speed up your computation (I'm sure other's could expound on this, but displaying outputs while running loops tends to slow things down). If you want to monitor the output of a parallel computation while it's running, check this SO post.\n\nEdit Just realized that putting Quiet on Check kills the whole point of your computation. I think it would be best if you just do the calculation as a Table and extract the data at the end:\nQuiet@ParallelTable[{i[[1]], j[[1]], \n    Quiet[FindGeometricTransform[i[[2]], j[[2]], \n      Transformation -> \"Translation\"]]}, {i, files}, {j, files}];\n\nI'm not completely sure why I need both of those Quiet commands, but it seems to need it.\n", "sql - MySQL Connection Problem": "\nIn the past, years ago, I have had problems with the MySQL connection that were solved following Wolfram's tech support advice of updating the java connector to its latest version. This can be done by:\n\nDownload the connector from MySQL web page: http://www.mysql.com/downloads/connector/j/\nInstall it at  $InstallationDirectory->SystemFiles->Links->DatabaseLink->Java\n\nMy Mathematica 8 has version 5.1.13 installed and the latest available now at mysql.com is 5.1.18\nYou could try this, and save the original connector in a separate location just in case you need to revert.\nBTW, Which platform and mysql version are you using?\n\nAfter reading your comment I realized that what you need to do is to wrap your connection code inside a TimeConstrained command. In the past I have used this code to connect reliably to my database:\nNeeds[\"DatabaseLink`\"];\nCloseSQLConnection[conn];\nTimeConstrained[\n    conn = OpenSQLConnection[JDBC[\"mysql\",\"localhost:3306/my_database_name\"],\n                             \"Username\"->\"login\",\n                             \"Password\"->\"secret\"],\n    5,\n    CloseSQLConnection[conn]\n];\n\n", "programming - Alternative to overloading Set": "\nReasons why adding rules to Set is a really bad idea\nFirst, let me list the reasons why I think that adding rules to  Set globally is a very bad practice:\n\nThis is a hugely non-local system modification. We have no idea which parts of the system will be affected, but we can be sure that there will be many.\nSet is a very frequently used command (see first point)\nSet is fundamental to the system, and in some ways more low-level command than most others.\nIt could have been already overloaded internally for certain purposes. We may even break that internal code, and in this case, there would be absolutely no way to know,\nWe may degrade the performance, in unpredictable ways.\n\nSome possible ways out\nNow, here are some suggestions of what one could do.\n\nOverload Set via UpValues, when you can. One example can be found here. It is  not always possible however, due to the limitation on the depth-1 UpValues search.\nDefine yout own custom assignment operator, like mySet, and use that. This is the option I use most frequently myself. A bit more typing and less syntactically pleasing, but saves a lot of hassle in the long term. Besides, custom assignment operators are a very powerful programming tool, because you can do some extra stuff along with making assignments.\nCreate local environments. These can be lexical or dynamic. I will illustrate with a dynamic environment, for a simple example of a type point, that will hold a list of 2-dimensional coordinates. Our goal is that if some variable var is of type point (i.e. holds an expression like point[{x,y}], then if I make an assignment like var = {3,4}, I should have now point[{3,4}] stored in var.\n\nHere is the code:\nClearAll[withCustomSet];\nSetAttributes[withCustomSet, HoldAll];\nwithCustomSet[code_] :=\n   Internal`InheritedBlock[{Set},\n     Unprotect[Set];\n     Set[var_Symbol, {x_, y_}] /;\n        MatchQ[HoldComplete[var] /. OwnValues[var], HoldComplete[_point]] :=\n            var[[1]] = {x, y};\n     Protect[Set];\n     code];\n\nLet us see:\na = b = point[{1,2}]\n\na = {3,4};\na\n\n(*\n   ==>{3,4}\n*)\n\nwhile\nwithCustomSet[b = {3,4}];\nb\n\n(*\n   ==>  point[{3,4}]\n*)\n\nIn practice, you can execute arbitrary code inside withCustomSet, and the new redefinition of Set will take effect all the way down the execution stack. This is powerful but at the same time dangerous, however, much less dangerous that an analogous but global redefinition.\nA lexical environment is also easy to construct:\nClearAll[withCustomSetLex];\nSetAttributes[withCustomSetLex, HoldAll];\nwithCustomSetLex[code_] :=\n  Unevaluated[code] /.\n     HoldPattern[\n       Set[var_Symbol, {x_, y_}] /; \n           MatchQ[HoldComplete[var] /. OwnValues[var], HoldComplete[_point]]] :>\n             (var[[1]] = {x, y});\n\nYou can test that it works fine with the same simple test as above. However, it will only affect the instances of Set explicitly present in the code inside it. OTOH, this is yet much safer, since the stack is not affected.\nSummary\n\nDon't ever add rules to Set globally, if you want predictable behavior from Mathematica\nThere are plenty of ways to go around this problem, so this is not that serious of a limitation, really.\n\nEDIT\nTo address the specific question (added in the update): the lexical environment would look like\nClearAll[withCustomSetLex];\nSetAttributes[withCustomSetLex, HoldAll];\nwithCustomSetLex[code_] :=\n  Unevaluated[code] /. \n      HoldPattern[Set[symbol_[key_], value_]] :>  ObjectSet[symbol, key, value]\n\nA dynamic environment is trivial to implement: replace the code I used above in between Unprotect[Set] and Protect[Set] with your code.\n", "probability or statistics - Conditional T distribution": "\nTry this:\nbivTCond[x_, y_, \u03bd_, \u03c1_] := \n Evaluate @ PDF[MultivariateTDistribution[{{1, \u03c1}, {\u03c1, 1}}, \u03bd], {x, y}]/\n Evaluate @ PDF[StudentTDistribution[0, 1, \u03bd], x]\n\nPlot[bivTCond[1, y, 3, 0.5], {y, -3, 3}]\n\n\n", "Does Mathematica implement the fast Fourier transform?": "\nFourier[list] computes the discrete Fourier transform of list.  I assume it uses the FFT when it can.\n", "algebraic manipulation - Expand modulus squared": "\nSomething like (ComplexExpand with all three arguments, Expand and a rule) :\nrule = {Im[x_]^2 + Re[x_]^2 -> Abs[x]^2, f_ Re[x_] Re[y_] + f_ Im[x_] Im[y_] -> f Re[Conjugate[x] y]};\n\nExpand[ComplexExpand[Abs[Subscript[z, 1] + Subscript[z, 2]]^2, {Subscript[z, 1],Subscript[z, 2]}, TargetFunctions -> {Re, Im}]] //. rule\n\nAbs[Subscript[z, 1]]^2 + Abs[Subscript[z, 2]]^2 + Re[Conjugate[Subscript[z, 1]] Subscript[z, 2]]\n\nExpand[ComplexExpand[Abs[Subscript[z, 1] + Subscript[z, 2] + Subscript[z, 3]]^2, {Subscript[z, 1], Subscript[z, 2], Subscript[z, 3]}, TargetFunctions -> {Re, Im}]] //. rule\n\nAbs[Subscript[z, 1]]^2 + Abs[Subscript[z, 2]]^2 + Abs[Subscript[z, 3]]^2 + Re[Conjugate[Subscript[z, 1]] Subscript[z, 2]] + Re[Conjugate[Subscript[z, 1]] Subscript[z, 3]] + Re[Conjugate[Subscript[z, 2]] Subscript[z, 3]]\n\n", "linear algebra - Discrete Convolution": "\nYou could use ListConvolve:\nListConvolve[a, b, {1, -1}, 0]\n\nconcerning the padding:\nArrayPad[b, 3, 0]\n\nAnd you could use Partition for the second of your steps:\nPartition[Range[Length[ArrayPad[b, 3, 0]]], 3, 1]\n\n", "compile - How to use a matrix variable for a compiled function": "\nNot only can Matrix be a PackedArray, it must be a PackedArray. However, it will be packed for you if necessary before the compiled code is called.\nThe following code is substantially faster than that given by acl above and does not require any post-processing of the output, but is still sub-optimal in terms of requiring CopyTensor calls and using a rather larger working set than one would think necessary. Perhaps these limitations can be lifted, but after a brief survey of possible implementations I didn't find a way better than this (though note that I didn't try anything with Internal`Bag).\nclusterFind = Compile[{{inte, _Real, 0}, {matrix, _Complex, 2}},\n    Module[{tmp = matrix[[All, {1, 2, 3, 4, -1}]]},\n        Select[tmp, Last[#] == inte &][[All, ;; -2]]\n    ], RuntimeAttributes -> Listable, Parallelization -> True\n];\n\nAn example of the improved timings:\nrange = {0, 10};\ndata = RandomInteger[range, {1*^5, 100}];\n\nacl's version:\nTiming[\n    cf4[RandomInteger[range], data];\n]\n\nproducing: {2.297, Null}\nMy version:\nTiming[\n    clusterFind[RandomInteger[range], data];\n]\n\nwhich gives {0.047, Null}.\nNote that the above timings are not for C-compiled versions of the two functions; compilation to C does not help very much as there is not much computational work to be done in this process anyway and most of the timing consists of copying or extracting parts of tensors. Also, I should mention that RuntimeAttributes -> Listable and Parallelization -> True do not really buy you anything here unless you are operating on a list of matrices.\n", "version 8 - RunScheduledTask didn't execute itself the first time, why?": "\nCan't you do something like\nRunScheduledTask[Pippo[]; RunScheduledTask[Pippo[], 60*60*24], {0}, ABSTIME]\n\n", "graphics - How to draw multiple coordinates on mathematica?": "\nYou build this in Mathematica like you would do in any other descriptive language (you might want to use TikZ for this): step by step. Choosing nicer colors,adjusting the distances  etc. is left as an exercise to the reader.\ncosy[labels_, labelstyle_] := Flatten@{\n    Arrow[{{0, 0, 0}, {1, 0, 0}}],\n    Arrow[{{0, 0, 0}, {0, 1, 0}}],\n    Arrow[{{0, 0, 0}, {0, 0, 1}}],\n    labelstyle,\n    Text[labels[[1]], {1.1, 0, 0}],\n    Text[labels[[2]], {0, 1.1, 0}],\n    Text[labels[[3]], {0, 0, 1.1}]\n};\nGraphics3D[{\n    { (* Coordinate system 1 *)\n\n   cosy[{\"X\", \"Y\", \"Z\"}, Darker@Orange],\n        Darker@Orange,\n        Text[\"World\", {-.3, -.3, .5}]\n    },\n    { (* Coordinate system 2 *)\n\n   Rotate[cosy[{\"x\", \"y\", \"z\"}, Blue], -30 \\[Degree], {-1, 0, 1}]~\n    Translate~{0, 0, -2}\n    },\n\n    { (* Connecting arrow *)\n        Darker@Green,\n        Arrow[{{0, 0, 0}, {0, 0, -2}}],\n        Text[\"C(t)\", {0, -.2, -1}]\n    },\n\n    { (* Red stuff *)\n        Red,\n        Arrow[{{0, 0, 0}, {0, 3, -1}}],\n        Arrow[{{0, 0, -2}, {0, 3, -1}}],\n        Text[\"\\!\\(\\*SubscriptBox[\\(p\\), \\(world\\)]\\)\", \n    1/2 {0, 3, -1} + {0, 0, .5}],\n        Text[\"\\!\\(\\*SubscriptBox[\\(p\\), \\(0\\)]\\)\", \n    1/2 {0, 3, -1} + {0, 0, -1.5}],\n        Text[\"p(t)\", {0, 3, -1} + {0, .5, 0}]\n    }\n  }, Boxed -> False]\n\n\n\n\n", "programming - Downloading files without using Import": "\nHow about a version of:\nNeeds[\"Utilities`URLTools`\"];\npath = FetchURL[\n   \"http://www-roc.inria.fr/gamma/download/counter.php?dir=MECHANICAL//&\\\nget_obj=ifp2_cut.mesh.gz&acces=ifp2_cut\", \"ifp2_cut.mesh.gz\"];\n\n", "Knowing when a notebook has changed programmatically": "\nI think that\n\"ModifiedInMemory\" /. NotebookInformation@SelectedNotebook[]\n\ndoes what you want (ie, returns False if the notebook is saved, True if it is not saved). Although maybe not quite, try NotebookInformation[CreateDocument[\"hi\"]]\nBut it seems to work once you modify a notebook that's been saved once. I could be wrong though...\n", "numerics - Why is MainEvaluate being used when LinearSolve can be compiled?": "\nacl already posted the crucial information needed to solve this conundrum (i.e., the definition of Internal`CompileValues[LinearSolve]), but wishes to delete his post since he had not interpreted it to give the complete answer. Therefore I re-post the following observation along with a summary of what it means.\nThe input,\nInternal`CompileValues[];\nClearAttributes[Internal`CompileValues, ReadProtected];\nInternal`CompileValues[LinearSolve]\n\nyields:\nHoldPattern[Internal`CompileValues[LinearSolve]] :> {\n  HoldPattern[\n    LinearSolve[\n      System`CompileDump`x_?(Internal`TensorTypeQ[Real, {_, _}]), \n      System`CompileDump`b_?(Internal`TensorTypeQ[Real, {_}])]\n    ] :> _?(Internal`TensorTypeQ[Real, {_}]), \n  HoldPattern[\n    LinearSolve[\n     System`CompileDump`x_?(Internal`TensorTypeQ[Complex, {_, _}]), \n     System`CompileDump`b_?(Internal`TensorTypeQ[Complex, {_}])]\n    ] :> _?(Internal`TensorTypeQ[Complex, {_}])\n}\n\nBriefly put, this tells us that when the compiler sees a function call like LinearSolve[x, b], it knows that:\n\nwhen x is a real matrix and b is a real vector, the result is a real vector\nwhen x is a complex matrix and b is a complex vector, the result is a complex vector\n\nAs a result of this knowledge, the compiler is able to determine what type of register is needed to store the return value from LinearSolve in these two cases. This is important if further operations are then carried out on the result: in the absence of type information, all subsequent operations on LinearSolve's return value would need to be performed via the interpreter using MainEvaluate for full generality, but because the type of the result is predetermined, such operations can be compiled instead. However, since LinearSolve is a highly optimized top-level function, compilation does not offer any benefit outside of this scenario, and so knowing the return type has no value if LinearSolve[x, b] is the entire contents of the compiled function, since the operation may as well have been performed via the interpreter anyway.\nAs regards why LinearSolve[x, b, Method -> m] produces a message: it is because the definition for Internal`CompileValues[LinearSolve] does not provide for pattern matching against LinearSolve calls when any Method is specified. It handles only the form LinearSolve[x, b].\nConclusion\nJust because Internal`CompileValues[func] is defined for some function func, one cannot assume that func can be called directly from compiled code without using a MainEvaluate call. It simply means that the compiler has information about func which it can incorporate into the compilation process as a whole.\n", "random - Creating randomly oriented planes": "\nWhy don't you pick a random vector on the sphere to be your first vector, instead of $\\mathbf{n}$, and then pick a random uniform number between $0$ and $2 \\pi$ to orient the second vector aronud the first?\nSomething like this, assuming you have your function randomVectorOnUnitSphere[] already\n(haven't tested it)\ngenerateRandomPositioning[v1_, v2_] := \n With[{angle = VectorAngle[v1, v2], mag1 = Norm[v1], mag2 = Norm[v2], \n   rvec = randomVectorOnUnitSphere[]},\n  Module[{v1out, v2out},\n   v1out = rvec mag1;\n   v2out = \n    Cross[rvec, v2] //\n      (* this just gives a particular vector perpendicular to v2out, \n      assuming they are not colinear *) \n      RotationTransform[angle, #][rvec] & //\n      (* now I have a particular vector at the corresponding angle of v1out *) \n      RotationTransform[RandomReal[2 Pi], rvec]//(* now it's distributed uniformly *) \n      Normalize[#] mag2 &;\n    {v1out, v2out}\n  ]\n]\n\nOk, here's my test\nrandomVectorOnUnitSphere[]:=With[{\u03b8 = RandomReal[2 \u03c0], \u03c6 = ArcCos[RandomReal[{-1,1}]]},\n    {Cos[\u03b8] Sin[\u03c6],Sin[\u03c6] Sin[\u03c6],Cos[\u03c6]}\n]\n\nListPointPlot3D[Table[randomVectorOnUnitSphere[], {10000}], AspectRatio -> 1]\n\n\nIn[28]:= v1 = {0, 1, 1}; v2 = {0, 3, 0.4};\ntest = Table[generateRandomPositioning[v1, v2], {500}];\n\nIn[13]:= arrowCouple[{pt1_, pt2_}] := {Arrow[{{0, 0, 0}, pt1}], \n   Arrow[{{0, 0, 0}, pt2}]};\n\nIn[30]:= Equal @@ VectorAngle @@@ test\n\nOut[30]= True\n\nIn[31]:= VectorAngle @@ First@test == VectorAngle[v1, v2]\n\nOut[31]= True\n\nGraphics3D[{Opacity[\n   0.2], {RGBColor[RandomReal[], RandomReal[], RandomReal[]], \n     arrowCouple[#]} & /@ test}, Boxed -> False]\n\n\nGraphics3D[{Black, arrowCouple[{v1, v2}], \n    {RGBColor[RandomReal[], RandomReal[], RandomReal[]], \n     arrowCouple[#]} & /@ test[[;; 3]]}, Boxed -> False]\n\n\nI know, these aren't proper tests, nor am I sure this is what you want to accomplish.\nIf I think about it more formally, and I remember well, you need to have a clear idea of how you measure sets of \"pairs of vectors of given magnitude and angle between them\", so that you can talk about uniform distribution. It would mean that the probabilty of the final pair of vectors being in a certain subset is proportional to the subset's measure... But if we assume that your measure is invariant to rotations, which makes sense, then probably it's all the same\n", "Manipulate with a variable number of sliders": "\nThe Advanced Dynamic Functionality in Mathematica documentation has the following example that looks like what you need.\nDynamicModule[{n = 5, data = Table[RandomReal[], {20}]},\nColumn[{\nSlider[Dynamic[n], {1, 20, 1}],\nDynamic[Grid[Table[With[{i = i},\n   {Slider[Dynamic[data[[i]]]], Dynamic[data[[i]]]}], {i, n}]\n ]]}]]\n\n\nIt builds a list of controllers (Slider-s in this particular case) by using the fact that you can assign values to not just symbols but also to members of a list by doing data[[1]] = value. Which is exactly the thing that happens inside Dynamic[data[[i]]], as it is equivalent to:\nDynamic[data[[i]], (data[[i]] = #)&]\n\ntelling Mathematica to whenever the actual value of data[[i]] is changed, use the new value (#) to update the expression data[[i]].\nAlso from the Documentation Center, the last example in Manipulate: Neat Examples may be useful:\nManipulate[\nArrayPlot[\nTake[data, h, w]], {{data, RandomInteger[{0, 1}, {10, 20}]}, \nControlType -> None}, {{h, 5}, 1, 10, 1}, {{w, 5}, 1, 20, 1}, \nDynamic[Panel[\n Grid[Outer[Checkbox[Dynamic[data[[#1, #2]]], {0, 1}] &, Range[h], \n Range[w]]]]]]\n\nwhich gives\n\n", "syntax - Multiple colors in Graphics[] environment": "\nMaybe something like this?  I've controlled the colors based on the radius r and am passing in a location loc so that different disks are produced in the following example.\nf[loc_, r_] := Graphics[{If[r > 0, Blue, Red], \n                  EdgeForm[Black], Disk[loc, Abs[r]]}]\n\nHere it is for 100 random locations each with a radius ranging from 0 to 2.\nShow[Table[f[i, RandomReal[{-2, 2}]], {i, RandomReal[{-10, 10}, {100, 2}]}]]\n\n\nEdit: I'm not sure I understand exactly what you are asking for in the edits to the question. Going with the second it seems to me that you want to create a matrix of colored disks that corresponds to your original matrix m?  If that is the case, you could do something like the following.\ndiskMatrix[m_]:=\n    Block[{r,max = Max[m^2],n=Length[m],p=Length[m[[1]]]},\n       Graphics[\n         Table[\n            r=m[[i,j]]^2;\n            {EdgeForm[Black],\n            If[m[[i,j]]>0,Blue,Red],\n            Tooltip[Disk[{j,-i},\n                    Rescale[r,{0,max},{0,2/n}]],\n                    Row[{\"Radius : \",r}]\n            ]}\n         ,{i,n},{j,p}\n         ]\n       ]\n    ]\n\nThis code is going to take a matrix m and effectively produce a grid of disks where the ijth disk has radius m[[i,j]]^2 and is red if m[[i,j]] is negative, blue otherwise. In order to prevent overlap in the resulting graphic I've rescaled the radii. A Tooltip is used to show the value of the radii on mouse-over.\nHere is an example using the matrix provided in the simple example.\nm1 = {{-1/2, 1/2, 0, -1/Sqrt[2]}, {1/2, 1/2, -1/Sqrt[2], 0}, {-1/2, \n    1/2, 0, 1/Sqrt[2]}, {1/2, 1/2, 1/Sqrt[2], 0}};\n\ndiskMatrix[m1]\n\nProduces the following image...\n\nEdit 2:\nOne last try in light of the most recent edit and posted comments. The following function will take a matrix of possibly complex values.  It assumes there will be 4 columns in this matrix.  \nFor each row m[[i]] a square is drawn. Proceeding from bottom left and counter-clockwise around the square a disk is rendered at each vertex.  The radius of the disk is proportional to Abs[m[[i,j]]]^2. The color is chosen based on the sign of the real part of m[[i,j]].\ndiskTangle[evect_] := \n Block[{r, max = Max[Abs[Flatten[evect]]^2], \n   pos = {{0, 0}, {1, 0}, {1, 1}, {0, 1}}}, \n  Table[Show[Graphics[{EdgeForm[Thick], White, Rectangle[]}], \n    Graphics[\n     Table[r = Abs[e[[i]]]^2; {EdgeForm[Black], \n       If[Sign[Re[e[[i]]]] > 0, Blue, Red], \n       Tooltip[Disk[pos[[i]], Rescale[r, {0, max}, {0, 1/2}]], \n        Row[{\"Radius : \", r}]]}, {i, Length[e]}]]], {e, evect}]]\n\nUsing m1 from above...\nevects = Eigensystem[m1][[2]]//N;\n\ndiskTangle[evects]\n\n\n", "syntax - Using variables in function names": "\nYou can also use ToExpression to join the index n to your base function name, C, as in the following example:\nC1 = Sin[x];\nC2 = Cos[x];\nC3 = Tan[x];\nTable[Plot[Evaluate[ToExpression[\"C\" <> ToString@i]], {x, -\u03c0, \u03c0}], {i, 3}]\n\n\n", "replacement - Replace rule also matching complex numbers": "\nAssuming you want to do all this with replacement rules rather than some built-in functions as noted in the comments, if you modify the rule and correct the typos you get the desired output from the example. For example:\n rule2 = g_  x_^4 + h_   x_^2  y_^2 + g_  y_^4 /; h == 2 g -> \n  g (x^2 + y^2)^2 ;\n\nand\n(2 Re[Hy Conjugate[Hx]] kx^4 vx vy)/(k^2 (kx^2 + ky^2)) + (4 Re[\n  Hy Conjugate[Hx]] (kx^2  ky^2) vx vy)/(k^2 (kx^2 + \n   ky^2)) + (2 Re[\n  Hy Conjugate[Hx]] ky^4 vx vy)/(k^2 (kx^2 + ky^2)) //. rule2\n\ngives \n (2 (kx^2 + ky^2) vx vy Re[Hy Conjugate[Hx]])/k^2\n\n", "Good ways to organize and document collections of mathematica notebooks?": "\nThere are two answers to this question, and only one has anything to do with directory structure, and that only mildly. \nThe first answer is to structure the notebook itself using the style groupings provided. This will greatly enhance your ability to find something within any given notebook. For instance, as a materials physicist I use a model known as tight binding, and as part of my learning about how to apply it to a particular crystal structure, I have a notebook that I treat as a lab notebook. It has three main sections: Setup, Preliminary Testing, and Full Testing all at the highest level of the hierarchy. The least organized section is the Preliminary Testing, but even there I make ample use of Text cells to record my thoughts and observations. The other two sections make full use of the hierarchy to organize and group my examinations of the tight-binding method.\nThe second answer is packages. If you have some code that you find yourself referring to often, put in a package. Here I tend to use a rule of three, if I have to refer to or rewrite something 3 or more times, it needs to be in a package. It is here that a directory structure is helpful.  In my case, my packages are currently organized into three directories: Quantum, Utilities, and Wien2k (a software package I've written interface scripts for) for a total of 16 packages. \nI try to make each package somewhat complete in that they provide a full range of services. For example, the Wien2k package for loading their crystal structure files provides a full range of functions for accessing the structured information in those files, but sadly not saving them, as I haven't had the need to write it. But, some packages are just buckets of loosely related functions, and they're perfect that way. \n", "cudalink - CUDA: setting grid dimensions": "\nYou cannot specify the grid dimensions, you can specify how many threads to launch. This is done by passing an extra argument when calling the CUDAFunciton, so \ncolorNegate = CUDAFunctionLoad[{srcf}, \"imageColorNegate\",\n {{_Integer, _, \"InputOutput\"},_Integer, _Integer, _Integer}, {16, 16}]\n\nthis will figure out the number of threads automatically:\ncolorNegate[img, 512, 512, 3]\n\nthis will force CUDALink to launch {256, 256} threads\ncolorNegate[img, 512, 512, 3, {256, 256}]\n\n", "random - creating vectors with normal distribution of lengths": "\nTechnically, the normal distribution is defined on the real line, $\\mathbb{R}$, but vector lengths are nonnegative numbers, elements of $\\mathbb{R}_{0+}$. So you can't really have the lengths of your vectors satisfy a normal distribution. You have to choose a distribution for the lengths that has the correct domain, $\\mathbb{R}_{0+}$.\nOne thing you can do, and my best guess at what you really want, is to use the restriction of the normal (or half-normal) distribution to the nonnegative numbers. That would be accomplished exactly like you said, by choosing the length from HalfNormalDistribution.\nIf the angular distribution of the vectors (the distribution of their directions) has reflection symmetry, in the sense that a vector is just as likely to point in any particular direction $\\hat{n}$ as it is to point in the opposite direction $-\\hat{n}$, then you actually can multiply the unit vectors you have by random numbers chosen from the full normal distribution. If the random number is negative, it will switch the direction of your vector, but since $P(\\hat{n}) = P(-\\hat{n})$, the probability of switching any one direction to the opposite direction is the same as the probability of switching the opposite direction to the original direction. Those two effects cancel out. If the angular distribution is not symmetric, however, then using the full normal distribution will have the effect of symmetrizing it, i.e. you'll wind up with a new distribution of directions $P'$ such that $P'(\\hat{n}) = \\frac{1}{2}\\bigl(P(\\hat{n}) + P(-\\hat{n})\\bigr)$.\n", "Export Graphics[] without white edges": "\nThere's another, undocumented, approach, although I can't take credit for discovering this one. The solution you're probably looking for (in the sense that Brett Champion's solution seems to clip off a little too much at the edges) is the Method option for Graphics:\nMethod -> {\"ShrinkWrap\" -> True}\n\ne.g. (graphics example from the documentation for Circle):\nGraphics[\n  Table[{Hue[t/20], Circle[{Cos[2 Pi t/20], Sin[2 Pi t/20]}, 1]}, {t, 20}], \n  Method -> {\"ShrinkWrap\" -> True}\n]\n\nNote that this has to be written as Method -> {\"ShrinkWrap\" -> True}. The form Method -> \"ShrinkWrap\" -> True might be expected to work, but it doesn't.\n", "front end - WYSIWYG table creating and editing": "\nMathematica already has some of these features: e.g\n\n\nRegarding your comment about the appearance when you do this in a text cell. Here is what it looks like for me on a Mac:\n\nSo the font is Courier which, unless you have reconfigured your system, is not the default font for text cells. You can fix this by changing the grid box options: To do this -- in a menu driven way -- click on the cell bracket and go to Format > Option Inspector and type gridbox in the search field then when presented with the options edit the BaseStyle\n\nHere I've changed the font to Times and you can see the change in the input cell. Note that you have also commented about alignments. You can set the grid alignments the same way. I'd suggest that you read up on various alignment points in the Grid documentation.\nYou are probably already thinking that this is inconvenient to do regularly so instead you can set up your own Grid style in a style sheet. The downside to that is that this will style Grid the same in all cells. So in fact what you need to do is create a stylesheet with a modified Text style:\n\nStylesheeting is beyond the scope if this Q&A but if you search you will find information about how to go about this. I'd suggest this is your best option for regular routine use.\nFinally, to style tables and output a set of rules for later use a demo can be seen here from which a slightly reduced set of features can be downloaded.\n", "graphics - Generate Random Text within a Rectangle": "\nMaybe something like this (using Inset and Pane to place text inside the rectangle):\ntxdt = ExampleData[{\"Text\", \"LoremIpsum\"}]; \nManipulate[Graphics[{EdgeForm[Thick], Opacity[0], Rectangle[{0, 0}, {160, 90}], \nOpacity[1], \nInset[Pane[\n Style[txdt, TextAlignment -> Left], {Scaled[1], Scaled[.75]}, \n Alignment -> Center,\n Scrollbars -> Automatic, AppearanceElements -> {\"ResizeArea\"}, \n ImageSizeAction -> \"Scrollable\"], {left, bottom}, {Left, \n Bottom}, {right - left, top - bottom}], \n Flatten@({Flatten@(Table[\n        RandomChoice[{GrayLevel[.15], c0[[#]]}], {3}] & /@ \n      Range[2, 4, 1]), \n   MapThread[Function[{Xs, Ys}, \n     Rectangle[{Xs, Ys}, {Xs + 16, Ys + 9}]], {Flatten@\n      Table[Range[0, 32, 16], {3}], \n     Flatten@(Table[#, {3}] & /@ \n        Range[63, 81, 9])}]}\\[Transpose]), Black, Thick, \n Line[{{0, 63}, {160, 63}}]}, PlotRange -> {{0, 160}, {0, 90}}, \n ImageSize -> 400], {{left, 0}, 0, 140, 1}, {{bottom, 0}, 0, 55, 1}, \n {{right, 160}, 10, 160, 1}, {{top, 75}, 0, 75, 1}]\n\nWith output:\n:\nSource: Inset trick based on TextRect courtesy of Wolfram's John Fultz: pls see    MathGroup\nEDIT: Without assuming that the current question is related to \nOP`s previous question, using just plain rectangles and text: \n Graphics[{EdgeForm[Thick], Opacity[0], Rectangle[{0, 0}, {160, 90}], \n   Opacity[1], \n   Inset[Pane[Style[#, 12, TextAlignment -> Left], {Scaled[1], \n      Scaled[.75]}, Alignment -> Center, Scrollbars -> Automatic, \n     AppearanceElements -> {\"ResizeArea\"}, \n     ImageSizeAction -> \"Scrollable\"], {5, 5}, {Left, \n     Bottom}, {150, 100}]}, PlotRange -> {{0, 160}, {0, 90}}, \n  ImageSize -> 400] &@\n  RandomChoice@Take[ExampleData[{\"Text\", \"LoremIpsum\"}, \"Lines\"], \n  {1,-1,2}] & /@    Range@4 // Grid[Partition[#, 2]] & \n\nwhich gives\n \nIf the rectangles are known to be large enough so that scrolling will not be needed, then Pane is not needed; you can use the following version of the Inset:\n Inset[Style[Text[#], 12, TextAlignment -> Left], {5, 90}, {Left, \n   Top}, {150, 100}]\n\nEDIT 2: Putting the text in the proper rectangle (in response the OPs edit), using txt1 from Lorem Ipsum\n txt1 = Take[ExampleData[{\"Text\", \"LoremIpsum\"}, \"Lines\"], {1, -1, 2}][[1]] //\n StringTake[#, 330] & ;\n\nin \n Graphics[{EdgeForm[{Thickness[0.005`], Black}], White, \n Rectangle[{0, 0}, {160, 90}], Black, Opacity[0.7`], \n EdgeForm[{Thickness[0.005`], Black}], Rectangle[{0, 0}, {80, 63}], \n Inset[Pane[\n Style[txt1, 12, TextAlignment -> Left], {Scaled[1], \n Scaled[0.75`]}, Alignment -> Center, \n ImageSizeAction -> \"Scrollable\"], {0, 8}, {Left, Bottom}, {78, \n 67}], Flatten[\n Transpose[{Flatten[(Table[\n      RandomChoice[{GrayLevel[0.15`], c0[[#1]]}], {3}] &) /@ \n   Range[2, 4, 1]], \n MapThread[\n  Function[{Xs, Ys}, \n   Rectangle[{Xs, Ys}, {Xs + 16, Ys + 9}]], {Flatten[\n    Table[Range[0, 32, 16], {3}]], \n   Flatten[(Table[#1, {3}] &) /@ Range[63, 81, 9]]}]}]], Null, \nBlack, Thickness[0.005`], Line[{{0, 63}, {159, 63}}]}, \nPlotRange -> {{0, 160}, {0, 90}}, Method -> {\"ShrinkWrap\" -> True}, \nImagePadding -> 2, ImageMargins -> 0, ImageSize -> 500]\n\nyou get\n\n", "Selectively Mapping over elements in a List": "\nHere's an option which only passes moons with images to the Labeled function:\nLabeled[# // Text, AstronomicalData[#, \"Image\"]] & /@ \n  Select[AstronomicalData[\"PlanetaryMoon\"], \n   ImageQ[AstronomicalData[#, \"Image\"]] &] // Row\n\n\n", "How to develop an Import/Export converter for Compress[]ed data?": "\nIn this case, developing the converters is dead-easy (which is not a good thing IMO, since it means that we really don't utilize the power of Import/Export framework, but rather are adding syntactic sugar):\nCompressedFormat`CompressedFormatImport[filename_String, options___] :=\n    {\"Data\" -> Uncompress@Import[filename, \"String\"]};\n\nCompressedFormat`CompressedFormatExport[filename_String, data_, opts___] :=\n    Export[filename, Compress@data, \"String\"];\n\nImportExport`RegisterImport[\n   \"CompressedFormat\",\n   CompressedFormat`CompressedFormatImport\n]\n\nImportExport`RegisterExport[\n   \"CompressedFormat\", \n   CompressedFormat`CompressedFormatExport \n]\n\nExample:\nfile = $TemporaryPrefix <> \"test\";\nExport[file, Range[1000000], \"CompressedFormat\"];\nImport[file, {\"CompressedFormat\", \"Data\"}] // Length\n\n(* \n  ==>  1000000\n*)\n\nThat said, I think using Import - Export framework makes much more sense for specific formats where you can specify distinct elements and the framework makes it convenient to create importers for those elements (possibly avoiding full imports when unnecessary). So, for a meaningful exposition of the importer-writing procedure using Import/Export framework, some e.g. particular graphics of numerical format would be a better choice IMO, because your stated goal is too general for that. \nFor that matter, I think that my large data framework (perhaps when extended and generalized) will make for a much better case for Import/Export framework use, as well as cover your use case and many more, because it:\n\nDoes use Compress under the cover\nUses lazy loading, which opens many possibilities to define certain elements for Import/Export, which are loaded individually / efficiently\nDoes not have a limitation that the file must fit in memory\nCan be very fast for large files\nIn practice, we use large files much more frequently than carry them around from platform to platform. My framework can switch from extremely fast .mx files to Compress-ed non-.mx files very easily, and the details can be completely hidden from the user, who will just use Import in all cases, and have great performance. \n\nIn other words, I feel that the direction I outlined there, does contain your suggestion as a special case, and is much more fruitful both for further development of the large-data framework / file format, and for the utilization of the power of the Import/Export framework (and, sure enough, this is the direction I will be extending the large-data framework in the future).\n", "front end - Toolbars in Mathematica": "\nTo begin with, if you use menu: Palettes > Install Palette... the palette should open in the place it last appeared every time you start Mathematica.  I always have two custom palettes visible when I start Mathematica:\n\nA palette to open one of dozen Notebooks I use frequently\nSzabolcs's Paste Tabular Data\n\nThese admittedly do not \"dock\" if I move them around, but I have never actually looked for that option so it may be possible.  I know that you can make a palette float always-on-top with the option WindowFloating (in fact this may be the default; it it switchable with WindowFloating).\nIn answer to why I suppose:\n\nBecause people do such a range of different things with Mathematica there is less value in a standard toolbar.\nPalettes actually do provide for a reasonably similar functionality\nActual toolbars are seen as taking up screen space\nSomeone in the FrontEnd GUI department is lazy.  This would also explain the lack of a multi-step Undo. ;-)\n\n", "graphics - How to get rid of Panel margins?": "\nIn these situations I like to use Pane instead of Panel.  It has no frame or extra margins.\nPane[Graphics[{Circle[]}, ImageSize -> 300, Frame -> True, \n  FrameTicks -> None]]\n\n\nDoes this help?\n\nIn case if you just want a Panel with no margins, not even the small margins that are left after FrameMargins -> 0:\nThe problem is that the Panel margin is styled by the operating system and will look different on different platforms. For example, on Windows XP it has an \"engraved\" look. This would be not possible without some extra margin. If we take away the system-styled margins, then all we're left with is a Pane.\n", "Fit an image within a Rectangle [] in Graphics": "\nWhat about this to create the textured rectangle. Here, pic is the picture you want to use for the Texture and ll and ur are the lower left and upper right corners of the box.\nrec[ll_, ur_, pic_] := Module[{crop, boxrat},\n  boxrat = #2/#1 & @@ MapThread[Abs[#2 - #1] &, {ll, ur}];\n  crop = ImageCrop[pic, Transpose[{ ImageDimensions[pic]}], \n    AspectRatio -> boxrat];\n\n  {Texture[ImageData[crop]],\n   Polygon[Tuples[Sort /@ Transpose[{ll, ur}]][[{1, 2, 4, 3}]],\n    VertexTextureCoordinates -> Tuples[{0, 1}, 2][[{1, 2, 4, 3}]]]}]\n\nFor your example you would get\npic = Import[\n      \"http://dailytechgadgets.files.wordpress.com/2011/02/old-ferrari.jpg\"];\n\nGraphics[{EdgeForm[Thickness[.005]], White, \n  Rectangle[{0, 0}, {160, 90}], Black, Opacity[.7], \n  Rectangle[{0, 0}, {80, 63}], White, Opacity[1],\n\n  rec[{80, 0}, {160, 63}, pic], Opacity[1], \n\n  Flatten@({Flatten@(Table[\n        RandomChoice[{GrayLevel[.15], c0[[#]]}], {3}] & /@ Range[2, 4, 1]), \n    MapThread[\n     Function[{Xs, Ys}, \n       Rectangle[{Xs, Ys}, {Xs + 16, Ys + 9}]], {Flatten@\n         Table[Range[0, 32, 16], {3}], \n       Flatten@(Table[#, {3}] & /@ \n           Range[63, 81, 9])}]}\\[Transpose])}, \n Method -> {\"ShrinkWrap\" -> True}, ImageSize -> 500]\n\nwhich produces\n\nEdit \nInstead of cropping the image first and using that as the texture you can also play around with the settings for VertexTextureCoordinates. For example you could also do\nrec2[ll_, ur_, pic_, f_:.5] := \n Module[{boxrat, picrat},\n  picrat = #2/#1 & @@ ImageDimensions[pic];\n  boxrat = #2/#1 & @@ MapThread[Abs[#2 - #1] &, {ll, ur}];\n  {Texture[ImageData[pic]],\n   Polygon[Tuples[Sort /@ Transpose[{ll, ur}]][[{1, 2, 4, 3}]], \n    VertexTextureCoordinates -> \n     Tuples[{ \n       {f Max[0, 1 - picrat/boxrat], 1 - (1-f) Max[0, 1- picrat/boxrat]}, \n       {f Max[0, 1 - boxrat/picrat], 1 - (1-f) Max[0, 1- boxrat/picrat]}}]\n         [[{1, 2, 4, 3}]]]}]\n\nI've added an extra argument f which indicates which indicates how much of the left or right of the image should be cropped. For example a setting of 0 would indicate that all cropping should be from the right side of the image (or the top depending on the aspect ration of the image). When f==0.5 equal parts are cropped from the left and right sides and when f==1 the image is only cropped on the left side (or bottom). \nEdit 2\nIt looks like Texture isn't playing nicely with Inset used in kguler's answer to your previous. To get the text and the image in the same picture you could do something like this instead\nrec[ll_, ur_, pic_] := Module[{crop, boxrat},\n  boxrat = #2/#1 & @@ MapThread[Abs[#2 - #1] &, {ll, ur}];\n  crop = ImageCrop[pic, Transpose[{ ImageDimensions[pic]}],\n    AspectRatio -> boxrat];\n  Inset[crop, Min /@ Transpose[{ll, ur}], {Left, Bottom}, \n   Abs[ur - ll]]]\n\nCombined with kguler's answer you get something like\nGraphics[{EdgeForm[{Thickness[0.005`], Black}],\n   FaceForm[White], Rectangle[{0, 0}, {160, 90}],\n   FaceForm[Darker[Gray]], Rectangle[{0, 0}, {80, 63}],\n\n   (* code for picture *)\n   {rec[{80, 0}, {160, 63}, pic],\n    FaceForm[Opacity[0]],\n    Rectangle[{80, 0}, {160, 63}]},\n\n   (* code for text *)\n   Inset[Pane[\n     Style[txt1, 12, TextAlignment -> Left], {Scaled[1], \n      Scaled[0.75`]}, Alignment -> Center, \n     ImageSizeAction -> \"Scrollable\"], {0, 8}, {Left, Bottom}, {78, \n     67}],\n\n   Flatten[\n    Transpose[{Flatten[(Table[\n           RandomChoice[{GrayLevel[0.15`], c0[[#1]]}], {3}] &) /@ \n        Range[2, 4, 1]], \n      MapThread[\n       Function[{Xs, Ys}, \n        Rectangle[{Xs, Ys}, {Xs + 16, Ys + 9}]], {Flatten[\n         Table[Range[0, 32, 16], {3}]], \n        Flatten[(Table[#1, {3}] &) /@ Range[63, 81, 9]]}]}]],\n   {Black, Thickness[0.005`], Line[{{0, 63}, {159, 63}}]}}, \n  PlotRange -> {{0, 160}, {0, 90}}, Method -> {\"ShrinkWrap\" -> True}, \n  ImagePadding -> 2, ImageMargins -> 0, ImageSize -> 500]\n\nwhich produces something like\n\n", "performance tuning - Parallelize evaluation of function with memoization": "\nThe problem with SetSharedFunction is that it forces f to be evaluated on the main kernel: this means that if you simply do\nSetSharedFunction[f]\n\nthen you will lose parallelization (a timing of ParallelTable[f[x], {x, 3}] will give about 9 seconds).\nThis property of SetSharedFunction is not clear from the documentation in my opinion.  I learned about it from this answer.  It is also not clear if the behaviour is the same in version 7 (can someone test? I tested my answer on version 8 only).\nWe can however store the memoized vales on the main kernel, while evaluating the expensive computations on the paralell kernels.  Here's one way to do it:\nf[x_] :=\n With[{result = g[x]},\n  If[result === Null,\n   g[x] = (Pause[3]; N[Sin[x]]),\n   result\n  ]\n ]\n    \nSetSharedFunction[g]\n\nHere I used the special property of shared functions that they return Null on the paralell kernels when they have no value for a given argument.\nThe first time we run this, we get a 6 s timing, as expected:\nAbsoluteTiming@ParallelTable[f[x], {x, 3}]\n\n(* ==> {6.0533462, {0.841471, 0.909297, 0.14112}} *)\n\nThe second time it will be very fast:\nAbsoluteTiming@ParallelTable[f[x], {x, 3}]\n\n(* ==> {0.0260015, {0.841471, 0.909297, 0.14112}} *)\n\nHowever, as you noticed, evaluating f on the parallel kernels is a bit slow.  On the main kernel it's much faster.  This is due to the communication overhead: every time f is evaluated or changed on a subkernel, it needs to communicate with the main kernel.  The slowdown does not really matter if f is really expensive (like the 3 seconds in your toy example), but it can be significant if f is very fast to execute (comparable in time to the apparently ~10 ms communication overhead)\nParallelTable[AbsoluteTiming@f[x], {x, 3}]\n\n(* ==> {{0.0100006, 0.841471}, {0.0110006, 0.909297}, {0.0110007,  0.14112}} *)\n\nTable[AbsoluteTiming@f[x], {x, 3}]\n\n(* ==> {{0., 0.841471}, {0., 0.909297}, {0., 0.14112}} *)\n\n\nFinally a note about benchmarking:  in general, measuring very short times like the 10 ms here should be done with care.  On older versions of Windows, the timer resolution is only 15 ms.  On Windows 7, the resolution is much better.  These timings are from Windows 7.\n\nUpdate:\nBased on @Volker's @Leonid's suggestion in the comments, and @Volker's original solution, we can combine subkerel and main kernel caching like this:\nf[x_] := With[{result = g[x]}, (f[x] = result) /; result =!= Null];\nf[x_] := g[x] = f[x] = (Pause[3]; N[Sin[x]])\n\n\nPackaged up solution\nWe can bundle all these ideas into a single memoization function (see the code at the end of the post).\nHere is an example use:\nClear[f]\nf[x_] := (Pause[3]; Sin[x])\n\nAbsoluteTiming@ParallelTable[AbsoluteTiming@pm[f][Mod[x, 3]], {x, 15}]\n\n(* ==>\n{6.0683471, {{3.0181726, Sin[1]}, {0.0110007, Sin[2]}, \n             {3.0181726, 0}, {0., Sin[1]}, {3.0191727, Sin[2]}, \n             {3.0181726, 0}, {0.0110007, Sin[1]}, {0., Sin[2]}, \n             {0., 0}, {0., Sin[1]}, {0., Sin[2]}, \n             {0., 0}, {0., Sin[1]}, {0., Sin[2]}, {0., 0}}}\n*)\n\nThe function simply needs to be called using pm[f][x] instead of f[x].  Memoized values are associated with f as UpValues, so I thought automatic distribution of definitions should take care of both synchronizing memoized values and clearing them when necessary.  Unfortunately this mechanism doesn't seem to be reliable (sometimes it works, sometimes it doesn't), so I provided a function clearParallelCache[f] that will clear all memoized values on all kernels.\nCaching happens at two levels: on the main kernel level and on subkernels.  Computed or main-kernel-cached values are copied to the subkernels as soon as possible.  This is visible in the timings of the example above.  Sometimes retrieving cached values takes 10 ms, but eventually it becomes very fast.  Note that it might happen that the two kernels will each compute the same value (if they start computing it at the same time).  This can sometimes be avoided by using a different setting for the Method option of Parallelize (depending on the structure of the input data).\nFor simplicity, I restricted pm to only work with functions that take a single numerical argument (and return anything).  This is to avoid having to deal with more complex conditional definitions (especially cases when the function won't evaluate for certain argument types).  It could safely be changed to accept e.g. a vector or matrix of values instead.\n\nThe code\npm[f_Symbol][x_?NumericQ] :=\n With[{result = memo[f, x]},\n  If[result === Null,\n   With[{value = valueOnMain[f, x]},\n    If[value === Null,\n     f /: memo[f, x] = setValueOnMain[f, x, f[x]],\n     f /: memo[f, x] = value]\n    ],\n   result]\n  ]\n\nmemo[___] := Null\nDistributeDefinitions[memo];\n\nvalueOnMain[f_, x_] := memo[f, x]\n\nsetValueOnMain[f_, x_, fx_] := f /: memo[f, x] = fx\n\nSetSharedFunction[valueOnMain, setValueOnMain]\n\nclearParallelCache[f_Symbol] := \n  (UpValues[f] = {}; ParallelEvaluate[UpValues[f] = {}];)\n\n", "plotting - Why does ListPlot ignore some global options?": "\nIn version 7 it appears that ListPlot only uses global Options[] that are acceptable to Graphics (probably via FilterRules).  You can work around this manually with explicit declaration:\nSetOptions[ListPlot, {PlotMarkers -> {\"A\"}, Filling -> Axis}];\n\nListPlot[Range[10], Options[ListPlot]]\n\n\nIf you want to make this fix automatic you can do this:\nUnprotect[ListPlot];\n\nListPlot[args___] :=\n  Block[{$lpOptsFix = True},\n    ListPlot[args, Options[ListPlot]]\n  ] /; ! TrueQ[$lpOptsFix]\n\n", "numerics - How to fix errors in Gram-Schmidt process when using random vectors?": "\nI'm not sure why you'd expect the resulting vectors to remain in the original swath because you're forcing the angle between the two resulting vectors to be 90 deg. Pairs of vectors with cross products far from the poles of the sphere will necessarily result in one of the vectors \"popping out\" of the swath.\nI'd also like to point out that you don't need Gram-Schmidt to create an orthonormal basis for the two vectors.  Instead, you can just do the following: Given two vectors v1 and v2, define u1=v1 then construct u2=Normalize[v1 x v2]. Finally, u3 = u2 x u1.  Now u1 will be aligned with v1 and u3 will be in the plane defined by v1 and v2 but it will be orthogonal to u1 and in the general direction of v2. \n", "Pattern to match a non-empty list of non-empty lists": "\nIf I am understanding you:\nx : {{__} ..}\n\nSee Repeated for more information and additional options.  Also see RepeatedNull while you're there.\nMake sure you understand BlankSequence and Pattern as well.\n\nHere is a breakdown of the expression above.  First let us view the FullForm which is as close to the way Mathematica sees it as possible:\nFullForm[ x:{{__}..} ]\n\n\nPattern[x,\n  List[\n    Repeated[\n      List[\n        BlankSequence[]\n      ]\n    ]\n  ]\n]\n\n\nThis expanded form is useful to remove any ambiguity in Mathematica's parsing.\nTherefore from the inside out we have (short form : long form : description):\n__ : BlankSequence[] : one or more arguments with any head\n{ } : List[ ] : inside the head List\n.. : Repeated[ ] : one or more arguments matching the given pattern\n{ } : List[ ] : inside the head List\nx: : Pattern[x, ] : a unique expression that matches the given pattern, named x\nPay attention to this last point: naming the pattern changes the way it behaves, such that it represents a unique expression.  Consider this superficially similar pattern:\nx : {{a__} ..}\n\nThis will only match e.g. {{1, 2}, {1, 2}, {1, 2}} but not {{1, 2}, {3}, {4, 5, 6}} because by naming the first sequence 1, 2 all other sequences must be identical.  Simply matching the pattern a__ independently is not enough.\n", "interface - How can I use the Klingon alphabet symbols?": "\nI found the solution.  Mathematica is set up to use the font KLIpIqaDmey.  The tip-off is in the UnicodeFontMapping.tr file referenced in the question.  The header reads:\n@@resource UnicodeFontMapping\nMathematica: Times Automatic\nMathematica: (Times Courier) Automatic\nMathematica: (Mathematica1 Mathematica1Mono) Automatic\nMathematica: (Mathematica2 Mathematica2Mono) Automatic\nMathematica: (Mathematica3 Mathematica3Mono) Automatic\nMathematica: (Mathematica4 Mathematica4Mono) Automatic\nMathematica: (Mathematica5 Mathematica5Mono) Automatic\nMathematica: (Mathematica6 Mathematica6Mono) Automatic\nMathematica: (Mathematica7 Mathematica7Mono) Automatic\nMathematica: MathematicaInternal Automatic\nMathematica: Zapf_Dingbats Automatic\nMathematica: (DefaultKanjiFont DefaultMonoKanjiFont) Japanese\nMathematica: (DefaultKoreanFont DefaultMonoKoreanFont) Korean\nMathematica: (DefaultChineseSimplifiedFont DefaultMonoChineseSimplifiedFont) ChineseSimplified\nMathematica: (DefaultChineseTraditionalFont DefaultMonoChineseTraditionalFont) ChineseTraditional\nMathematica: KLIpIqaDmey Klingon\n\n\n\n#  0  =  special: dynamically assigned\n#  1  =  base font\n#  2  =  Mathematica1: Greek letters and common operators\n#  3  =  Mathematica2: Radicals, brackets, integrals, arrows\n#  4  =  Mathematica3: Operators and shapes\n#  5  =  Mathematica4: Arrows, vectors, over/under brackets, keys, icons\n#  6  =  Mathematica5: the archaic alphabets, Script\n#  7  =  Mathematica6: Gothic\n#  8  =  Mathematica7: DoubleStruck\n#  9  =  FE Internal\n#  10  =  Zapf Dingbats\n#  11  =  Kanji (if present)\n#  12  =  Korean (if present)\n#  13  =  Chinese Simplified (if present)\n#  14  =  Chinese Traditional (if present)\n#  15  =  Klingon (if present)\n\nAt first glance I overlooked the significance of the Mathematica: lines, but then I realized their relation to 0 - 15 below.\nImage captured from Mathematica with the font installed:\n\n", "java - Unit testing J/Link projects in Workbench": "\nMUnit testing is surely supported on JLink projects (I used it in JLink projects which also contained Java classes,  without problems). In fact, MUnit is all about Mathematica, so you just follow the usual procedure. I actually never bothered to create configurations etc. \nI just took your code, created a J/Link project, and run the unit test file as Run As -> Mathematica test (position mouse on any place within a unit test file in the WorkBench editor, then right-click and choose Run-As). Everything was fine.\n\n", "combinatorics - Permutations[Range[12]] produces an error instead of a list": "\nCombinatorica` has the function NextPermutation which allows you to iterate over the permutations. There may be ways of generating a smaller subset if you have more information about what you are looking for.\n", "Feed a Manipulate[] Output into a Graphics[]": "\nJust Set dist[[1]] to your output inside Manipulate. Putting additionally a Dynamic to your plots let's you see the change live.\n(Edit) You can put your graphics of course inside the same Manipulate and change the graphics too. So after evaluating all your definitions from the first code-block, you could do something like\nManipulate[\n Column[{\n   distToMean[[1]] = (Flatten@\n       allTeamAverageStats[[Flatten@\n          Position[\n           Total[{v1, v2, v3, v4, v5, v6, v7, v8, v9, v10}/\n                Total@{v1, v2, v3, v4, v5, v6, v7, v8, v9, \n                  v10} (allTeamAverageStats[[#]] - rosterRAMean)/\n                rosterRASD] & /@ Range[792], \n           Max[Total[{v1, v2, v3, v4, v5, v6, v7, v8, v9, v10}/\n                 Total@{v1, v2, v3, v4, v5, v6, v7, v8, v9, \n                   v10} (allTeamAverageStats[[#]] - rosterRAMean)/\n                 rosterRASD] & /@ Range[792]]]]]) - rosterRAMean,\n   Show[Function[attributes, \n      Graphics[{Blend[{{-Max[Abs[distToMean[[1]]]], Red}, {0, \n           LightRed}, {0, LightGreen}, {+Max[Abs[distToMean[[1]]]], \n           Green}}, distToMean[[1]][[attributes]]], \n        Rectangle[{If[distToMean[[1]][[attributes]] < 0, \n           distToMean[[1]][[attributes]]*10, 0], \n          attributes - 1}, {If[distToMean[[1]][[attributes]] < 0, 0, \n           distToMean[[1]][[attributes]]*10], attributes}], \n        PlotRange -> {{-6, 6}, {0, 10}}}, AspectRatio -> 16/9, \n       Epilog -> {Black, Thickness[thickness], \n         Line[{{0, 0}, {0, 11}}]}]] /@ Range[10], Frame -> False, \n    FrameTicks -> False]\n   }, Center\n  ],\n\n {v1, Range[.1, 1, .1]}, {v2, Range[.1, 1, .1]}, {v3, \n  Range[.1, 1, .1]}, {v4, Range[.1, 1, .1]}, {v5, \n  Range[.1, 1, .1]}, {v6, Range[.1, 1, .1]}, {v7, \n  Range[.1, 1, .1]}, {v8, Range[.1, 1, .1]}, {v9, \n  Range[.1, 1, .1]}, {v10, Range[.1, 1, .1]}, {thickness, 0.01, 0.1}, \n ControlType -> Manipulator]\n\nNote: This is far from being good programming style but for a test it should be fine.\n", "list manipulation - How to Delete Elements from List1 appearing in List2?": "\nUse\nDeleteCases[list1, Alternatives @@ list2]\n\nIn new versions (M8.0+), DeleteCases is optimized on patterns not involving blanks, so this will be fast also for large lists. For earlier versions, this will work:\nReplace[list1, Dispatch[Thread[list2 -> Sequence[]]],{1}]\n\nbeing 2-3 times slower, but still very fast.\n", "list manipulation - Check in a series if there exists adjacent values with less than a certain number of missing values": "\nSuppose $p_k$ with $1\\leq k\\leq N_0$ is the position of the $k$-th zero in the data list $\\{a_1,\\ldots,a_N\\}$, then each sublist which contains $\\leq M$ zeros will be a sublist of one of the sublists\n$$\n\\{ a_{p_k+1},\\ldots, a_{p_{k+M+2}-1}\\}, \\qquad 1\\leq k \\leq N_{0}-M-2\n$$ \nor $\\{ 1,\\ldots, a_{p_{M+1}-1}\\}$ or $\\{a_{p_{N_0-M-1}+1},\\ldots, a_N\\}$, so in Mathematica speak it is sufficient to construct the lists \nTake[lst {zlst[[k]]+1 ;; zlst[[k+maxZeros+2]]-1}]\n\nfor which zlst[[k+maxZeros+2]]-zlst[[k]]-1 >= minLen where zlst is the list of positions of the zeros in lst padded with 0 on the left and Length[lst]+1 on the right. This could be implemented as\nfindLsts2[lst_, minLen_Integer?Positive, maxZeros_, \n  n : (_Integer | All) : All] :=\n Module[{zeroLst, rangeLst},\n  zeroLst = Flatten[Position[lst, (0 | 0. | Null)]];\n  If[Length[zeroLst] <= maxZeros,\n   lst,\n   rangeLst = Transpose[{Prepend[Drop[zeroLst + 1, -maxZeros], 1],\n      Append[Drop[zeroLst - 1, maxZeros], Length[lst]]}];\n   {Take[lst, #], #} & /@ \n    Select[rangeLst, (#[[2]] - #[[1]] + 1) >= minLen &, \n     n /. All -> Sequence[]]\n   ]\n  ]\n\nThis would return the sublists of maximum length which contain at most maxZeros zeros together with the indices of these sublists in the data list lst. Example\nfindLsts2[{1, 0, 2, 0, 3, 0, 0, 0, 2, 4, 5, 6, 7, 0}, 4, 2] // MatrixForm\n\n\nEdit\nThis updated version of findLsts2 randomly selects n sublists from all possible sublists of length len with at most maxZeros zeros from lst.\nfindLsts3[lst_, len_Integer?Positive, maxZeros_, \n  n : (_Integer | All) : All] :=\n Module[{zeroLst, rangeLst, startLst},\n  zeroLst = Flatten[Position[lst, (0 | 0. | Null)]];\n  If[Length[zeroLst] <= maxZeros,\n   startLst = Range[Length[lst] - len + 1],\n   rangeLst = Transpose[{Prepend[Drop[zeroLst + 1, -maxZeros], 1],\n      Append[Drop[zeroLst - len, maxZeros], Length[lst] - len + 1]}];\n   startLst = Flatten[Range @@@ (List @@ (Interval @@ \n          Select[rangeLst, (#[[2]] - #[[1]]) >= 0 &])), 1]];\n  {lst[[# ;; # + len - 1]], #} & /@ Sort@RandomSample[startLst, n]\n  ]\n\nFor the previous example we get\nfindLsts2[{1, 0, 2, 0, 3, 0, 0, 0, 2, 4, 5, 6, 7, 0}, 4, 2] // MatrixForm\n\n\nEdit 2\nThe $k$-th pair in rangelst in findLsts3 corresponds to the values $\\{j_1, j_2\\}$ such that \n$$p_{k-1}+1 = j_1\n\\qquad\\text{and}\\qquad\nj_2+l-1 = p_{k+M+1}-1$$\nwhere $l$ is the length of the sublist you want to extract and $p_k$ is as above. Provided that $j_{1}\\leq j_{2}$ we then have that for all $j_{1}\\leq j\\leq j_{2}$ the sublist $\\{a_j,\\ldots,a_{j+l-1}\\}$ is a subset of $\\{ a_{p_{k-1}+1},\\ldots, a_{p_{k+M+1}-1}\\}$. What the Select statement in startLst does is to filter out the pairs in rangelst for which $j_1\\leq j_2$ doesn't hold. startLst is then the Union of the ranges Range[j1, j2] for all remaining pairs.\n", "plotting - ListPlot with each point a different color and a legend bar": "\nIn this case I would use Point for plotting the points. For example\nn = 5000;\npos = RandomVariate[NormalDistribution[0, 2], {n, 2}];\naltitude = Norm /@ pos;\ncolorf = Blend[{{Min[altitude], Yellow}, {Max[altitude], Red}}, #] &\n\npl = Graphics[MapThread[{colorf[#1], Point[#2]} &, {altitude, pos}], \n  Axes -> True, AspectRatio -> 1]\n\nAs for plotting legends, that's a reoccurring issue in Mathematica. There is a package called  PlotLegends` which you could try but it is not very user friendly and the legends it produces are quite ugly IMHO. I find that it's often faster to just create a legend by hand. For example, this is a function I use for creating legends with contour plots:\nplotLegend[{min_, max_}, n_, col_] := \n Graphics[MapIndexed[{{col[#1], \n      Rectangle[{0, #2[[1]] - 1}, {1, #2[[1]]}]}, {Black, \n      Text[NumberForm[N@#1, {4, 2}], {4, #2[[1]] - .5}, {1, 0}]}} &, \n   Rescale[Range[n], {1, n}, {min, max}]],\n  Frame -> True, FrameTicks -> None, PlotRangePadding -> .5]\n\nHere, n is the number of subdivisions and col is the colour function. You could combine the legend with the original plot using Grid, e.g.\nleg = plotLegend[Through[{Min, Max}[altitude]], 20, colorf];\nGrid[{{Show[pl, ImageSize -> {Automatic, 300}], \n  Show[leg, ImageSize -> {Automatic, 250}]}}]\n\n\n", "evaluation - General::ivar is not a valid variable when plotting": "\nThe problem lies in g[x_] := D[f[x], x]; remember that what SetDelayed (that is, :=) does is to replace stuff on the right corresponding to patterns on the left before evaluating. Thus, when one does something like g[2] (and something like this happens within Plot[]), you are in fact evaluating D[f[2], 2], and since one cannot differentiate with respect to a constant ;), you get the General::ivar error message.\nIf you use Set instead (that is, g[x_] = D[f[x], x]), f[x] is differentiated first before the result of D[] is assigned to g[x_]. Since what's on the right of g[x_] is now an actual function, Plot[] no longer has a reason to complain.\n", "graphs and networks - How can I remove B -> A from a list if A -> B is in the list?": "\nThis seems to do what you want:\nrules = {\"A\" -> \"B\", \"B\" -> \"A\", \"C\" -> \"D\"};\n\nRule @@@ Union[Composition[Sort, List] @@@ rules]\n(* {\"A\" -> \"B\", \"C\" -> \"D\"} *)\n\n", "notebooks - How to set default magnification for all windows": "\nIf the reason you ask is because the fonts are much too small, then there is another approach that is arguably more correct than changing Magnification, and that is to specify a better screen resolution.  By default it is 72ppi, but screens haven't been like that for years (mine is about 100ppi).\nSetOptions[$FrontEndSession, \n FontProperties -> {\"ScreenResolution\" -> 96}\n]\n\nIf you like the setting and what to make it persist between sessions, replace $FrontEndSession with $FrontEnd.\n", "programming - Can Mathematica be regarded as a software prototyping environment?": "\nI think that Mathematica is a great prototyping environment, and has a bright future as a system for both prototyping and implementation of complete components of other systems, from back-ends to front-ends. In my opinion, we are now witnessing the process of it being transferred from pure scientific tool to a general software engineering tool / language.\nSo, I think that moving to another language can be often done pretty late in the development cycle (disclaimer: I have not personally built large systems involving Mathematica as a part - although I worked on large systems written in Java  before -  so what I write here is mostly an educated guess based on my separate experiences in Mathematica and other languages). The great benefit of Mathematica is that it is a very high-level development environment which can serve as a gluing medium for development of hybrid systems, where different parts are written in different languages. For example, I found it a great testing / development medium for Java applications. This is generally not yet quite apparent since we still lack some tools to boost productivity and overcome cross-lnaguage barriers. But I am more than positive that such tools are going to emerge pretty soon. When you develop the system, what matters is how flexible is your architecture, how testable are your modules, and how fast are the development iterations. A high-level environment like Mathematica is a great win for all these.\nThat said, I would not currently use Mathematica as a central run-time of the application, simply because the kernel crashes every now and then. I would make that another runtime (e.g. Java), which calls Mathematica and handles possible errors, exceptions, crashes and the like (actually, WebMathematica is just that - Mathematica managed by the Java runtime and bundled as a web application for some Java container like Apache Tomcat). Mathematica can however serve as both an excellent back-end and an excellent prototyping environment, so once again, my feeling is that one can benefit a lot from developing even large industrial systems in or with Mathematica. There are actually companies which do just that, and are quite successful.\nAs to when to use C etc - my advice is: as late as you can. Many problems for which Mathematica is perceived as slow can be solved quite efficiently with the knowledge of how to write efficient Mathematica code. May be even more importantly, it is rare that you know the exact method you will use for a given problem, all in advance. Once you switch to C, you will have to deal with lots of low - level details, which will  increase development time and chances for errors, plus they will distract you from the essence of the problem you are solving. Even if you switch to C at the end, Mathematica can save you a lot of time in prototyping your solution, and minimize the amount of low-level work you have to do.\nScaling to large code bases:\nThis is a problem in pretty much every language. There are probably many factors which determine how well a given language scales. Part of this is also probably not just about language itself, but about existing development tools. For example, Java scales reasonably well, but no one in their right mind would use it for large projects without smart IDE-s. So, I'd set out a few important factors (a list is incomplete, of course):\n\nType system. Strongly typed languages can use the compiler to help find errors, and this will be particularly powerful for those with type inference (ML family languages for example).\nMeans for composition. These include classes / interfaces / inheritance for OO, and higher-order functions / closures / possibly macros for FP. I am biased towards FP here.\nMeans for information hiding, and separation between interface and implementation. This is extremely important, and this is where OO shines, IMO. You can get it in FP, but have to be more disciplined.\nPackage / module system, and namespaces - this is a very important tool for large-scale encapsulation / information-hiding\nDevelopment tools (IDE-s, debuggers, profilers) - can make a huge difference.\nStandards of coding and code exchange. When they exist, it makes for much easier code reuse, assuming that you don't write everything yourself.\n\nThere are probably other important factors I missed. The question is how does Mathematica fare regarding these factors. I'd say that potentially, Mathematica can fare quite well. I think right now it suffers the most from a lack of certain development tools (a really good / useful debugger, for one) and coding / code exchange standards. Also, the programming practices which allow to scale to larger systems, while certainly possible in Mathematica, are not developed / not in widespread use yet. For example, closures and higher-order functions are very useful for that,  but it's not something every second Mathematica programmer is using. Also, while Mathematica allows to write macros (functions which manipulate code), its rather complex evaluation control mechanisms make them hard to write. And macros are the extremley powerful scaling tool - in LISP they allow for easy creation of DSL-s because essentially they extend the compiler in the direction you want. Another problematic thing is that Mathematica is often too general, and this generality gets in the way in forms of evaluation and performance surprises. Some intermediate language layer would be a big help here.\nTo summarize, my opinion is this; Mathematica can be used for large projects, even at present (it actually is used for at least two huge ones: it is written largely in itself, and WolframAlpha is another example. From my personal experience, a few of my projects were several thousand lines long), but your code won't scale automatically for you, and you need to be a pretty good Mathematica programmer to be able to manage the complexity of large projects. In this regard, many modern languages provide more automatic tools for scaling the code base, and more tecniques are well-known and in widespread use. I also think, that the situation with Mathematica will improve in the future, we will have better development tools, more programming practices will be shared, etc. So, yes, you definitely can use it for large projects, but right now it won't be as easy as say in Java, Python, or some other well-known languages. Much of it is not at all inherent in Mathematica per se, but reflects its young age as a general-purpose programming language used for larger projects outside academia. My two cents.\n", "front end - Customizing syntax highlighting for private cell styles": "\nAs a part of a larger sets of development tools which I am working on currently, I have developed a general syntax highlighter generator which does just that (not yet with styles though, this is coming). I wanted to put in on GitHub and do a bit more polishing / development, but since you asked the question, here goes.\nFeatures\n\nFrom a simple lexical specification, a whole package is generated, which provides code highlighting capabilities for a given language. Once you generate the package, you (supposedly) start happily using it, and don't depend on the master package (the generator), unless you want to generate another highlighter package. For those who are familiar with js Google prettify, this is similar in spirit, but less developed as of now.\nThe lexical analyzer is generated automatically from your specifications, but you can also override it with a custom one.\nYou can customize it in many ways, including colors for keywords etc.\nThere are several optimizations which can be switched on and off, to control the responsiveness of the highlighter\nkeywords etc are highlighted as you type\nBracket and paren-matching  / highlighting is supported.\nCells can be evaluatable.\n\nFor the impatient, the package and a notebook with an example for C language can be downloaded here and here. I also made a gist where one can look at them as well. The notebook can be regarded as a brief manual to the package.\nInstallation steps\n\nPlace a CodeHighlighterGenerator.m package into any directory where Mathematica can find it (e.g. FileNameJoin[{$UserBaseDirectory,\"Applications\"}])\n\nOpen the CodeHighlighterGenerator.nb notebook and follow the discussion there.\n\n\nFuture plans\nI plan to place the project to GitHub properly in a few days. There are several directions in which I plan to extend the package, it is a work in progress. All comments & suggestions are more than welcome!\n\nHere are a few screen-shots:\n\n\n", "Default position and size of front-end windows (in Windows 7)": "\n( Think out of the box? ) - Start Mathematica with a Windows macro ( any recorder will do ). First record the start of MMa and the resizing / moving of the menu bar and so on, then use the recording to start MMa.\n", "front end - How do I extract the contents of a selected cell as plain text?": "\nAssuming nb is your notebook object, then this will do what you want without touching the clipboard:\nFirst[FrontEndExecute[\n  FrontEnd`ExportPacket[NotebookSelection[nb], \"InputText\"]]]\n\nSome notes about this solution:\n\nIt preserves evaluation semantics precisely, regardless of typesetting.\nIt does not dirty the clipboard\nIf you prefer to get the appearance as opposed to the evaluation semantics, you can use \"PlainText\" (for example, grids copy as tabular looking things as opposed to as lists)\nI tested this in 8.0.1, but it might not work in earlier versions\n\nThis FE packet only supports a limited number of formats. The public formats include \"GIF\", \"PPM\", \"EnhancedMetafile\" (Windows), \"PICT\" (Mac) , \"PostScript\", \"RTF\", \"PDF\", and \"SVG\".\nI should say that the first argument of ExportPacket can also be any Notebook, Cell, or Box expression. Also, a NotebookObject, in which case it'd convert the entire notebook rather than just the selection. \nWhen the selection does not contain a full cell it is enough to work around by using the results of NotebookRead. E.g.:\nFirst[FrontEndExecute[ FrontEnd`ExportPacket[BoxData @ NotebookRead[nb], \"PPM\"]]]\n\n", "How to neatly get the sum of symmetric elements in a list?": "\nPlaying with patterns:\n{a, b, c, d, e} //. {h_, b___, t : Except[_List]} :> {h + t, {b}} // Flatten\n\nThis can be written more efficiently, without the full rescanning inherent in //., using recursion:\nf1 = # /. {h_, b___, t_} :> Prepend[f1 @ {b}, h + t] &;\n\nAlso as a DownValues definition which is a bit more efficient still:\nf2[{h_, b___, t_}] := Prepend[f2 @ {b}, h + t]\nf2[x_] := x\n\nf2 @ {a, b, c, d, e}\nf2 @ {a, b, c, d, e, f}\n\n\n{a + e, b + d, c}\n{a + f, b + e, c + d}\n\n\n\nDisregarding elegance, this is the fastest method I could come up with for packed arrays:\nModule[{ln = Length@#, x},\n  x  = #[[ ;; \u2308ln/2`\u2309 ]];\n  x += #[[ -1 ;; \u230aln/2`\u230b + 1 ;; -1 ]];\n  If[OddQ @ ln, x[[-1]] /= 2 ];\n  x\n] &\n\nI imagine it can be bested by compile-to-C in v8, but I don't have that.\n", "graphics - Background image in a polygon / CountryData": "\nThis example is from the documentation for Texture in Mathematica version 8:\nWith[{vc = \n Transpose[\n  Rescale /@ Transpose[First[CountryData[#, \"Coordinates\"]]]]}, \nShow[CountryData[#, \"Shape\"], \n ImageSize -> {{100}, {100}}] /. {RGBColor[__] :> \n  Texture[ImageReflect[Image[CountryData[#, \"Flag\"]], \n    Top -> Right]], \n Polygon[a_] :> \n  Polygon[First[a], VertexTextureCoordinates -> vc]}] & /@ \nCountryData[\"SouthAmerica\"]\n\nbut I don't know whether it does what you need. Still, it looks pretty.\n\n", "front end - Custom Mathematica Shortcut: Copy as $\\LaTeX$": "\nMenuEvaluator->Automatic uses the default kernel to evaluate the expression in the menu. MenuEvaluator->None is the default, which means that the front end \"evaluates\" the expression (which generally means the expression is composed only of FE tokens and packets). One could also use MenuEvaluator->\"kernelname\" to point to an explicit kernel.\nFor doing the kind of menu editing you wish to do, you have to rewrite the menus wholesale. You can begin by reading the menu from the layout, tweaking it how you want, and then sending it to the FE in ResetMenusPacket. Here's an example:\nBegin[\"System`\"];\nmenu = Get[\n   FileNameJoin[{$InstallationDirectory, \"SystemFiles\", \"FrontEnd\", \n     \"TextResources\", \"Windows\", \"MenuSetup.tr\"}]];\nEnd[];\nmenu = menu /. {MenuItem[\"Plain &Text\", ___] -> \n     MenuItem[\"Plain &Text\", FrontEnd`CopySpecial[\"PlainText\"]], \n    MenuItem[\"&LaTeX\", ___] -> \n     MenuItem[\"&LaTeX\", \n      KernelExecute[ToExpression[\"FrontEnd`CopyAsTeX[]\"]], \n      MenuKey[\"C\", Modifiers -> {\"Control\", \"Shift\"}], \n      MenuEvaluator -> Automatic]};\nFrontEndExecute[FrontEnd`ResetMenusPacket[menu]]\n\nSome notes about this code:\n\nA number of symbols in the menu expression aren't in the System` context, but need to be for this to work. That's the reason for the Begin/Endcalls.\nTo make this code work on Linux, replace \"Windows\" with \"X\"\nTo make this code work on Mac, replace \"Windows\" with \"Macintosh\", \"Control\" with \"Command\", and remove the ampersands.\nThis code only work on v7 and later (when MenuItem was introduced)\n\nFinally, and this is really important, you need to be playing with this stuff in a fresh session of Mathematica, and frequently either saving your work or copying to the clipboard. If you make any mistakes, you can lose all of your menus, including the ability to evaluate, save, or copy.  You might be able to recover by using the contextual menu, but probably safer to just quit and restart.\nAssuming you haven't really hosed your menus, you can reset to the default by evaluating:\nFrontEndExecute[FrontEnd`ResetMenusPacket[{Automatic}]]\n\nAnother option is to simply make your own MenuSetup.tr which is in $UserBaseDirectory or $BaseDirectory, in the same location it is now in $InstallationDirectory. But I don't generally advise this because, if you do, all copies of Mathematica will find it, including past and future versions, which could cause you hopeless confusion.\n", "list manipulation - Selecting a sublist based on Length": "\nIf you only want one item from the resulting list, you can use the two-argument form of Ordering instead of Sort to be a bit more efficient:\ntest[[Ordering[test, -1]]]\n\n\nbiglist = \n  Table[RandomInteger[10, RandomInteger[100]], {10^5}];\n\nTiming[biglist[[Ordering[biglist, -1]]]]\n\n(*\n==> {0.006476, {{10, 10, 10, 3, 4, 7, 4, 3, 9, 8, 8, 1, 2, 1, 5, \n   10, 10, 10, 9, 4, 6, 6, 9, 1, 2, 10, 8, 3, 0, 9, 1, 2, 5, 1, 1, 2, \n   7, 8, 9, 10, 8, 4, 8, 4, 7, 9, 3, 4, 5, 1, 6, 6, 4, 5, 8, 6, 3, 2, \n   6, 4, 9, 9, 9, 7, 1, 10, 4, 2, 10, 8, 0, 8, 1, 0, 9, 10, 7, 4, 5, \n   3, 6, 6, 6, 4, 2, 3, 1, 4, 9, 6, 5, 1, 8, 10, 0, 1, 3, 5, 10, 4}}}\n*)\n\nTiming[Last@Sort@biglist]\n\n(*\n==> {0.170369, {10, 10, 10, 3, 4, 7, 4, 3, 9, 8, 8, 1, 2, 1, 5, \n  10, 10, 10, 9, 4, 6, 6, 9, 1, 2, 10, 8, 3, 0, 9, 1, 2, 5, 1, 1, 2, \n  7, 8, 9, 10, 8, 4, 8, 4, 7, 9, 3, 4, 5, 1, 6, 6, 4, 5, 8, 6, 3, 2, \n  6, 4, 9, 9, 9, 7, 1, 10, 4, 2, 10, 8, 0, 8, 1, 0, 9, 10, 7, 4, 5, 3,\n   6, 6, 6, 4, 2, 3, 1, 4, 9, 6, 5, 1, 8, 10, 0, 1, 3, 5, 10, 4}}\n*)\n\n", "dynamic - How can I set the speed of manipulate play button?": "\nAnimationRate is at least one way to do this, and it can be applied on a per-control basis:\nManipulate[x, {x, 0, 10, AnimationRate -> 1/10, Appearance -> \"Open\"}]\n\nManipulate[x, {x, 0, 10, AnimationRate -> 10, Appearance -> \"Open\"}]\n\n", "Most Efficient Way to Calculate the Product of All Items in a List?": "\nThe function you're looking for is Times. Use it as Times@@list, or keeping in line with your functions,\nlistProduct[x_List] := Times @@ x\n\n", "front end - How do I view initialization (or other invisible) cells in a notebook?": "\nThe initialization cells are not necessarily invisible.\nYou can convert any cell to an initialization cell using the relevant menu item:\n\nTo find such cells in your colleague's notebook, look for brackets that look like this (this is a magnified version):\n\nThe difference from a normal input cell is the little vertical spur coming off the diagonal. I think of this as being an \"i\" for initialization.\nIf the cell really is invisible, it means that it does not have the property \"Open\" as shown in the menu above. But there should be a small bracket visible nonetheless.\nIf the cell brackets are invisible for all cells, you might need to change something in the Options Inspector (under Cell Options -> Display Options -> CellBracket Options).\n", "plotting - How do I change the Font in BarChart Legend?": "\nActually you can do it without using Map[] as Placed[] takes a third optional argument for cases like this:\nBarChart[{1, 2, 3}, ChartStyle -> \"Pastel\", \n ChartLegends -> \n  Placed[{\"John\", \"Mary\", \"Bob\"}, Bottom, Style[#, FontFamily -> \"Courier\"] &]]\n\n", "front end - How to make a parallel auto-generated .m package from Initialization cells?": "\nThis may be set from the Option Inspector (Format->Option Inspector) from this option:\n\nAutomatic automatically creates a package.\n(to be clear, you need to select Global Preferences for this to apply to all your notebooks).\n", "dynamic - How to create interrelated sliders?": "\nThis?\n{Slider[Dynamic[x], {0, 10}], \n Slider[Dynamic[2 x, Set[x, #/2] &], {0, 20}]}\n\n\nThe documentation explains, under More Information, that \"Dynamic[expr,f] makes interactive operations not change expr except by virtue of the evaluation of f[val,expr]. \". Otherwise, Mathematica attempts to assign a value to 2x.\n", "plotting - Why is ContourPlot not displaying this curve?": "\nThis has to do with the HoldAll attribute of ContourPlot. Try it with Evaluate inserted, like this:\nContourPlot[\n   SecondDegreeCurve[RandomReal[{5}, 6], x, y] // Evaluate,\n   {x, -2, 2}, {y, -2, 2}\n]\n\nyou get ouput like this:\n\nor\n\n", "undocumented - Items known by CurrentValue": "\nOther answers have already suggested ways of querying options. There's no way of systematically generating a list of all string values, but it's not too difficult to put together a list of all of the values which are used by Wolfram Research in Mathematica itself. If you look in the various files in these locations:\n\n$InstallationDirectory/SystemFiles/FrontEnd/StyleSheets\n$InstallationDirectory/SystemFiles/FrontEnd/TextResources\n$InstallationDirectory/SystemFiles/FrontEnd/SystemResources\n\nfor instances of CurrentValue, you'll get a pretty good list of what is in active use by Wolfram Research developers at any given time. Most of the undocumented string values are created specifically to fulfill a purpose required by one of these files, so that's a pretty good list.\nThere may be a few others used directly by the kernel but not anywhere in these files, but if so, not many. Any undocumented string values which are not in use by the product somewhere are likely to be untested as well, so if you're tempted to complain that this list isn't absolutely complete, be careful what you wish for.\n", "front end - Mouse gestures or keyboard shortcuts for navigating forward/backward in the documentation center": "\nAccording to the help page ref/menuitem/DocumentationCenter, the keyboard shortcuts to navigate one page backward or forward in Mathematica for OS X are \u2318 [ and \u2318 ]\n(or alternatively \u2325 \u2318 \u2190 and \u2325 \u2318 \u2192 ), so you could use a third-party app like for example MagicPrefs to bind those keys to a trackpad gesture.\nFor the sake of completeness, the corresponding shortcuts on Windows & Linux systems are Alt \u2190 and Alt \u2192 respectively.\n", "front end - How do I prevent auto loading of blank notebook at startup?": "\nIn Windows, you set InitialUntitledNotebook to False in the Global Options > PrivateFrontEndOptions section of the Option Inspector to prevent a Untitled-1 notebook opening at start-up. You can also supress/show the welcome splash screen.The combination \"ShowAtStartup\"->\"New Document\" and \"InitialUntitledNotebook\"->False\" gives just the MMA toolbar at startup.\n\n", "Function that takes another function inside": "\nThe reason you're getting that error is because you're using O, which is a built-in function to represent a term of a particular order. This has the attribute Protected, which prevents you from assigning any definition to it.\nAttributes@O\nOut[1]= {Protected, ReadProtected}\n\nHowever, to answer the question in your title, here are a few simple ways in which you can use a function inside another function:\n1: Simply call the function!\nf[x_] := x^2\ng[x_] := Sin[f[x]]\n\n\n2: Use a Module\ng[x_] := Module[{f},\n  f[y_] := y^2; Sin[f[x]]\n  ]\n\n\n3: Pass the symbol for the function\nf[x_] := x^2\ng[func_Symbol, x_] := Sin[func[x]]\n\n\n", "front end - How to change default notebook background color?": "\nYou can SetOptions for the current notebook as:\nSetOptions[EvaluationNotebook[], Background -> LightGreen]\n\nto change the background to whatever colour you like. You can also supply an RGB colour as:\nSetOptions[EvaluationNotebook[], Background -> RGBColor[0.9, 0.7, 0.7]]\n\n\nOther possibilities for the first argument of SetOptions are \n\n$FrontEnd which will change the background for all notebooks and last across restarting Mathematica.\n$FrontEndSession which will change the background for all notebooks but won't be saved if you restart Mathematica.\n\n", "syntax - Single dot textual form": "\nUse OverDot\nref/OverDot in the documentation (but one of those cases where you need to know what you want in order to be able to enter it)\nOverDot[Q]\n\n\n", "string manipulation - How to overload System`StringJoin to automatically use ToString on arguments?": "\nShort answer: because StringJoin has this little-known  behavior normally:\nStringJoin[\"abc\", {\"def\"}, \"ghi\"]\n\n(* \n  ==> \"abcdefghi\"\n*)\n\nwhile after you overloaded it, the result is \n\"abc{def}ghi\"\n\nLong answer\nYou start by using \nTrace[Append[test, 1], TraceInternal -> True]\n\nfrom the Trace output, you can locate the following code:\nStringJoin[(If[ListQ[#1], StringJoin[\"\\[NoBreak]\", #1, \"\\[NoBreak]\"],  #1] & ) /@ \n   StringSplit[\n       \"Nonatomic expression expected at position `1` in `2`.\", \n        System`Dump`del : \"`\" ~~ DigitCharacter ... ~~ \"`\" :> \n           {System`Dump`del}]\n]\n\nreturning\n\"Nonatomic expression expected at position \\[NoBreak]{`}\\[NoBreak] in \\[NoBreak]{`}\\[NoBreak].\"\n\nAnalyzing this code leads to the short answer above.\nConclusions\nDon't overload built-ins globally. Who knows what else you will break? There are other options to do what you want. For example, you can use Internal`InheritedBlock to create local environments, as explained e.g. here.\n", "plotting - Removing unwanted appearance of underlying mesh": "\nYou are combining the images in the form \nShow[Graphics[simplePrimitives], complicatedRegionPlot]\n\nThe options in the resulting figure are inherited from the first term, namely Graphics[simplePrimitives].  This does not include the \"TransparentPolygonMesh\" -> True generated by RegionPlot.  You see the mesh as a result.  If you combine things as follows:\nShow[complicatedRegionPlot, Graphics[simplePrimitives]]\n\nThen the resulting image will have the standard RegionPlot options and you'll no longer see the mesh.\nI think the preferred way to do this, however, is to use Epilog, as in J.M.'s response.\n", "export - Reading from a text file and store the results back into it": "\nI'm new to Mathematica too, and finding some of it quite difficult, etc. However, the Import and Export commands seem to be pretty useful and simple for simple tasks.\nTo import a text file of numbers, one to a line, you basically do this:\naList = Import[\"test,dat\", \"Table\"]\n\nwhere the Table option reads the file into a list of lists, where each line is a list. So you might end up with something like this:\n{{42}, {142857}, {6}, {12}}\n\nThis is then easy to operate on. Mathematica has functions for nearly everything, and lists are about the best thing to put your data in, so you can just write your own wrapper function:\nnumberToBinary[n_] :=  IntegerString[n, 2, 24];\n\nFinally, you can export the numbers and convert them all in one go, by mapping this function over the list you created earlier:\nExport[\"test1.dat\", numberToBinary[#] &  /@ aList, \"Table\"]\n\nand the file might well contain this:\n000000000000000000101010\n000000100010111000001001\n000000000000000000000110\n000000000000000000001100\n\nIt's true that things are rarely as simple as this, but it's a start... (And performance for 100,000 numbers might be important, I didn't check.)\n", "graphics - Plotting several functions": "\nMesh will do the trick:\nPlot3D[Sin[x^2 - y], {x, -2, 2}, {y, -3, 3}, MeshFunctions -> {#2 &}, \n PlotStyle -> None, Mesh -> 30]\n\n\nPlacing the \u201cwires\u201d on integer values is also easy \u2013 see example below. For the range {y, -7, 5} there are 13 integers so you need to ask for 11 wires Mesh -> 11 (in red) because 2 are taken by boundary (blue). With such settings \"wires\" fall exactly on integer values.\nPlot3D[Sin[x^2 - y/2], {x, -2, 2}, {y, -7, 5}, MeshFunctions -> {#2 &}, \nPlotStyle -> None, Mesh -> 11, MeshStyle -> {Thick, Red}, \nBoundaryStyle -> {Thick, Blue}]\n\n\n", "export - Is Compress[] compatible between different Mathematica versions?": "\nCompress[expr] will take an expression, convert it to a string, using some form, which would allows to recover the expression later on (most likely InputForm is used) and compress the string. \nIf the resulting compressed expression is uncompressed in an earlier version of Mathematica, the result is going to be an expression, which has no code associated with it, so it will, most likely, just remain unevaluated, if executed. \nTo reiterate, yes, Compress/Uncompress is cross version compatible, yet the result obtained on uncompressing, may not evaluate in earlier versions of Mathematica\n", "performance tuning - How are MemberQ and FreeQ so fast?": "\nWhat you observed seems to be an instance of the general behavior of the pattern-matcher when used with what I call \"syntactic patterns\" - patterns which only reflect the rigid structure of an expression, like e.g. _f. The speed-up with respect to the scanning is because the main evaluation loop is avoided - for FreeQ and MemberQ, the scannng is done all inside the pattern-matcher, which is lower-level compared to the main evaluator. \nIn this answer, and also here, there are some examples of this behavior, and further discussion. I think that a good rule of thumb is that you gain an order and a half of magnitude speed-up by clever use of syntactic patterns in place of top-level scanning code (pushing all work into the pattern-matcher), and you gain 2-3 orders of magnitude speed-up if you manage to recast the problem as a vectorized numerical problem on packed arrays.\n", "output formatting - Show path with arrows in a matrix": "\nMathematica's Graph related functionality is pretty great. You can easily style vertexes, edges and their labels, apply interesting functions. For small increase in code sophistication you gain quite a bit of advantage. Your data:\npoli = {{1, 1}, {2, 1}, {3, 1}, {4, 1}, {5, 1}, {5, 2}, {4, 2}, {3, \n    2}, {2, 2}, {1, 2}, {1, 3}, {2, 3}, {3, 3}, {4, 3}, {5, 3}, {5, \n    4}, {4, 4}, {4, 5}, {5, 5}};\n\nA simple solution with still quite wide styling options I think would be this\narrow[coord_, e_] := Style[Arrow[coord], Red, Thickness[.01], Arrowheads[0.06]]\n\npg = PathGraph[Range[19], VertexCoordinates -> poli, \nEdgeShapeFunction -> arrow, ImageSize -> 300, PlotRangePadding -> .2];\n\ngg = GridGraph[{5, 5}, EdgeStyle -> Dashed, VertexLabels -> \"Name\", \nImageSize -> 300, PlotRangePadding -> .2];\n\nOverlay[{gg, pg}]\n\n\nThe rest is some more elaborate exploratory fun with graphs.\nWe'll use GridGraph again but instead of PathGraph we'll use GraphHighlight option. GridGraph has its own 1D node index system (see indexes above), not 2D indexes as in matrix. So we have to remap the indexes.\nvertex = (5 (#[[1]] - 1) + #[[2]]) & /@ poli;\n\nedge = ( #[[1]] \\[UndirectedEdge] #[[2]]) & /@ Partition[vertex, 2, 1];\n\nTo add correct labels:\nlab = MapThread[Rule[#1, ToString@#2] &, {vertex, poli}];\n\nGridGraph[{5, 5}, EdgeStyle -> Dashed, GraphHighlight -> edge, \n VertexLabels -> lab, PlotRangePadding -> .3]\n\n\nIf you want arrows there are many ways around, especially depending on how you choose the path. Quick cooking gives something like this:\narr[coord_, e_] := \n Style[Arrow[\n   If[Positive[(e)[[2]] - (e)[[1]]], Identity[coord], \n    Reverse[coord]]], Red, Thickness[.01], Arrowheads[0.06]]\n\nGridGraph[{5, 5}, EdgeStyle -> Dashed, GraphHighlight -> edge, \n VertexLabels -> lab, PlotRangePadding -> .5, \n EdgeShapeFunction -> (# -> arr & /@ edge)]\n\n\n", "front end - What is this character: [esc][comma][esc]?": "\nIt's what's called an \\[InvisibleComma]. It's useful for those times where you don't want a comma to appear, but you still need it, e.g. \"a[[p\\[InvisibleComma]q]]\" for a matrix entry.\n\nThe third entry uses an \\[InvisibleComma] in between the matrix indices.\n", "Is it possible to prerender animation in Wolfram Mathematica?": "\nHere is an example of how to create an animation from DensitPlot results. I have chosen a simple Gaussian function to plot, but its center depends on a parameter t. Now I create a table of plots for many different values of t, and then I take several different steps to create various kinds of movies from it. The parameter t and its step size is going to be the main variable that you have to decide on depending on your application, in order to make a smooth animation. \nNote on speed\nTo save time, you should execute the following commands in separate cells, and only choose the export or display method that you need. Otherwise the evaluation will probably stretch your patience.\nexampleFrames =\n  Table[\n   DensityPlot[\n    Evaluate[\n     Exp[-((x - Cos[t])^2 + (y - Sin[t])^2)/.025]\n     ],\n    {x, -1.5, 1.5}, {y, -1.5, 1.5},\n    ColorFunction -> GrayLevel,\n    PlotRange -> All,\n    PlotPoints -> 30,\n    Frame -> None,\n    PlotRangePadding -> None\n    ],\n   {t, Pi/50, 2 Pi, Pi/50}\n   ];\n\nrasterizedFrames = Map[Image, exampleFrames];\n\nExport[\"movie.mov\", exampleFrames];\n\nExport[\"movie.avi\", exampleFrames];\n\nListAnimate[rasterizedFrames]\n\nWhat I did above is to first rasterize the individual frames before making the ListAnimate. \nUpdate: thanks to Alexey Popkov for reminding me that Image can be used instead of Rasterize to perform the rasterization more efficiently.\nWorking with rasterizedFrames speeds up the ListAnimate process. This is especially noticeable if your movie has 3D graphics as frames. Rasterization allows you in principle to customize the quality of the video frames. For the export as .mov and .avi, though, it seems to be faster to not use the pre-rasterized frames and instead start from the original exampleFrames. \nIf you want the movie in Flash format, do this:\nExport[\"movie.swf\", rasterizedFrames];\n\nIn the Flash file, rasterization leads to a smaller file size but the export takes longer for this format.\nEdit\nThanks to @halirutan for pointing out that Rasterize gets much faster when replacing the above instruction by:\nrasterizedFrames = Map[Rasterize[#,\"Image\"]&, exampleFrames];\n\nUpdate In Mathematica version 9, though, I see no speed difference with our without the \"Image\" argument.\nListAnimate is the easiest way to create animations in Mathematica, but it can sometimes by so horribly slow that the notebook becomes unresponsive. This may happen if you have many frames with complicated plots. \nThat's why I also included some Export commands that generate movies in standard formats that can be read by other applications (media players). The file movie.mov should be a Quicktime movie, and movie.swf is a Flash animation. \nFinally, depending on your operating system, it may in fact be best to create the movie in an external application. In that case, you can do the following:\nExport[\"movie001.png\", exampleFrames, \"VideoFrames\"];\n\nThis will create all the frames as individual files numbered movie001.png, movie002.png, etc. These can subsequently assembled in a movie editor. \nIf you want to go that route, that's a different topic that I have discussed some more on the following page:\nMathematica image sequence export\n", "programming - Threading a compiled function over multiple arguments of different lengths": "\nI think your problem is equivalent to trying to get something like this\nl := Power[2, 2]\n\nf /@ l\n\nreturn f[2]^f[2] instead of 4\nYou can control argument evaluation in MMA, for it to be either evaluated or not evaluated, but not half evaluated. If you wanted that you would have to either redesign your variables, or use things like replacement rules of OwnValues/DownValuess\nIn your case, you are expecting ppost1 to evaluate to fc, but fc not try to evaluate its arguments (until Thread had a chance to act)\nIf someone understood better than I did what your goal is, perhaps he can help you do it in some way\nEDIT\nPerhaps what you're looking for then can be achieved by masking the compiled function with a function that knows how to stay symbolically unevaluated\nWith[{cmp = \n   Compile[{{arg, _Real, 1}, {c1, _Real, \n      1}, {c2, _Real}, {c3, _Real}}, c3*arg + c2*c1]},\n fc[arg : {___Real}, c1 : {___Real}, c2_Real, c3_Real] :=\n  cmp[arg, c1, c2, c3]\n ]\n\n", "combinatorics - Probability problem -- Rube Goldberg solution?": "\nDon't even know how I came across this old question, but, interesting and seeing as Mr. W asked it, it piqued my interest.\nThe answer by David is a good use of simulation, and his \"back-o-the-envelope\" approximation using the probability functions of Mathematica over a discrete uniform is also kind of neat.\nThe other two answers, however are flat-out wrong: Both admit hand sets that are impossible, e.g., looking at the first entry of allPossibilities from Rojo's answer shows an entry of {{1, 1}, {1, 1}, {1, 1}}. I don't know about you, but \"a standard 52 card deck\" with six aces would get you shot in the old west...\nIn addition, counting winning hands via tuples/etc. and getting a ratio of winning to total hands is not correct (although by happenstance, it gets pretty close): take, e.g., the hand sets {{4, 4}, {3, 3}, {3, 3}} vs  {{6, 5}, {4, 3}, {2, 1}}. In both, the \"first\" hand wins. But the second set is over 14X more likely to occur. So any tuple-counting/filtering approach must calculate the probabilities of each winning set and total them...\nSo, why not solve it directly and exactly?\n(* bulid lists of possible ways to take from ranks of deck in two draws, pairs and singlets *)\n\ntwo = Permutations[Prepend[ConstantArray[0, 12], 2]];\none = Permutations[Join[{1, 1}, ConstantArray[0, 11]]];\ntt = Tr /@ (two*Range@13);\noo = Tr /@ (Range@13*# & /@ one);\nways = Sort@Join[Transpose[{oo, one}], Transpose[{tt, two}]];\n\n(* helper functions - get p of a draw sum given current deck configuration,\n   and p of draw sums less than given sum *)\npe[n_, db_] := With[{c = Select[ways, #[[1]] == n &]},\n  Module[{z = #, r}, \n     If[FreeQ[r = db - z, _?Negative], {PDF[\n        MultivariateHypergeometricDistribution[2, db], z], r}, {0, r}]] & /@ c[[All, 2]]]\n\nple[n_, db_] := With[{c = Select[ways, #[[1]] < n &]},\n  Module[{z = #, r}, \n     If[FreeQ[r = db - z, _?Negative], {PDF[\n        MultivariateHypergeometricDistribution[2, db], z], r}, {0, r}]] & /@ c[[All, 2]]]\n\n\n(* get probabilities of paths for given sum and remaining 2 players both having less *)\nMonitor[res = Table[{n,\n     peres = pe[n, ConstantArray[4, 13]];\n     secondres = Map[ple[n, #] &, peres[[All, 2]]];\n     step3 = Transpose[{secondres[[All, All, 1]]*peres[[All, 1]], secondres[[All, All, 2]]}];\n     step4 = Map[With[{c = #}, Map[ple[n, #] &, c]] &, step3[[All, 2]]];\n     Total[Total /@ Map[Total, step3[[All, 1]]*step4[[All, All, All, 1]], {2}]]\n     }, {n, 2, 26}], n];\n\n(* final probability of a player winning *)\n\nres[[All, 2]] // Total\n% // N\n\n(*\n4710593/15268890\n0.308509\n*)\n\nAnd some graphical results (a priori probability of holding some sum, probability of sum given you won, and probability of winning given you are holding some sum):\n\n", "java - Why does JLink lock unopened jar-files in Windows": "\nI also encountered this problem. Not an authoritative answer, but here is one blind guess to what is happening. JLink has its own classloader, JLinkClassLoader.java, which calls another one, JLinkClassLoaderHelper.java. The latter is a sub-class of URLClassLoader.java. Both are used in the class JLinkSystemClassLoader.java. The second part of this story is that there is an unresolved bug in the JVM related to URLClassLoader.java class, which locks jars, on Windows only. It has been discussed on SO here. The problem seems to be Windows-specific. What I don't know is at what time this happens, and why this affects jars that weren't even used. If this is at all a right guess, this can probably be traced by using a debugger.\n", "front end - Syntax highlighting for your own functions": "\nWhat you want is SyntaxInformation. With this, you can use every highlighting which already exists for things like Table, Solve, etc. for your own functions. You can specify the pattern of the arguments. With this you get the typical red commas if you use too many parameters. Or you can highlight locally used variables inside the function-arguments:\nSetAttributes[SequenceVars, HoldAll]\nSyntaxInformation[SequenceVars] = {\"ArgumentsPattern\" -> {_, _}, \n   \"LocalVariables\" -> {\"Solve\", {1, 1}}};\nSequenceVars[vars_List, expr_] := \n Block[vars, vars = Range@Length@vars; expr]\n\nIt looks like this in the front-end:\n\nThe usage of the \"LocalVariables\" highlighting is as follows. First, you choose the general type of highlighting. For instance \"Solve\" provides simple x or lists like {a,b} while \"Plot\" provides highlighting for the first element in e.g. {a,1,2}.\nYou can use the following settings as templates\n{\"Table\", \"Solve\", \"Integrate\", \"Limit\", \"Plot\", \"Manipulate\"}\n\nAdditionally, you need to specify at which places of your function call the local variable specifications can appear. Say you want a function where in the first argument is some expression and then can follow arbitrary many lists of local variables. The definition for that would look like\nSyntaxInformation[f] = {\"ArgumentPattern\" -> {_, __},\n  \"LocalVariables\" -> {\"Solve\", {2, Infinity}}}\n\nThis looks then like\n\n\n\nand should make clear how \"LocalVariables\" has to be used.\nUpdate\nSince this function seems to be of unexpected interest, I should add one more important thing: SyntaxInformation can highlight wrong options. If you use OptionsPattern in your \"ArgumentsPattern\" option, all non-existent options will be highlighted in red\nOptions[f] = {a -> 1, b -> True};\nf[x_] = Identity;\nSyntaxInformation[f] = {\"ArgumentsPattern\" -> {_, OptionsPattern[]}};\n\nNow using f with right/wrong options gives\n\n", "mathlink or wstp - Suppress Mathematica Kernel taskbar tab when using .NETLink": "\nThe command line option to call the kernel with to suppress the taskbar button is -noicon.  You need to pass this flag to MathKernel.exe when launching it.\nHere's a demonstration from within Mathematica:\nkernel = LinkLaunch[First[$CommandLine] <> \" -mathlink -noicon\"]\n\nThis will launch a new kernel and connect to it.  On Windows, the new kernel will not show on the taskbar.\nI do not remember where I learned about this command line flag.  It took me quite a few minutes to be able to recall it at all.\n", "databaselink - Stealth daylight saving shift in SQL data": "\nDatabaseLink uses Java Database Connectivity (JDBC) internally.  The behaviour you describe is a known, long-standing, and annoying bug in JDBC.  The problem is that Java inappropriately attempts to apply daylight savings time adjustments to dates in the database -- even though such adjustments are likely to have taken place already.  This bug occurs even if the server and client machines are configured to be in the same time zone.  There is no easy workaround to this problem as long as the class java.sql.Date (et al) is in the loop.  Non-trivial workarounds involve things such as trying to configure the entire database stack to use UTC.  Also, some JDBC drivers provide alternate data-type mapping for date/time types.\nHowever, the simplest workaround is to change your SQL statements to return dates as strings.  This side-steps all of the JDBC date arithmetic nightmare.  In most dialects of SQL, this means changing:\nSELECT ... myDate ...\n\nto something like\nSELECT ... CAST(myDate AS VARCHAR) ...\n\nUnfortunately, the exact syntax is not standardized so you will have to look it up for your dialect of SQL.\nIn SQL Server, for example, we have a couple of options:\nSELECT CAST(GETDATE() AS VARCHAR)\n\nreturns a localized string like \"Feb  7 2012  8:56PM\".  Mathematica has no trouble interpreting this:\n\"Feb  7 2012  8:56PM\" // AbsoluteTime // DateString\n(* Tue 7 Feb 2012 20:56:00 *)\n\nHowever, we might want to take out the vagaries of localization by converting dates to a fixed format instead.  Again, using SQL Server as an example:\nSELECT CONVERT(VARCHAR, GETDATE(), 121)\n\nreturns an ISO-like date string: \"2012-02-07 20:56:32.733\".  Again, you will have to adjust the syntax to suit your specific dialect of SQL.\n", "front end - How to set focus of a dialog window?": "\nAfter Istv\u00e1n Zachar's points, I was investigating Input definitions to learn more. It seams that 2 years later WRI changed approach from SelectionMove based to more automatic BoxReferenceFind.\nusage\nSo what we only have to do is to set BoxID option for fields of interest and find those references when we want, with:\nMathLink`CallFrontEnd[\n FrontEnd`BoxReferenceFind[ \n   FE`BoxReference[\n     _NotebookObject, {{ID_String}}, \n     FE`BoxOffset -> {FE`BoxChild[1]},   \n     FE`SearchStart -> \"StartFromBeginning\"\n   ]\n ]\n]\n\nThis is a way more flexible approach, e.g. you can easily put InputField somewhere else and you don't have to change SelectionMove steps to get there.\nexample\nDynamicModule[{name = \"\", surname = \"\", setFocus}\n  , Column[{\n        InputField[Dynamic@name, String, BoxID -> \"name\"]\n      , InputField[Dynamic@surname, String, BoxID -> \"surname\"]\n      , Button[\"setFocusToFirst\", setFocus[EvaluationNotebook[], \"name\"]]\n    }]\n  , SynchronousInitialization -> False\n  , Initialization :> (\n        setFocus[nb_, ID_] :=  MathLink`CallFrontEnd[\n            FrontEnd`BoxReferenceFind[ FE`BoxReference[\n                nb\n              , {{ID}}\n              , FE`BoxOffset -> {FE`BoxChild[1]}\n              , FE`SearchStart -> \"StartFromBeginning\"\n            ]]\n        ]\n      ; setFocus[EvaluationNotebook[], \"surname\"]\n    )\n]\n\n", "graphics - How do you draw the plane on which two vectors lie?": "\nSeedRandom[3];\n{v1, v2} = RandomReal[{-2, 2}, {2, 3}];\nn = Cross[v1, v2];\nShow[{\n  ContourPlot3D[n.{x, y, z} == 0, {x, -2, 2}, {y, -2, 2}, {z, -2, 2},\n    ContourStyle -> Opacity[0.5], Mesh -> False],\n  Graphics3D[{Arrow[{{0, 0, 0}, v1}], Arrow[{{0, 0, 0}, v2}]}]\n}]\n\n\n", "databaselink - What is the quickest way to convert a lot of SQLDateTime[] objects to DateLists": "\nThe fastest way should be to use Part I think, particularly as your list gets larger.\ndata={{SQLDateTime[{2005, 10, 3}], 188.88}, {SQLDateTime[{2005, 10, 4}], \n184.53}, {SQLDateTime[{2005, 10, 5}], \n176.5}, {SQLDateTime[{2005, 10, 6}], \n172.}, {SQLDateTime[{2005, 10, 7}] . . . etc}\n\nFor example\ndata[[All, 1]] = data[[All, 1, 1]]\n\nleaves you with\ndata\n\n{{{2005, 10, 3}, 188.88}, {{2005, 10, 4},184.53}, {{2005, 10, 5}, \n    176.5}, {{2005, 10, 6},172.}, {{2005, 10, 7} . . . etc}\n\nThis is another way but probably slower:\ndata /. SQLDateTime -> Identity\n\nTimings\nUsing kgulers data generator with a list of 10000 elements:\nClearSystemCache[];\nTiming[tmp1 = data /. SQLDateTime[x_] :> DateList[x];]\n{0.469574, Null}\n\nClearSystemCache[];\nTiming[tmp2 = data /. SQLDateTime[x_] :> x;]\n{0.024052, Null}\n\nClearSystemCache[];\nTiming[tmp3 = Map[{#[[1]][[1]], #[[2]]} &, data];]\n{0.043545, Null}\n\nClearSystemCache[];\nTiming[tmp4 = data /. SQLDateTime -> Identity;]\n{0.060517, Null}\n\nClearSystemCache[];\nTiming[data[[All, 1]] = data[[All, 1, 1]];]\n{0.006412, Null}\n\ntmp1 == tmp2 == tmp3 == tmp4 == data\nTrue\n\nPart is the fastest.\nEdit\nI'm not sure why you would actually do SQLDateTime[x_] :> DateList[x], the \"x\" is already a date list. SQLDateTime[x_]->x is sufficient. ...but since Part is faster I guess the discussion is redundant.\n", "graphics - How do I draw a triangle given the lengths of the sides?": "\n\nI'm not sure how to draw a triangle if all I care about is the length of the sides. (I'm happy to place one of the vertices at the origin and place one of the sides on the nonnegative side of the $x$-axis, but that doesn't really matter.) Is there a straightforward way?\n\nGiven a triangle with side lengths $p \\leq q \\leq r$ (assuming the lengths satisfy the triangle inequality, of course), with hypotenuse on the positive $x$-axis, and the origin as one endpoint, you can solve a system of equations to get the third point, apart from $(0,0)$ and $(r,0)$:\nFullSimplify[{x, y} /. \n             Last[Solve[{x^2 + y^2 == p^2, (x - r)^2 + y^2 == q^2}, {x, y}]]]\n{(p^2 - q^2 + r^2)/(2 r),\n Sqrt[-(p - q - r) (p + q - r) (p - q + r) (p + q + r)]/(2 r)}\n\nand thus, either of \nGraphics[Line[{{0, 0}, {r, 0}, {(p^2 - q^2 + r^2)/(2 r),\n         Sqrt[-(p - q - r) (p + q - r) (p - q + r) (p + q + r)]/(2 r)}, {0, 0}}]]\n\nor\nGraphics[Polygon[{{0, 0}, {r, 0}, {(p^2 - q^2 + r^2)/(2 r),\n         Sqrt[-(p - q - r) (p + q - r) (p - q + r) (p + q + r)]/(2 r)}}]]\n\ndoes the job.\nVerify the triangle:\nFullSimplify[\n Norm /@ Differences[{{0, 0}, {r, 0}, {(p^2 - q^2 + r^2)/(2 r), \n     Sqrt[-(p - q - r) (p + q - r) (p - q + r) (p + q + \n          r)]/(2 r)}, {0, 0}}], 0 <= p <= q <= r && p + q >= r]\n{r, q, p}\n\n\n\nThis raises the additional question, \"how do I draw a triangle in Mathematica, given three angles?\". (Say I want to it to reside somewhere in the unit circle.)\n\nThe law of sines saves your bacon here (the ratio of a side length and the sine of the opposite angle gives the diameter of the triangle's circumcircle). Skipping details, here's how to inscribe a triangle with specified angles into the unit circle:\nparts = IntegerPartitions[180, {3}];\n\n(* generate corresponding sides from randomly chosen angles *)\nangles = parts[[RandomInteger[{1, Length[parts]}]]];\n{r, q, p} = 2 Sin[angles Degree];\n\nGraphics[{Line[{{1, 0}, {1 - p^2/2, p Sqrt[1 - p^2/4]},\n                {1 - q^2/2, -q Sqrt[1 - q^2/4]}, {1, 0}}], \n          Circle[{0, 0}, 1]}]\n\nYou can use the next two snippets to verify that the triangle generated fits the specifications:\n(* check side lengths *)\nNorm /@ RotateLeft[Differences[\n     N[{{1, 0}, {1 - p^2/2, p Sqrt[1 - p^2/4]},\n        {1 - q^2/2, -q Sqrt[1 - q^2/4]}, {1, 0}}]]] - {r, q, p} // Chop\n\n(* check angles *)\n(Apply[VectorAngle, Map[Function[pt, pt - First[#]], Rest[#]]]/Degree) & /@ \n   NestList[RotateLeft, N[{{1, 0}, {1 - p^2/2, p Sqrt[1 - p^2/4]},\n       {1 - q^2/2, -q Sqrt[1 - q^2/4]}}], 2] - angles // Chop\n\nBoth snippets should return {0, 0, 0} if all goes well.\n", "evaluation - Implementing a safe ValueQ that does not evaluate its argument": "\nPreamble\nThis has been discussed before, and this problem was also identified and partially addressed in the same question. I will use a slightly simpler implementation which also covers UpValues. It is probably not complete either, but it covers many common cases of interest. \nImplementation\nHere is the code:\nClearAll[symbolicHead];\nSetAttributes[symbolicHead, HoldAllComplete];\nsymbolicHead[f_Symbol[___]] := f;\nsymbolicHead[f_[___]] := symbolicHead[f];\nsymbolicHead[f_] := Head[Unevaluated[f]];\n\nClearAll[valueQ];\nSetAttributes[valueQ, HoldAllComplete];\nvalueQ[a_Symbol] /; OwnValues[a] =!= {} :=\n    With[{result = (# =!= (# /. OwnValues[a])) &[HoldComplete[a]]},\n       result /; result];\n\nvalueQ[a : f_Symbol[___]] /; DownValues[f] =!= {} :=\n    With[{result = (# =!= (# /. DownValues[f])) &@HoldComplete[a]},\n       result /; result];\n\nvalueQ[a_] :=\n    With[{sub = SubValues[Evaluate[symbolicHead[a]]]},\n      With[{result  = (# =!= (# /. sub)) &[HoldComplete[a]]},\n          result /; result] /; sub =!= {}\n    ];\n\nvalueQ[a_] :=\n   With[{upsyms  =\n       Flatten@Cases[Unevaluated[a], s_Symbol :> UpValues[s], 1, Heads -> True]},\n          With[{result  = (# =!= (# /. upsyms)) &[HoldComplete[a]]},\n             result /; result] /; upsyms =!= {}\n   ];\n\nvalueQ[_] := False;\n\nSymbolic heads are further discussed in this answer. The order of definitions is important, and roughly corresponds to the order of steps applying those global rules,  in the main evaluation sequence.\nExamples\na := Print[\"*\"];\nb[1] := Print[\"*\"];\nc[1][4] := Print[\"*\"];\nd /: f[x_Integer, d, y_Integer] := Print[\"*\"];\n\nvalueQ /@ Unevaluated[{a, b[1], c[1][4], f[1, d, 2]}]\n\n(*\n  ==> {True, True, True, True}\n*)\n\nLimitations\nI did not include the NValues (this can be done, but the question is whether we really want to do that). This seems to pretty much exhaust the set of things we can do without really evaluating an expression in question. In certain cases, the results will be different from ValueQ, for example:\n{valueQ[N[Pi]],ValueQ[N[Pi]]}\n\n(*\n  ==> {False,True}\n*)\n\nSummary\nThe code above was not meant to be absolutely complete, and probably can not be, since not everything is exposed to the top-level / end user. But it is hoped that it covers many cases of interest, and can be further extended to cover some that it misses currently. Note that, since internal global rules are not available at the top-level, valueQ is mostly limited to user-defined or top-level functions and variables. If one wants to include system symbols with internal rules, I don't see other ways than allowing the expression to evaluate. \nThis may also explain (to some extent), why built-in ValueQ was written the way it was - to also cover the system symbols and be general. On a deeper level, this seems to reflect that the separation between internal and top-level rules is rather artificial and sometimes flies in the face of the core language semantics, particularly when one wants to write some general functions related to introspection, such as ValueQ.\n", "graphics - How to fix the orientation and scaling of Graphics3D?": "\nHave you tried setting PlotRange->10 ?\n", "symbols - How to unload automatically loaded packages?": "\nIf you want to revert the entire system to some state, then CleanSlate` may be the best option. If you want to unload a few specific packages though, you can use my package PackageManipulations`, available here. It has a function PackageRemove, which does exactly that. It has an accompanying notebook with explanations. Some additional notes on it are in this and this answers. If you want to just clear all the package and sub/package symbols but not Remove them, you can use functions PackageClear and PackageClearComplete from the same package (a disclaimer : the package may contain bugs, although I used it successfully many times)\nNote that removing all symbols in the package (and subsequently removing its context) - which is what PackageRemove does and what you seem to ask for - may be unsafe if other packages use some of those symbols, since those symbols in the definitions of symbols in dependent packages would turn to Removed[symbs] and won't be usable any more, in a sutble way. To check that there are no such dependencies, you can use another package I wrote, PackageSymbolsDependencies`, available from the same place (it also has a notebook with explanations and examples).\n", "evaluation - How to determine how much of a table is generated?": "\nGiven your current situation, there is another option that might help if you have set \"Enable notebook history tracking\" in Preferences > Advanced:\n\nThen, you go to Cell > Notebook history and navigate to your currently evaluating cell and look at the time stamp when you last edited it. Chances are that you edited it just prior to evaluating (note that if you open an old notebook and execute the cell right away, this might not work, because the last edit timestamp will not be what you want it to be).\n\nNow find the current time from your system clock. Assuming you know how long it takes for one evaluation of SuperSlowExpression, you can now simply do:\n$$\\mathrm{approx\\ progress=\\frac{current\\ time - last\\ edited\\ time}{time\\ for\\ one\\ evaluation}}$$\nThis will give you a rough estimate of the progress \u2014 enough to make a decision whether to wait a bit longer or to give up. \nRemember, this should be a last ditch option! There are many ifs and buts here, but seeing as all the other options require an iterator and you don't have one (and your Table is running), it's worth trying...\n", "performance tuning - How can I speed up image importing?": "\nThe cause of the slow speed is the presence of a modified System` function: StringJoin. As this modified StringJoin operates at suboptimal speed (see Leonid's answer and comments here), there is a performance drop of 1-2 magnitudes. So I did learn the hard way why is it a bad idea to modify built-in symbols.\n", "Is there a syntax for single-line comments for notebooks?": "\nThere is no way to comment out a single line.\nMathematica doesn't really respect lines, it pushes working at the expression level when possible (not at the source text level).  Converting cells between different forms (StandardForm, InputForm) will even shuffle around newlines.  Copying and pasting code does the same.\nAs @acl has mentioned, you can select a piece of code and comment it out with Alt-/.  The shortcut Ctrl-. makes it easy to select subparts of expressions.  These commands are found in the Edit menu (mentioning in case the keyboard shortcut is different on other platforms).\nI am not advocating this behaviour, just explaining the current situation.\n", "linear algebra - Obtaining the square-root of a general positive definite matrix": "\nAre all of the Fs real? If so, try this:\nAssuming[{F11, F12, F13, F21, F22, F24, F33, F35, F44, F45, F53, F54, \n   F55} \\[Element] Reals, MatrixPower[Ftemp, 1/2]]\n\nYou'll get an answer, but it'll be ugly...\nYou can use Position to test for zero elements like this (in this case I'm applying it to your original matrix to show that it works):\nPosition[Ftemp,x_/;PossibleZeroQ[x]]\n{{1, 4}, {1, 5}, {2, 3}, {2, 4}, {2, 5}, {3, 2}, {3, 4}, {4, 1}, {4, \n  2}, {4, 3}, {5, 1}, {5, 2}}\n\nSo for the matrix you're interested in:\nFtempInv = Assuming[{F11, F12, F13, F21, F22, F24, F33, F35, F44, F45, F53, \n     F54, F55} \\[Element] Reals, MatrixPower[Ftemp, 1/2]];\nPosition[FtempInv,x_/;PossibleZeroQ[x]]\n\nUnfortunately, when I do that MMA spends a great deal of time thinking and I have yet to see an answer. There may be better test to use here than PossibleZeroQ; if so, I'm sure someone else will suggest one.\nIt turns out that PossibleZeroQ is Listable, so you can you just do\nPossibleZeroQ[FtempInv]\n\nBut that doesn't solve the speed problem...\nI let PossibleZeroQ[FtempInv] run for a while. Here's what I got:\n{{False, False, False, False, False}, {False, False, False, False, \n  False}, {False, False, False, False, False}, {False, False, False, \n  False, False}, {False, False, False, False, False}}\n", "graphics - Export a Row or Column as an image": "\nI'd do this, probably\nExport[\n \"~/Desktop/out.png\",\n GraphicsGrid[\n  {\n   {Graphics@Disk[], Graphics@Rectangle[]}, {Graphics@Rectangle[], \n    Graphics@Disk[]}\n   },\n  ImageSize -> 800\n  ]\n ]\n\n", "graphics - Take off {} using Position []": "\nYou can add a parameter to Position so it returns only one result and apply First or Partas needed\nsubIDs = {\"AK6\", \"CF11\", \"CL4\", \"FC21\", \"MK5\"};\n\nsubColors = {LightOrange, LightBlue, LightYellow, LightGreen, LightRed}\n\nGraphics[{subColors[[Position[subIDs, #, 3, 1][[1, 1]]]], \n    Rectangle[]}] & /@ subIDs\n\nFurthermore, you could also use Extract that's more suited to Position's output\nsubIDs = {\"AK6\", \"CF11\", \"CL4\", \"FC21\", \"MK5\"};\n\nsubColors = {LightOrange, LightBlue, LightYellow, LightGreen, LightRed}\n\nGraphics[{First@Extract[subColors, Position[subIDs, #, 3, 1]], \n    Rectangle[]}] & /@ subIDs\n\n", "numerics - How to apply restrictions to the \"integrated\" variable, when using NDSolve?": "\nYou could do something like this which is inspired by the bouncing ball example in the tutorial on the \"EventLocator\" Method: \ng[x_] := Floor[x]\n\nh[x0_, x1_] := Function[{t}, Evaluate@Module[{f},\n    Reap[NestWhile[\n       Module[{sol, xend},\n         sol = First@NDSolve[{f'[x] == 1/2 + g[x] - f[x], \n           f[#] == g[# + .0001]}, f, {x, #, x1},\n         Method -> {\"EventLocator\", \"Event\" -> (f[x] <= g[x])}];\n           xend = sol[[1, 2, 1, 1, -1]];\n           Sow[{f[t] /. sol, # < t < xend}];\n         xend] &, \n       x0, (# < x1) &],\n    _, Piecewise[#2] &][[2, 1]]\n]]\n\nThe basic idea is to run NDSolve until f[x] drops below some critical function g[x], calculate a new initial value for f, continue the calculation starting from the position where NDSolve stopped until f[x] drops below g[x] again, etc. until a final time x1 is reached. The solution for this example looks like\nsol = h[0, 10];\nPlot[{sol[x], g[x]}, {x, 0, 10}]\n\n\n", "interruption - How to abort on any message generated?": "\nI found a robust solution described in this MathGroup message by Maxim Rytin:\nmessageHandler = If[Last[#], Abort[]] &\n\nInternal`AddHandler[\"Message\", messageHandler]\n\nThis will abort the computation whenever a message would be printed.  \nIt can be turned off using\nInternal`RemoveHandler[\"Message\", messageHandler]\n\nAlternatively this can be temporarily applied to a piece of code like this:\nInternal`HandlerBlock[\n {\"Message\", messageHandler},\n (* ... code here ... *)\n]\n\nThe currently set message handlers can be retrieved using\nInternal`Handlers[\"Message\"]\n\n(Internal`Handlers[] will return all existing handlers)\nWhenever a message is generated, Hold[message, printed] is passed to all \"Message\" handler functions where message is the message text and printed is True is the message would be printed, False otherwise.\nThe debugging palette appears to use the same mechanism to break on messages.\n\nTo make it work with parallel evaluations, one can simply register the same handler on all kernels using ParallelEvaluate.\n", "graphics - Apply 2 Styles within Text[]": "\nYou could use Row to build up the text to be shown:\naboveBox[info_, colors_] := \n Graphics[{colors, EdgeForm[Thick], Rectangle[{0, 0}, {26, 3}], \n   Text[Row[{Style[\"subject\", 12, Bold, Black, \n       TextAlignment -> Center], \n      Style[info, 18, Bold, Red, TextAlignment -> Center]}], {26, 3}/\n     2]}, ImageSize -> 300]\n\naboveBox[\"AK6\", LightBlue]\n\n\n", "graphics - Recovering data points from an image": "\nI started with the image you provide and called it img. This solution isn't perfect but it might serve as a starting point.\nGet some known points:\nI right clicked the image and selected \"Get Coordinates\".  I then clicked as closely as possible to the origin, and the points {0,1.3} and {10.,.82}.  On Windows hold Ctrl+C to copy those points.  And then Ctrl+V to paste them into the notebook...\n{o, y, x} = {{36.5173`, 206.72`}, {17.5824`, 17.3711`}, {391.209`, 54.9028`}};\n\nFind a transformation that will return the proper points:\nHere I use FindGeometricTransform and feed it the known values for the selected points along with their image coordinates. This produces a TransformationFunction to use later.\ntrans = FindGeometricTransform[\n            {{0, .82}, {0, 1.3}, {10, .82}}, \n             {o,      y,        x}\n         ][[2]];\n\nObtain and process the image data:\nHere I round the RGB color values in the ImageData so that the blue curve is coded as {0,0,1}. This will allow me to extract the curve.\ndata = Round[ImageData[img], 1];\n\ncol = DeleteDuplicates[Flatten[Round[ImageData[img], 1], 1]];\n\nGraphics[{RGBColor[#], Disk[]}, ImageSize -> Tiny] & /@ col\n\n\nThe nice blue color I'm wanting to extract is the third color in the list. Now I binarize the image. I convert non-blue pixels to black and the blue to white.\nbinImage = Image@Replace[data, {col[[3]] -> 1, _ :> 0}, {2}]\n\n\nBut this has some spurious points I'd like to remove so I only have the curve remaining. I'll use a GaussianFilter to create a binary mask that will allow me to filter those points out. This should give me the curve I want.\ncurve = ImageApply[{0, 0, 0} &, binImage, \n  Masking -> ColorNegate[Binarize[GaussianFilter[binImage, 5]]]]\n\n\nThat's much cleaner! Now to extract the locations of the white pixels while maintaining the proper orientation.\ncurvLoc = (Reverse /@ \n    Position[ImageData[curve, DataReversed -> True], {1., 1., 1.}]);\n\nApply the transformation before to the curve points and show it with the original plot before distortion. I called this plot...\nShow[ListPlot[trans@curvLoc, PlotRange -> All], plot]\n\n\nIts not perfect, but it should be a start.\nEDIT: I realized that the coordinates of the origin were actually {0,.82} rather than {0,.8}. With this realization we get an even better approximation. Note that I've also employed an interpolating function. Using various smoothing techniques on the function values prior to interpolating should further improve things.\npts = Sort[trans@curvLoc];\n\ng = Interpolation[pts, InterpolationOrder -> 1]\n\nShow[Plot[g[x], {x, .05, 10}, PlotStyle->Red], plot]\n\n\n", "cudalink - Can't use CUDA shared memory": "\nThis Mathematica 8 documentation should answer your question.\n", "front nd - Txt in columns - Mathmatica Stack Exchang": "\nCheck MakeBilateralCells.m in the directory \n$InstallationDirectory\\Mathematica\\8 .0\\AddOns\\Applications\\AuthorTools\nExamples:\nThis package has been around since Version 4. \nHaven't checked/test all features, but the basic functions seems to work with Version 8.0.4. \nSome examples:\n Needs[\"AuthorTools`\"];\n PasteBilateralTemplate[EvaluationNotebook[]]\n\npastes a template that you can edit:\n\nOpen another notebook (Untitled-5 on the left in the screenshot) and evaluate an expression (say Plot something). \nIn your input notebook (Untitled-4 in my example), evaluate\n Notebooks[]\n\nto get the list of open notebooks:\n\nYour screen now looks like:\n\nSelect the first cell group in the target notebook. Go back to the input notebook and evaluate the folowing:\n MakeBilateral[NotebookSelection[Notebooks[][[2]]]]\n\nThe fist cell group in the target notebook now becomes:\n\n\n", "functions - Can someone explain this snippet: (#[#] &)[#[#][#] &]": "\nGoing out on a limb here, but the exhibited expression looks like a brave but flawed attempt to implement the Y-combinator extremely concisely.\nThe Y-combinator is a technical trick used to implement recursion in the lambda calculus.  Here is an implementation that stoops to using some symbols:\nY[f_] := #[#]&[Function[n, f[#[#]][n]]&]\n\n... and here is an example of its use to calculate factorials recursively:\nfac[r_] := If[# < 2, 1, # * r[# - 1]]&\n\nY[fac][10]\n\n\n3628800\n\nOf course, in Mathematica there is no need to engage in such gymnastics since explicit recursion is supported directly.  But it is a nice brain-teaser: can Y be expressed using no symbols?  (Ideally using nothing other than special input form #, the postfix operator &, the matchfix operator [...] and parentheses -- just like the original expression.)\nThe Obscurity Continues\nSince we are exploring obscure corners of Mathematica function syntax, here is another version of the Y-combinator that uses the rarely seen \\[Function], an infix operator for function definition (keyboard shortcut: ESCfnESC):\nY = f \u21a6 (g \u21a6 g[g])[h \u21a6 n \u21a6 f[h[h]][n]]\n\n(* but copy this instead to get the correct Mathematica character:\nClearAll[Y]\nY = f \\[Function] (g \\[Function] g[g])[h \\[Function] n \\[Function] f[h[h]][n]]\n*)\n\n", "differential equations - Solution Curves and Order of Evaluation Question": "\nWhen you do solns = Table[y = Sin[x] + i, {i, -5, 5}], you are setting y=Sin[x]+i at each iteration; the last one is y=Sin[x]+5, so that is what y is. \nIf you instead do solns = Table[Sin[x] + i, {i, -5, 5}] and then ContourPlot[y == solns, {x, -5, 5}, {y, -5, 5},  FrameLabel -> Automatic]  then you get y as a label, because now no value has been assigned to y.\nRegarding it being an unintended consequence, y=expr explicitly sets y to expr; so if you do not intend this, then simply do not put y there. And as for this not being indicated, it is not indicated for the same reasons something like x=12 would not be; it just returns the value being assigned to x.\nThat is, what is effectively happening with something like Table[f[i],{i,1,10}] is that a loop is set up (with i localized, effectively with Block); at each iteration, f[i] is evaluated, and whatever it returns is appended to a list. In the end, the list is returned. Thus, if evaluating f[i] has side effects (such as assigning a value to y), you do not see that.\nSo in this case, you can think of Table[f[i], {i, 1, 10}] as equivalent to \nModule[{\n  lst = {}},\n Do[\n  AppendTo[lst, f[i]], {i, 1, 10}\n  ];\n lst\n ]\n\n", "dynamic - Checking from a preemptive evaluation whether a main evaluation is ongoing": "\nIf you control the launch of the main evaluation process, then a very simple way is to wrap your code in a dynamic environment (Block), which would set some flag:\nmainEvaluationOngoingQ[] := TrueQ@mainEvaluationQ\n\nBlock[{mainEvaluationQ = True}, Do[i^2, {i, 1, 10^8}]]\n\nYou can automate this by creating an environment:\nSetAttributes[withMainEvaluation, HoldAll];\nwithMainEvaluation[code_] :=\n    Block[{mainEvaluationQ = True}, code]\n\nYou can further automate this with $Pre, if needed: $Pre = withMainEvaluation.\n", "export - Exporting graphics to PDF": "\nMy preferred method to export graphics to pdf is to do something like\nExport[\"figure.pdf\", plot, \"AllowRasterization\" -> True, \n    ImageSize -> 360, ImageResolution -> 600]\n\nThis uses vectors for simple graphics, but produces a high resolution rasterized image if the plot becomes too complicated.\n", "parallelization - Monitor doesn't work with ParallelTable": "\nOne way is to set a shared variable that would be assigned to an iterator variable, and monitor that:\nSetSharedVariable[j]\nMonitor[\n   ParallelTable[j = n;Length[FactorInteger[2^n - 1]], {n, 50, 300}], \n   j\n]\n\nThis may make sense if the computation for each i is rather intensive, so that the overhead of communication with the main kernel is negligible. Note also that the results you see are not generally in sequential order, since they depend on how ParallelTable schedules the computations to available kernels. As to the original example, here is a modified version,\nSetSharedVariable[j]\nMonitor[ParallelTable[Pause[RandomReal[{0.5, 4.}]];j = i, {i, 1, 10}], j]\n\nwhere the intervals to pause are random, so that not all kernels finish computing at the same time. \nEDIT\nAs mentioned by @Szabolcs in the comments, \n\nYou could use j++ in place of j=i, if you are mostly interested in the overall progress\nOne should be aware of what type of communication overhead this induces. \n\nHere is one way to find out:\nj = 0;\nFirst@AbsoluteTiming[ParallelTable[j++, {i, 1, 1000}];]/1000\n\nwhich returns 0.0028 on my machine.\n", "parallelization - PrintTemporary in ParallelTable": "\nThis will display a list that's updated as long as the calculation runs, and vanishes afterwards:\n(* Pattern that translates the kernel's ID to\n   a number from 1 to $KernelCount *)\nkernels = ParallelTable[$KernelID -> i, {i, $KernelCount}];\nSetSharedVariable[kernels]; (* for Mathematica 7 *)\n\n(* This is the list that will display each kernel's current operation *)\nSetSharedVariable[currentNumber]\ncurrentNumber = ConstantArray[0, Length@kernels];\n\nPrintTemporary[\"Current calculations:\"];\nPrintTemporary@Dynamic[currentNumber];\n\n(* Start the computation *)\nParallelTable[\n    Pause@RandomReal[{0, .25}]; (* Long calculation *)\n    currentNumber[[$KernelID /. kernels]] = i,\n    {i, 100},\n    Method -> \"FinestGrained\"\n]\n\nThe immediate output looks like this:\n\nCurrent calculations:\n{15, 24, 16, 23, 25, 29, 27, 20}\n\n\nNow wait for ParallelTable to finish, and the above will disappear, leaving only the result:\n\n{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...}\n\n\nYou can modify the Dynamic statement according to your needs of course, such as adding a // Column to the argument to print it nicer etc.\n", "list manipulation - How to change step size of ListPlot": "\nLists don't save the value they have been generated with. Consider the example of plotting a sine using a discrete point set:\ndata = Table[Sin[2 Pi x], {x, 0, 1, 0.05}];\nListPlot[data]\n\n\n\n\nNotice the nonsense values on the $x$ axis.\nThere are three possible solutions for this, all of which give the following plot as a result:\n\nUsing DataRange to manually specify the domain of the data in ListPlot\ndata = Table[Sin[2 Pi x], {x, 0, 1, 0.05}];\nListPlot[data, DataRange -> {0, 2 Pi}]\n\nThe disadvantage of this approach is that the data range is not known to the plot, and it has to be entered by the user manually. If the data itself changes, the plot will still assume these manual numbers, even if the domain is now much larger (consider expanding the above table to run from 0 to 20).\nEmbedding the data range into the list\ndata = {\n        Table[Sin[2 Pi x], {x, 0, 1, 0.05}],\n        DataRange -> {0, 2 Pi}\n       };\nListPlot @@ data\n\nDisadvantage: the DataRange option is only useful for a couple of functions. When you're planning to further modify the data, you will always have to pay attention that data doesn't save the data on the first level, but on the second one of this nested list.\nIncorporating the x values when generating the data\ndata = Table[{2 Pi x, Sin[2 Pi x]}, {x, 0, 1, 0.05}];\nListPlot[data]\n\nThe disadvantage of this approach is of course a more complicated list structure, as well as about twice the amount of data.\n", "Is there a more elegant and efficient way to write brainf*** style loops in Mathematica?": "\nMy solution isn't precisely what was asked for: it is the complete parser. At the moment, it is strictly a parser, but the functionality is all ready to be added.\nClear[bfinterpreter, bfeval, movf, movb, add1,  sub1, write, read, loop, \n      stored, loopdepth, rls]\nrls = {\">\" -> movf, \"<\" -> movb, \"+\" -> add1, \n       \"-\" -> sub1, \".\" -> write, \",\" -> read,\n       \"]\" :> With[{mode = loopdepth--}, loop[stored[mode]]]\n  };\n\nbfeval[a : (\">\" | \"<\" | \"+\" | \"-\" | \".\" | \",\" | \"]\")] := \n  With[{val = a /. rls}, \n   If[loopdepth == 0, \n    val[ptr], \n    AppendTo[stored[loopdepth], val]; ## &[]] \n  ]\n\nbfeval[\"[\"] := (stored[++loopdepth] = {}; ## &[])\nbfeval[_] := (## &[])\n\nbfinterpreter[code_String] := \n  Block[{loopdepth = 0, stored, ptr, \n         movf, movb, add1,  sub1, write, read}, \n   bfeval /@ StringSplit[code, \"\"]\n  ];\n\nA user would access this by passing bfinterpreter as String of BF commands.  The string is split into individual characters via StringSplit[code, \"\"], and then bfeval is mapped over the resulting list. Scan would be better for the full implementation, but I used Map here to show that the parser works. In particular, using this on the OPs supplied BF code we get\n(* spaces added for demo purposes *)\nbfinterpreter[\"[[-]>> > . <<<]>>>  >>>.\"]\n(*\n=> {loop[{          (* [ *)\n      loop[{sub1}], (* [-] *)\n      movf, (* > *)\n      movf, (* > *)\n      movf, (* > *) \n      write, (* . *) \n      movb, (* < *) \n      movb, (* < *) \n      movb  (* < *)\n     }               \n    ][ptr],    (* ] *)\n    movf[ptr], (* > *) \n    movf[ptr], (* > *) \n    movf[ptr], (* > *) \n    movf[ptr], (* > *) \n    movf[ptr], (* > *) \n    movf[ptr], (* > *) \n    write[ptr] (* . *)\n   }\n*)\n\nAs you've probably figured out, all the magic happens in bfeval. The first form accepts all BF characters {\">\", \"<\", \"+\", \"-\", \".\", \",\", \"]\"}, but the open loop, \"[\". It works by applying a list of replacement rules to the supplied character and either storing it, if we're within a loop, or evaluating it immediately. The close loop rule, though, has added functionality in that it needs to both reduce loop counter, loopdepth, and return the stored commands for the loop, hence the use of RuleDelayed (:>).\nThe second form of bfeval simply increments the loop counter, and returns ##&[] to ensure the final list doesn't contain Nulls. And, the final form is the catch all for every other type of character.\n", "performance tuning - Setting a lower limit on calculation time": "\nA similar but slightly shorter solution...\nSetAttributes[pauseAtLeast2, HoldFirst]; \n\npauseAtLeast2[calculation_, pause_] := \n   With[{res = AbsoluteTiming[calculation]},\n        If[res[[1]] < pause, \n               Pause[pause - res[[1]]]\n        ]; \n\n        res[[2]]\n   ]\n\n", "graphics - How can Magnify be forced to ignore the notebook's window width?": "\nTry setting ImageSize:\np = Plot[x^2, {x, -1, 1}, ImageSize -> 300];\nMagnify[p, 4]\n\nAs Szabolcs kindly notes one may use ImageSize -> Medium to preserve the default sizing while still embedding an explicit ImageSize that prevents the resize-to-window behavior you wish to avoid.\nYou could also rasterize at 4X normal ppi (default 72) and display 1:1 :\nppi = CurrentValue[\"FontPropertiesScreenResolution\"];\n\nImage[p, ImageResolution -> 4 * ppi, Magnification -> 1]\n\n", "function construction - How to avoid collision between optional arguments and options": "\nMathematica has to be able to tell that the default arguments can't be rules. So, for some special cases, you could do \nOptions[f] = {\"g\" -> Identity};\n\nf[x_, y_Integer: 2, z_Integer: 3, OptionsPattern[]]:= OptionValue[\"g\"][x + y + z]\n\nTesting:\nf[1, 2, 3, \"g\" -> (#^2 &)]\n\n\n36\n\n\nf[1]\n\n\n6\n\n\nf[1, \"g\" -> (#^2 &)]\n\n\n36\n\n\n", "packages - How to distribute proprietary Mathematica code": "\nMy suggestion is to use a combination of encryption, DumpSave (as noted in some answers / comments), and Locked / ReadProtected, which should give your code a reasonable level of security. You can't make things totally safe, in Mathematica or any other language.  Using DumpSave however means that you should create a version of a package for each platform you want to support. But, if you really want to protect your code, this extra work does not seem that unreasonable.\n", "front end - How to convert between various ItemSize/ImageSize units?": "\nIt's not really the done thing to answer a question you've set a bounty on, but here is an explanation of why Mike's answer isn't quite right. The first point to note is that item sizes include the width of frames, so one needs to allow for the thickness of the frames in the ImageSize option for the second grid (thus the +2 in the option since FrameStyle has a setting including AbsoluteThickness[1] and you need to count both sides.)\nIt's also necessary to ensure ContentPadding is False. This affects placement of the text in the grid cell.\nFinally, Row doesn't take the  Spacings option while Grid does. In these circumstances it helps to used Grid for both cases. Notice I've used the Offset specification of spacing, which only counts the spacing excluding frames and borders.\nOverlay[{Grid[{{\"Sample\", \"Text\"}}, Frame -> All, \n   FrameStyle -> Directive[AbsoluteThickness[1], Red], \n   Spacings -> {Offset[0], 0}, ItemSize -> itemSize, \n   Alignment -> {Left, Center}], \n  Grid[{{Framed[\"Sample\", \n      ImageSize ->  2 + Dynamic[\n         itemSize*{CurrentValue[\"FontMWidth\"], \n           CurrentValue[\"FontLineHeight\"]}], FrameMargins -> 0, \n      BaseStyle -> Red, \n      FrameStyle -> Directive[AbsoluteThickness[1], Blue], \n      ContentPadding -> False], \n     Framed[\"Text\", \n      ImageSize -> \n       Dynamic[{2, 2} + \n         itemSize*{CurrentValue[\"FontMWidth\"], \n           CurrentValue[\"FontLineHeight\"]}], FrameMargins -> 0, \n      BaseStyle -> Red, \n      FrameStyle -> Directive[AbsoluteThickness[1], Blue], \n      ContentPadding -> False]}}, Spacings -> {Offset[0], 0}]}]\n\n\n", "replacement - Replace rule does not match": "\nPattern matching with complex numbers is notoriously difficult because Complex numbers are atomic yet have non-trivial FullForm.\n{AtomQ[-3 I], FullForm[-3 I]}\n\n\n{True,Complex[0,-3]}\n\n\nExamining the FullForm of your expression, perhaps you want the following.\nrule = a_Complex*x_*Re[y_] + b_Complex*y_*Re[x_] :>\n  Abs[a]*Re[I x Conjugate[y]] /; a == -b;\n-3 I Ez Re[Ex] + 3 I Ex Re[Ez] /. rule\n\n\n-3 Im[Ex Conjugate[Ez]]\n\n\n", "export - Question about $\\LaTeX$ generated by Mathematica": "\nThe immediate problem with the LaTeX is that \\( and \\) appear twice.  Thus, the following works fine, assuming the setspace package has been loaded.\n\\begin{doublespace}\n\\noindent\\(\\{0,10,1\\}\\)\n\\end{doublespace}\n\nAnother question, of course, is why this export went wrong and how to change that.  That's hard to say without seeing the Mathematica expression.\n", "graphs and networks - How to determine edgeweights from width of skeleton using MorphologicalGraph (or workaround)?": "\nThis is more of a remark than a solution, but it was too long for a comment.\nFirst of all, although it's not visible in the plot, MorphologicalGraph with EdgeWeight -> Automatic does set edge weights for the edges. However, these are not based on the thickness of the edges but on their length. For example, for the example in the original post the edge weights of g are equal to \ng = MorphologicalGraph[img, EdgeWeight -> Automatic];\nweights = OptionValue[Options[g, EdgeWeight], EdgeWeight]\n\n\n{22, 20, 5, 11, 5, 34, 49, 13, 41, 12, 7, 6, 9, 34, 44, 24, 29, 54, \n  65, 17, 34, 26, 38, 21, 43, 41, 13, 52, 3, 14, 6, 47, 19, 24, 9, 14, \n  82, 8, 13, 13, 52, 23, 63, 99, 73, 84, 40}\n\n\nUsing a custom EdgeRenderingFunction for GraphPlot to colour the edges and change their thickness according to weights you get something like\nvertices = VertexList[g];\ncrds = OptionValue[Options[g, VertexCoordinates], VertexCoordinates];\nedges = List @@@ EdgeList[g];\n\nGraphPlot[Rule @@@ edges,\n  VertexCoordinateRules -> Thread[vertices -> crds],\n  EdgeRenderingFunction -> (With[{w = \n        Pick[Rescale[weights], edges, (#2 | Reverse[#2])][[1]]},\n      {Thickness[.02 (.1 + w)],\n       ColorData[\"SunsetColors\"][.9 w], Line[#1]}] &), \n  AspectRatio -> 1]\n\n\n", "graphics - Animating a rotating disk": "\nLets start with some parameters (note that I've chosen larger values for a and x0 here to actually see the movement of the centre)\nradius = 20;\nx0 = 10;\na = 5;\nom1 = 10 Degree; \nom2 = 10 Degree; \n\nThe centre of the rotating object at time t is given by\ncentre[t_] := {x0 + a Cos[om1 t], a Sin[om1 t]};\n\nI'm using RegionPlot to create an image of the disk centred at the origin\ncirc = RegionPlot[x^2 + y^2 <= radius^2, {x, -radius, radius}, \n  {y, -radius, radius}, \n  Mesh -> 20, MeshStyle -> {{Red}, {Blue}}, BoundaryStyle -> Black, \n  PlotStyle -> None]\n\n\nNext, we're defining a function for creating the plot at time t. I'm using Rotate and Translate to get the orientation and position of the disk. The path of the centre is plotted using ParametricPlot\nplot[t_] := Show[Graphics[\n  Translate[Rotate[{circ[[1]], Point[{0, 0}]}, om2 t], centre[t]]],\n  If[Abs[t] <= $MachineEpsilon, {},\n    ParametricPlot[centre[s], {s, 0, t}, PlotStyle -> {Black}]],\n  PlotRange -> {{-2 radius, 2 radius}, {-2 radius, 2 radius}}, \n  Axes -> True]\n\nPlugging this function into Animate will create an animation of this function:\nAnimate[plot[t], {t, 0, 36}]\n\n\n", "programming - Embed CDF into an Apple iBook?": "\nThe first question would be: do the devices on which your iBook will be viewed also allow you to install the CDF player? If not, then that's the end of it. The FAQ says CDF doesn't run on the iPad (yet?). \nJust as an aside: when I saw that FAQ, I was reminded of Wolfram Publicon (there was a similar FAQ for it ten years ago, and it had a very similar statement along the lines of: the release is just around the corner, just contact us...).\n", "guidelines - Resource management in Mathematica": "\nThere is an undocumented function, CheckAll, that can be used for this purpose.  It dates back to at least version 7.  All the usual caveats about undocumented functions apply -- it might not be supported in future releases, there may be gaps in its functionality, etc.  Buyer beware.\nThe usage information looks like this:\n\nThe usage text is slightly in error as the control arguments are wrapped in Hold rather than HoldComplete.\nCheckAll can be used to detect all manner of non-local exits, such as:\nCheckAll[Abort[], List]\n(* {$Aborted, Hold[Abort[]]} *)\n\nCheckAll[Throw[1], List]\n(* {$Aborted, Hold[Throw[1]]} *)\n\nCheckAll[Goto[a], List]\n(* {$Aborted, Hold[Goto[a]]} *)\n\nCheckAll[MemoryConstrained[Range@1000, 100], List]\n(* {$Aborted, Hold[]} *)\n\nCheckAll[TimeConstrained[Pause[1000], 1], List]\n(* {$Aborted, Hold[]} *)\n\nWe can use this function to build unwindProtect, a control structure that assures that a clean-up expression is evaluated after any non-local exit of its body:\nClearAll @ unwindProtect\nSetAttributes[unwindProtect, HoldAll]\nunwindProtect[body_, cleanup_] :=\n  CheckAll[body, HoldComplete] /.\n    ( cleanup\n    ; { _[_, _[r__]] :> r\n      , _[r_, _[]] :> r\n      }\n    )\n\nIt starts by evaluating the body, guarded by CheckAll.  Then it evaluates the clean-up expression.  Finally, it returns either the pending non-local control actions or, if there are none, the return value of the body (which might be a held Sequence).\nHere are some examples of its use:\nhi[] := Print@\"hi\"\nbye[] := Print@\"bye\"\nfail[] := Print@\"FAIL!\"\n\nunwindProtect[hi[]; Abort[], bye[]]\n(* During evaluation of In[75]:= hi\n   During evaluation of In[75]:= bye\n   Out[75]= $Aborted *)\n\nCatch @ unwindProtect[hi[]; Throw[1]; fail[], bye[]]\n(* During evaluation of In[76]:= hi\n   During evaluation of In[76]:= bye\n   Out[76]= 1 *)\n\nModule[{n = 0}\n, Label[a]\n; If[n < 2, unwindProtect[Print[\"hi \", ++n]; Goto[a], Print[\"bye \", n]]]\n]\n(* hi 1\n   bye 1\n   hi 2\n   bye 2 *)\n\nIt even handles some tricky cases:\nCatch@unwindProtect[hi[];Throw[Unevaluated[Abort[]]], bye[]]\n(* During evaluation of In[82]:= hi\n   During evaluation of In[82]:= bye\n   Out[82]= $Aborted *)\n\nCatch@unwindProtect[hi[];Throw[Unevaluated[Throw[$Failed]]], bye[]]\n(* During evaluation of In[83]:= hi\n   During evaluation of In[83]:= bye\n   Out[83]= $Failed *)\n\nunwindProtect can be used to build a still higher-level control structure (withSetup) that supports the declaration of Module-like variables, with sequential assignment and resource-cleanup expressions:\nClearAll[withSetup]\nSetAttributes[withSetup, HoldAll]\n\nwithSetup[{}, body_] := body\n\nwithSetup[{var_ = val_; cleanup___, rest___}, body_] :=\n  Module[{var = val}\n  , unwindProtect[withSetup[{rest}, body], CompoundExpression[cleanup]]\n  ]\n\nwithSetup[{var_ = val_, rest___}, body_] :=\n  Module[{var = val}, withSetup[{rest}, body]]\n\nw:withSetup[___] := (Message[withSetup::malformed, Short@HoldForm[w]]; Abort[])\n\nwithSetup::malformed = \"``\";\n\nwithSetup starts out resembling Module:\nwithSetup[{x = 1}, x + 1]\n(* 2 *)\n\nIt differs from Module in that the variable assignments are performed sequentially:\nwithSetup[{x = 1, y = x + 1}, {x, y}]\n(* {1, 2} *)\n\nBut the real value of withSetup is that it can be used to declare clean-up actions for each variable:\nopen[f_] := (Print[\"opened \", f]; file[f])\nclose[f_] := Print[\"closed \", f]\n\nwithSetup[{f = open[\"f1\"]; close[f]}, f]\n(* During evaluation of In[152]:= opened f1\n   During evaluation of In[152]:= closed file[f1]\n   Out[154]= file[f1] *)\n\n... and those clean-up actions are performed even in the face of a non-local return:\nCatch @ withSetup[{f = open[\"f1\"]; close[f]}, Throw[\"early exit\"]]\n(* During evaluation of In[160]:= opened f1\n   During evaluation of In[160]:= closed file[f1]\n   Out[160]= early exit *)\n\nClean-up actions are performed in reverse order from their corresponding initializations:\nwithSetup[\n  { file1 = open[\"f1\"]; close[file1]\n  , file2 = open[\"f2\"]; close[file2]\n  , files = {file1, file2}\n  }\n, doStuffWith[file1, file2, files]\n]\n(* During evaluation of In[155]:= opened f1\n   During evaluation of In[155]:= opened f2\n   During evaluation of In[155]:= closed file[f2]\n   During evaluation of In[155]:= closed file[f1]\n   doStuffWith[file[f1],file[f2],{file[f1],file[f2]}] *)\n\nwithSetup assumes that any variable initialization that is a compound expression is initialized using the first part of the expression, and is cleaned up using the remaining parts.  One is free to write {var = (init1; init2); cleanup1; cleanup2} if desired.\nBeware that any errors or other non-local exits from the clean-up actions can cause all kinds of strange behaviour.  Clean-up actions should be foolproof, with no reasonable chance of failure.  Wrap them in CheckAbort, AbortProtect or even unwindProtect if there is any doubt and circumstances demand it.  unwindProtect does not do this automatically, although it could be changed to do so according to one's personal preference (I prefer to see the errors rather than muffle them).\nUpdate\nI subsequently discovered that CheckAll muffles all messages generated by the exit function.  Furthermore, any messages from the main expression are also muffled in such circumstances.  Here is a revised version of unwindProtect that performs some gymnastics to preserve the main messages and to inform the user when a clean-up expression fails:\nClearAll@unwindProtect\nSetAttributes[unwindProtect, HoldAll]\nunwindProtect[body_, cleanup_] :=\n  CheckAll[body, HoldComplete] /.\n    ( CheckAll[cleanup, HoldComplete] /. _[v_, _[c__]] :>\n        Check[\n          Message[unwindProtect::cleanupFailed\n          , HoldForm @ cleanup\n          , HoldForm @ {v}\n          , HoldForm @ {c}\n          ]\n        , Null\n        ]\n    ; { _[_, _[r__]] :> r\n      , _[r_, _[]] :> r\n      }\n    )\n\nunwindProtect::cleanupFailed =\n  \"Cleanup expression failed: ``, results: ``, controls:  ``\";\n\n", "front end - How make AddMenuCommands work in an init.m": "\nI can only speak for Windows but I would expect the solution should be similar for Mac.\nI created a file $BaseDirectory\\FrontEnd\\init.m\nIn that file I added the following lines. Note they are slightly different than what you provide but should do what you want.\nFrontEndExecute[AddMenuCommands[\"AboutBoxDialog\",{Delimiter,\n  Item[\"Installed Add Ons\",FrontEndExecute[FrontEnd`FrontEndToken[\"OpenHelpLink\",\n    {\"guide/InstalledAddOns\",Automatic}]]],Item[\"Standard Extra Packages\",\n       FrontEndExecute[FrontEnd`FrontEndToken[\"OpenHelpLink\",\n          {\"guide/StandardExtraPackages\",Automatic}]]]}]]\n\nI attempted to do this using $UserBaseDirectory\\FrontEnd but Mathematica insists on wiping out any changes I make to the init.m file that already exists there.\nEDIT:\nFollowing the comment by @Matariki one can place the init.m file in $UserBaseDirectory\\Autoload\\PacletManager\\Configuration\\FrontEnd\\ instead. I'm not sure which is preferable. The $BaseDirectory installation should add the customization for any user on the machine whereas the $UserBaseDirectory option will only work for the selected user.\nExtension:\nAlso worth noting is that \"AboutBoxDialog\" is a front end token that can be found in MenuSetup.tr located in $InstallationDirectory/SystemFiles/FrontEnd/TextResources/.  \nThese tokens, to my knowledge, are the only way to control the placement of new commands in menus. I could for example have added a background color to the Format>Background Colors menu by noting that \"BackgroundDialog\" is the token closest to the relevant menu in MenuSetup.tr. Adding the following code to the previously mentioned init.m will add a Linen color to the Background Colors sub-menu.\nFrontEndExecute[ \n  AddMenuCommands[\"BackgroundDialog\", {Delimiter, \n   Item[\"L&inen\",Background->RGBColor[0.980,0.941,0.902]]}]];\n\n", "pattern matching - Replacement rule only matches part of expression": "\nIn reply to the remaining issue addressed in the comments, here is the reason the 3 is not taken out of the brackets.\nYou have\nrule = {f_ x_ + f_ y_ -> f (x + y), f_ x_ - f_ y_ -> f (x - y)};\n\n3 Hx Re[Ez] vz - 3 Ez Re[Hx] vz //. rule\n\n\nvz (3 Hx Re[Ez] - 3 Ez Re[Hx])\n\nleaving the multiple 3 inside.  Taking a simplified case, this works:\n3 a + 3 b /. f_ x_ + f_ y_ :> f (x + y)\n\n\n3 (a + b)\n\nBut this does not work, for the reason stated by Mr. Wizard:\n3 a - 3 b /. f_ x_ - f_ y_ -> f (x - y)\n\n\n3 a - 3 b\n\nAnd neither does this:\n3 a - 3 b /. f_ x_ + f_ y_ -> f (x + y)\n\n\n3 a - 3 b\n\nfor reason that FullForm[3 a - 3 b] is\n\nPlus[Times[3, a], Times[-3, b]\n\nso f cannot ever match 3 and -3.\nAn awkward solution to this simple case is:\n3 a - 3 b /. \n f_ x_ + g_ y_ :> \n  Which[f == g, f (x + y), f == -g, f (x - y), True, f x + g y]\n\n\n3 (a - b)\n\nBut this does not work for more complicated inputs.\nSimplify on the other hand works ok:\nSimplify[3 a - 3 b]\n\n\n3 (a - b)\n\n3 Hx Re[Ez] vz - 3 Ez Re[Hx] vz // Simplify\n\n\n3 vz (Hx Re[Ez] - Ez Re[Hx])\n\nAnd perhaps rule = f_ x_ + g_ y_ :> Simplify[f x + g y] would work for your original case, depending on what you are specifically seeking.\n", "parallelization - Parallelizing Numerical Integration in Mathematica": "\nThe best you can do it is to speed up your function. Your calc is using a replace, but it's better if you use With:\ncalc[a_, b_, c_, d_, e_, f_] := \n With[{Q = (8000000 \\[Pi] Sin[\n       1/2 ArcCos[\n         1/2 Sqrt[Cos[2 c] + Cos[2 d]] Sqrt[Cos[2 e] + Cos[2 f]] + \n          Sin[c] Sin[e] + \n          Sin[d] Sin[f]]])}, (1.97531*10^15 (3. Q Cos[(3 Q)/20000] - \n         20000. Sin[(3 Q)/20000])^2)/(1.58025*10^24 + \n      6.32099*10^16 Q^2 + \n      Q^6 + (-1.58025*10^24 + 7.90123*10^15 Q^2 - \n         3.55556*10^8 Q^4) Cos[(3 Q)/10000] + (-4.74074*10^20 Q - \n         2.96296*10^12 Q^3) Sin[(3 Q)/10000])*\n   UnitStep[5/2 - a]^2 UnitStep[5/2 + a]^2 UnitStep[5 - b]^2 UnitStep[\n     5 + b]^2 UnitStep[5 - a - 1944 c] UnitStep[\n    5 + a + 1944 c] UnitStep[5 - b - 1944 d] UnitStep[\n    5 + b + 1944 d] UnitStep[40 + a - 1600 e] UnitStep[\n    40 - a + 1600 e] UnitStep[45/2 + b - 1600 f] UnitStep[\n    45/2 - b + 1600 f]]\n\nFor working with parallel, it's better if you distribute your definitions before calling parallel:\nDistributeDefinitions[calc]\n\nThen try:\nTotal[ParallelTable[\n   NIntegrate[\n    calc[a, b, c, d, e, f], {a, -1, 1}, {b, -1, 1}, {c, -1, \n     1}, {d, -1, 1}, {e, -1, 1}, {f, -1 + i/4, -1 + (i + 1)/4}], {i, \n    0, 7}]] // AbsoluteTiming\n\n", "differential equations - Evaluation of a Variable Coefficient PDE": "\nAs far as I know Mathematica can only solve very special cases of partial differential equations exactly. However, since you want to render the solution, a numerical solution will be enough. Here's an example using the heat equation as a placeholder:\n(* Differential equation *)\neqn = D[u[x, t], t] - D[u[x, t], x, x];\n(* Boundary/Initial conditions:\n   Absorbing boundaries, Gaussian bump *)\nic = {\n    u[x, 0] == Exp[-x^2/2],\n    u[-10, t] == u[10, t] == Exp[-10^2/2]\n};\n(* Unleash the fury *)\ns = NDSolve[{eqn == 0}~Join~ic, u, {x, -10, 10}, {t, 0, 20}];\n(* Visualize result *)\nPlot3D[Evaluate[u[x, t] /. s], {x, -10, 10}, {t, 0, 20}]\n\n\n\n\nNDSolve does not care about the type of differential equation, so your variable coefficients aren't a problem (modulo numerical instabilities of course). Replace eqn by your equation and add according initial conditions and you'll be fine. Here's an example of the same equation, only that now the diffusion constant is not $1$ but $e^{-t/3}$, making diffusion disappear over a time scale of $3$:\neqn = D[u[x, t], t] - E^(-t/3) D[u[x, t], x, x];\nic = {\n    u[x, 0] == Exp[-x^2/2],\n        u[-10, t] == u[10, t] == Exp[-10^2/2]\n    };\ns = NDSolve[{eqn == 0}~Join~ic, u, {x, -10, 10}, {t, 0, 20}];\nPlot3D[Evaluate[u[x, t] /. s], {x, -10, 10}, {t, 0, 20}, AxesLabel -> Automatic, MaxRecursion -> 8, PlotPoints -> 32]\n\n\n\n\n", "How can I extract the data from an image and process it pixel by pixel?": "\nCertainly. For instance, here's how to reduce the number of colours to 10 (randomly chosen in RGB space):\ni = Import[\"ExampleData/lena.tif\"]\n\n\nYou can try ImageData[i] to see the actual RGB values for each pixel. Now produce ten random triplets of reals between 0. and 1., and construct a function to quickly pick the one closest to some given number:\ncolours = RandomReal[{0, 1}, {10, 3}];\nnf = Nearest[colours];\n\nThen map the thing over the RGB values of the image and look at it:\nMap[First[nf[#]] &, ImageData[i], {-2}] // Image\n\n\nTry increasing the number of randomly selected colours to see what happens:\nManipulate[\n Module[{colours = RandomReal[{0, 1}, {num, 3}], nf},\n  nf = Nearest[colours];\n  Map[First[nf[#]] &, ImageData[i], {-2}] // Image\n  ],\n {{num, 10}, 1, 1000, 1}\n ]\n\n\n", "graphics - Mathematica: Label specific vertices in GraphPlot": "\nYou could do something like this. It's an adaptation of the first example in the documentation for VertexLabelingFunction where I used an If statement to determine whether a vertex should be labeled or not. The function offset is just a helper function to determine by what amount the arrows should be shortened based on whether they end or start at a labeled vertex or not and lblLst is the list of vertices you want to label:\nlblLst = {1, 5, 10};\n\noffset[lblLst_, edge : {e1_, e2_}] := If[MemberQ[lblLst, #], .13, .07] & /@ edge\n\nGraphPlot[data, \n EdgeRenderingFunction ->\n  ({Red, Arrowheads[Small], Arrow[#1, offset[lblLst, #2]]} &),\n\n VertexRenderingFunction -> (If[MemberQ[lblLst, #2],\n     {White, EdgeForm[Black], Disk[#, .1], Black, Text[#2, #1]},\n     {Blue, Point[#1]}] &)]\n\n\n", "Changing the MouseAppearance on the entire notebook front end": "\nOne can change the default cursor for all Output by setting up $Post with something like the following.\nmouseApp[expr_] := \n      MouseAppearance[expr, Graphics[{Red, Disk[]}, ImageSize -> 10]]\n\n$Post = mouseApp;\n\nI'm not sure this answers your question though since it doesn't change the appearance of the mouse cursor for Input.\n", "programming - Generating a matrix using sublists A and B n times": "\nPerhaps this:\nx = 2;\na = Range[0, x, 0.5];\nb = Range[0.25, x + 0.25, 0.5];\n\nPadRight[#, Length@#[[1]], #] & @ {a, b}\n\nCould also be written:\nPadRight[{a,b}, Length@a, {a,b}]\n\n\nPerformance\nThere is a reason to use the form I proposed over that which Heike gave.  If the first argument of PadRight is a packed array, and the padding list is packable (but not necessarily packed) the result will also be packed, and it is produced more quickly than if it were not packed.\nfoo = Range[5]; (* packed array *)\n\n(r1 = PadRight[{},  5*^6, foo];) // RepeatedTiming\n(r2 = PadRight[foo, 5*^6, foo];) // RepeatedTiming\n\nDeveloper`PackedArrayQ /@ {r1, r2}\nDivide @@ ByteCount /@ {r1, r2} // N\n\n\n{0.047, Null}\n\n{0.0096, Null}\n\n{False, True}\n\n2.99999\n\n\nSo using the list to pad as the seed instead of {} can result in five times better speed and three times better memory consumption.\nHowever as Karsten 7. notes this doesn't actually help with the question example.  In either case the vector elements are kept packed but the outer list is not:\nNeeds[\"Developer`\"]\n\nPackedArrayQ /@ PadRight[#,  Length@#[[1]], #] &@{a, b}\nPackedArrayQ /@ PadRight[{}, Length@#[[1]], #] &@{a, b}\n\n\n{True, True, True, True, True}\n{True, True, True, True, True}\n\n\nSo while in principle it is better to pad the input list rather than {} as some cases greatly benefit from it, this case does not.\n", "front end - Changing default window appearance": "\nThe help window position can be set to be remembered from the Options Inspector: open it, select Global preferences, go to Global Options -> Dialog Settings -> Help Viewer Settings and set Enabled to True. \n", "notebooks - Quickly editing the stylesheet and saving it": "\nNormal behavior is that simply closing the edited style sheet will transparently save it.\nIf you create a new private style sheet for a new Notebook and you still do not have this behavior then you must have changed a global configuration setting.\nIf this problem is peculiar to a particular private style sheet then I suggest going over the raw file looking for how it differs from the freshly created Notebook described above.\nAlso, you describe having to save this private style sheet with Save As into $UserBaseDirectory; as far as I know this is not how private style sheets work.  How did you create this \"private\" style sheet in the first place?\n", "packages - What is a \"Paclet\"?": "\nUpdate for version 12.1\nStarting with version 12.1, paclets are now exposed as user-accessible packaging functionality.  They are documented here.\nTodd Gayley of WRI has published some preliminary documentation about Paclets and Paclet Development.  There is also an associated introductory video.\n\nOriginal Response\nA paclet is a distribution mechanism for resources that contribute to the contents of a package.  Most of the paclet machinery is in the PacletManager context, which is not public API.\nIt appears that the only part of paclet functionality presently intended for public use involves PacletInfo.m, a descriptor file for Mathematica applications.  This is described in the Wolfram Workbench documentation.\n", "probability or statistics - How to define a new copula distribution family": "\nThe function ProbabilityDistribution allows you to define your own distribution functions that can be used with all distribution-related functions. The following example is from the documentation. \nDefine a custom probability distribution giving its pdf:\n  dD = ProbabilityDistribution[ Piecewise[{{x^2/9, 0 < x <= 3}}], {x, -\\[Infinity], \\[Infinity]}];\n\nThen you can use the built-in functions CDF, Mean etc with it just like any other built-in distribution function. For example:\n  CDF[dD,x]\n\ngives:\n\nDocumentation also contains examples of how construct your own multivariate distributions. There are no specific examples of custom copulas in the documentation but the same principle should apply: you need to use ProbabilityDistribution to define such things in order to be able to use built-in function like CDF, PDF, RandomVariate... with them.\n", "performance tuning - Efficient conditional Mean[] on a large data set": "\nYou could do something like this\nmean = Reap[Sow @@@ Flatten[cogAK6, 1];, _, {Mean[#2], #} &][[2]];\n\nThis will be a lot faster than your approach because by using Sow and Reap this code only iterates through the list of data once. In your code, you reiterate through all elements of the data list for every value of gazeNo (so 3000 times instead of only once).\n", "warning messages - Table function with Part[] call misbehaving, but only after initial startup of Mathematica": "\nOne way to deal with problems like this is to use DynamicModule inside the Manipulate:\nManipulate[\n  DynamicModule[{e1, e2, standardBasis, y, p}\n  , e1 := {1, 0}\n  ; e2 := {0, 1}\n  ; standardBasis := {e1, e2}\n  ; y := 3\n  ; Dynamic[\n      p := {x, y}\n    ; arrowsReference =\n        Table[Arrow[{p, p + Part[standardBasis, j]}], {j, 2}]\n    ]\n  ]\n  , {{x, 1}, -10, 10}\n]\n\nThe example localizes all of the symbols except arrowsReference.  In the original example, it seemed like arrowsReference was meant to \"escape\" the Manipulate.  Adjust these decisions to meet your needs.\nThe expressions that initialize e1, e2, standardBasis and y will each be evaluated exactly once (each session) as the Manipulate is initialized.  Only the contents of the Dynamic expression will be re-evaluated each time the controls are manipulated.\nThis approach saves the state of the localized variables across Mathematica front-end sessions.  Also, the output cell can be copied and pasted to create a new independent cell with its own state -- a desirable attribute when creating CDFs and demonstrations.\nAll this works because of the unusual evaluation sequence documented under the More Information section of DynamicModule.  Essentially, there is a kind of \"double evaluation\" at work.  The initial definitions (e1 := ... through Dynamic[...]) are evaluated in the first pass as if they were defined within a Module.  Then, the final result (in this case Dynamic[...]) is wrapped into a new DynamicModule and that becomes the content of the the Manipulate.\n", "Adding a point to an already existing graphic": "\nradius = 20;\n\ncirc = RegionPlot[\n  x^2 + y^2 <= radius^2, {x, -radius, radius}, {y, -radius, radius}, \n  Mesh -> 20, MeshStyle -> {{Red}, {Blue}}, BoundaryStyle -> Black, \n  PlotStyle -> None]\n\ncirc2 = Show[circ, Graphics[{PointSize[0.025], Point[{10, 10}]}]]\n\n\nYou could have used ListPlot too, but the point here is that Show combined Graphics into a new Graphics, so you need to feed it with Graphics (ListPlot returns a Graphics object)\ncirc3 = Show[circ, \n  ListPlot[{{10, 10}}, PlotStyle -> PointSize[0.025]]]\n\nAnother option perhaps more similar to what you were trying could be\nShow[circ, Epilog -> {PointSize -> Large, Point[{{10, 10}}]}]\n\nGraphics are composed of primitives, directives and options. \nPrimitives are the shapes (Line, Point, Circle, etc). \nDirectives are stuff that affect the shapes, such as color settings, point size, line type, arrow heads, etc. In the same Graphic object you can combine several directives, affecting different primitives (a red circle with a black dot)\nOptions are general to the graphic. AspectRatio, stuff about the axes, etc..\nSo, a Graphics object is Graphics[{list of primitives and directives}, options]\nWhat Show does is take several Graphics, combine its primitives and directives, and optionally change the general options.\nPlotStyle is an option for functions that automatically create Graphics, like Plot and his family. It is NOT a Graphics option. In those functions, it allows among other things to set directives to the stuff you're plotting. So if you're used to writing Plot[f[t], {t, 0, 10}, PlotStyle->something, otheroptions->othervalues] then that something is probably a directive. And probably, otheroptions are general graphic options (or other particular options of the plotting function such as Filling, etc).\nSo, let's see what you were trying to do with your code\nShow[circ, \nEpilog -> Inset[ListPlot[{10, 10}], PlotStyle -> PointSize[0.025]] ]\n\nYou were trying to create a new Graphics with the same primitives and directives than circ, but with an extra option Epilog. Furthermore, you were trying to add as options to the Graphics something that is not an option :P. \nEpilog just adds more primitives to the Graphics object after it is rendered. It is more or less the same as adding more primitives to the list, except that it allows to do it as an option so it's convenient to add annotations in functions such as Plot. The fact that they are added after the Graphics was rendered also means you can mix 2D and 3D primitives. No different in your case than writing the following\nShow[circ, Graphics[{Inset[ListPlot[{10, 10}]]}]]\n\nMoving on. Inset takes a Graphics, Image, cell expression, string, etc, and turns it into a primitive. So, the Graphics object generated by ListPlot now is taken as a whole, with it's own set of axes and everything, and combined with the primitives of circ. Not what you wanted\nFinal comment. ListPlot if it's given a one dimensional list, interprets all the numbers as y-coordinates. If you want it to plot (x,y) pairs, you need to give it a list of (x, y) pairs. In your case, a list of only one pair,  {{10, 10}}\nHope that now you not only understand why your code didn't work but also why what works works\n", "Dimensions of the results of Text[] within Graphics[]": "\nHere you go:\nt = Text[Style[\"how quickly daft jumping zebras vex\", \n    FontFamily -> \"Verdana\", FontSize -> 20]];\n{l, h} = d = Rasterize[t, \"RasterSize\"];\nGraphics[{Green, Rectangle[{0, 0}, d], Black,\n  Inset[t]}, PlotRange -> {{0, l}, {0, h}}, ImageSize -> l]\n\n\n", "programming - How can I make CurrentValue for font characteristics pick up the font of the output not the input cell?": "\nYou could do something like\n{Framed@Graphics[\n   Text[Style[DynamicWrapper[\"how quickly daft jumping zebras vex\",\n       p = CurrentValue[\"FontNWidth\"]], FontFamily -> \"Verdana\", \n     FontSize -> 20]], ImageSize -> Dynamic[p]*35], Dynamic[p]}\n\n\nThis code demonstrates that the font chosen for the styled output is definitely being picked up by CurrentValue.\nManipulate[{Framed@\n   Graphics[\n    Text[Style[\n      DynamicWrapper[\"how quickly daft jumping zebras vex\", \n       p = CurrentValue[\"FontNWidth\"]], FontFamily -> fontfam, \n      FontSize -> i]], ImageSize -> Dynamic[p]*42], Dynamic[p]}, {i, \n  10, 40}, {fontfam, {\"Verdana\", \"Arial\", \"TimesNewRoman\", \"Tahoma\"}}]\n\n\n", "programming - Alternative ways to implement a triangular recursion": "\nThe following is a naive but general implementation of the recursion formula\n$$T_k^{(n)}=f(T_{k-1}^{(n)},T_{k-1}^{(n+1)})$$\ntriangular[f_, initial_] := \n  First@Nest[\n   f @@@ MapIndexed[Join, Partition[#, 2, 1]] &,\n   initial,\n   Length[initial] - 1\n  ]\n\ntriangular takes a function f[tn0, tn1, n] where tn0 corresponds to $T_{k-1}^{(n)}$, tn1 corresponds to $T_{k-1}^{(n+1)}$ and n corresponds to $n$.\nThen the Bernoulli number function can be implemented as\nmyBernoulliB[n_] := triangular[#3 (#1 - #2) &, 1/Range[n+1]]\n\nWe can write it a bit more readably as\ntriangular[Function[{Tn0, Tn1, n}, n (Tn0 - Tn1)], 1/Range[5]]\n\nThe other two algorithms can also be written in terms of triangular[], but I don't think this is really better than your Do loop.  (triangular[] would need to be extended to pass $k$ to the function as well.)\n\nThis can be generalized, based on the same principle, to return multiple results ($\\{T_0^{(3)}, T_1^{(2)}, T_2^{(1)}, T_3^{(0)} \\}$ above) like this:\ntriangular2[f_, initial_] := Module[{tag, a, b},\n  {{a}, {b}} = Reap[\n    Nest[\n     Function[arg,\n      Sow[Last[arg], tag];\n      f[##, Last[arg]] & @@@ MapIndexed[Join, Partition[arg, 2, 1]]\n      ],\n     initial,\n     Length[initial] - 1\n     ],\n    tag\n    ];\n  Append[b, a]\n  ]\n\nThen bezierChop can be implemented using:\nfb[u_] := Function[{tn0, tn1}, u tn1 + (1 - u) tn0];\n\nbezierChop[BezierCurve[pts_?MatrixQ, opts___], u_?NumericQ] :=\n BezierCurve@Transpose@MapThread[triangular2[fb[u], {##}] &, pts]\n\nTo make this easier to understand using the original triangular function, MapThread[triangular[fb[u], {##}]&, pts] would return only the first point out of all points included in the resulting BezierCurve.\n", "Symmetrical image transformation for a kaleidoscope-type image": "\nI think the main problem is that ArcTan runs from $-\\pi$ to $\\pi$, but the DataRange in the x direction runs from 0 to 1, so you're actually using 6 and a bit copies of the original image to cover the whole circle. This is easily fixed by specifying explicit values for DataRange, i.e.\nManipulate[\n With[{sectors = 8},\n  ImageTransformation[\n   ImagePad[im, {{-x, x}, {-x, x}}, Padding -> \"Reversed\"], \n   Function[{pt}, {ArcTan[-#2, #1] & @@ (pt), Norm[pt]}], 250,\n   DataRange -> {Pi/sectors {-1, 1}, {0, 1}}, \n   PlotRange -> {{-2, 2}, {-2, 2}}, Padding -> \"Reversed\"]], {x, 0, \n  100, 5}]\n\n\nHere, sectors is the number of sectors in the transformed image.\nEdit\nNote that while ImageTransformation works it isn't very fast. If you are using Mathematica 8 you could use for example ParametricPlot in combination with TextureCoordinateFunction to  get a similar but faster result.  \nFirst, we need a source image for the Texture. To get the right tiling where two neighbouring images are each other's reflection, I'm using the following:\nimReflected = ImageAssemble[{\n   {ImageReflect[im, Bottom], ImageRotate[im, Pi]},\n   {im, ImageReflect[im, Left]}}]\n\n\nNext, we need a TextureCoordinateFunction. To get the reflections of the shifted image in the circles r=a and the radial lines t=b where a and b are integers I'm using a triangle wave with period 2 and amplitude 1/2 which is vertically shifted by some offset corresponding to x in the solution above.\nfunc[p_, x_] := x + TriangleWave[{0., 1/2.}, p/2 - 1/4]\n\nThe transformed image can then be plotted according to\nManipulate[\n ParametricPlot[{r Cos[2 Pi/sectors t], r Sin[2 Pi/sectors t]}, \n    {r, 0, 3}, {t, 0, sectors},\n  Mesh -> None, BoundaryStyle -> None,\n  Axes -> False,\n  PlotStyle -> {Opacity[1], Texture[imReflected]},\n  TextureCoordinateFunction -> ({func[#4, x], func[#3, x]} &),\n  TextureCoordinateScaling -> False,\n  PerformanceGoal -> \"Quality\", \n  PlotPoints -> {4, 1 + Round[40, sectors]},\n  PlotRange -> {{-2, 2}, {-2, 2}}],\n {x, 0, 1},\n {{sectors, 6}, 4, 10, 2}]\n\n\nNote that for the best result the number of plot points in the r and t direction should be one plus a multiple of the number of rings and sectors, respectively. \nEdit\nInspired by faleichik's answer below, I've decided to implement his solution using textured triangles. There are basically two different triangles in the tessellation, one being the mirror image of the other. The other triangles are rotated and/or translated copies of either of these triangles which can be constructed from the base triangles using Rotate and Translate. Therefore, one way to get the tessellation is as follows:\nManipulate[\n DynamicModule[{texcrds, base, hex, im},\n  im = ImageResize[ExampleData[{\"TestImage\", \"Mandrill\"}], 100];\n\n  texcrds = offset + {{0, 0}, {1, 0}, {1/2, Sqrt[3]/2}};\n  base = {Polygon[{{0, 0}, {1, 0}, {1/2, Sqrt[3]/2}}, \n     VertexTextureCoordinates -> texcrds],\n    Polygon[{{0, 0}, {1, 0}, {1/2, -Sqrt[3]/2}}, \n     VertexTextureCoordinates -> texcrds]};\n  hex = Rotate[base, #, {0, 0}] & /@ {0, 2 Pi/3, -2 Pi/3};\n\n  Graphics[{Texture[im],\n    Translate[Translate[hex, {{0, 0}, {3/2, -Sqrt[3]/2}}], \n     Tuples[{3 Range[0, n/2], Range[0, n] Sqrt[3]}]]},\n   PlotRange -> {{-1/2, 3 n/2 + 1/2}, {-Sqrt[3]/2, n Sqrt[3]}}]],\n {{n, 3, \"resolution\"}, 1, 5, 1},\n {{offset, 0}, 0, 2}]\n\n\n", "matlab - Pass many variables in SQL query": "\nUse AND keyword in your SQL query for multiple criteria. You can use SPRINTF MATLAB function to insert variable parameters. I've also separated your query into multiple substrings for better readability.\nsql = sprintf( [ ...\n    'SELECT lic.licence_plate_num, lic.owner_name, lic.owner_address, '...\n    'lic.owner_tel_no, lic.owner_email, vio.violation_date, '...\n    'vio.violation_time, vio.vehicle_type, vio.violation_type '...\n    'FROM licence_plate_details lic RIGHT JOIN violated_vehicles vio '...\n    'ON lic.licence_plate_num = vio.licence_plate_num '...\n    'WHERE vio.vehicle_type = \"%s\" AND vio.violation_type = \"%s\"' ], ...\n    vehicle, violation_type );\n\n", "syntax - Why doesn't PatternTest work with Composition?": "\nBecause PatternTest binds very tightly. You need extra parentheses:\nMatchQ[3, _?(Composition[Not, OptionQ])]\n\n", "plotting - Series of piecewise  functions": "\nYou can pretty much enter your question in that form in Mathematica:\n\nThe first definition, f[x_, n_] /; n == 0, reads \"define $f_n(x)$ in the case of $n=0$ to be the following\". The fancy bracket is pretty frontend notation for the Piecewise function (shortcut: EscpwEsc). The next line is the same thing again, after that there's the definition of your function $f(x)$, which is the partial sum up to $\\mathcal N$. I don't think you can use $\\mathcal N=\\infty$ in this case, as it will exceed the maximum recursion depth by, well, infinity. If you want to have an exact result, try using RSolve to get an explcit equation for $f_n(x)$.\nIf you want to evaluate the code above on your own, here's a copyable version:\nf[x_, n_] /; n == 0 := Piecewise[{\n    {3 x, 0 <= x <= 1/3},\n    {-3 x + 2, 1/3 < x <= 2/3},\n    {3 x + 2, 2/3 < x <= 1},\n    {Indeterminate, True}\n}]\nf[x_, n_] /; n >= 0 := Piecewise[{\n    {1/3 f[3 x, n - 1], 0 <= x <= 1/3},\n    {1/3 + 1/3 f[3 x - 1, n - 1], 1/3 < x <= 2/3},\n    {2/3 + 1/3 f[3 x - 2, n - 1], 2/3 < x <= 1},\n    {Indeterminate, True}\n}]\nf[x_, _, \\[ScriptCapitalN]_] := Sum[(-1)^k f[x, k], {k, 0, \\[ScriptCapitalN]}]\nPlot[f[x, _, 10], {x, 0, 1}, PlotPoints -> 100, MaxRecursion -> 5]\n\nFor the third part of your question, simply define $p$ as an additional parameter for your function, so it's something like f[x_, n_, p_] := ..., and edit the definitions accordingly.\n", "Automatically counting the number of lines of code in a set of notebooks": "\nAssuming that the notebook object is contained in the variable nb (for the current notebook do nb = EvaluationNotebook[]), one could use the following:\nStringCount[\n First@FrontEndExecute@FrontEnd`ExportPacket[\n    Notebook@Cases[First@NotebookGet[nb], Cell[_, \"Input\"|\"Code\", ___]],\n    \"PlainText\"],\n \"\\n\"\n ]\n\nUsing \"InputText\" will wrap lines much more frequently and will give a substantially larger count.\nThis is equivalent to Alt-clicking an input cell to select all input cells, then copying the contents as \"plain text\" or \"input text\" and counting the lines.\nAs you can see, Mathematica does not really respect line breaks.  If you are trying to measure the volume of code, I suggest using the LeafCount of expressions instead of counting code lines.\n", "syntax - Differentiation w/o assiging concrete values": "\nThe error comes from the first line. I am not sure what the second does; finally, you differentiate with respect to s, but have a variable S, which is different.\nPerhaps you wanted to do this:\nv = v0*Sin[Pi*s/s0]\nD[v, s]\n\nwhich works.\nTo see the problem with recursion, run this:\nClearAll[v]\nv = Subscript[v, 0]\n\n\nWhat is happening is the same that happens if you evaluate k = k + 1.\n", "dynamic - I want to update a financial chart when I select a new stock from a popup menu": "\nI believe the easiest way to accomplish this is with Manipulate.\nManipulate[\n InteractiveTradingChart[\n  FinancialData[ticker, \n   \"OHLCV\", {{2008, 7, 3}, {2008, 9, 30}}]], {ticker, instruments}]\n\n\n", "signal processing - Numerical Fourier transform of a complicated function": "\nThere is the function NFourierTransform[] (as well as NInverseFourierTransform[]) implemented in the package FourierSeries`. The function, as with the related kernel functions, takes a FourierParameters option so you can adjust computations to your preferred normalization as needed. For your specific normalization, you apparently want the setting FourierParameters -> {1, 1}.\nNow, since NFourierTransform[] internally uses NIntegrate[], the function also takes options that can be passed to NIntegrate[]; you can thus change Methods as seen fit. I will in particular recommend that you look into the Method choices \"ExtrapolatingOscillatory\" (Longman's method), \"DoubleExponentialOscillatory\" (Ooura-Mori double exponential quadrature) and \"LevinRule\" (Levin's method), as well as the general controller method \"OscillatorySelection\". See this scicomp.SE answer for a short description of oscillatory quadrature methods and links to references, and NIntegrate Integration Strategies in the Mathematica help file for more details on how to employ them within Mathematica.\n", "plotting - Seeing the whole financial chart": "\nEdit\nMy initial answer seems to have missed the point, which was about how to call up InteractiveTradingChart[] with its controls initialized to some values other than defaults.\nSomeone more able than moi may want to examine the output from \nInteractiveTradingChart[{\"GOOG\", {{2009, 1, 1}, {2009, 12, 31}}}]\nFullGraphics[%] // InputForm\n\nand determine whether variables such as plotrangemin can be set by the programmer.\n\nThe date range you specify in the command sets the full time period you work with. The actual display is handled by the buttons and slider at the button of the chart.  If you click on the Max setter button, the whole period will be displayed.  If you click on the month button, one month will be displayed.  You may move to other months (than the one currently being displayed) by using the Slider.  Same respective behavior for Week.\nBy default, the chart does not display the full time period but rather only a part of it.\n \n", "plotting - What is the most efficient way to save a big graphic?": "\nFor a nice plot you don't need all the million points in your graphic. 10^10 points is a bit heavy for this curve, so why not using Plot? It has the advantage of adaptive sampling and it seems to do it absolutely correct in this case. The runtime is only about 1 second:\nPlot[100 PrimePi[x]/x, {x, 1, 10^10}, \n  PlotRange -> {Automatic, {0, 10}}]\n\n\nAnd even if you reduce your range, it catches all features\nPlot[100 PrimePi[x]/x, {x, 1, 50}, PlotRange -> Automatic]\n\n\nUpdate on Accuracy\nIn the comment you asked how accurate this is. I assume you mean \"are there enough points in the plot to represent important features?\" Consider the following Manipulate where you can visually inspect the sampling points in your plot with different settings for PlotPoints and MaxRecursion\nManipulate[\n Plot[100 PrimePi[x]/x, {x, 1, xEnd}, PlotRange -> Automatic, \n  Mesh -> All, MeshStyle -> Directive[PointSize[.005], Red], \n  MaxRecursion -> maxRecursion, PlotPoints -> plotPoints, \n  AxesOrigin -> {0, 0}],\n {xEnd, 10, 1000}, {maxRecursion, 0, 5, 1}, {plotPoints, 5, 30, 1}]\n\n\nBasically those options work like that: PlotPoints defines how many sampling points are in your region initially. With the MaxRecursion setting Plot has the opportunity to subdivide the region at places where the function is not represented properly. This can be deduced by some curvature measure, but what exactly Mathematica is using for this decision is afaik not documented. \nTherefore, MaxRecursion is more important to catch features than many PlotPoints alone. On the other hand when you want a plot from 1 to 10^10 than you are clearly more interested in the overall tendency of the function than in the structure of the sharp edges between 4 and 10, which couln't be displayed anyway.\nSo when you are asking about accuracy, I'm not really sure what to answer. Every (red) point you see above is as accurate as it would be in DiscretePlot and usually the default settings for Plot work nicely and catch most features you want to see. But to have a feeling for that you can now use the Manipulate and watch what happens. \nIn return I could ask, in your DiscretePlot do you see the difference between point 10^5 and point 10^5+1? Or is this maybe the wrong scale and you are more interested in the global bend from 0 to 2*10^9, because then you could leave out many points and exactly this is, what Plot tries to do. \n", "programming - Does AbsoluteTiming slow the evaluation time?": "\nIf you look in the Option Inspector, there's a setting called EvaluationCompletionAction that I keep set to \"ShowTiming\"\n\nThe result of this is that whenever an evaluation finishes, the amount of time it took is displayed in the status area at the bottom of the notebook\n\nThis saves me from needing to remember to wrap inputs in Timing or AbsoluteTiming.  \nOne thing to note is that the time shown includes the conversion of the kernel output to boxes as well as the MathLink transmission time.  I don't think it includes any time used by the frontend to draw the result to screen.\nThe downside is that there's no history.\n", "How do I export to Excel in multiple, named worksheets?": "\nUsing Export and specifying rules to create the sheet names:\nExport[\"sampledata.xlsx\", {\"list1\" -> list1, \"list2\" -> list2}]\n\n", "plotting - Plot draws list of curves in same color when not using Evaluate": "\nThe list structure is not manifest to Plot as it has the attribute HoldAll (to get a function's attributes, either use Attributes[func] or ??func). Hence Plot evaluates the Table functions as one unit and it appears as if there is only one function, not four. \nEvaluate will make the list structure manifest and each function will be plotted with a separate style.\n", "import - How do you convert a string containing a number in C scientific notation to a Mathematica number?": "\nI think probably the cleanest way to do this (at least, if you have only a single string, or are faced with a separate string for each number you wish to convert as a result of some other process) is to use the undocumented function Internal`StringToDouble, i.e.:\ns = \"1.23e-5\";\nInternal`StringToDouble[s]\n\nwhich gives:\n0.0000123\n\nHowever, if you are trying to convert many such numbers at once, the standard, documented methods (Import, Read, etc.), are likely to represent better approaches.\nUPDATE:  As of at least version 12.3 the proper way to invoke this is:\nInternal`StringToMReal[\"1.23e-5\"]\n\n", "formatting - What is the most convenient way to read definitions of in-memory symbols when we don't have the source files? (Spelunking tools)": "\nLink to the code on GitHub\n\nI have been using this. It's mostly Leonid's code from the stackoverflow question you linked to, but it uses Definition instead of DownValues. Symbol names are printed without any context, but the full symbol name is put into a Tooltip so you can always find out what context a symbol is in.\nUpdate\nFullDefinition[symbol] claims to \"print the definitions given for symbol, and all symbols on which these depend\", but sometimes one wants to explore deeper than the first level of dependency. Here is a version of Spelunk which uses plain Definition instead of FullDefinition, but allows you to click on symbols in the definition to get their definition. So you can dig right down into the dependency chain.\nUpdate 2\nThe code now copes with definitions containing strings with backticks in, and cases where Definition throws an error.\nAlso, it now works for symbols which have OwnValues, e.g. Internal`$VideoEncodings.\nBeginPackage[\"Spelunk`\"];\n\nSpelunk::usage = \"Spelunk[symbol]\";\n\nBegin[\"`Private`\"];\n\ndefboxes[symbol_Symbol] := Hold[symbol] /. _[sym_] :>\n        If[MemberQ[Attributes[sym], Locked], \"Locked\",\n          Internal`InheritedBlock[{sym},\n            Unprotect[sym]; ClearAttributes[sym, ReadProtected];\n            Quiet@Check[ToBoxes[Definition@sym], \"DefError\"] /. \n            InterpretationBox[a_, b___] :> a ]];\n\ndefboxes[s_String] := defboxes[#] &@ToExpression[s, InputForm, Unevaluated]\n\nprettyboxes[boxes_] := \n  boxes /. {\" \"} -> {\"\\n-----------\\n\"} //. {RowBox[{left___, \";\", \n       next : Except[\"\\n\"], right___}] :> \n     RowBox[{left, \";\", \"\\n\", \"\\t\", next, right}], \n    RowBox[{sc : (\"Block\" | \"Module\" | \"With\"), \"[\", \n       RowBox[{vars_, \",\", body_}], \"]\"}] :> \n     RowBox[{sc, \"[\", RowBox[{vars, \",\", \"\\n\\t\", body}], \"]\"}]};\n\nfancydefinition[symbol_Symbol] :=\n  Cell[BoxData[\n    prettyboxes[\n     defboxes[symbol] /. \n      s_String?(StringMatchQ[#, __ ~~ \"`\" ~~ __] &) :> \n       First@StringCases[s, \n         a : (__ ~~ \"`\" ~~ b__) :> processsymbol[a, b]]]], \"Output\", \n   Background -> RGBColor[1, 0.95, 0.9],\n   CellGroupingRules->\"OutputGrouping\",\n   GeneratedCell->True,\n   CellAutoOverwrite->True,\n   ShowAutoStyles->True,\n   LanguageCategory->\"Mathematica\",\n   FontWeight->\"Bold\"\n];\n\nprocesssymbol[a_, b_] := Module[{db},\n  Which[\n   ! StringFreeQ[a, \"\\\"\"], a,\n   ! StringFreeQ[a, \"_\"] || (db = defboxes[a]) === \"Null\", \n   TooltipBox[b, a],\n   db === \"Locked\", TooltipBox[b, a <> \"\\nLocked Symbol\"],\n   db === \"DefError\", TooltipBox[b, a <> \"\\nError getting Definition\"],\n   True, ButtonBox[TooltipBox[b, a], ButtonFunction :> Spelunk@a, \n    BaseStyle -> {}, Evaluator -> Automatic]]]\n\nSpelunk[symbol_Symbol] := CellPrint[fancydefinition[symbol]];\n\nSpelunk[s_String] := CellPrint[fancydefinition[#] &@ToExpression[s, InputForm, Unevaluated]];\n\nSetAttributes[{defboxes, fancydefinition, Spelunk}, HoldFirst] \n\nEnd[];\n\nEndPackage[];\n\n", "output formatting - List of different values which have to be formatted differently": "\n(edit: you should use lower-case letters to start user function names so as not to conflict with built-ins.)\nPlease tell me if this does what you want:\nformats[{}, _] = {};\nformats[list_, 1] := NumberForm[N[list], {3, 2}]\nformats[list_, 5] := DateString[list, {\"Quarter\", \" \", \"Year\"}]\n\n\nTesting.  With dat1 set to your Out[2259]=, and dat2 set to your Out[2265]= :\nMap[{First[First[#]], formats[Last[#], 1]} &, dat1]\n\n\n{{Australia,{}},{Austria,-1.21},{Belgium,-1.46},{Canada,-1.30},{Czech\n  Republic,-1.67},{Denmark,-1.87},{Estonia,-3.97},{Finland,-2.53},{France,-1.00},{Germany,-1.74},{Greece,-1.16},{Hungary,-1.45},{Iceland,-1.83},{Ireland,-1.67},{Israel,{}},{Italy,-1.42},{Japan,-0.69},{Korea,{}},{Luxembourg,-1.67},{Netherlands,-0.98},{New\n  Zealand,-0.50},{Norway,-0.64},{Poland,{}},{Portugal,-0.40},{Republic\n  Slovak,{}},{Slovenia,-3.31},{Spain,-0.71},{Sweden,{}},{Switzerland,-0.82},{Turkey,-3.39},{Kingdom\n  United,-1.45},{States United,-1.28}}\n\nMap[{First[First[#]], formats[Last[#], 5]} &, dat2]\n\n\n{{Australia, {}}, {Austria, \"1 2008\"}, {Belgium, \"2 2008\"}, {Canada,\n  \"3 2008\"}, {Czech Republic, \"3 2008\"}, {Denmark,    \"2 2008\"},\n  {Estonia, \"2 2008\"}, {Finland, \"2 2008\"}, {France,    \"1 2008\"},\n  {Germany, \"1 2008\"}, {Greece, \"3 2008\"}, {Hungary,    \"1 2008\"},\n  {Iceland, \"3 2008\"}, {Ireland,    \"4 2007\"}, {Israel, {}}, {Italy, \"1\n  2008\"}, {Japan,    \"3 2010\"}, {Korea, {}}, {Luxembourg, \"1 2008\"},\n  {Netherlands,    \"1 2008\"}, {New Zealand, \"4 2007\"}, {Norway,    \"2\n  2008\"}, {Poland, {}}, {Portugal,    \"3 2010\"}, {Republic Slovak, {}},\n  {Slovenia, \"3 2008\"}, {Spain,    \"1 2008\"}, {Sweden, {}},\n  {Switzerland, \"2 2008\"}, {Turkey,    \"1 2008\"}, {Kingdom United, \"1\n  2008\"}, {States United, \"2 2008\"}}\n\n", "front end - How to anchor a Pane's scroll position to the bottom?": "\nI was busy exploring this problem on my own for some time now, and was not satisfied with any of the answers. They both work for some extent, but, concerning Szabolcs's answer, I would like to avoid image-processing and in case of Mr.Wizard's answer there are slight problems with it during startup (see comments) and it breaks down when the scroll position is defined as a dynamic variable itself. Thus I set out to find a better solution.\nThe problem\nFirst, I want to clearly state the problem (at least what my problem was originally): given a Pane that listens to a dynamic variable text, I have to update it such that whenever text changes by a controller (e.g. a button), the Pane is automatically scrolled down to the actual end of content. But I also want to keep both the manipulable scrollbar of the Pane and the possibility to manipulate the vertical scroll position pos via another external controler (e.g. a slider). Thus the resulting Pane must be updated differently, depending on whether text or pos triggers an update.\nI present two solutions, the second one being the better one in my opinion. For both cases, I exploit the fact that if the initial vertical scroll position value (pos) is set large enough, Mathematica automatically finds and sets the scroll position to the end of content.\n1. Injecting code in the external controller\nThe simpler method is to separate the different updates by assigning them to the external controllers. Here, a button is provided that updates text externally (external to the dynamic Pane object), but it also directly redraws the Pane to find the end-of-content position.\npos = 1000; (* vertical scroll position *) \nc = 5; (* text update counter *)\ntext = \"1\\n2\\n3333333333333333\\n44\";\n\n(* note that this button explicitly contains the update[] code *)\nButton[\"Update text\", cc = c++; text = text <> \"\\n\" <> \n   StringJoin@Table[ToString@cc, {RandomInteger@{1, 15}}] <> \"<\"; pane = update[]]\nupdate[] := (\n   pos = pos + 1000; \n   Framed@Pane[Dynamic@text, ImageSize -> {120, 60}, \n     Scrollbars -> {False, True}, \n     ScrollPosition -> Dynamic[{0, pos}, (pos = Last@#) &]]\n  );\n\npane = update[]; (* initialize Pane *)\n{Dynamic@pane, Dynamic@pos}\n\nNote that updating text via the button or via the scrollbar correctly updates pane and pos. The only problem here is that one has to manually put the pane = update[] code into the controller, which is unwanted (at least in my case), as one only wants to change text via the button.\n2. Separating updates via selective triggers\nThe beautiful answer by @Leonid provides a method to selectively separate different update methods of a dynamic expression depending on which \"parent\" variable triggers an update.\nSetAttributes[makeTrigger, HoldAll];\nmakeTrigger[res_, var_, updateCode_] := Module[{varOld = var, trigger}, \n   trigger /; varOld =!= var := (varOld = var; res = updateCode); \n   trigger];\n\npos = 1000;\nc = 5;\ntext = \"1\\n2\\n3333333333333333\\n44\";\nsize = {120, 60};\n\nButton[\"Update text\", cc = c++; text = text <> \"\\n\" <> \n   StringJoin@Table[ToString@cc, {RandomInteger@{1, 15}}] <> \"<\";]\nRow@{\"Update pos: \", Slider[Dynamic@pos, {0, 200}]}\nupdate[] := Framed@Pane[text, ImageSize -> Dynamic@size, \n    Scrollbars -> {False, True}, \n    ScrollPosition -> Dynamic[{0, pos}, (pos = Last@#) &]];\n\n(* triggers ONLY if text is changed! *)\ntrigger = makeTrigger[pane, text, (pos = pos + 1000; update[])];\npane = update[]; (* initialize pane *)\n{With[{tr = trigger}, Dynamic[tr; pane, TrackedSymbols :> {text, pos}]], Dynamic@pos}\n\n\n(The \"<\" character indicates the end of newly added content.)\nFirst, a trigger is set up in the final line, that listens to whether text or pos is changed. If only pos is changed, then the resulting expression becomes Dynamic[pane], updating the vertical scroll position as required. However, if text is changed, then trigger triggers and update[] kicks in, redrawing the whole Pane object from scratch, finding and setting the correct end-of-content position.\nNow it became possibly to have various controllers only updating independent variables (like text, pos, etc.) and a dependent expression that listens to the independent variables and updates according to which of them was triggered.\n", "calculus and analysis - Kramers-Kronig relations": "\nI think you intended to use {li, 200, 800} instead of {li, 800, 200}.\nIf you do so, then you could visualize the result :\nListLinePlot@dnFpoints\n\n\nMoreover I would rather define  daF in the following form :\ndaF[l_]:= 500 * 0.28 Exp[-((l - 500)/90)^2]\nc = 3 10^8;\n\nEdit\nInstead of using Table of dnFpoints I add an alternative method for calculation of dnF function.\ndnF[ln_] := \n  1/( 4c Pi^3 10^18 ) NIntegrate[ daF[li] / ( 1/li^2 - 1/ln^2 ), \n                                  { li, -\\[Infinity],  ln, \\[Infinity] }, \n                                  Method ->  \"PrincipalValue\", \n                                  Exclusions ->  Automatic  \n                                ] // Quiet\n\nIn general one should choose appropriate options for NIntegrate like PrecisionGoal and MaxRecursion  however in this case it is quite sufficient to use Quiet for evaluating of dnF function without outputting any messages generated.\nNow we can plot dnF function  increasing appropriately a range of the dependent variable, e.g. :\nPlot[dnF[ln], {ln, 30, 900}, AxesOrigin -> {0, 0}, PlotPoints -> 200]\n\n\n", "list manipulation - Finding time-series direction reversal of certain magnitude": "\nYou seem to be on the right track.  If I understand your question I believe this will help:\nf = If[#2 + 4 <= #, -\u221e, Max[##]] &;\n\nFoldList[f, ts]\n\nPosition[%, -\u221e, {1}]\n\n(See Shorter syntax for Fold and FoldList? regarding FoldList[f, ts].) \nThe above assumes that you want to reset the new maximum to the value after the reversal (3).\nIf you want to reset it to the reversal point value itself, try this:\nf = If[#2 + 4 <= Max@#, {#2}, Max[##]] &;\n\nFoldList[f, ts]\n\nPosition[%, {_}, {1}]\n\n\nI argue the superiority of the FoldList method over Module/MapIndexed.  The latter introduces a variable that it does not need to, it is longer, and it is slower.\nSeedRandom[1]\nts = RandomInteger[20, 50000];\n\nTiming[\n  r1 =\n   Module[{max = -\u221e}, \n       MapIndexed[(max = Max[max, #1]; \n           If[max - #1 >= 4, Sow[#2]; max = -\u221e;]) &, ts];] //\n       Reap // Last // Flatten;\n]\n\n\n{0.1966, Null}\n\nf = If[#2 + 4 <= #, -\u221e, Max[##]] &;\n\nTiming[\n  r2 = Join @@ Position[FoldList[f, #, {##2}] & @@ ts, -\u221e, 1];\n]\n\n\n{0.0874, Null}\n\nr1 === r2\n\n\nTrue\n\n", "performance tuning - Function does not compile with Greater in it": "\nThe following seems to work based on what I assumed would be valid input.\ncompiledFunc = \n  Compile[{{w, _Real, 2}, {v, _Integer, 1}, {hb, _Real, \n     1}, {vb, _Real, 1}}, \n   Module[{h, hs, vr, hr, rr}, h = 1./(1. + Exp[-(w.v + hb)]);\n    rr = RandomReal[{0, 1}, Length@hb];\n    rr = h - rr;\n    hs = UnitStep[rr] Unitize[rr];\n    vr = 1./(1. + Exp[-((Transpose@w).hs + vb)]);\n    hr = 1./(1. + Exp[-(w.vr + hb)]);\n    w + (0.01*(Outer[Times, h, v] - Outer[Times, hr, vr]))], \n   Parallelization -> True];\n\nEdit:\nSince you are comparing to random reals we can safely assume none of the elements of hb will ever equal the pseudo-random values and remove the Unitize[rr] from the code. The above is for a more general comparison where equality can occur. Here is the cleaned up but less general version.\ncompiledFunc = \n  Compile[{{w, _Real, 2}, {v, _Integer, 1}, {hb, _Real, \n     1}, {vb, _Real, 1}}, \n   Module[{h, hs, vr, hr}, h = 1./(1. + Exp[-(w.v + hb)]);\n    hs = UnitStep[h-RandomReal[{0, 1}, Length@hb]];\n    vr = 1./(1. + Exp[-((Transpose@w).hs + vb)]);\n    hr = 1./(1. + Exp[-(w.vr + hb)]);\n    w + (0.01*(Outer[Times, h, v] - Outer[Times, hr, vr]))], \n   Parallelization -> True];\n\nAs for the second part of the question, apparently Compile doesn't like Boole being applied outside of MapThread. OleksandrR explained why in the comments. Compile cannot work with the boolean tensor that is created by MapThread. You can replace the line with \nMapThread[Boole[#1 > #2] &, {h, RandomReal[{0, 1}, Length@hb]}]\n\nand it should work.\n", "evaluation - With/Function(/etc) replacement behaviour": "\nYou were asking why\nf[_?NumericQ] := 8\n\nWith[{a = f[a]}, Block[{NumericQ = True &}, a]]\n\noutputs f[a].\nThis is because of caching of the result of Conditions and PatternTests.  Compare with this:\nWith[{a = f[a]}, Block[{NumericQ = True &}, Update[]; a]]\n\n(* ==> 8 *)\n\nGenerally, making global changes that might affect the outcome of a Condition will have unpredictable results due to caching---unless you use Update[] after each change.\nPlease see also the last paragraph of Controlling Infinite Evaluation.\n", "programming - ParallelTable and Table do not give same result": "\nWhy the unexpected result?\nYou quoted the documentation:\n\nParallelize[Table[expr,iter, \u2026]] (which is equivalent to\nParallelTable[expr,iter,\u2026]) will give the same results as Table,\nexcept for side effects during the computation.\n\nThe explanation why the parallelized version returns an incorrect result is that your code does have side effects: you are using Set (i.e. =) to change the elements of an array.\nWhat is a side effect?\nLet me illustrate using ParallelMap:\nIf we have a list of values list = {1, 2, 3, 4, 5, 6, 7, 8}, and we wish to evaluate a function for all these values, we can use Map:\nf /@ list\n\nThis is easily parallelized to two processors by splitting the list into two parts (list1 = {1, 2, 3, 4} and list2 = {5, 6, 7, 8}), sending them to two different Mathematica kernels running on these two processors, and performing the map operation on the two sublists separately:\nf /@ list1 (* evaluated on processor 1 *)\nf /@ list2 (* evaluated on processor 2 in parallel *)\n\nThe reason this works at all is that these two operation are completely independent: the result of one does not depend on the evaluation of the other.\nActually this is only true if f is a function in the mathematical sense: it simply takes an input and produces an output, but computing its value does not change the \"outside world\" (the Mathematica kernel's user-visible state) in any way.  Examples: Sin is a function without side effects in this sense.  Print is not without side effect because while its value is being computed (it always returns Null), the outside world changes: something appears on your screen.  Set also has side effects because it induces permanent outside changes again: the value of a variable will be different after evaluating Set.\nIf our function f has side effects then there is no guarantee that {f[1], f[2]} will give the same result as {f[2], f[1]} because evaluating f[1] might change the environment in a way that will affect the outcome of f[2].  The order of evaluation might matter, so parallelization cannot work reliably (the order of evaluation is unpredictable in any kind of parallel evaluation).\nYou are using Set (i.e. =) in your code, which has side effects.  What actually happens is that a copy of arrayToBeFilled is sent to both subkernel 1 and subkernel 2, and different parts of the array are changed on the two subkernels.  But the changed arrayToBeFilled is not being sent back to the main kernel (which one should be sent back at all?  the one on subkernel 1 or the one on subkernel 2?  they are different because different indices have been changed on the two subkernels)\nHow to make the code auto-parallelizable?\nWe just need to write the expression to be computed in a way that avoids side effects:\narrayToBeFilled = \n   Parallelize[Map[If[# <= 0, # + 5, # - 5] &, arrayA]]; // AbsoluteTiming\n\nThis is both much faster and parallelizable.  In fact it's so fast that when the array is only 1000 elements long the parallelization overhead will just slow the computation down.  (For much larger arrays though it will speed it up.)\n", "syntax - Working with PhysicalConstants": "\nAs J.M. comments, but opts not to post as an answer, you can use Convert in the Units package to convert between types.  Be sure to read the documentation on that package.\nNeeds[\"Units`\"]\n\nConvert[(32.5 Newton)/(7 Meter/Second^2), Kilogram]\n\n\n4.64286 Kilogram\n\nYou will also find use in the Automatic Units package described on the Wolfram Blog.\n", "interoperability - Web Browsing Automation with Mathematica": "\nHere is a package which does what you want:\nhttps://github.com/arnoudbuzing/webunit\nClone the repository from github, and place the WebUnit folder under $UserBaseDirectory/Applications\nTo use it:\n\nNeeds[\"WebUnit`\"]\nInstallWebUnit[] (* launches chromedriver.exe *)\nStartWebSession[] (* launches Chrome web browser, assuming you have that installed *)\nOpenWebPage[\"http://mathematica.stackexchange.com\"] (* opens the web page *)\nClickElement[Id[\"nav-users\"]] (* clicks the web element 'nav-users' the users tab *)\n\nAnd then TypeElement works similarly (assuming you have an input field with an id).\nEdit: You can also use JavascriptExecute[\"alert('hi');\"] to execute arbitrary javascript (in this example case it brings up the alert dialog).\n", "plotting - How can I set the ratio of the axis to 1:1 when plotrange->1 or how can I scale a rectangle according to the axis": "\nDepending on your needs is may be both simpler and more flexible to bypass ListPlot completely and do this directly in Graphics.  Here is a simple example:\ndat = RandomReal[11, {15, 2}];\n\nGraphics[{\n   {Hue @ RandomReal[], Rectangle[# - 0.5]} & /@ #,\n   {GrayLevel[.3], PointSize[.02], Point@#, Thick, Line@#}\n  },\n  AspectRatio -> 0.5,\n  Frame -> True\n] & @ dat\n\n\n", "plotting - How to plot planar graphs as such?": "\nYou can plot it using the GraphLayout option, which has, since v9, \"PlanarEmbedding\" as a possible value:\nGraph[Rule @@@ {{1, 2}, {2, 3}, {3, 1}, {1, 4}, {3, 4}, {2, 4}}, GraphLayout -> \"PlanarEmbedding\"]\n\n.\n(BTW: This is the standard Mathematica Graph, not the Combinatorica Graph function)\nAnother one:\ntruncatedCube =\n  {{0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1}, {1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1}, \n   {1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1}, {1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0}, \n   {0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0}, {1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0}, \n   {0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0}, {1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0}, \n   {0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0}, {1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, \n   {0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0}, {1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0}, \n   {0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0}, {1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}};\n\nAdjacencyGraph[truncatedCube, \n  GraphLayout -> \"PlanarEmbedding\", \n  VertexLabels -> Array[# -> # &, Length @ truncatedCube], \n  PlotRangePadding -> 0.5]\n\n\nWithout GraphLayout -> \"PlanarEmbedding\":\n\n", "How to force Compile to return multiple results?": "\nWhat about making the result uniform inside Compile and constructing things back afterwards? Like\n   cFunc = Compile[\n       {{a, _Integer, 1}}, \n       Join @@ {a, {a . a}}]; \ncFunc[{1, 3}]\nFunction[z, {Most[z], \n       Last[z]}][%]\n\nwhich has the nice feature of not calling MainEvaluate:\n    Needs[\"CompiledFunctionTools`\"]; cFunc // CompilePrint\n\n(* \n==>\n    1 argument\n        2 Integer registers\n        3 Tensor registers\n        Underflow checking off\n        Overflow checking off\n        Integer overflow checking on\n        RuntimeAttributes -> {}\n\n        T(I1)0 = A1\n        I0 = 4\n        Result = T(I1)2\n\n1   I1 = DotVV[ T(I1)0, T(I1)0, I0]]\n2   T(I1)1 ={ I1 }\n3   T(I1)2 = Join[ T(I1)0, T(I1)1]]\n4   Return\n\n*)\n\n", "Workbnch Profil[] qustion - Mathmatica Stack Exchang": "\nIf you can settle for anything other than Workbench's Profile, here is a simplistic profiler function with a fairly low latency:\nClearAll[profile];\nSetAttributes[profile, HoldAll];\nprofile[code_] :=\n  Block[{$totalTime = 0, t, res, time,exclude},\n     SetAttributes[{time, exclude}, HoldAll];\n     exclude[cd_] := \n       (t = AbsoluteTime[];res = cd; $totalTime -= AbsoluteTime[] - t; res);\n     time[cd_] := \n       (t = AbsoluteTime[];res = cd; $totalTime += AbsoluteTime[] - t; res);\n     {code, $totalTime}];\n\nTo illustrate how you can use it:\nb[] := Do[Range[10], {100}];\naa[] :=\n  Module[{},\n     Pause[2];\n     Do[time@b[], {1000}];\n     Pause[3];\n  ];\n\nNote that I inserted time wrapper in the place in the code which I want to profile. All invocations of time will add up:\nprofile[aa[]]\n\n(*\n   ==> {Null, 0.0791}\n*)\n\nNote that profile has some overhead, but it seems to at least give the right order of magnitude for the result:\na[] :=\n  Module[{},\n     Pause[2];\n     time@Do[b[], {1000}];\n     Pause[3];\n  ]; \n\nprofile[a[]]\n\n(*\n   ==> {Null,0.0781250}\n*)\n\nThe granularity may be not as good as in Profile, but in case it is not enough (meaning you are timing something very fast), you should try to wrap time around pieces of code where your very fast operation is repeated (like loops). You can wrap pieces inside those which you want to exclude, in the exclude wrapper. Obviously, the code or functions it uses should not use the symbols time and exclude for other purposes, but this is easy to fix by placing profile into a separate context / package.\n", "programming - Deploying Mathematica Content Online": "\nYou cannot use CDF for this because you have textual import fields and these are not supported when you embed online. You will just get a big grey box. InputField cannot accept strings (non-numeric) for online CDFs unless you are Wolfram Research and can override it. (I'm guessing you don't want to pay many thousands for CDF Pro.)\nYou also cannot import and export into an online embedded CDF, not even a Pro CDF (got that first hand from Wolfram). This is for security reasons.\nSo to create something like you have described using Mathematica and have online, the only possible way to do it, it would seem, is to use webMathematica. \n", "matrix - Take[] and other Mathematica functions with live streams": "\nThe question doesn't provide enough specifics to give a very detailed answer but here are a couple of things that might help get you started.\nFirst, here I use my webcam's CurrentImage with ColorConvert to create a live grayscale video.  Note the semicolon.  If you are going to be doing a lot of dynamic video stuff the additional outputs will slow things down.\nimg = Dynamic@ColorConvert[CurrentImage[], \"Grayscale\"];\n\nThere are a whole host of image processing capabilities that I would try first before digging into the matrix data themselves.  Chances are good, you will find what you want there without having to reinvent the wheel.  Here I use ImagePartition to break the image live video into blocks 64x64 pixels. Note the use of Dynamic.  This ensures that this updates rather than grabbing the value of img at evaluation.\nDynamic[ImagePartition[img[[1]], 64]]\n\nNow if you don't find what you need in image processing you can still get the image data. Here I obtain the first 18x12 matrix of color values using ImageData and Part.  \nDynamic[ImageData[img[[1]]][[1 ;; 18, 1 ;; 12]]]\n\nSome notes: \nOne reason you might have been having difficulty is that the head of img is Dynamic not Image.  This is why I take img[[1]] every time I use it.\nIn[119]:= Head[img]\n\nOut[119]= Dynamic\n\nIn[120]:= Head[img[[1]]]\n\nOut[120]= Image\n\nAlso, you want to make sure you save very often and that you are familiar with the menu command Evaluation>Dynamic Updating Enabled.  Working with live video will cause you a number of headaches and you don't want to lose hard work.'\nEdit: \nIn response to the answer to your own question. First off, you've placed \"Byte\" in the wrong place. It should be an argument to ImageData.  Once you've fixed that it should just work.  Here is my interpretation of the 1/2 byte data for the first 18x12 submatrix.\nDynamic[Floor[ImageData[img[[1]], \"Byte\"][[1 ;; 18, 1 ;; 12]]/2]]\n\nEdit 2:\nNow if you want the Mean of this dynamic byte data we could use\nrawimg = Dynamic[Floor[ImageData[img[[1]], \"Byte\"][[1 ;; 18, 1 ;; 12]]/2]];\n\nDynamic[Mean[rawimg[[1]]]]\n\n", "import - Importing .txt or .csv financial data": "\nOverall, your data is just badly formatted. For instance, later in the list your dates look similar to \"3-Mar\" which is interpreted as the third of March not March 2003, as you intended. For the most part, this is not your fault, but Excel arbitrarily formats data, and you have to be vigilant that it doesn't misinterpret it. Towards that end, I've rewritten my answer to work around the misformatting.\nFirst things first, your numeric data is formatted with commas, so we need to get rid of them.\nkillCommas[a_String] := StringReplace[a, \",\" -> \"\"]\nkillCommas[a_] := a\n\nSecond, your dates, as I said above, are misformatted. The code, below, splits the date at \"-\", checks if the numeric part has length 1 and prepends it with a \"0\" if it does, sorts the two strings by length, reverses the sort, and puts them back together with \"-\" between. \nfixDate[a_String] := StringJoin@\n  Riffle[Reverse[\n    If[StringLength[#] == 1, \"0\" <> #, #] & /@ \n     SortBy[StringSplit[a, \"-\"], StringLength]],\n   \"-\"]\n\nNow, I strip off the header from the list\ndat = Import[<txt url>, \"TABLE\"][[2 ;;]] \n\nand using the helper functions, I fix all of the data:\n{DateList[{fixDate[#1], {\"MonthNameShort\", \"YearShort\"}}],\n   Sequence @@ ToExpression[ killCommas /@ {##2}]} & @@@ dat\n\n", "guidelines - How to compile effectively?": "\nI'll just throw in a few random thoughts in no particular order, but this will be a rather high-level view on things. This is necessarily a subjective exposition, so treat it as such.\nTypical use cases\nIn my opinion, Compile as an efficiency-boosting device is effective in two kinds of situations (and their mixes):\n\nThe problem is solved most efficiently with a procedural style, because for example an efficient algorithm for it is formulated procedurally and does not  have a simple / efficient functional counterpart (note also that functional programming in Mathematica is peculiar in many respects, reflecting the fact that functional layer is a thin one on top of the rule-based engine. So, some algorithms which are efficient in other functional languages may be inefficient in Mathematica). A very clear sign of it is when you have to do array indexing in a loop.\nThe problem can be solved by joining several Compile-able built-in functions together, but there are (perhaps several) \"joints\" where you face the performance-hit if using the top-level code, because it stays general and can not use specialized versions of these functions, and for a few other reasons. In such cases, Compile merely makes the code more efficient by effectively type-specializing to numerical arguments and not using the main evaluator. One example that comes to mind is when we compile Select with a custom (compilable) predicate and can get a substantial performance boost (here is one example).\n\nI use this rule of thumb when determining whether or not I will benefit from Compile: the more my code inside Compile looks like C code I'd write otherwise, the more I benefit from it (strictly speaking, this is only true for the compilation to C, not MVM).\nIt may happen that some portions of top-level code will be the major bottleneck and can not be recast into a more efficient form, for a given approach to the problem. In such a case, Compile may not really help, and it is best to rethink the whole approach and try to find another formulation for the problem.  In other words, it often saves time and effort to do some profiling and get a good idea about the real places where the bottlenecks are, before turning to Compile.\nLimitations of Compile\nHere is an (incomplete) list of limitations, most of which you mentioned yourself\n\nCan only accept regular arrays (tensors) of numerical or boolean types. This excludes ragged arrays and more general Mathematica expressions.\nIn most cases, can only return a single tensor of some type\nOnly machine-precision arithmetic\nFrom the user-defined functions, only pure functions are compilable, plus one can inline other compiled functions. Rules and \"functions\" defined with rules are inherently not compilable.\nNo way to create functions with memory (a-la static variables in C)\nOnly a small subset of built-in functions can be compiled to byte-code (or C)\nPossibilities for writing recursive compiled functions seem to be very limited, and most interesting cases seem to be ruled out\nNo decent pass-by-reference semantics, which is a big deal (to me anyways)\nYou can not really use indexed variables in Compile, although it may appear that you can.\n...\n\nWhether or not to compile to C?\nI think this depends on the circumstances. Compilation to C is expensive, so this makes sense only for performance-critical code to be used many times. There are also many cases when compilation to MVM will  give similar performance, while being much faster. One such example can be found in this answer, where the just-in-time compilation to MVM target led to a major speed-up, while compilation to C would have likely destroyed the purpose of it - in that particular case. \nAnother class of situations when compiling to C is may not be the best option is when you want to \"serialize\" the CompiledFunction object, and distribute it to others, for example in a package, and you don't want to count on a C compiler being installed on the user's machine. As far as I know, there is no automatic mechanism yet to grab the generated shared library and package it together with the CompiledFunction, and also one would have to cross-compile for all platforms and automatically dispatch to the right library to load. All this is possible but complicated, so, unless the speed gain can justify such complications for a given problem, it may be not worth it, while compilation to MVM target creates the top-level CompiledFunction object, which is automatically cross-platform, and does not require anything (except Mathematica) to be installed.\nSo, it really depends, although more often than not compilation to C will lead to faster execution and, if you at all decide to use Compile, will be justified.\nWhat to include in Compile\nI share an opinion that, unless you have some specific requirements, it is best to only use Compile on minimal code fragments which would benefit from it the most, rather than have one big Compile. This is good because:\n\nIt allows you to better understand where the real bottlenecks are\nIt makes your compiled code more testable and composable\nIf you really need it, you can then combine these pieces and use \"InlineCompiledFunctions\" -> True option setting, to get all the benefits that one large Compile would give you\nSince Compile is limited in what it can take, you will have less headaches on how to include some uncompilable pieces, plus less chances to overlook a callback to the main evaluator\n\nThat said, you may benefit from one large Compile in some situations, including:\n\nCases when you want to grab the resulting C code and use it stand-alone (linked against Wolfram RTL)\nCases when you want to run your compiled code in parallel on several kernels and don't want to think about possible definitions distribution issues etc (this was noted by @halirutan)\n\nListable functions\nWhen you can, it may be a good idea to use the RuntimeAttributes -> Listable option, so that your code can be executed on (all or some) available cores in parallel. I will give one example which I think is rather interesting, because it represents a problem which may not initially look like one directly amenable to this (although it is surely not at all hard to realize that parallelization may work here) - computation of Pi as a partial sum, of a well-known infinite sum representation. Here is a single-core function:\nClear[numpi1];\nnumpi1 = \n   Compile[{{nterms, _Integer}}, \n      4*Sum[(-1)^k/(2 k + 1), {k, 0, nterms}], \n        CompilationTarget -> \"C\", RuntimeOptions -> \"Speed\"];\n\nHere is a parallel version:\nnumpiParallelC = \n  Compile[{{start, _Integer}, {end, _Integer}}, \n    4*Sum[(-1)^k/(2 k + 1), {k, start, end}], CompilationTarget -> \"C\",\n       RuntimeAttributes -> Listable, RuntimeOptions -> \"Speed\"];\n\nClear[numpiParallel];\nnumpiParallel[nterms_, nkernels_] := \n  Total@Apply[numpiParallelC, \n     MapAt[# + 1 &, {Most[#], Rest[#] - 1}, {2, -1}] &@\n        IntegerPart[Range[0, nterms, nterms/nkernels]]];\n\nNow, some benchmarks (on a 6-core machine):\n(res0=numpiParallel[10000000,1])//AbsoluteTiming\n(res1=numpiParallel[10000000,6])//AbsoluteTiming\n(res2=numpi1[10000000])//AbsoluteTiming\nChop[{res0-res2,res0-res1,res2-res1}]\n\n(*\n ==>\n {0.0722656,3.14159}\n {0.0175781,3.14159}\n {0.0566406,3.14159}\n {0,0,0}\n*)\n\nA few points to note here:\n\nIt may happen that the time it takes to prepare the data to be fed into a Listable compiled function, will be much more than the time the function runs (e.g. when we use Transpose or Partition etc on huge lists), which then sort of destroys the purpose. So, it is good to make an estimate whether or not that will be the case.\nA more \"coarse-grained\" alternative to this is to run a single-threaded compiled function in parallel on several Mathematica kernels, using the built-in parallel functionality (ParallelEvaluate, ParallelMap, etc). These two possibilities are useful in different situations.\n\nAuto-compilation\nWhile this is not directly related to the explicit use of Compile, this topic logically belongs here. There are a number of built-in (higher-order) functions, such as Map, which can auto-compile. What this means is that when we execute\nMap[f, list]\n\nthe function f is analyzed by Map, which attempts to automatically call Compile on it (this is not done at the top-level, so using Trace won't show an explicit call to Compile). To benefit from this, the function f must be compilable. As a rule of thumb, it has to be a pure function for that (which is not by itself a sufficient condition) - and generally the question of whether or not a function is compilable is answered here in the same way as for explicit Compile. In particular, functions defined by patterns will not benefit from auto-compilation, which is something to keep in mind. \nHere is a little contrived but simple example to illustrate the point:\nsumThousandNumbers[n_] := \n   Module[{sum = 0}, Do[sum += i, {i, n, n + 1000}]; sum]\n\nsumThousandNumbersPF = \n   Module[{sum = 0}, Do[sum += i, {i, #, # + 1000}]; sum] &\n\nNow, we try:\nMap[sumThousandNumbers, Range[3000]]//Short//Timing\nMap[sumThousandNumbersPF, Range[3000]]//Short//Timing\n\n(*\n  ==> {3.797,{501501,502502,503503,504504,505505,<<2990>>,3499496,\n               3500497,3501498,3502499,3503500}}\n\n      {0.094,{501501,502502,503503,504504,505505,<<2990>>,3499496,\n               3500497,3501498,3502499,3503500}}\n*)\n\nwhich shows a 40-times speedup in this particular case, due to auto-compilation.\nThere are in fact many cases when this is important, and not all of them are as obvious as the above example. One such case was considered in a recent answer to the question of extracting numbers from a sorted list belonging to some window. The solution is short and I will reproduce it here:\nwindow[list_, {xmin_, xmax_}] := \n    Pick[list, Boole[xmin <= # <= xmax] & /@ list, 1]\n\nWhat may look like a not particularly efficient solution, is actually quite fast due to the auto-compilation of the predicate Boole[...] inside Map, plus Pick being optimized on packed arrays. See the aforementioned question for more context and discussion.\nThis shows us another benefit of auto-compilation: not only does it often make the code run much faster, but it also does not unpack, allowing surrounding functions to also benefit from packed arrays when they can.\nWhich functions can auto-compile? One way to find out is to inspect SystemOptions[\"CompileOptions\"]:\nCases[\"CompileOptions\"/.SystemOptions[\"CompileOptions\"],\n      opt:(s_String->_)/;StringMatchQ[s,__~~\"Length\"]]\n\n{\"ApplyCompileLength\" -> \\[Infinity], \"ArrayCompileLength\" -> 250, \n \"FoldCompileLength\" -> 100, \"ListableFunctionCompileLength\" -> 250, \n \"MapCompileLength\" -> 100, \"NestCompileLength\" -> 100, \n \"ProductCompileLength\" -> 250, \"SumCompileLength\" -> 250, \n \"TableCompileLength\" -> 250}\n\nThis also tells you the threshold lengths of the list beyond which the auto-compilation is turned on. You can also change these values. Setting the value of ...CompileLength to Infinity is effectively disabling the auto-compilation. You can see that \"ApplyCompileLength\" has this value. This is because it can only compile 3 heads: Times, Plus, and List. If you have one of those in your code, however, you can reset this value, to benefit from auto-compilation. Generally, the default values are pretty meaningful, so it is rarely necessary to change these defaults. \nA few more techniques\nThere are a number of techniques involving Compile, which are perhaps somewhat more advanced, but which sometimes allow one to solve problems for which plain Compile is not flexible enough. Some which I am aware of:\n\nSometimes you can trade memory for speed, and, having a nested ragged list, pad it with zeros to form a tensor, and pass that to Compile.\nSometimes your list is general and you can not directly process it in Compile to do what you want, however, you can reformulate a problem such that you can instead process a list of element positions, which are integers. I call it \"element-position duality\". One example of this technique in action is here, for a larger application of this idea see my last post in this thread (I hesitated to include this reference because my first several posts there are incorrect solutions. Note that for that particular problem, a far more elegant and short, but somewhat less efficient solution was given in the end of that thread). \nSometimes you may need some structural operations to prepare the input data for Compile, and the data contains lists (or, generally, tensors), of different types (say, integer positions and real values). To keep the list packed, it may make sense to convert integers to reals (in this example), converting them back to integers with IntegerPart inside Compile. One such example is here \nRun-time generation of compiled functions, where certain run-time parameters get embedded. This may be combined with memoization. One example is here, another very good example is here\nOne can emulate pass-by-reference and have a way of composing larger compiled functions out of smaller ones with parameters (well, sort of), without a loss of efficiency. This technique is showcased for example here\nA common wisdom is that since neither linked-lists, nor Sow-Reap are compilable, one has to pre-allocate large arrays most of the time, to store the intermediate results. There are at least two other options:\n\nUse Internal`Bag, which is compilable (the problem however is that it can not be returned as a result of Compile as of now, AFAIK).\nIt is quite easy to implement an analog of a dynamic array inside your compiled code, by setting up a variable which gives the current size limit, and copy your array to a new larger array once more space is needed. In this way, you only allocate (at the end) as much space as is really needed, for a price of some overhead, which is often negligible.\n\nOne may often be able to use vectorized operations like UnitStep, Clip, Unitize etc, to replace the if-else control flow in inner loops, also inside Compile. This may give a huge speed-up, particularly when compiling to MVM target. Some examples are in my comments in this and  this blog posts, and one other pretty illustrative example of a vectorized binary search in my answer in this thread\nUsing additional list of integers as \"pointers\" to some lists you may have. Here, I will make an exception for this post, and give an explicit example, illustrating the point. The following is a fairly efficient function to find a longest increasing subsequence of a list of numbers. It was developed jointly by DrMajorBob, Fred Simons and myself, in an on and off-line MathGroup discussion (so this final form is not available publicly AFAIK, thus including it here)\n\nHere is the code\nClear[btComp];\nbtComp = \nCompile[{{lst, _Integer, 1}}, \n   Module[{refs, result, endrefs = {1}, ends = {First@lst}, \n      len = Length@lst, n0 = 1, n1 = 1, i = 1, n, e}, \n     refs = result = 0 lst;\n     For[i = 2, i <= len, i++, \n        Which[\n          lst[[i]] < First@ends, \n             (ends[[1]] = lst[[i]]; endrefs[[1]] = i; refs[[i]] = 0),\n          lst[[i]] > Last@ends, \n             (refs[[i]] = Last@endrefs;AppendTo[ends, lst[[i]]]; AppendTo[endrefs, i]), \n          First@ends < lst[[i]] < Last@ends, \n             (n0 = 1; n1 = Length@ends;  \n              While[n1 - n0 > 1, \n                n = Floor[(n0 + n1)/2];\n                If[ends[[n]] < lst[[i]], n0 = n, n1 = n]];\n                ends[[n1]] = lst[[i]];\n                endrefs[[n1]] = i;\n                refs[[i]] = endrefs[[n1 - 1]])\n        ]];\n        For[i = 1; e = Last@endrefs, e != 0, (i++; e = refs[[e]]), \n            result[[i]] = lst[[e]]];\n        Reverse@Take[result, i - 1]], CompilationTarget -> \"C\"];\n\nHere is an example of use (list should not contain duplicates):\ntest = RandomSample[#, Length[#]] &@ Union@RandomInteger[{1, 1000000}, 1000000];\n\nbtComp[test] // Length // Timing\n\nThe fastest solution based on built-ins, which is indeed very fast, is still about  6 times slower for this size of the list:\nLongestCommonSequence[test, Sort@test] // Short // Timing\n\nAnyways, the point here is that this was possible because of extra variables refs and endrefs, the use of which allowed to only manipulate single integers (representing positions of sub-lists in a larger list) instead of large integer lists.\nA few assorted remarks\n\nThings to watch out for: see this discussion for some tips on that. Basically, you should avoid\n\nCallbacks to the main evaluator\nExcessive copying of tensors (CopyTensor instruction)\nAccidental unpacking happening in top-level functions preparing input for Compile or processing its output. This is not related to Compile proper, but it happens that Compile does not help at all, because the bottleneck is in the top-level code. \n\nType conversion I would not worry about performance hit, but sometimes wrong types may lead to run-time errors, or unanticipated callbacks to MainEvaluate in the compiled code.\nCertain functions (e.g. Sort with the default comparison function, but not only), don't benefit from compilation much or at all. \nIt is not clear how Compile handles Hold- attributes in compiled code, but there are indications that it does not fully preserve the standard semantics we are used to in the top-level.\nHow to see whether or not you can effectively use Compile for a given problem. My experience is that with Compile in Mathematica you have to be \"proactive\" (with all my dislike for the word, I know of nothing better here). What I mean is that to use it effectively, you have to search the structure of your problem / program for places where you could transform the (parts of) data into a form which can be used in Compile. In most cases (at least in my experience), except obvious ones where you already have a procedural algorithm in pseudo-code, you have to reformulate the problem, so you have to actively ask: what should I do to use Compile here. \n\n", "How to sum up subelements of a list of unknown length": "\nUse either \nPlus@@c\n\nor\nTotal[c]\n\n", "plotting - Day of the week vs time on BoxWhiskerChart": "\nAssuming that the days and times in the gathered data list are strings you could do something like\ndays = {\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \n   \"Saturday\", \"Sunday\"};\n\ndata2 = Reap[\n    Sow[(AbsoluteTime[#2] - AbsoluteTime[\"00:00:00\"])/3600., #1] & @@@\n      Flatten[data, 1],\n    days, #2 &][[2, All, 1]];\n\nShow[BoxWhiskerChart[data2],\n  FrameTicks -> {Thread[{Range[7], days}],\n   {#, IntegerString[#, 10, 2] <> \":00\"} & /@ Range[0, 24, 4],\n   Thread[{Range[7], \"\"}], Thread[{Range[0, 24, 4], \"\"}]}]\n\n\n", "equation solving - Using results of Reduce": "\nYou may want to look at the documentation for ToRules.  When applied to the output of Reduce you provided, the result is\nSequence[{x -> 1, y -> 1}, {x -> 1, y -> 2}, {x -> 1, y -> 3}, \n         {x -> 2, y -> 1}, {x -> 2, y -> 2}, {x -> 3, y -> 1}]\n\nIf you want to substitute this back to f[x,y], put curly braces to turn the sequence into a list and use ReplaceAll:\nf[x,y] /. {%}\n\nThis will give the desired output {115000, 150000, 185000, 145000, 180000, 175000}.\n", "number theory - Which DirichletCharacter is KroneckerSymbol?": "\nI wrote this answer as I was figuring things out. If you just want the answer, copy the definitions of fundQ, Ast, ksFactors, foo, makeOneIndex and magicJ out of the code blocks below. You should have\nDirichletCharacter[d, magicJ[d], n] == KroneckerSymbol[d, n]\n\nDisclaimer 1: This answer is based on plausible interpretations of things not quite said in the DirichletCharacter documentation and tested for $-120 \\leq d \\leq 120$. To be sure it's right, you would have to actually look inside DirichletCharacter or find better documentation.\nDisclaimer 2: $\\newcommand{\\KS}[2]{\\left( \\frac{#1}{#2} \\right)}$ The set up of this question assumes that $d$ is a fundamental discriminant. I really need that. For $s$ odd, we have $\\KS{-1}{2^b s} = (-1)^{(s-1)/2}$, so $\\KS{-1}{n}$ is not periodic in $n$, and DirichletCharacter[k,j,n] is always periodic modulo $k$. So not all Kronecker symbols can be expressed as Dirichlet characters. Fortunately, the fundamental discriminants can. If you run magicJ[] on something which is not a fundamental discriminant, it objects. If you run the internal helper functions on something which is not a fundamental discriminant, I make no promises as to what will happen.\n\nHere is a function to test whether $d$ is a fundamental discriminant:\nfundQ[d_] := Switch[Mod[d, 4], 1, SquareFreeQ[d], \n                      0, SquareFreeQ[d/4] && (Mod[d/4, 4] == 2 || Mod[d/4, 4] == 3), \n                      _,  False]\n\ndiscs = Select[Range[-120, 120], fundQ]\n(* Out={-120, -119, -116, -115, -111, -107, -104, -103, -95, -91, -88, -87,  \n        -84, -83, -79, -71, -68, -67, -59, -56, -55, -52, -51, -47, -43, -40, \n        -39, -35, -31, -24, -23, -20, -19, -15, -11, -8, -7, -4, -3, 1, 5, 8, \n         12, 13, 17, 21, 24, 28, 29, 33, 37, 40, 41, 44, 53, 56, 57, 60, 61, \n         65, 69, 73, 76, 77, 85, 88, 89, 92, 93, 97, 101, 104, 105, 109, 113, 120}\n\nFor any odd prime $p$, define $p^{\\ast} = (-1)^{(p-1)/2} p$. Let $d = u 2^b (p_1^{\\ast})^{a_1} (p_2^{\\ast})^{a_2} \\cdots (p_r^{\\ast})^{a_r}$ with $u = \\pm 1$ and $p_i$ distinct odd primes listed in increasing order. If $d$ is a fundamental discriminant then all the $a_i$ are $1$ and $u 2^b$ is one of $1$, $-4$, $8$ or $8$ so we will assume this from now on.\nHere is some code to perform the above computations\n Ast[p_] := (-1)^((p-1)/2) p;\n\n ksFactors[d_] := \n   If[fundQ[d], Module[{facts = FactorInteger[d], primes},\n         primes =Map[Ast, Select[Map[First, facts], (# != -1 && # != 2)&]];\n         Prepend[primes, d/Product[p, {p, primes}]]], \n      \"Error: Not a fundamental discriminant\"]\n\n   ksFactors[120]\n   (* Out={-8,-3,5} *)\n\nThen we have \n$$\\KS{d}{n} = \\KS{u 2^b}{n} \\prod \\KS{p_i^{\\ast}}{n}^{a_i}$$\nFor any odd prime $p$, the character $\\KS{p^{\\ast}}{n}$ is the unique nontrivial real Dirichlet character modulo $|p|$. According to the documentation, the real characters modulo $p$ will be in positions $1$ and $\\phi(p)/2+1$, and the one in position $1$ will be trivial. \nActually, the documentation (version 8) says \"Real Dirichlet characters modulo k have index $1$ or $\\phi(k)/2+1$\", which would seem to say that those are the only two real Dirichlet characters. That can't be true since, in many cases, there are more than two real Dirichlet characters. However, it does appear to be true that the characters in those positions are always real. \nIn any case, when $p$ is prime, there is only one nontrivial real Dirichlet character, namely $\\KS{p^{\\ast}}{n}$, and it appears in index $\\phi(p)/2+1$. Also, for $p$ prime, $\\phi(p)/2+1$ simplifies to $(p+1)/2$. Let's check that we're right so far:\nTable[KroneckerSymbol[Ast[p], Range[4p]] == DirichletCharacter[p,(p+1)/2,Range[4p]], \n         {p,Prime[Range[2,20]]}]]\n\n(* Out = {True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True} *)\n\nNow, let's deal with the $\\KS{u 2^b}{n}$ term. By trial and error, I found\nKroneckerSymbol[1,n]==DirichletCharacter[1,1,n]\nKroneckerSymbol[-4,n]==DirichletCharacter[4,2,n]\nKroneckerSymbol[-8, n] == DirichletCharacter[8, 4, n]\nKroneckerSymbol[8, n] == DirichletCharacter[8, 2, n]\n\nLet's define a function to handle what we know so far\nfoo[x_] :=\n    If[PrimeQ[Abs[x]] && Mod[x, 4] == 1, {Abs[x], (Abs[x] + 1)/2}];\nfoo[1] = {1, 1};\nfoo[-4] = {4, 2};\nfoo[-8] = {8, 4};\nfoo[8] = {8, 2};\n\nmap[foo, ksFactors[120]]\n(* Out = {{8, 4}, {3, 2}, {5, 3}} *)\n\nthing1 = Table[DirichletCharacter[8, 4, n]*DirichletCharacter[3, 2, n]*DirichletCharacter[5, 3, n], {n, 1, 120}];\n\nthing2 = KroneckerSymbol[120, Range[120]];\n\nthing1 == thing2\n(* Out = True *)\n\nWe now need to combine all of those DirichletCharacters into a single term.\nLook at the documentation of DirichletCharacter and scroll down to the portion of Properties and Relations beginning \"A character modulo $k$ can be written as a product of characters modulo prime powers...\". I've cut off the last bit of the quote because it is misleading; they say \"prime powers of $k$\" but they mean \"prime power factors of $k$\".\nThe documentation doesn't quite say the following, but it appears to be true: If $d=\\prod_{i=1}^r p_i^{a_i}$, where the $p_i$ are primes listed in increasing order, and\n$$j = 1+\\sum_{i=1}^r (j_i-1) \\cdot  \\phi\\left( \\prod_{k=i+1}^r p_i^{a_i} \\right)$$\nthen DirichletCharacter[d,j,n] is the product of the terms DirichletCharacter[p[i]^a[i], j[i],n].\nLet's write some code to do this:\nmakeOneIndex[jList_] :=\n  1 + Sum[\n    (Last[jList[[i]]] - 1)*\n    EulerPhi[Product[\n       First[jList[[k]]], \n    {k, i + 1, Length[jList]}]], \n {i, 1, Length[jList]}]\n\n magicJ[d_]:=\n    If[fundQ[d], makeOneIndex[Map[foo, ksFactors[d]]], \"Not a fundamental discriminant\"]\n\nAnd let's test it:\nTable[DirichletCharacter[d, magicJ[d], Range[d]] == KroneckerSymbol[d, Range[d]], {d, discs}]\n\n (* Out = {True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True} *)\n\n", "equation solving - Arithmetic operation on the value returned by Solve": "\nTry using\nx + n /. First[SolC1]\n\n(* ==> L/2 + n *)\n\nIf you need a new rule as the result, then you can do\nx -> (x + n /. First[SolC1])\n\n", "graphs and networks - Centrality measures for single nodes": "\nImportant note: The order in which BetweennessCentrality (or any other graph-related function, including AdjacencyMatrix) will return results is not the same as the order in which you passed vertices to Graph, nor is it the lexicographic order of vertices.  It is the order in which VertexList returns vertices.\nMisunderstandings about this are a common source of error, so I thought it important to spell this out. Do not count on vertex n corresponding to the nth element in the result list.  Always use VertexList!\nNow, an easy way to pick out the betweenness centrality of vertex is\nPick[BetweennessCentrality[graph], VertexList[graph], vertex]\n\nUnfortunately it does not seem to be possible to compute the result for one vertex only.\nTo get the centrality of more than one node, contained in the list vertices, use \nPick[BetweennessCentrality[graph], VertexList[graph], Alternatives @@ vertices]\n\nTo see all vertex names paired up with their centralities in a table, you can use\nGrid[Transpose[{VertexList[graph], bc}]]\n\n", "dfin a function from a list - Mathmatica Stack Exchang": "\nScan[] is your friend:\nScan[(f[First[#]] = Last[#]) &, \n  WaveletFilterCoefficients[DaubechiesWavelet[2], \"PrimalHighpass\"]];\nf[_] = 0;\n\n??f\n  Global`f\nf[-2]=-0.0915064\n\nf[-1]=-0.158494\n\nf[0]=0.591506\n\nf[1]=-0.341506\n\nf[_]=0\n\n", "plotting - How to plot layered graphs?": "\nI was about to give this a second go and implement a layout algorithm manually based on Szabolcs's answer, when I realized that since v9, we have built-in options to lay out trees and directed acyclic graphs in the above specified layered way:\nSetOptions[Graph, VertexLabels -> \"Name\", ImagePadding -> 10];\nedges = {1 -> 2, 1 -> 3, 1 -> 5, 1 -> 8, 2 -> 4, 4 -> 6, 4 -> 7, 5 -> 10, 6 -> 9};\nPrepend[\n  Graph[edges, GraphLayout -> #, PlotLabel -> If[ListQ@#, Column@#, #]] & /@ {\n  \"LayeredEmbedding\", {\"LayeredEmbedding\", \"RootVertex\" -> 1}, \n  \"LayeredDigraphEmbedding\", {\"LayeredDigraphEmbedding\", \"Orientation\" -> Left},\n  {\"LayeredDigraphEmbedding\", \"Tolerance\" -> .5}},\n LayeredGraphPlot[edges, Top, VertexLabeling -> True, PlotLabel -> \"LayeredGraphPlot\"]]\n\n\nNote that simple \"LayeredEmbedding\" still produces the wrong layout (1 is below 2), but now a \"RootVertex\" option can specify the root node. I've included LayeredGraphPlot for comparison. \"LayeredDigraphEmbedding\" was specifically added in v9 for directed acyclic graphs. Its submethod options can be used to tweak the position of the root, orientation and the tolerance used in terminating the energy minimization process.\nOne could get the vertex coordinates as follows:\ncoord = {};\nGraph[edges, GraphLayout -> \"LayeredDigraphEmbedding\", \n  VertexShapeFunction -> (Disk[AppendTo[coord, #2 -> #1]; #1, .1] &)]\ncoord\n\n\n{1 -> {0., 4.}, 2 -> {1., 3.}, 3 -> {-2., 3.}, 5 -> {-1., 3.}, 8 -> {0., 3.},\n 4 -> {1., 2.}, 6 -> {0., 1.}, 7 -> {1., 1.}, 10 -> {-1., 2.}, 9 -> {0., 0.}}\n\n\nCheck out the GraphLayout option because it contains some more layout methods in v9!\n", "linear algebra - Can Eigenvalues[] and Eigenvectors[] be assumed to return the same ordering?": "\nIf you need to be sure that the order is correct, there is a function Eigensystem that returns a list of both the eigenvalues and -vectors, which is in the right order.\n{eValues, eVectors} = Eigensystem[{{2, 0}, {0, 1}}];\neValues\neVectors\n\n\n{2, 1}\n{{1, 0}, {0, 1}}\n\n\nIt's probably worth using just for the slight off-chance that Eigenvalues and Eigenvectors do not yield the same order (not sure about whether this may or may not happen), which will be really painful to debug.\n", "functions - Using a PatternTest versus a Condition for pattern matching": "\nI usually consider PatternTest as local to a specific pattern such as x_Integer?Positive and Condition as more general, often involving multiple patterns, e.g.:\nf[x_, y_] /; x+y < 10 := x*y\n\nAn aspect of PatternTest that is different from Condition is that it is automatically applied to each element of a sequence, whereas Condition applies to the whole.  A pattern such as __?EvenQ means a sequences of arguments all of which pass EvenQ.  Consider:\nf2[x__?EvenQ] := . . .\n\nThis is awkward with Condition:\nf1[x__] /; (And @@ EvenQ /@ {x}) := . . .\n\nFurthermore the naive method above does not short-circuit on a failure therefore it will be inefficient.  This could be fixed but it will be even more clumsy.\nThen consider the converse:\nf3[x__] /; Plus[x] == 7 := . . .\n\nTo do this using PatternTest we would need to apply it to the entire expression f3[x__], complicating its form and risking unwanted evaluation or recursion.  (Counterexample: see my proposed solution to Quick way to use conditioned patterns when defining multi-argument function? for where I feel that PatternTest is the best way to proceed.)\nThere is one rather obscure (at least to me) yet very important use of Condition that extends this generality.\n\nlhs := Module[{vars}, rhs /; test] allows local variables to be shared\n  between test and rhs. You can use the same construction with Block and\n  With.\n\nThis is quite unusual in Mathematica's patterns and assignments.  It allows execution of code as part of the definition, then testing by a condition based on the result.  If the condition fails, the pattern matcher then moves on to search for other matches.  The evaluation that occurred can produce side effects but otherwise Mathematica behaves as though the entire pattern (lhs := rhs assignment) did not match.\nOne elegant use of this functionality is the Trott-Strzebonski method for In-Place Evaluation.\n\nLeonid wrote, and encouraged me to include here:\n\nOne other thing I want to mention is that with PatternTest, it is\n  easier to inadvertently leak evaluation, while in Condition avoiding\n  that is usually just a matter of inserting Unevaluated in a proper\n  place. I discussed this topic to some extent here\nFinally, there are some syntactic differences which are good to keep\n  in mind, for example precedence-related issues like this one.\n\n\nRojo stated:\n\nAnother consequence of this shows when you want to store a pattern in\n  a variable, or inject it with a With. ... Can't do that with Condition\n  unless you want all the instances of the pattern in each definition to\n  be the same.\n\nAs a rather contrived counter-example one can use Unique symbols in a pattern constructor:\npat[] := Pattern[#, _] /; # > 4 & @ Unique[]\n\nf[a : pat[], b : pat[]] := {a, b}\n\nf[5, 6]\n\n\n{5, 6}\n\nOf course it is better to use PatternTest for this, but I think it is useful to show that it can be done.\n", "calculus and analysis - Equation of a line that is tangent to a curve at point": "\nCertainly, there is a better way:\ny[x_] := 2 x Sin[x]; a = Pi/2;\nCollect[Normal[Series[y[x], {x, a, 1}]], x, Simplify]\n\nRecall that the formula for a Taylor polynomial looks a bit like this:\n$$f(x)=\\color{red}{f(a)+f^\\prime (a)(x-a)}+\\frac{f^{\\prime\\prime}(a)}{2}(x-a)^2+\\cdots$$\nand reconciling this with the geometric interpretation of the Taylor polynomial as the best one-point osculatory (agrees at function and derivative values) approximation of a function shows why the approach works. I believe this should be a standard way to look at Taylor polynomials in the textbooks, if it already isn't.\n\nHere is an equivalent approach:\nCollect[InterpolatingPolynomial[{{{a}, y[a], y'[a]}}, x], x, Simplify]\n\nThis is based on the fact that the tangent line is the unique Hermite interpolating polynomial of degree $1$.\n\nCertainly, one could do the plodding, \"traditional\" (whatever that means) approach:\ny[x_] := 2 x Sin[x]; a = Pi/2;\nCollect[y[a] + y'[a] (x - a), x, Simplify]\n\nIn any event, Solve[] is definitely unnecessary here.\n", "output formatting - ScientificForm is not being applied": "\nThe result of that sum is an (exact) integer, so Mathematica will display every digit because they're all significant. To get the output you're looking for, you just have to convert the result to a floating point number using N.\nScientificForm[N@Sum[2^Binomial[n, 2], {n, 58, 3249}]]\n\n", "Txt[] using Graphics - Mathmatica Stack Exchang": "\nIf you take out Method -> {\"ShrinkWrap\" -> True} it works as I think you expect.\n", "graphs and networks - Convert GraphPlot[]s with many nodes into something that's human-understandable": "\nYour graph has many vertexes, while the exemplary graph you link to does not and this is why it looks so nice. Styling with pie charts is not a problem at all:\ng = RandomGraph[{15, 43}];\n\nvfc[{xc_, yc_}, name_, {w_, h_}] := \n Inset[PieChart[{VertexDegree[g, name], VertexList[g] // Length}, \n   SectorOrigin -> {Automatic, .7}, \n   ChartStyle -> \"AvocadoColors\"], {xc, yc}, Automatic, \n  VertexDegree[g, name]/30]\n\nSetProperty[g, VertexShapeFunction -> vfc]\n\n\nI by the way understand that you want more - to replace \"heavy\" sub-graphs by nodes reflecting their statistics. That could be done, but it is a bit messy and ambiguous, more of a research question. If I find time I may post a solution. \nHere is another angle at a quicker analysis. Automatic spatial layouts Mathematica uses for graph carry a lot of information too. We can use FindClusters to analyse it. I will remove directed and multiple edges for clear picture. To see clustering of regions, after you execute your code do this:\nn = 10;(*number of clusters*)\ngrr = Graph[Union[Sort /@ gc], DirectedEdges -> False, GraphStyle -> \n      \"LargeNetwork\", VertexSize -> 0];\ncls = ListPlot[FindClusters[AbsoluteOptions[grr, VertexCoordinates][[2]], n],\n      PlotStyle -> ColorData[3, \"ColorList\"]];\nShow[grr, cls, BaseStyle -> PointSize[.01]]\n\n\n", "plotting - adding labels to points in ListPlot": "\nAll plotting functions are just wrappers for Graphics objects. Show can be used to combine these objects, and that's one way of doing what you want here.\nTake the following code as a starting point; you will of course have to tweak the positions of the labels (right now it's just a radial factor that offsets them). Note that I modified the data variable so that it includes $t$; it is now of the form {t, Re, Im}. The ListPlot will plot only the real and imaginary parts (data[[All, {2, 3}]]), while the Text passage also takes into account the value of $t$.\ndata = Table[{t, Re[5 Exp[I 5/2 t]], Im[5 Exp[I 5/2 t]]}, {t, 0, 6}];\ndataPlot = ListPlot[data[[All, {2, 3}]], PlotStyle -> PointSize -> Large];\nlabels = Text[#[[1]], 1.1 #[[{2, 3}]]] & /@ data;\nShow[\n    dataPlot,\n    Graphics[{Red, labels}],\n    PlotRange -> 6 {{-1, 1}, {-1, 1}},\n    AspectRatio -> 1\n]\n\n\n\n\nYou can of course generalize this arbitrarily, e.g. color the labels differently, change font size etc. I kept the above to a minimum to avoid cluttering, the rest is up to you.\n", "equation solving - Result of Reduce contains duplicate terms": "\nI'll try to sum up here the answers given so far in comments:\n\nif you work in a single period, you get the expected results:\nIn:=  Reduce[f'[x] == 0 && 0 <= x <= 2 Pi, x]\nOut=  x == \\[Pi]/2 || x == (3 \\[Pi])/2\n\nif you work on the whole real domain, you can get the expression to be reduced by using Simplify:\nIn:=  Simplify[Reduce[f'[x] == 0, x]]\nOut=  C[1] \\[Element] Integers && (\\[Pi] + 2 x == 4 \\[Pi] C[1] || \\[Pi] + 4 \\[Pi] C[1] == 2 x || 2 x == \\[Pi] (3 + 4 C[1]))\n\nthe reason why you get one of the elements twice in the first place is that it's a double root.\n\n", "How to add fill color to a 2D Graphics object?": "\nI presume you are looking for FilledCurve.\n\n\n", "Module vs DynamicModule for a dynamic variables in a grid. || Spelling Bee": "\nThis is because the object created by DynamicModule does not actually evaluate until it is displayed, therefore Grid has nothing to format other than the outer list.\nwords = {\"lightning\", \"lightning\", \"cloudy\"};\n\ndynlist = \n  DynamicModule[{x = 0, t = 0},\n    {\n     #,\n     Button[\"Start\", t = Hold@AbsoluteTime[] - AbsoluteTime[]], \n     Button[Style[\"\\[Checkmark]\", Darker@Green], t = ReleaseHold[t]; x++],\n     Button[Style[    \"\\[Times]\",        Red  ], t = ReleaseHold[t]; x--],\n     Dynamic[x],\n     Dynamic[Clock[]; ReleaseHold[t]]\n     }\n    ] & /@ words;\n\n\nToString[ dynlist[[1]] ]\n\n\n\"DynamicModule[{x = 0, t = 0}, {lightning, Button[Start, t = \\\n  Hold[AbsoluteTime[]] - AbsoluteTime[]], Button[[Checkmark], t = \\\n  ReleaseHold[t]; x++], Button[[Times], t = ReleaseHold[t]; x--], \\\n  Dynamic[x], Dynamic[Clock[]; ReleaseHold[t]]}, DynamicModuleValues :>\n  \\ {}]\"\n\nYou could build the rows inside the module:\nColumn[\n DynamicModule[{x = 0, t = 0},\n    Grid@{{\n     #,\n     Button[\"Start\", t = Hold@AbsoluteTime[] - AbsoluteTime[]], \n     Button[Style[\"\\[Checkmark]\", Darker@Green], t = ReleaseHold[t]; x++],\n     Button[Style[    \"\\[Times]\",        Red  ], t = ReleaseHold[t]; x--],\n     Dynamic[x],\n     Dynamic[Clock[]; ReleaseHold[t]]\n     }}\n    ] & /@ words]\n\n\n\nAddressing your comment you could move the map operation inside Grid like this:\nDynamicModule[{x, t},\n x[_] = 0;\n t[_] = 0;\n Grid[\n  MapIndexed[\n    {#, Button[\"Start\", t[#2] = Hold@AbsoluteTime[] - AbsoluteTime[]], \n     Button[Style[\"\\[Checkmark]\", Darker@Green], \n      t[#2] = ReleaseHold[t[#2]]; x[#2]++], \n     Button[Style[\"\\[Times]\", Red], t[#2] = ReleaseHold[t[#2]]; \n      x[#2]--], Dynamic[x[#2]], \n     Dynamic[Clock[]; ReleaseHold[t[#2]]]} &,\n   words\n]]]\n\n\n", "programming - RecurrenceTable not evaluated: mathematica just echoes input": "\nAs far as I can see with a quick look, you system is overdetermined.\nYou have to leave out s1[0, k] == 1\nRecurrenceTable[\n  {\n   s1[n, k] == s1[-1 + n, -1 + k] + s1[n, -1 + k],\n   s1[n, 0] == Boole[n == 0],\n   s1[n, 1] == Boole[n <= 2]\n   }, s1, {n, 0, 6}, {k, 0, 4}] // Grid\n\n(*\n1   1   1   1   1\n0   1   2   3   4\n0   0   1   3   6\n0   0   0   1   4\n0   0   0   0   1\n0   0   0   0   0\n0   0   0   0   0\n*)\n\n", "numerics - Is there any automatic differentiation package?": "\nFor anyone still interested in this: I'm working on an implementation of dual numbers for Mathematica which should allow you to calculate automatic derivatives of (hopefully) many programs.\nCheck it out on GitHub.\nHere's a quick example of how to obtain the derivative of a programmatic function with a While loop (adapted from the documentation). It's a fixed point algorithm to solve an equation:\nf[a_?NumericQ, x0 : _?NumericQ : 1.0] := \n Module[{ x = x0, y, i = 0},\n  While[(y = Cos[a x]) != x,\n   x = y;\n   i++\n   ];\n  x\n ];\n\nIt doesn't have a symbolic derivative:\nDerivative[1] @ f\n(* Derivative[1][f] *)\n\nYou can find the derivative of its first argument simply by passing a Dual with non-standard part equal to 1:\n<<DualNumbers`\nf[1.]\nf[Dual[1., 1.]]\n(* 0.739085 *)\n(* Dual[0.739085, -0.297474] *)\n\nThe first argument of Dual is the function value and the second argument is the derivative at that point. Let's convince ourselves that this derivative is correct:\nWith[{h = 0.001, a = 1.0},\n (f[a + h] - f[a - h])/(2 h)\n ]\n(* -0.297474 *)\n\nLet's also check the derivative of the second argument:\nf[1., Dual[1., 1.]]\n(* Dual[0.739085, 1.86543*10^-14] *)\n\nThe derivative of the second argument is pretty much zero. This makes sense, of course, since small variations in the initial value in the fixed point search shouldn't influence the result.\n", "system variables - Where can I permanently modify $Path?": "\nYou can add the following line:\nAppendTo[$Path, FileNameJoin[{$UserBaseDirectory, \"ExtraPackges\"}]]\n\nto the file:\nFileNameJoin[{$UserBaseDirectory, \"Kernel\", \"init.m\"}]\n\ninit.m is described here, under \"more information\".\n\nTo do this automatically you can run:\nWith[\n {newPath = FileNameJoin[{$UserBaseDirectory, \"ExtraPackges\"}]},\n PutAppend[\n  Unevaluated @ AppendTo[$Path, newPath],\n  FileNameJoin[{$UserBaseDirectory, \"Kernel\", \"init.m\"}]\n ]\n]\n\n", "numerics - RootSearch for complex or multiple equations": "\nYou can use Solve to specify a range of interest.\nIn[10]:= Solve[{Tan[z] + I == (I) (z)^(-1/2), Abs[z]<=10}, z]\n\n(*\nSolve::incs: Warning: Solve was unable to prove that the solution set found is\n complete.\n*)\n\n\nOut[10]= {\n {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , \n\n   -7.132251035054214302104690186362585697068142403087646814465 - \n\n    0.842662781181162221826225669202853177237728217131893274490 I}]}, \n\n {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , \n\n   -4.0072460838160107316714173702742991366776869325551029661934 - \n\n    0.7019645733961268997044074293090492296764597316326821770525 I}]}, \n\n {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , \n\n   -0.9400640610224741334606974053019750421040015028175053694335 - \n\n    0.3643340656419651371252025602838905385545008341650161006297 I}]}, \n\n {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , \n\n   0.42502056063258650274891169514957099586187780514338474096327 + \n\n    0.28887193948823718272333177173656870529846993666625322445517 I}]}, \n\n {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , \n\n   3.0894479592377390694689578127850505603723837467810656253546 - \n\n    0.4659016059311814902662713357028283109716496004755022472595 I}]}, \n\n {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , \n\n   6.2485902300197850812539412523087220367984004253401247062207 - \n\n    0.6952369865703343084749992220176303906987008887723814228223 I}]}, \n\n {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , \n\n   9.3988273465945532374205413428073199349703889446719754737117 - \n\n    0.8189381870367646618319736159465519157976282115012488727359 I}]}}\n\n\nI doubt any roots were missed, warning message notwithstanding. But it can be iffy when dealing with functions that are not everywhere analytic in the region of interest.\n", "parallelization - Efficiency of ParallelDo when a global variable./matrix is being updated": "\nIs there any reason you can't directly construct the Table, as in:\nDistributeDefinitions[a,b]\nc1 = ParallelTable[b[[i, j]] + a[[i, j]], {j, 1, n}, {i, 1, n}]\n\nOn my machine, with n=500, Table[b[[i, j]] + a[[i, j]], {j, 1, n}, {i, 1, n}];// AbsoluteTiming takes 0.59 s, while ParallelTable takes only 0.16 s. With n=1000, Table takes 2.1s while ParallelTable takes only 0.47s.\nFor future reference, unlike in MATLAB or other languages, in Mathematica you do not need to first \"initialize\" the table, and then fill it.\n", "graphics - Rectangle with rounded edges": "\nUsing pieces from the linked answers, and Heike's code:\nText piece:\n txt1 = Take[\n ExampleData[{\"Text\", \"LoremIpsum\"}, \"Lines\"], {1, -1, 2}][[1]] //\n StringTake[#, 330] &;\n\nImage piece:\n pic = Import[\"http://dailytechgadgets.files.wordpress.com/2011/02/old-ferrari.jpg\"];\n\nAnd Heike's code for rectangles:\n rec[ll_, ur_, pic_] := \n Module[{crop, boxrat}, \n boxrat = #2/#1 & @@ MapThread[Abs[#2 - #1] &, {ll, ur}]; \n crop = ImageCrop[pic, Transpose[{ImageDimensions[pic]}], \n AspectRatio -> boxrat]; \n Inset[crop, Min /@ Transpose[{ll, ur}], {Left, Bottom}, \n Abs[ur - ll]]]\n\nand Heike's code again for putting all together -- just adding RoundingRadius to rectangle objects and commenting out lines that produce lines--:\n Graphics[{EdgeForm[{Thickness[0.005`], Black}], FaceForm[White], \n Rectangle[{0, 0}, {160, 90}, RoundingRadius -> 4], \n FaceForm[Darker[Gray]], \n Rectangle[{0, 0}, {80, 63}, \n RoundingRadius -> 4],(*code for picture*){rec[{80, 0}, {160, 63}, \n pic], FaceForm[Opacity[0]], \n Rectangle[{80, 0}, {160, 63}, \n RoundingRadius -> 4]},(*code for text*)\n Inset[Pane[\n Style[txt1, 12, TextAlignment -> Left], {Scaled[1], \n Scaled[0.75`]}, Alignment -> Center, \n ImageSizeAction -> \"Scrollable\"], {0, 8}, {Left, Bottom}, {78,67}], \n Flatten[Transpose[{Flatten[(Table[\n      RandomChoice[{GrayLevel[0.15`], c0[[#1]]}], {3}] &) /@ \n   Range[2, 4, 1]], \n MapThread[\n  Function[{Xs, Ys}, \n   Rectangle[{Xs, Ys}, {Xs + 16, Ys + 9}, \n    RoundingRadius -> 4]], {Flatten[Table[Range[0, 32, 16], {3}]],\n    Flatten[(Table[#1, {3}] &) /@ Range[63, 81, 9]]}]}]](*,{Black,\n Thickness[0.005`],Line[{{0,63},{159,63}}]}*)}, \n PlotRange -> {{0, 160}, {0, 90}}, Method -> {\"ShrinkWrap\" -> True}, \n ImagePadding -> 2, ImageMargins -> 0, ImageSize -> 500]\n\nproduces:\n\nYou need further refinements to clean up. \nIn particular, the image needs to be masked with a rectangle with rounded corners.\nEDIT: For masking an image with a round-cornered reactangle, play with the parameters of Rectangle in\n pic2 = ImageAdd[ pic, \n Graphics[{Black, Rectangle[{2, 1}, {4, 2}, RoundingRadius -> .2]}]]\n\nUpdate: For better masking using SetAlphaChannel and better handling of image size (Thanks: @ssch and @Jens)\nroundImage[img_, r_] := Module[{dim = ImageDimensions[img], sr}, \nsr = Max[dim]*r; \nSetAlphaChannel[img, \n   Graphics[{White, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}], RoundingRadius -> sr]},\n Background -> Black, PlotRangePadding -> 0, \n PlotRange -> {{0, 0}, dim}\\[Transpose], AspectRatio -> Automatic] ]]\n\n", "parallelization - List of Parallelize[]-able functions": "\nWhile I cannot answer the general question, I would like to point out that Parallelize does more than replace certain functions with their parallel versions.\nConsider this:\nParallelize[{f[$KernelID], f[$KernelID], f[$KernelID], f[$KernelID]}]\n\n(* ==> {f[2], f[2], f[1], f[1]} *)\n\nParallelize[f[$KernelID] + f[$KernelID] + f[$KernelID] + f[$KernelID]]\n\n(* ==> 2 f[1] + 2 f[2] *)\n\nNotice that Parallelize has evaluated instances of f in parallel even when they appeared in a more complex expression (in a list or in a sum)\nThe documentation mentions somewhere (I can't find where right now, if you do please edit it in) that a general way to parallelize the evaluation of a function f is to replace every instance of f by Composition[ParallelSubmit, f], then applying WaitAll to the whole expression.  (One must be careful to keep things in an unevaluated state before submitting the evaluations though.)\nAs an example, I copied the following possible (not actual) implementation of ParallelMap directly from a comment in the Parallel package:\nParallelMap[f_, h_[exprs___]] := \n    h @@ WaitAll[ Composition[ParallelSubmit,f] /@ {exprs} ]\n\nThis type of parallelization is not ideal though because it corresponds to using the finest granularity: each evaluation of f is submitted separately, one by one (not in batches), thus the overhead is large.\nThe sources of the parallel computing tools are available and are commented, so if you have time, you can try digging in the package to find the answer to the question.\nUpdate From the Evaluate.m source file in the parallel computing tools package it appears that the following functions are treated specially by Parallelize:\nMap, MapIndexed, MapThread, Scan, Apply, Outer, Inner, Dot, Through\nPick\nTable, Sum, Product, Do, Array\nCases, Select\nCount, MemberQ, FreeQ\n\nSome other functions are treated specially as well.  I did not take the time to go through the source and understand it in detail.\nThe point I want to emphasize is that Parallelize seems to be able to parallelize very general expressions, but not all of them with the same quality (granularity)\n", "list manipulation - Transform vector with lag": "\nAssuming that the vector is called z and $n$ in your formula is the integer index of vector elements, use\nx = Drop[z, 2] + 0.7 Drop[z, -2]\n\nThis adds the vector (sans the last two elements) to the vector times 0.7 with the first two elements removed (i.e. shifted by two elements to the left).  Of course the result will be 2 elements shorter than the original.  If this is not desired, you need to decide what $Z_0$ and $Z_{-1}$ should be and pad (PadLeft) z with these values.\nThis is likely the fastest possible solution in Mathematica.\nEDIT\nAnother, also very fast possibility is\nx = ListCorrelate[{0.7, 0, 1}, z]\n\nListCorrelate has settings for padding the arrays as well, if needed.\n", "mathlink or wstp - Calling IronPython code from Mathematica": "\nBeing the fan of Mathematica<->CLR interop that I am, your question has inspired me to try to get IronPython fully working with Mathematica for the last couple of days.\nI haven't yet had total luck. Part of my problem is that I don't have a Windows Mathematica license, so I can't fully double-check my work. While I'm trying to hunt down Mathematica for Windows, here's my work so far. There's a good chance it'll work fine for you.\nNote: If it fails on one of the LoadNETType[] lines, let me know. I had to recompile all of the .NET/Link binaries from source to link them against .Net 4.0. The binaries with Mathematica 8, at least on Mac, are linked against .NET 2.0 with an exuberant message that it works just fine with .NET 3.0 since they only added a few namespaces. Unfortunately, that's not much consolation for those of us IronPython users who need .NET 3.5 or newer.\n(If it turns out that a version update is necessary on Windows as it was for me and you need instructions for the \"rebuild from source\", let me know in comments, and I can write up my build steps.)\n(* .NET/Link ceremony *)\nNeeds[\"NETLink`\"]\nInstallNET[]\n\n(* This is one of the steps that doesn't really work for me,\n   but I think it'll work on Windows. *)\n\nShowNETConsole[]\n\n(* IronPython-specific imports *)\n\nLoadNETAssembly[\"/PATH/TO/IronPython.dll\"]\nLoadNETAssembly[\"/PATH/TO/Microsoft.Scripting.dll\"]\nLoadNETType[\"IronPython.Hosting.Python\", StaticsVisible -> True]\nLoadNETType[\"Microsoft.Scripting.SourceCodeKind\"]\n\n(* Transliteration of the first IronPython hosting example from\n   http://www.voidspace.org.uk/ironpython/hosting_api.shtml *)\n\nengine = IronPython`Hosting`Python`CreateEngine[]\nst = SourceCodeKind`Statements\nsource = \"print 'Hello World'\";\nscript = engine@CreateScriptSourceFromString[source, st]\nscope = engine@CreateScope[]\nscript@Execute[scope]\n\nNote: You'll have to change /PATH/TO/ above (2 occurrences) to be the correct path to the IronPython binaries on your system. An alternative would be to install them in the GAC.\nAs I hinted in the code comments above, there's a pretty good crash-course on the IronPython hosting API on Michael Foord's blog.\n", "fitting - Using FindFit to fit $a\\,b^t$: how to avoid introducing complex numbers?": "\nThe solution\nIt's usually a very very very very good idea to plot your data to see what shape it roughly has in the beginning. In your case, it looks like this:\n\n... wait, that's not an exponentially rising function! Of course $a\\,b^t$ won't fit that, but $a\\,b^{-t}$ might work, let's try:\nFindFit[data, a*b^(-t), {a, b}, t]\n\n\n{a -> 100.004, b -> 22099.8}\n\n\nTadaa :-)\nSome further remarks\nI have of course used the fact that $b^t=\\left(\\frac1b\\right)^{-t}$ here. You could have fitted with your function as well, only that Mathematica chose inappropriate starting parameters. I do not know how Mathematica determines these, but I think assuming it uses something around 1 is reasonable. My impression is always that it favors large to small numbers, but I wouldn't count on that.\nYou can specify starting parameters like this:\nFindFit[data, a*b^t, {{a, aStart}, {b, bStart}}, t]\n\nThis will tell Mathematica to use aStart and bStart initially; it will then continue to slighly alter these values to see whether the fit gets better.\n\"Wait, but if I don't know these parameters at all, how can I find good starting values out\" - here's one of the great powers of Mathematica: easy interactivity. Simply code a Manipulate environment where you can set the parameters yourself, like this:\nManipulate[\n    Show[\n        ListLinePlot[data],\n        Plot[a b^(-t), {t, 0, .10}, PlotStyle -> Red]\n    ],\n    {a, 0, 200},\n    {b, 0, 50000}\n]\n\n\n\n\nHere you can play around with the parameters, until your function (in red) roughly matches the data. Read the values of the parameters, use them as starting values, get delicious fit.\nLet's say you found out your starting parameters using Manipulate or from some solution manual (cough). Say your approximate values are $a\\approx 100$, $b\\approx10^{-5}$:\nFindFit[data, a*b^t, {{a, 100}, {b, 10^(-5)}}, t]\n\n\n{a -> 100.004, b -> 0.0000452493}\n\n\nThat's your textbook solution right there.\nAnother thing worth mentioning is NonlinearModelFit, the big brother of FindFit. It features not only fitting, it also generates a huge amount of extra data for statistical analysis, for example error estimates of the parameters and plotting confidence bands. Here's an example where I fitted a Gaussian point set with the theoretical curve:\n\n", "graphics - How can this confetti code be improved to include shadows and gravity?": "\n\nHow can this code be improved, for example, by including shadows, raytracing or the effects of gravity to make it more realistic?\n\nI felt that this question deserved an answer.  The one I describe here is to create a set of confetti \"agents\" that respond in quasi-physical ways to external forces and \"know\" how they should be displayed.\nIt is handy, and a whole lot of fun, to do this in an extensible and easily modified way, because you're going to think of loads of improvements to make once the framework is in place.  It helps to have well-documented code--there is less cognitive burden on you, the programmer, when modifying it--so I hope you won't mind that it's somewhat more verbose than usual.\nBy taking a top-down approach, this code practically writes itself.  Start with the agents themselves, the confetti:\nupdate[confetto[symbols_, location_, frame_, momentum_, angularMomentum_], \n      force_, {t_, dt_}] := \n  With[{\u03b4Momentum = force[location, frame, momentum, t]},\n   confetto[symbols, location + dt momentum, \n   rotate[frame, dt angularMomentum], \n   momentum + dt \u03b4Momentum, angularMomentum]\n  ];\n\nI have endowed a single \"confetto\" with information about how to draw it (symbols), its present location and momentum (location and momentum)--that is, its physical state--, and some internal state information (frame for the orientation and angular momentum for its rate of change: you will see the little pieces of paper rotate as they move).  That should be enough for rich simulations.  A simulation will proceed by applying update over time periods of short duration to update the state of each object.  This will rely on two other methods: force to compute forces and display to draw an object in its current state.\nUpdate calls rotate to change the orientation, so let's take care of that detail now:\ncrossProduct[{x_, y_, z_}, {x0_, y0_, z0_}] := \n   {y z0 - y0 z, z x0 - z0 x, x y0 - x0 y};\nrotate[frame_, \u03b1_] := # / (Norm[#] + 0.000001) & /@ \n      (Map[# + crossProduct[#, \u03b1] &, frame, {1}]);\n\n(You can probably do this faster with quaternions, but this is good enough for a start.)\nThere are many ways to display a confetto, depending on what kind of object you would like it to be.  For instance--this will be relatively fast and is useful for testing--just draw a point as a visual placeholder:\ndisplay[confetto[symbols_, location_,  ___]] := {symbols, Point[location]}\n\nYou can get more information by drawing a \"tail\" showing how the objects have been moving:\ndisplay[confetto[symbols_, location_, frame_, momentum_, ___]] := \n    {symbols, Thick, Line[{location, location - 0.2 momentum}]}\n\nTo emulate the other examples offered in this thread, and to show how the angular momentum works, let's view each object as a square.  The frame attribute of a confetto determines its size and orientation.  At the same time we draw these objects, we also draw their \"shadows,\" provided they are in front of the coordinate planes. Here, then, is a fancier version of display:\nshadow[x_, k_] /; 1 <= k <= Length[x] := ReplacePart[x, k -> 0];\ndisplay[confetto[symbols_, location_, frame_, ___]] := \n  Block[{x = frame[[1]], y = frame[[2]], vertices, objects, \n    shadowPlanes},\n   vertices = {location + x, location + y, location - x, location - y};\n   objects = {symbols, Polygon [vertices]};\n   shadowPlanes = Pick[Range[Length[location]], Positive[location]];\n   If [Length[shadowPlanes] > 0,\n    f = Function[{k}, Polygon[shadow[#, k] & /@ vertices]];\n    objects = Join[objects,\n      {Opacity[0.5], GrayLevel[0.3], EdgeForm[{GrayLevel[0.3], Opacity[0.1]}]},\n      f /@ shadowPlanes];\n    ];\n   objects\n   ]\n\nWrite your own display function to simulate other objects.\nNotice that none of this graphical work needs to get done except when we want to look at an object.  Thus, we could create a long simulation (using update) but call display only at key times, or when interesting things happen.  Separating the physics from the graphics is a good strategy.\nLater on, to help the eye make sense of these shadows, we will want to have some fixed \"walls\" on which the shadows appear.\nwalls[indexes_List, size_, \u03f5_] := \n  With[{square = {{1, 1}, {-1, 1}, {-1, -1}, {1, -1}}},\n   {RGBColor[.97, .97, .97], Opacity[.1],\n    Polygon /@ \n     Outer[Insert[ #2, \u03f5, #1] &, indexes, size square, 1] \n    }\n   ]\n\nUpdate invokes a \"force\" function to change an object's momentum.  Newtonian gravitation on a flat earth is especially simple:\ngravity[location_, frame_, momentum_, time_] := {0, 0, -1}\n\nIn general, the forces applied to an object depend on its location, the time (for time-varying forces), the object's location, and the situations of all other objects.  Handling the latter is complicated so I have not built it into this framework: only external forces are applied.  Here is a more complex example of what we can still do despite this limitation:\nsmokeRing[location_, frame_, momentum_, time_] := \n  Module[{normal = crossProduct @@ frame, origin = {15, 15, 15}, x,\n    wind0 , \u03c1, z, wind1, wind, windSpeed = 5},\n   x = location - origin;\n   wind0 = {x[[2]], -x[[1]], 0};\n   \u03c1 = Sqrt[x[[1]]^2 + x[[2]]^2] ; \n   If[\u03c1 == 0, \u03c1 = 1];\n   z = x[[3]] ;\n   wind1 = {-z x[[1]] / \u03c1, -z x[[2]]/ \u03c1, \u03c1 - 3};\n   wind = (wind0  + wind1) windSpeed / Norm[x] - momentum;\n    Abs[normal . wind] wind / Norm[wind] \n   ]\n\nYou can see it in action in the example below, where it has been added to the gravitational force.  If you would like to see this force field, (partial) visualizations can be drawn; e.g.,\nVectorPlot3D[\n    smokeRing[{x, y, z}, {{1, 0, 0}, {0, 0, 1}}, {0, 1, 0}, 0], \n        {x, 0, 30}, {y, 0, 30}, {z, 0, 30}]\n\nNote, though, that the force on a confetto depends on its orientation and its momentum: this attempts a realistic simulation of what wind does to a small slip of paper.\nYou might like to write code for other kinds of forces.  Can you blow one smoke ring through another and then turn it green? :-)\nWe're all set to go!  Let's make some confetti.  I will place them all at the same location with the same orientation at the outset, but endow them with randomly varying momenta and angular momenta so that they all do different things:\nr[n_] := RandomReal[NormalDistribution[0, 1], n];\nconfetti = \n  Table[confetto[\n    Hue[RandomReal[]], {20, 20, 25}, {{1,0,0}, {0,1,0}}, r[3], r[3]/2], {320}]\n\nTo make them fly, we just need to keep updating their state as a clock ticks:\n Module[{c = confetti, speed = 0.06, nFrames = 240, \n    w = walls[Range[3], 30, e = -0.02], time = 0, slices, \n    force = Through[(gravity + smokeRing)[##]] &},\n   slices = Table[time = time + speed; \n   c = ParallelMap[update[#, force, {time, speed}] &, c, {1}], {i, 1, nFrames}];\n   frames = ParallelMap[Graphics3D[{w, Map[display, #, {1}]}, \n         PlotRange -> {{e, 29}, {e, 29}, {e, 29}},\n         ViewVector -> {{70, 50, 40}, {-1, -1, -1}},\n         Boxed -> False, ImageSize -> 400] &, Prepend[slices, confetti], {1}]\n  ];\n\n(You could anti-alias the graphics here if you like.  I find that the computation takes too long, so I have left it out.)  Through is a handy way to create combinations of forces: this gives you a manageable way to handle extremely complex combinations of additive forces.\nThat was a 30 second calculation, by the way: not fast, but not too shabby.\nTo keep the file size down, I have exported only some of these frames:\nExport[\"F:/temp/confetti4a.gif\", frames[[141 ;; 210]]]\n\nEnjoy!\n\n", "options - Passing down arguments": "\nAre you looking for implementing option handling by any chance?\nHere's a small demonstration of implementing the WorkingPrecision option for function fun, giving it a default value, and always passing it down to subfun.\nOptions[fun] = {WorkingPrecision -> MachinePrecision}\n\n(* ==> {WorkingPrecision -> MachinePrecision} *)\n\nfun[arg1_, OptionsPattern[]] := \n subfun[arg1, WorkingPrecision -> OptionValue[WorkingPrecision]]\n\nfun[1]\n\n(* ==> subfun[1, WorkingPrecision -> MachinePrecision] *)\n\nfun[1, WorkingPrecision -> 10]\n\n(* ==> subfun[1, WorkingPrecision -> 10] *)\n\nIf you need to pass down every option, then @Mr.Wizard's solution is the right one.  To restrict it to options only (expressions of the form name -> value), use\nClearAll[fun]\nfun[arg_, opt: OptionsPattern[]] := subfun[arg, opt]\n\nfun[1, WorkingPrecision -> 10, someOptions -> \"value\"]\n\n(* ==> subfun[1, WorkingPrecision -> 10, someOptions -> \"value\"] *)\n\n", "What is the fastest way to locate an image inside a larger image?": "\nUsing ImageCorrelate, you can do something like\nbbox[img_, crop_] := {#, # + Reverse@ImageDimensions[crop] - 1} &@\n  Position[ImageData@\n     Binarize[\n      ImageCorrelate[img, crop, SquaredEuclideanDistance, \n       Padding -> None], .001], 0][[1]]\n\nExample\nimg = ExampleData[{\"TestImage\", \"Mandrill\"}]\ncrop = ImageTake[img, {40, 80}, {141, 200}]\n\nbbox[img, crop]\n\n\n{{40, 141}, {80, 200}}\n\n\nEdit\nIn response to the OP's question,here is an explanation of how bbox works.\nImageCorrelate in bbox creates a new image by calculating the Euclidean distance between crop and each of the sub images of img with the same dimensions as crop. The option Padding -> None is to make sure that the pixel at {i,j} in the result of ImageCorrelate corresponds to the sub image whose upper left corner is at position {i,j} in the original image. \nThe Euclidean distance between two images is zero only if they are the same, so to find the position of crop in img we just need to extract the position of the pixels with value {0.,0.,0.} from the image data of ImageCorrelate which is what Position[ImageData@Binarize[....]], 0] does. \nThis will give us the position of the upper left corner of crop. The lower right corner is then the upper-left corner plus the dimensions of crop (note that since ImageDimensions returns {number of cols, number of rows}, and the bounding box is given as {{rowMin, colMin}, {roxMaw, colMax}} we need to reverse ImageDimensions)\nEdit 2\nAs Szabolcs pointed out, the cut off in Binarize is somewhat arbitrary, and might cause false positives. As an alternative you could do something like this instead, which would find the best fit in the image:\nbbox[img_, crop_] := {#, # + Reverse@ImageDimensions[crop] - 1} &@\n (Position[#, Min[#]][[1]] &@\n   ImageData[ColorConvert[\n     ImageCorrelate[img, crop, SquaredEuclideanDistance, \n      Padding -> None], \"Graylevel\"]])\n\n", "programming - Visualizing several long lists of numerical information to see relative frequency": "\nIt seems to me that the zeros take up a lot of space and, if I understand the problem correctly, they aren't very useful in determining which works best match a particular search. \nHere is an alternative visualization that allows you to set thresholds on some basic statistics which ultimately allows you to \"zoom in\" on the works that are a best match under certain criteria. Note that it will drop any works where all word counts are zero (you can of course adjust this).\nviewerCount2 = RandomChoice[viewerCount1, Length[viewerCount1]];\nviewerCount3 = RandomChoice[viewerCount1, Length[viewerCount1]];\n\nManipulate[\n BarChart[Map[\n   Tooltip[Most[#], Row[{\"Work: \", Last[#], \" Counts: \", Most[#]}]] &,\n    DeleteCases[\n    Transpose@{viewerCount1, viewerCount2, viewerCount3, \n      Range[Length[viewerCount1]]}, {x__, w_} /; \n     Max[x] <= max || Mean[{x}] <= mean]], ChartLayout -> \"Stacked\", \n  ChartLegends -> {\"word1\", \"word2\", \"word3\"}], {max, 0, 20, \n  1}, {mean, 0, 10}]\n\n\n", "list manipulation - How to Derive Tuples Without Replacement": "\nHere is an alternative version of Mr. Wizard's uniqueTuples function, which is faster on the data I have tested.\nThe idea is to create a function f which has the following properties:\n\nIt returns an empty Sequence[] if two of its arguments are the same\nFor any other input it outputs a List of the arguments, but also\nsets a downvalue so that next time it is called with the same\narguments, it returns an empty Sequence[]\nIt is Orderless so that \"the same arguments\" can be in any order\n\nThe two input lists are then processed by Outer, feeding each tuple (as a flattened sequence of arguments) to f.\nFor example, \n\nThe list elements provided by Outer are {1,2,3} and 2. We evaluate f[1,2,3,2] which returns Sequence[] because 2 is duplicated.\nThe next list elements provided by Outer are {4,5,6} and 7.  We evaluate f[4,5,6,7] which returns {4,5,6,7} and sets f[4,5,6,7]=Sequence[].\nThe next list elements provided by Outer are {5,7,4} and 6.  We evaluate f[5,7,4,6] which is the same as f[4,5,6,7] and therefore returns Sequence[].\n\nSo the output from these 3 calls to f is just {4,5,6,7} as the others are not considered unique.\nThe alternative uniqueTuples looks like this:\n(* this is the re-written bit *)\nuniqueTuples[a_List, b_List] := Module[{f},\n  f[___, x_, x_, ___] = Sequence[];\n  f[x_, y__] := (f[x, y] = Sequence[]; {x, y});\n  SetAttributes[f, Orderless];\n  Flatten[Outer[f @@ Flatten[{##}] &, a, b, 1], 1]]\n\n(* this is the same as Mr. Wizard *)\nuniqueTuples[{a_List, x__List}] := Fold[uniqueTuples, a, {x}] \n\nTesting on data = RandomInteger[40, {6, 11}] gave me a Timing of 47.7 seconds for Mr. Wizards original code, and 6.6 seconds using this. I have no idea how the timings and memory usage scale as you go to larger data sets.\n", "image processing - Measure a DensityHistogram[] pair similarity": "\nWe'll use SmoothKernelDistribution. Correlated pair with left data set reflected around y-axis:\nlefTimagE = SmoothKernelDistribution[{-1, 1} # & /@ allSymFix[[3, 1]]];\nrighTimagE = SmoothKernelDistribution[allSymFix[[3, 2]]];\n\nVisualize in 3D:\n  Row@Plot3D[Evaluate[#], {x, -13, 13}, {y, -13, 13}, PlotRange -> All,\n  MeshFunctions -> {#3 &}, Mesh -> 15, PlotPoints -> 50] & /@ \n  {PDF[lefTimagE, {x, y}], PDF[lefTimagE, {x, y}] PDF[righTimagE, {x, y}], \n  PDF[righTimagE, {x, y}]}\n\n\nThe middle is overlap - notice small values. Integrate to find total characteristic\nNIntegrate[Evaluate[PDF[lefTimagE, {x, y}] PDF[righTimagE, {x, y}]], \n{x, -13, 13}, {y, -13, 13}, Method -> \"AdaptiveMonteCarlo\"] \n\nAnswer: 0.00549086\nRandom pair:\nlefTimagE = SmoothKernelDistribution[{-1, 1} # & /@ allSymFix[[3, 1]]];\nrighTimagE = SmoothKernelDistribution[allSymFix[[15, 2]]];\n\nVisualize in 2D this time for verity:\nRow@ContourPlot[Evaluate[#], {x, -13, 13}, {y, -13, 13},PlotRange -> All, \nMesh -> 15, PlotPoints -> 50] & /@ {PDF[lefTimagE, {x, y}], PDF[lefTimagE, \n{x, y}] PDF[righTimagE, {x, y}], PDF[righTimagE, {x, y}]}\n\n\nThe middle is overlap. Integrate to find total characteristic\nNIntegrate[Evaluate[PDF[lefTimagE, {x, y}] PDF[righTimagE, {x, y}]], \n{x, -13, 13}, {y, -13, 13}, Method -> \"AdaptiveMonteCarlo\"]\n\nAnswer: 0.0038788\nI liked Andy's analysis of the whole set for his metric. I ran it for my integral metric too:\nCorrelated pairs:\ncoRdaT = Table[NIntegrate[Evaluate[PDF[SmoothKernelDistribution[{-1, 1} \n# & /@ allSymFix[[k, 1]]], {x, y}] PDF[SmoothKernelDistribution[\nallSymFix[[k, 2]]], {x, y}]], {x, -13,13}, {y, -13, 13}, \nMethod -> \"AdaptiveMonteCarlo\"] , {k, 1, 93}];\n\nRandom pairs:\nuNcoRdaT = Table[NIntegrate[Evaluate[PDF[SmoothKernelDistribution[{-1, 1} \n# & /@ allSymFix[[k, 1]]], {x, y}] PDF[SmoothKernelDistribution[\nallSymFix[[RandomInteger[{1, 93}], 2]]], {x, y}]], {x, -13, 13}, \n{y, -13, 13}, Method -> \"AdaptiveMonteCarlo\"] , {k, 1, 93}];\n\nAnalysis:\nSmoothHistogram[{coRdaT, uNcoRdaT}, Filling -> Axis, \nPlotStyle -> {{Thick, Blue}, {Thick, Red}}]\n\n\nConclusion: on average integral of overlap for correlated pairs almost order of magnitude greater than for random pairs.\n======= ARCHIVE: less reliable, needs-polishing approach =======\nHere is a very simple take on this. If my understanding is correct, @500 wishes to see spatial correlation between left and right 2D patterns. I'll use SmoothDensityHistogram because it IMO gives better data representation in this case, but you can use your original approach too. The idea is to use ImageMultiply to \"amplify\" overlapping regions. Midle image is the overlap for a specific set of your data. Note it was ImageAdjust-ed for better visual perception. As numeric measure you have red number (computed before ImageAdjust for uniform scale) The red number is total \"intensity\" of overlap which could be some sort of correlation measure. BTW we also need to reflect one of the images around vertical axis, otherwise overlap will be meaningless. Here is correlated pair - data set 3, left and right images. As you can see the red number is high and the overlap does look like originals.\nili = SmoothDensityHistogram[#, Background -> Black, \n     ColorFunction -> GrayLevel, ImageSize -> 300, \n     PlotRange -> {{-13, 13}, {-13, 13}}, ImagePadding -> 0, \n     ImageMargins -> 0, PlotRangePadding -> 0, Mesh -> 0] & /@ \n   allSymFix[[3]];\nil = {ImageReflect[ili[[1]], Left -> Right], ili[[2]]};\nFramed@Labeled[GraphicsRow[Riffle[il, (cori = \n       ColorConvert[ImageMultiply @@ il, \"Grayscale\"]) // \n     ImageAdjust], Spacings -> 1], ImageData[cori] // Total // Total, \n  Top, LabelStyle -> Directive[Red, Bold, 20]]\n\n\nAnd here is random pairing of set 3 left image and set 15 right image. As you can see the red number is much less and the overlap does not look like originals.\nili = SmoothDensityHistogram[#, Background -> Black, \n     ColorFunction -> GrayLevel, ImageSize -> 300, \n     PlotRange -> {{-13, 13}, {-13, 13}}, ImagePadding -> 0, \n     ImageMargins -> 0, PlotRangePadding -> 0, \n     Mesh -> 0] & /@ {allSymFix[[3, 1]], allSymFix[[15, 2]]};\nil = {ImageReflect[ili[[1]], Left -> Right], ili[[2]]};\nFramed@Labeled[GraphicsRow[Riffle[il, (cori = \n       ColorConvert[ImageMultiply @@ il, \"Grayscale\"]) // \n     ImageAdjust], Spacings -> 1], ImageData[cori] // Total // Total, \n  Top, LabelStyle -> Directive[Red, Bold, 20]]\n\n\nA word of caution: Andy's good comment made me realize there are a few things to worry about here. Most impotently, in most cases our graphics resales the data before it passes them to ColorFunction. This means that for these different data sets their maximums will look same bright on the plots:\nMax /@ {allSymFix[[3, 1]], allSymFix[[15, 2]]}\n*Answer:* {10.466, 11.172}\n\nThis affects correct overlap estimates. \n", "evaluation - Injecting a sequence of expressions into a held expression": "\n{3, 4} /. {x__} :> Hold[{1, 2, x}]\n\n\nHold[{1, 2, 3, 4}]\n\n\nLeonid Shifrin used this here long before I wrote this answer.\n\nIn light of Leonid's comment to halirutan it is worth pointing out that you can inject expressions from an arbitrary head including Hold.  You can also use -> rather than :> like this:\nexpr = Hold[{1, 2, x}];\n\nHold[6/2, 2 + 2] /. _[x__] -> expr \n\n\nHold[{1, 2, 6/2, 2 + 2}]\n\n\n", "performance tuning - Efficiently collecting results inside a compiled function": "\nAssuming you know the dimensions of the pieces that you want to come out you can always add a second argument to Internal`StuffBag that indicates the rank of the elements going in. The result is still flat so you have to partition after the fact.\ncf = Compile[{}, Module[{bag = Internal`Bag[]},\n    Do[Internal`StuffBag[bag, {i, i, i}, 1], {i, {0, 1, 2, 3}}];\n    Partition[Internal`BagPart[bag, All], 3]]];\n\nHere I'm indicating that vectors will be going in to the bag.  I would specify 2 for a matrix. Notice that it no longer calls MainEvaluate.\nIn[25]:= StringFreeQ[CompilePrint[cf], \"MainEvaluate\"]\n\nOut[25]= True\n\nIn[20]:= cf[]\n\nOut[20]= {{0., 0., 0.}, {1., 1., 1.}, {2., 2., 2.}, {3., 3., 3.}}\n\n", "How to write a function to add edges or vertex to a graph": "\nUpdate: Can I add a mixture list of vertices and edges to an existing graph?\nClearAll[addToGraph]\naddToGraph[g_Graph, stuffToAdd_] := Fold[\n If[Head[#2] === UndirectedEdge || Head[#2] === DirectedEdge, EdgeAdd, VertexAdd]@ ## &,\n g, stuffToAdd]\n\nExample:\ng = Graph[{a, b, c}, {a <-> b, b <-> c, c <-> a}, \n VertexLabels -> Placed[\"Name\", Center], VertexSize -> Scaled[.1], \n VertexLabelStyle -> 18, AspectRatio -> 1];\n\naddToGraph[g, {d, d <-> a, e, h <-> a}]\n\n\nOriginal answer:\nThe functions you need are VertexAdd, EdgeAdd, and their relatives VertexDelete and EdgeDelete.\nFor the graph\ng = Graph[{a, b, c}, {a <-> b, b <-> c, c <-> a}, \n VertexLabels -> Placed[\"Name\", Center], VertexSize -> Scaled[.1], \n VertexLabelStyle -> 18, AspectRatio -> 1]\n\n\nAdding a vertex \nVertexAdd[g, d]\n\n\nAdding an edge\nEdgeAdd[g, d <-> a]\n\n\nDeleting an edge\nEdgeDelete[g, c <-> a]\n\n\n", "Get the neighboring vertices and incident edges from a vertex in a graph": "\nA random graph\n g = RandomGraph[{15, 35}, VertexLabels -> \"Name\", PlotRangePadding -> .2]\n\n\nEdges for the vertex 4:\n EdgeList[g, 4 \\[UndirectedEdge] _]\n\nResult:\n\nNow vertexes around vertex4:\n VertexList[NeighborhoodGraph[g, 4]]\n\nResult:\n {4, 14, 11, 6, 7, 9, 13, 15}\n\nIllustration:\n  HighlightGraph[g, NeighborhoodGraph[g, 4]]\n\n\nThere are many other ways. You could also use AdjacencyMatrix to get all that info.\n", "front end - How can I change the keyboard shortcut for switching the active window?": "\nYou need to add the following to KeyEventTranslations.tr:\nItem[KeyEvent[\"Tab\", Modifiers -> {Control}],\n   FrontEndExecute[FrontEndToken[\"CycleNotebooksForward\"]]],\n\nItem[KeyEvent[\"Tab\", Modifiers -> {Shift, Control}],\n   FrontEndExecute[FrontEndToken[\"CycleNotebooksBackward\"]]],\n\nThis will map Control-Tab and Control-Shift-Tab to cycling between notebooks.\nFor some reason, using the Tab key sometimes fails, but any alternative shortcut could be used (for example Ctrl-`).\nOn Windows KeyEventTranslation.tr is located in\n$InstallationDirectory\\SystemFiles\\FrontEnd\\TextResources\\Windows\n\n", "hold - How can you stop ordering of InputField entries?": "\nYou could do something like\nInputField[Dynamic[d, (d = HoldForm @@ #) &], Hold[Expression]]\n\nThis will wrap the expression typed into the input field in HoldForm.\n\n\n\n", "calculus and analysis - Using implicit differentiation to find a line that is tangent to a curve at a point": "\nI'm not sure the implicit case allows for a solution as elegant as the explicit case; here is what I'd do, however:\neq = x^2 + x y + y^2 == 3; pt = {1, 1};\nWith[{m = (Dt[y, x] /. First[Solve[Dt[eq, x], Dt[y, x]]]) /.\n            Thread[{x, y} -> pt]}, \n           Collect[m (x - First[pt]) + Last[pt], x, Simplify]]\n2 - x\n\nAs you can see, this assumes a point pt on the implicitly-defined curve eq is already known; if not, a preliminary application of Solve[] is necessary.\n\nPrompted by Michael's answer, I managed to figure out a second solution, based on the properties of the gradient of a function of two variables (here computed as D[f, {{x, y}}]):\neq = x^2 + x y + y^2 == 3; pt = {1, 1};\nExpand[(D[Subtract @@ eq, {{x, y}}] /. Thread[{x, y} -> pt]).({x, y} - pt)] == 0\n-6 + 3 x + 3 y == 0\n\nThis also requires that both coordinates of pt are already known, as in the first method.\n\nWarning:\nIt must be noted, however, that both approaches given so far will fail spectacularly if the point being considered is in fact a singular point of the given curve (e.g. the (cru)node at the point $(0,0)$ of the folium of Descartes $x^3+y^3=3xy$). There are special techniques to attack cases like this (based on the clever evaluation of an appropriate limit), but I shall not say anything further about them in this answer.\n", "plotting - How to work around incorrect tooltips in plots exported to HTML": "\nSome time ago I wanted to have good tooltips for images composed by polygons. Mathematica generated square areas only, and the polygons had many shapes. Then I did my own export function for polygons with tooltips. I basicaly rescaled all the polygon points to the image size and wrote the image maps. I never found how to get the right area from Mathematica. I also investigated the SVG, but didn't find anything useful (didn't get the tooltips to work). I will have to check the SVG capabilities of M8, but I guess they have not change much.\n", "front end - Implementing efficient multiple undo": "\nI implemented a multiple undo mechanism in v10.\nIt's not as perfect as I would like it to be, yet, but it does a pretty decent job in my experience.   And a few of the documented options for it got ahead of the implementation...think of some of that stuff as a \"coming soon\".\nFeel free to ping me on any problems you find with it.\nEdit: In 10.0.2, all of the documented options are implemented except for \"SpoolDirectory\".\n", "numerics - Is it possible to use the LevenbergMarquardt algorithm for fitting a black-box residual function?": "\nHere is the solution based on Faysal's code:\nsteps=0; \nFindMinimum[Null,\n {optimVariables, initialGuess}\\[Transpose],\n Method -> {\"LevenbergMarquardt\", \n   \"Residual\" -> Sqrt[2] residualVector[optimVariables], \n   \"Jacobian\" -> {Sqrt[2] jacobianMatrix[optimVariables], EvaluationMonitor :> ++steps}, \n   \"StepControl\" -> {\"TrustRegion\", \"StartingScaledStepSize\" -> 1/1000, \"MaxScaledStepSize\" -> 1/10, \"AcceptableStepRatio\" -> 1/3}}]\n\nNote that it is recommended to use exact numbers for the parameters of the \"TrustRegion\" method because these parameters are used inside of the algorithm without any check for consistency with WorkingPrecision. I should also note that the actual residual vector and jacobian must be multiplied by Sqrt[2] for having FindMinimum returning the minimum equal to\nresidualVector[optimVariables].residualVector[optimVariables]\n\nand not to\nresidualVector[optimVariables].residualVector[optimVariables]/2\n\nas it is by default.\nThe jacobian may be calculated automatically by the following code:\njacobianMatrix[_] = D[residualVector[optimVariables], {optimVariables}]\n\nOne can restrict the jacobian to be evaluated for numerical values only by defining it as:\njacobianMatrix[_List?(VectorQ[#, NumberQ] &)] = \n    D[residualVector[optimVariables], {optimVariables}]\n\n", "export - How do I save a variable or function definition to a file?": "\nYou can use DumpSave:\nexampleData = {{1, 1}, {2, 3}, {3, 4}, {4, 7}, {5, 5}, {6, 4}, {7, 2}};\ninterPolFunc[x_] = Interpolation[exampleData, x]\n\n(note the use of Set (=) rather than SetDelayed so as to have the interpolating function evaluated only once; the way you had it, you interpolated each and every time).\nDumpSave[\"~/Desktop/interpol.mx\", interPolFunc]\n\nthen\nQuit[]\nDumpGet[\"~/Desktop/interpol.mx\"]\ninterPolFunc[4]\n(*7*)\n\n", "front end - Delete the current notebook cell using the keyboard": "\nReferencing Szabolcs's answer, here is the code that must be added to KeyEventTranslations.tr:\nItem[KeyEvent[\"m\", Modifiers -> {Control}],\n    FrontEndExecute[{\n        FrontEnd`SelectionMove[FrontEnd`SelectedNotebook[], All, Cell], \n        FrontEnd`FrontEndToken[\"Clear\"]\n    }]],\n\nI chose Ctrl+M at random; change it to whatever you want.\nSee this before you edit the file.\n", ".netlink - Using .NET 4.0 from NETLink": "\nUPDATE The following steps are no longer necessary if one is using Mathematica version 9 -- it comes preconfigured to use .NET 4.x.\nNETLink uses an interlude .NET application to broker communication with the framework. The application is called InstallableNET.exe (InstallableNET32.exe on 32-bit systems) and can be found in this directory:\nSystemOpen @\n  FileNameJoin[{$InstallationDirectory, \"SystemFiles\", \"Links\", \"NETLink\"}]\n\nThe application will use the version of the .NET framework that is configured in its .config file.  To make it use version 4.0, add a new line within the startup element:\n<supportedRuntime version = \"v4.0\"/>\n\nVersions are tried in the order that they appear in the file, so place the preferred version first.  The updated  InstallableNET.exe.config will look something like this:\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<configuration>\n  <startup>\n    <!-- The supportedRuntime lines control which version of the .NET Framework will\n         be used when .NET/Link is launched with InstallNET[].\n         .NET/Link requires at least .NET 2.0. If you have .NET 3.0 installed,\n         it will be used (note that the 3.0 version is really just the 2.0\n         version with some extra assemblies).\n      -->\n      <supportedRuntime version=\"v4.0\" />\n      <supportedRuntime version=\"v2.0.50727\" />\n  </startup>\n</configuration>\n\nNote: If you're using Mono instead of Microsoft's CLR, you'll have to delete the first few (invisible) bytes from the XML file due to a Mono bug. One way to do this would be to tell your text editor to save the XML file as ASCII instead of Unicode. Another way would be to copy and paste the body of the file into a new file and then copy the new file over the previous InstallableNET.exe.config file.\n\nUPDATE: .NET Versions 4.5.x and Later\nThe steps reported above will automatically select the latest installed version of the .NET Framework in the 4.x line.  This includes the 4.5.x releases.\nBeware, however, that the call to System`Environment`Version shown above can be misleading.  All of the 4.5.x versions report a version string that starts with \"4.0\".  For example, at time of writing my machine has version 4.5.2 installed.  Yet:\nSystem`Environment`Version@ToString[]\n(* 4.0.30319.34209 *)\n\nThe magic number 34209 on the end of this version string actually identifies it as a 4.5.2 build - see StackOverflow answer (12972517) for a list of version strings.\nThe .NET documentation for Environment.Version expressly discourages its use to identify the 4.x minor version.  Instead, it recommends querying the registry to identify the exact version:\nNeeds[\"Developer`\"]\nReadRegistryKeyValues @\n  \"HKEY_LOCAL_MACHINE\\\\Software\\\\Microsoft\\\\NET Framework Setup\\\\NDP\\\\v4\\\\Full\"\n\n(* { Version->4.5.51209,\n     TargetVersion->4.0.0,\n     Install->1,\n     MSI->1,\n     Servicing->0,\n     InstallPath->C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\,\n     Release->379893\n   } *)\n\nThe Release magic number is described in a Microsoft library article.  But be aware that this registry key does not exist for earlier .NET versions.\nIf we want even more evidence to convince ourselves that Mathematica is accessing the latest .NET version, we can always attempt to access API that does not exist in earlier versions.  Here is an example using a type that does not exist prior to version 4.5.x:\nLoadNETType[\"System.Reflection.ReflectionContext\"]\n(* NETType[System.Reflection.ReflectionContext,6] *)\n\n", "functional style - Using sets of arguments from a list": "\nYou could use Apply at the first level:\nTimes @@@ listA\n\n", "mathematical optimization - Symbolic Optimisation": "\nThe error is in your differentiation line:\nFOC = D[f[qu_, quu_, qud_, \\[Psi]_], quu]\n\nChange this to\nFOC = D[f[qu, quu, qud, \\[Psi]], quu]\n\nand you'll get a meaningful answer.\nThe reason for this behavior is that x_ is a pattern that matches anything, and this anything can then be referred to by using x. You can read your function definition, f[qu_, ...] := ... as \"Whenever Mathematica encounters an expression of the form f[something, ...], it is to be replaced by whatever you specified on the right side of the :=. When you call the function, you do of course not want to differentiate the pattern f[qu_, ...], you want Mathematica to substitute it by some term, and then differentiate whatever is the result of the substitution (i.e. your actual formula). What the program does right now is use your definition of f, insert a pattern as function values, and then differentiate that. You do not want that of course, you want to insert the actual variables.\n", "calculus and analysis - Hankel Transform integrals won't work in Mathematica": "\nThe answer is simply that integrating with the assumption that a variable comes from the class of integers is really difficult. What Integrate does with Assumptions -> Element[m, Integers] is try to generically integrate without the assumption and then apply the assumption to the result to try and simplify it. I've asked around about this before and there doesn't seem to be a good way to make a generic algorithm that actually handles assumptions like Element[m, Integers]. \nYou can find many cases where Assumptions -> Element[something, Integers] doesn't produce the expected simplification. Most of the cases I've seen of integrals where a variable is assumed to be an integer are where the integrand is the product of two orthogonal functions. In these cases,the way these are solved on paper doesn't generalize easily.\n", "formatting - Keeping Text Size the Same Throughout Entire Notebook File": "\nThere are a variety of ways to do this.  One can use Stylesheets as noted by acl.  Perhaps the most direct way is this:\nFor one Notebook:\nSetOptions[EvaluationNotebook[], FontSize -> 16]\n\nFor all Notebooks:\nSetOptions[$FrontEnd, FontSize -> 16]\n\nYou can also set FontSize for different Box types, such as GraphicsBox:\nSetOptions[$FrontEnd, GraphicsBoxOptions -> {BaseStyle -> {FontSize -> 15}}]\n\nIf you are more comfortable with a GUI, all of these options are available through the Options Inspector in the Format menu.\n\nIf you decide to go the advanced route and use style sheets here is a guide to get you started:\nDavid Park's StyleSheet creation notes (.zip file)\n\nDepending on your goals, this question may also be of interest:\nHow to set default magnification for all windows\n", "graphics - How do I plot a plane EM wave?": "\nHere's a variation of the plane wave rendering done in rm -rf's answer. Here, I use arrows instead of lines to indicate the wave's displacement from the axis:\nwaveDiagram[xm_, col_, k_] := Flatten[First[\n    Normal[Plot[Sin[x], {x, 0, xm}, Mesh -> Full, \n                PlotStyle -> Directive[col, Arrowheads[Small]]]] /. \n           Point[{x_, y_}] :> \n             If[Chop[Abs[y]] < 0.1, Point[{x, 0}], Arrow[{{x, 0}, {x, y}}]]]] /. \n          v_ /; VectorQ[v, NumericQ] && Length[v] == 2 :> Insert[v, 0, k]\n\nGraphics3D[(* axes *)\n           {{Gray, {Arrowheads[.02], \n            Arrow[{{0, 0, 0}, {9 \u03c0/2, 0, 0}}]}, {Arrowheads[.01 {-1, 1}], \n            Arrow[{{0, 1, 0}, {0, -1, 0}}], Arrow[{{0, 0, 1}, {0, 0, -1}}]}}, \n           waveDiagram[4 \u03c0, Darker[Blue], 2], \n           waveDiagram[4 \u03c0, Darker[Green], 3]},\n           Boxed -> False, BoxRatios -> {2, 1, 1}]\n\n\nAs a variation, here's a depiction of the circular polarization of a plane wave:\nShow[\n     (* circularly polarized wave *)\n     Normal[ParametricPlot3D[{t, -Sin[t], Cos[t]}, {t, 0, 4 \u03c0}, Mesh -> Full, \n            PlotStyle -> Directive[Darker[Blue], Arrowheads[Small]]]] /. \n     Point[{x_, y_, z_}] :> \n           If[Chop[Norm[{y, z}]] < 0.1, Point[{x, 0, 0}], \n              Arrow[{{x, 0, 0}, {x, y, z}}]],\n     (* axes *)\n     Graphics3D[{{Gray, {Arrowheads[.02], Arrow[{{0, 0, 0}, {9 \u03c0/2, 0, 0}}]},\n                 {Arrowheads[.01 {-1, 1}], Arrow[{{0, 1, 0}, {0, -1, 0}}], \n                  Arrow[{{0, 0, 1}, {0, 0, -1}}]}}}],\n                Axes -> None, Boxed -> False, BoxRatios -> {2, 1, 1}, PlotRange -> All]\n\n\n\nThe common theme in both diagrams is the use of the Mesh option of the plotting functions, which generates Point[]s on the curve(s) at preset locations. From here, we replace each Point[] object generated with an Arrow[] whose head has the coordinates of the original Point[]; how the position of the tail is determined depends on the plot being done.\n", "programming - How to make a function like Set, but with a Block construct for the pattern names": "\nPerhaps something like this:\nSetAttributes[localSet, HoldAll]\n\nlocalSet[lhs_, rhs_] := \n  Union @@ Cases[\n    Unevaluated[lhs], \n    Verbatim[Pattern][p_, _] :> HoldComplete[p],\n    Infinity,\n    Heads -> True\n  ] /. _[x___] :> Block[{x}, lhs = rhs;]\n\nTest:\nvar=3;\nlocalSet[f[var_],Normal[Series[Exp[var],{var,0,3}]]]\nDownValues[f]\n\n\n{HoldPattern[f[var_]] :> 1 + var + var^2/2 + var^3/6}\n\n\n", "plotting - Creating Plots for a Family of Solutions": "\nI guess you have some sort of time evolution of Bessel-like waves. I also see that your examples deal with 3rd zero of Bessel J0 - I'll use it too. Define a function: \nmYf[r_, t_, n_] := With[\n    {k = BesselJZero[0, n]}, \n    (Cos[k t] + Sin[k t]) BesselJ[0, k r]\n]\n\nBuild a time evolution list:\ngiflist = Table[\n    RevolutionPlot3D[\n        Evaluate[N@mYf[r, t, 3]],\n        {r, 0, 1}, \n        SphericalRegion -> True,\n        PlotRange -> {{-1, 1}, {-1, 1}, {-1.5, 1.5}},\n        ImageSize -> 450,\n        PlotStyle -> Opacity[.7],\n        ColorFunction -> \"TemperatureMap\", \n        MeshStyle -> Opacity[.5],\n        PlotLabel -> time == t\n    ], \n    {t, 0, 2 Pi/N[BesselJZero[0, 3]], .05}\n];\n\nDisplay as animated .GIF -\nExport[\"bessel.gif\", giflist]\n\n\nDisplay as a table:\nGraphicsGrid[\n    Partition[\n        Show[#,Boxed ->False, Axes -> False] & /@ giflist,\n        5\n    ], \n    ImageSize -> 500,\n    Spacings -> 0\n]\n\n\nCreate an interface to investigate parameters. You BTW did not define dependence of a and b on n so I'll just define them generically: \nManipulate[\n    RevolutionPlot3D[\n        Evaluate[N@mYf[r, t, n, a, b, \u03b1]],\n        {r, 0, 1},\n        SphericalRegion -> True, \n        PlotRange -> {{-1, 1}, {-1, 1}, {-1.5, 1.5}},\n        ImageSize -> 350,\n        PlotStyle -> Opacity[.7],\n        ColorFunction -> \"TemperatureMap\",\n        MeshStyle -> Opacity[.5],\n        PlotLabel -> time == t,\n        PlotPoints -> 25\n    ], \n    {{t, 1.36, \"time\"}, 0, 2, ImageSize -> Tiny},\n    Delimiter,\n    \"zero's order\", \n    {{n, 7, \"\"}, Range[7], SetterBar, ImageSize -> Tiny},\n    Delimiter,\n    {{a, 1.2, \"a_n\"}, 0, 2, ImageSize -> Tiny},\n    {{b, 1, \"b_n\"}, 0, 2, ImageSize -> Tiny},\n    {{\u03b1, .9, \"\u03b1\"}, 0, 2, ImageSize -> Tiny},\n    FrameMargins -> 0,\n    ImageMargins -> 0, \n    ControlPlacement -> Left, \n    Initialization :> (\n        mYf[r_, t_, n_, a_, b_, \u03b1_] := \n            With[\n                {k =  BesselJZero[0, n]},\n                (a Cos[\u03b1 k t] + \n                  b Sin[\u03b1 k t]) *\n                  BesselJ[0, k r]\n            ]\n    )\n]\n\n\n", "front end - How to automate a FrontEnd return?": "\nTry using this:\nFrontEndExecute[\n  {FrontEnd`NotebookFind[FrontEnd`SelectedNotebook[], \n                         \"Output\", All, CellStyle, AutoScroll->False], \n   FrontEnd`FrontEndToken[\"Clear\"]}]\n\n(Untested in KeyEventTranslations.tr, but works as a button!)\n\nRegarding automating confirming the dialog---I don't think it is possible from within Mathematica.  I'd like to note though that you can press Space to confirm the dialog (instead of using Enter), which is considerably easier for me due to the size and position of the key.\n\nUpdate:  As Albert Retey pointed out in a comment, this will only remove output cells, but not \"Message\" or \"Print\" cells.  Those need to be added separately to the command, and this is still a workaround to finding all GeneratedCells.\n", "What is the best way to clip a graphic to a region?": "\nI'm pretty sure this can't be done. As evidence of this I put forward Import[] of .EPS and .PDF with such clipping in it: mathematica imports the shapes unclipped. If there would be some undocumented function to do this clipping, I would assume that Import[] would make use of it.\n", "compile - Visual Studio Express 2010 on x86-64: libcmt.lib missing": "\nJust thought I'd share.\nI had the same problem after re-installing VS2010 Ultimate (I also have 2008).\nTo fix it, I copied the following\n\nlibcmt.lib\nlibcmt.pdb\nlibcmtd.lib\nlibcmtd.pdb\noldnames.lib\n\nfrom C:\\Program Files\\Microsoft Visual Studio 11.0\\VC\\lib\nto C:\\Program Files\\Microsoft Visual Studio 10.0\\VC\\lib\nHope this helps someone.\n", "graphics - Subplots with connector lines": "\nThis solution uses FullGraphics to transform axes and ticks in a plot to lines which allows you to resize and translate the plot while keeping the ticks of the original plot. In raster, main is the main plot, list is the list of sub plots, pts is the list of points in the main plot corresponding to the begin points of the red lines, and {dx, dy} are the gaps between the sub plots and the main plot. The sub plots are placed in clockwise direction starting with the one in the upper right corner. The end plot is such that the plot range of the main plot is {{0, 0}, {1, 1}}.\nraster[main_, list_, pts_, {dx_, dy_}] := \n Module[{fgmain, fglist, prm, prl, scmain, sclist, scpts, lines},\n  fgmain = FullGraphics[main];\n  fglist = FullGraphics /@ list;\n  prm = OptionValue[AbsoluteOptions[main, PlotRange][[1]], \n    PlotRange];\n  prl = OptionValue[Options[#, PlotRange][[1]], PlotRange] & /@ list;\n  scmain = \n   Translate[\n    Scale[fgmain[[1]], 1/(prm[[All, 2]] - prm[[All, 1]]), \n     prm[[All, 1]]], -prm[[All, 1]]];\n  scpts = Transpose[{Rescale[pts[[All, 1]], prm[[1]]],\n     Rescale[pts[[All, 2]], prm[[2]]]}];\n  sclist = MapThread[\n    Translate[\n      Scale[#, (.5 - {dx, dy}/\n           2)/(#2[[All, 2]] - #2[[All, 1]]), #2[[All, 1]]],\n      -#2[[All, 1]] + #3] &,\n    {fglist[[All, 1]], prl, {{-.5 - dx/2, 1 + dy},\n      {0, 1 + dy}, {.5 + dx/2, 1 + dy}, {1 + dx, 1 + dy},\n      {1 + dx, .5 + dy/2}, {1 + dx, 0}, {1 + dx, -.5 - dy/2},\n      {.5 + dx/2, -.5 - dy/2}, {0, -.5 - dy/2}, {-.5 - dx/2, -.5 - \n        dy/2},\n      {-.5 - dx/2, 0}, {-.5 - dx/2, .5 + dy/2}}}];\n  lines = Transpose[{scpts,\n     {{-dx, 1 + dy}, {.25 - dx/4, 1 + dy}, {.75 + dx/4, \n       1 + dy}, {1 + dx, 1 + dy},\n      {1 + dx, .75 + dy/4}, {1 + dx, .25 - dx/4}, {1 + dx, -dy},\n      {.75 + dx/4, -dy}, {.25 - dx/4, -dy}, {-dx, -dy},\n      {-dx, .25 - dy/4}, {-dx, .75 + dy/4}}}];\n  Graphics[{scmain, sclist, {Red, Dashed, Line[lines]}}]]\n\nExample:\nlist = MapIndexed[ParametricPlot[#, {x, 0, 2 Pi}, \n     Frame -> True, Axes -> False,\n     PlotStyle -> (ColorData[1] @@ #2)] &,\n   Table[{(n - 1) 2 Pi + x, n Sin[x]}, {n, 12}]];\nmain = Show[list, PlotRange -> All];\npts = N[Table[{(n - 1) 2 Pi + x, n Sin[x]}, {n, 12}] /. x -> Pi];\n\nraster[main, list, pts, {.15, .15}]\n\n\n", "linear algebra - Computing eigenvectors and eigenvalues": "\nThe function to obtain both the eigenvalues and the eigenvectors is Eigensystem. Use it as {eigVals,eigVecs} = Eigensystem[matrix]. \nIf the matrix is symbolic, then the output (if you wait long enough for it to churn out an answer!) will only be as a list of general solutions for the roots of a 9th order polynomial with unknown coefficients, and there are no closed form solutions for polynomials with orders greater than 4. The results will not have any particular ordering.\nOn the other hand, a 9x9 numerical matrix is a piece of cake (even if you were to solve the characteristic polynomial), so you should have no problems.\nTo obtain the largest (first) eigenvalue and the corresponding eigenvector, use the optional second argument as Eigensystem[matrix, 1]. Here's an example (with a smaller matrix to keep the output small):\nmat = RandomInteger[{0, 10}, {3, 3}];\n{eigVals, eigVecs} = Eigensystem[mat] // N\n\n(* Out[1]= {{21.4725, 6.39644, 0.131054}, {{1.3448, 0.904702, 1.}, \n            {0.547971, -1.99577, 1.}, {-0.935874, -0.127319, 1.}}} *)\n\n{eigVal1, eigVec1} = Eigensystem[mat, 1] // N\n(* Out[2]= {{21.4725}, {{1.3448, 0.904702, 1.}}} *)\n\n", "bugs - Avoid crash in recursive Dynamic": "\nBased on this MathGroup post describing a similar crash, the right click can be caught and discarded like this:\nl = 1;\nEventHandler[Dynamic[Sin[l = l + 1]], {\"MouseUp\", 2} :> Null]\n\nThis won't let you copy the value, but it will prevent crashes due to accidental right clicks.\nYou can obtain the value by evaluating l as a different input.\n", "programming - Simplifying already defined symbols": "\nHow about defining this function\nSetAttributes[updateSymbols, HoldAll]\nupdateSymbols[syms__] := \n   Scan[Function[x, If[ValueQ[x], x = x], HoldAll], Hold[syms]]\n\nthen running\nupdateSymbols[x, y]\n\nafter the definitions have been made?\nIt will redefine each symbol, evaluating the RHS of their definitions.\nNote: Only works for OwnValue-symbols, and I'm not entirely sure it can't break something.\n\nUsage example:\nx=y;\ny=2;\n\n?x\n(* ==>\n Global`x\n x=y\n*)\n\n?y\n(* ==>\nGlobal`y\ny=2\n*)\n\nupdateSymbols[x,y]\n\n?x\n(* ==>\nGlobal`x\nx=2\n*)\n\n?y\n(* ==>\nGlobal`y\ny=2\n*)\n\n", "java - How do you get Weisstein\u2019s Hyphenate package to run?": "\nThe package comments contain the following information:\n\nRequirements\n      Download and install http://www.davidashen.net/texhyphj.html in \n      $HyphenPath = \"/Volumes/Users/eww/tex/texhyphj\";\n\nThe package relies on this external Java code, and will not run without it. It needs to be downloaded separately, and put in the same folder as the Hyphenate.m file. Then, you modify the following code line from the package:\n$HyphenPath=\"/Volumes/Users/eww/tex/texhyphj\";\n\nto refer to the path of the files on your own system.\n", "scoping - Local variabls - Mathmatica Stack Exchang": "\nOk, let me tell you straight away that what you are trying to do is likely to be a bad idea. Now, let me explain. The problem you face on the surface is that Evaluate is only effective at the first level inside heads which hold their arguments. Since you have SetDelayed[f[y_],Module[...]], the stuff inside Module is too deep. You need With to inject arbitrarily deep, so we try:\nClearAll[f, x];\nWith[{tmp = tmp2},\n   f[y_] := Module[{x = 1}, y tmp]] \n\nHowever, now you face another problem: variable renaming mechanism in scoping constructs tries to protect the scoping and renames variables in part of your code:\n?f\nGlobal`f\nf[y$_]:=Module[{x$=1},y$ (1+x^2)]\n\nHere is what you can do to achieve your goal:\nClearAll[f, x];\nBlock[{tmp}, Unevaluated[f[y_] := Module[{x = 1}, y*tmp]] /. tmp -> tmp2]\n\nThis is explained in details here. Note however that the fact that we had to go against the system twice tells us already that this is a fragile and generally bad practice. Please see more discussion on that in the linked answer.\nEDIT\nIn response to the edit in the question: in your case, I suggest to use Block and create a dynamic environment, where to execute the code for which you do want your transformations:\nSetAttributes[withTransforms,HoldAll];\nwithTransforms[code_]:=\n Block[{kx=k*Sin[a]*Cos[b],ky=k*Sin[a]*Sin[b],kz=k*Cos[b]},\n   code\n ]\n\nThis will allow you to selectively enable these definitions:\nwithTransforms[Integrate[kx^2+ky^2,{a,0,2 Pi}]]\n\n", "export - Creating a realtime MIDI Out": "\nHere is a letter I got regarding this question from premier service technical support:\n\nThank you for taking the time to send this in. Unfortunately, I do not\n  believe this functionality currently exists in Mathematica and I have\n  forwarded the suggestion that it be included in a future release of\n  Mathematica to the developers in charge of this area.\n\nI can imagine that this might be possible just JLink or MathLink.\nEssentially it would require writing a Java or C program that served as an\ninterface with Mathematica.\"\n", "evaluation - A combination of Set::setraw and Set::shape errors": "\nThis problem occurs because you are trying to make assignments to the same object multiple times.  As far as I can tell this is simply broken code.  You get the Set::setraw because you give hyb[\"chip1\"] the value {7, 8}, then you try to set it to {6, 6}.  Because you are forcing an Evaluate here you get {7, 8} = {6, 6} which is not an acceptable assignment.  In effect:\nx = 1;\nEvaluate[x] = 2;\n\nI am going out on a limb and suggesting this is what you want:\nEvaluate[toylist] = \n  Table[Extract[toydata[[i]], toyindices[[j]]], {i, 1, \n    Length[toylist]}, {j, 1, Length[toyindices]}];\n\nhyb[\"chip2\"]\n\n\n{{16, 17}, {15, 15}, {12, 11}}\n\n\nThis however is not as clean as it could be.  I await an explanation of what you are actually trying to accomplish so that I can be more helpful.\nAs an example of cleaner coding, consider:\nOuter[Extract, toydata, toyindices, 1]\n\n\n{{{7, 8}, {6, 6}, {3, 2}},\n {{16, 17}, {15, 15}, {12, 11}},\n {{25, 26}, {24, 24}, {21, 20}}}\n\n\n\nAddressing your edit, first an explanation of Set::shape.  Set automatically threads over lists, such that {a, b} = {1, 2} is equivalent to a = 1; b = 2.  This will work at deeper levels of the lists as well.  If the lists on either side are not the same shape this fails.\n{a, b, c} = {1, 2} (* failure *)\n\n{{a}, b} = {{3}, 4} (* success *)\n\n{a, b} = {{3}, 4} (* success *)\n\n{{a}, b} = {3, 4} (* failure *)\n\nYou state:\n\nI have created a list called mmsignalnames which is composed of\n  indexed symbols such as mmsignal[\"GSM356796\"], mmsignal[\"GSM356797\"]\n  .... up to all 24 datasets.\n\nYou're doing it wrong. :-)  You should store the list of keys: {\"GSM356796\", \"GSM356797\", ...\"}.  This way you can handle the key names and the symbol mmsignal easily and without anything prematurely evaluating.  Example:\nkeys = {\"red\", \"green\", \"blue\"};\n\nDo[signal[ keys[[i]] ] = i^2, {i, 3}]\n\nsignal[\"green\"]\n\n\n4\n\n\nsignal /@ keys\n\n\n{1, 4, 9}\n\n\n", "graphics - Show[] combines my Graphics3D objects in an undesirable way": "\nChecking the values of plot range  for the three graphics object:\n {AbsoluteOptions[slab, PlotRange], AbsoluteOptions[EMw1, PlotRange]}\n\nyou get\n\n{{PlotRange -> {{0., 38.}, {0., 57.}, {0., 4.}}}, {PlotRange -> {{0., \n 6.27}, {-0.999974, 0.999999}, {-0.999999, 0.999974}}}}\n\n\nUsing this information, define the rescaling transform\n rscTr = RescalingTransform[{{0, 6.27}, {-1, 1}, {-1, 1}}, {{0, \n38}, {-8, 8}, {-8, 8}}]\n\nand rescale the data for EMw1:\n rescaledPts1 = rscTr[pts1]; rescaledPts2 = rscTr[pts2];\n\nand redraw your EMw1 with rescaled data:\n rescaledEMw1 = \n Graphics3D[{Thickness[0.007], {RGBColor[0.439, 0.188, 0.627], \n Line[rescaledPts1]}, {RGBColor[1, 0.721, 0.039], \n Line[rescaledPts2]}, Thickness[0.002], \n Line[{#, # {1, 0, 1}}] & /@ rescaledPts1[[;; ;; 3]], \n  RGBColor[1, 0.721, 0.039], \n Line[{#, # {1, 1, 0}}] & /@ rescaledPts2[[;; ;; 3]]}, \n AxesOrigin -> {0, 0, 0}, Axes -> {True, False, False}, \n Ticks -> None, \n AxesStyle -> \n Directive[Thickness[0.0075], RGBColor[0.439, 0.188, 0.627]], \n Boxed -> False, ImageSize -> {400, 520}]\n\nNow, \n Show[slab, grating, rescaledEMw1]\n\ngives \n\nThe same output from a different viewpoint:\n\nEDIT: Alternative approach: Define corrdinates of the slab and grating directly. I use a modification of R.M.`s answer to OP's previous question, and specify the coordinates of the slab and grating objects.\nFirst, slab and grating objects with modified coordinates:\n sw = 4 Pi; sh = .5; gw = .5; gh = .5; cw = 1.; sl = 9 gw + 8 cw; \n grating =  Graphics3D[{RGBColor[0.917, 0.082, 0.478], Opacity[.3], \n Cuboid[{{0, 0, 0}, {sw, gw, gh}}], \n Cuboid[{{0, gw + cw, 0}, {sw, 2 gw + cw, gh}}], \n Cuboid[{{0, 2 (gw + cw), 0}, {sw, 3 gw + 2 cw, gh}}], \n Cuboid[{{0, 3 (gw + cw), 0}, {sw, 4 gw + 3 cw, gh}}], \n Cuboid[{{0, 4 (gw + cw), 0}, {sw, 5 gw + 4 cw, gh}}], \n Cuboid[{{0, 5 (gw + cw), 0}, {sw, 6 gw + 5 cw, gh}}], \n Cuboid[{{0, 6 (gw + cw), 0}, {sw, 7 gw + 6 cw, gh}}], \n Cuboid[{{0, 7 (gw + cw), 0}, {sw, 8 gw + 7 cw, gh}}], \n Cuboid[{{0, 8 (gw + cw), 0}, {sw, 9 gw + 8 cw, gh}}]}, \n Boxed -> False, ImageSize -> {400, 520}];\n slab = Graphics3D[{RGBColor[0.101, 0.701, 0.623], Opacity[.5], \n Cuboid[{0, 0, -.5}, {4 Pi, 4 Pi, 0}]}, Boxed -> False, ImageSize -> {400, 520}];\n\nNext, a modifed version of R.M.`s waves (replicating the pair of waves four times):\n  Module[{w1, w2, w3, w4, w5, w6, w7, w8, colors, plot, lines}, \n  w1[x_] := {x, 0, Sin[x]}; w2[x_] := {x, Sin[x], 0}; \n  w3[x_] := {4 \\[Pi], x, Sin[x]}; w4[x_] := {4 \\[Pi] + Sin[x], x, 0}; \n  w5[x_] := {x, 4 \\[Pi], -Sin[x - Pi]}; \n  w6[x_] := {x, 4 \\[Pi] - Sin[x - Pi], 0}; w7[x_] := {0, x, Sin[x]}; \n  w8[x_] := {Sin[x], x, 0};\n  colors =   Darker /@ {Blue, Orange, Blue, Orange, Blue, Orange, Blue, Orange};\n  {plot, lines} = \n  ParametricPlot3D[{w1[x], w2[x], w3[x], w4[x], w5[x], w6[x], w7[x], \n   w8[x]}, {x, 0, 4 \\[Pi]}, Boxed -> False, AxesOrigin -> {0, 0, 0},\n  MaxRecursion -> 0, PlotRange -> {{-Pi, 5 Pi}, {-Pi, 5 Pi}, {-2, 2}}, \n  BoxRatios -> {1, 1, .5}, \n  PlotStyle -> {{Thick, Thick, Thick, Thick, Thick, Thick, Thick, \n    Thick}, colors}\\[Transpose], \n  EvaluationMonitor :> \n  Sow[{Line[{w1[x], {x, 0, 0}}], Line[{w2[x], {x, 0, 0}}], \n   Line[{w3[x], {4 \\[Pi], x, 0}}], Line[{w4[x], {4 \\[Pi], x, 0}}],\n    Line[{w5[x], {x, 4 \\[Pi], 0}}], \n   Line[{w6[x], {x, 4 \\[Pi], 0}}], Line[{w7[x], {0, x, 0}}], \n   Line[{w8[x], {0, x, 0}}]}]] // Reap; \n  GraphicsRow[{Show[plot, \n  Graphics3D[Insert[Flatten[lines, 1], colors, 1]\\[Transpose]], \n  ViewPoint -> {3.009, -1.348, 0.759}, \n  ViewVertical -> {0.406, -0.398, 5.732}, Ticks -> None, \n  AspectRatio -> 0.75], \n  Show[plot, slab, grating, \n  Graphics3D[Insert[Flatten[lines, 1], colors, 1]\\[Transpose]], \n  ViewPoint -> {3.009, -1.348, 0.759}, \n  ViewVertical -> {0.406, -0.398, 5.732}, Ticks -> None, \n  AspectRatio -> 0.75]}, ImageSize -> 900]]\n\nTwo views of the resulting 3D graphs:\n\n\n", "How to execute kernel command from Front End?": "\nYou can add the menu command to your Insert menu using AddMenuCommands in the following manner.  (These modifications will only persist for the current front end session.)\nFirst a demo function, just creating a dialog:\nFrontEndExecute[FrontEnd`AddMenuCommands[\"DuplicatePreviousOutput\",\n  {Delimiter, MenuItem[\"CreateDialog &Demo\",\n    FrontEnd`KernelExecute[CreateDialog[{TextCell[\"Click OK to close\"],\n       DefaultButton[]}]], \n    MenuKey[\"D\", Modifiers -> {\"Control\", \"Shift\"}],\n    System`MenuEvaluator -> Automatic]}]]\n\n(Note the required context specification for MenuEvaluator.)\nThis version will run OptionsExplorer[]\nFrontEndExecute[FrontEnd`AddMenuCommands[\"DuplicatePreviousOutput\",\n  {Delimiter, MenuItem[\"Options &Explorer\",\n    FrontEnd`KernelExecute[ToExpression[\"OptionsExplorer[]\"]],\n    MenuKey[\"O\", Modifiers -> {\"Control\", \"Shift\"}],\n    System`MenuEvaluator -> Automatic]}]]\n\n", "linear algebra - Simpler way of performing Gaussian Elimination?": "\nBased upon your update, you are trying to solve the system\n$$\\mathbf{A}\\vec{x} = \\vec{b}$$\nfor $\\vec{x}$, so LinearSolve is exactly what you want. Also, it has the exact form\nLinearSolve[A, b]\n\nthat you're asking for. Internally it uses a form of Gaussian elimination to solve such systems; this is most likely a variant of LU decomposition, but other methods are available. If you have more than one $\\vec{b}$, you can use the form\nsolv = LinearSolve[A]\n\nwhich returns a LinearSolveFunction which you can apply to each $\\vec{x}$ in turn via\nsolv[b]\n\nEdit:  In the case of your example, RowReduce will return the identity matrix as your matrix is invertible (non-singular), so it would not be immediately useful. You could make it \"useful\" and create an augmented matrix, via\n augA = ArrayFlatten[{{#, IdentityMatrix[Length@#]}}]& @ A\n\nwhich creates $$\\left(\\mathbf{A}\\, |\\, \\mathbf{I} \\right).$$ Then, \n redAugA = RowReduce[augA]\n\ngives a matrix of the form $$\\left(\\mathbf{I}\\, |\\, \\mathbf{A}^{-1} \\right),$$ and the inverse is extractable via \nredAugA[[All, Length@A + 1 ;; ]]\n\nwhich uses the shorthand form of Part and Span to extract only the columns you want. But, if your going to go to the trouble of getting the inverse, you might as well use Inverse[A] directly.\nHowever, if your matrix is singular, i.e. MatrixRank[A] < Length[A], then you need to use LeastSquares which returns the vector, $\\vec{x}$, that minimizes $\\lVert\\mathbf{A}\\vec{x} - \\vec{b}\\rVert_2$ where $\\lVert\\cdot\\rVert_2$ refers to the standard Euclidean norm. Which has the same calling convention\nLeastSquares[A, b]\n\nbut it lacks the pre-calculation capabilities of LinearSolve. If you need those, then you would first decompose the matrix using QRDecomposition and then LinearSolve is used, as follows \n{q,r} = QRDecomposition[A];\nLinearSolve[r, q.b]\n\nOr, if you want a single function that operates like the second form of LinearSolve but with the least squares minimization,\nsavedLeastSquares[m_?MatrixQ]:= \n Module[{q,r}, \n  {q,r} = QRDecomposition[m];\n  LinearSolve[r, q.#]&\n ]\n\n", "How does string interpolation work in Mathematica": "\nStringForm does not create a string.  As StringForm[\"x=``\", 1] // FullForm will show you, it stays unevaluated.  But it is shown in a special way in the notebook (i.e. the `` replaced by 1).\nYou can create a plain string from it using\nToString[ StringForm[\"x=``\", 1] ]\n\nwhich will give\n\"x=1\" \n\nUnfortunately, when we need to build strings, this does not always work perfectly:\nToString[ StringForm[\"x=``\", 1/2] ]\n\n  1\nx=-\n  2\n\nThis gave the result as a three-line string, in OutputForm.  We can try ToString[ StringForm[\"x=``\", 1/2], InputForm ], but it'll return \"StringForm[\\\"x=``\\\", 1/2]\" (unformatted).  We can also try ToString[ StringForm[\"x=``\", 1/2], StandardForm], but the result will be a string containing box expressions (as you noticed).  These special expressions can contain information about formatting (everything from font styles to two-dimensional math such as $\\frac{1}{2}$), but they can only be shown in a Mathematica notebook.  They are not human readable and cannot be used by other programs.\nTo get the desired \"x=1/2\", the workaround is \nToString@StringForm[\"x=``\", InputForm[1/2]]\n\nRecap:\n\nStringForm does not change the expressions passed to it at all.  StringForm expressions are merely displayed specially in notebooks.\nHow StringForm is displayed depends on the output format set (OutputForm, StandardForm, TraditionalForm, etc.)\nUse ToString to obtain an actual string.\n\n", "packages - Automated testing for compatibility with older Mathematica versions": "\nThe only reliable way seems to have a good set of unit test suites, and run them in earlier versions of Mathematica (I mention this here since the answer and comments mentioning this were deleted). However, having  explicit rules for when functions were introduced and / or last changed, extracted from the docs, seems to me a good thing, which may help reduce some work, give hints, etc. So, in addition to the suggestions in other answers / comments (I particularly support the unit testing suggestion), the following code can be executed to extract the versioning information from the documentation:\nClearAll[getVersionSince];\ngetVersionSince::fail = \"Unable to extract version information for function `1`\";\ngetVersionSince[file_String?FileExistsQ] :=\n  With[{nb = NotebookOpen[file, Visible -> False]},\n    With[{res = \n       Cases[\n         NotebookGet[nb],\n         Cell[s_String, \"History\", ___]:>\n          StringCases[StringTrim@s,\n           {\"New in\" ~~ (Whitespace | \"\") ~~ d : ((DigitCharacter | \".\") ..) ~~ __ ~~  \n             \"Last modified in\" ~~ (Whitespace | \"\") ~~  m : (((DigitCharacter | \".\") ..)) :>\n                 {d, m},           \n            \"New in\" ~~ (Whitespace | \"\") ~~ d : ((DigitCharacter | \".\") ..) :> d}\n         ],\n         Infinity]},\n      NotebookClose[nb];\n     First@res /; res =!= {}] /; nb =!= $Failed];\n\ngetVersionSince[file_String?FileExistsQ] :=\n   (Message[getVersionSince::fail, Style[FileBaseName[file], Red]]; $Failed);\n\nHere is the setup I used:\n$docdir = \n  FileNameJoin[{$InstallationDirectory, \"Documentation\", \"English\", \n      \"System\", \"ReferencePages\", \"Symbols\"}];\n$functions = FileNames[\"*.nb\", {$docdir}];\n\nTo produce the rules for the functions, you can use something like \nrules = Table[FileBaseName[f] -> getVersionSince[f],{f, $functions}]\n\nI actually used \nj = 0;\nMonitor[\n functionRules = \n   abortableTableAlt[(j++; FileBaseName[f] -> getVersionSince[f]), {f, $functions}], \n j]\n\nwhere the abortable table function abortableTableAlt is described at the bottom of this answer. The process was time and memory-consuming, so I saved the result to a file, available from this gist. The result has this format:\n{\"AbelianGroup\" -> {\"8\"}, \"AbortKernels\" -> {\"7\"}, \"Abort\" -> {\"2\"}, \n  \"AbortProtect\" -> {\"2\"}, \"Abs\" -> {\"1\"}, \"AbsoluteCurrentValue\" -> {\"6\"}, \n \"AbsoluteDashing\" -> {{\"2\", \"6\"}}, \"AbsoluteFileName\" -> {\"7\"}, << 3400 >>,\n \"$UserName\" -> {\"3\"},  \"$Version\" -> {\"1\"}, \"$VersionNumber\" -> {\"2\"}, \"$$Media\" -> {\"1\"}}\n\nWhere a single number (string) is the earliest version when the function (or at least the doc.page) was introduced, and the format like {{\"2\",\"6\"}} means that it was introduced in v.2 and last modified in v.6. In total, 3412 notebooks were processed. The only function for which this code failed was KConnectedComponents.\nYou can import the file from the mentioned gist, and I'd recommend to use Dispatch to speed up the rule application. Alternatively, you can use Save to attach these rules to whatever function (symbol) you want. As was suggested in another answer, this can be combined with some tool to extract dependencies, which would give you a list of system symbols used in your code. One such tool was developed David Wagner way back in 1996 and desribed in his article in the Mathematica Journal. I developed a similar tool here, but it is a work in progress and contains some bugs as of now.\n", "Krnl Managmnt - Mathmatica Stack Exchang": "\nYou can select which kernel is used by your notebook from the menu item Evaluation -> Notebook's Kernel. By default you will probably only have one kernel called Local available. If your Mathematica license allows for it (typically licenses allow for two simultaneous kernels on a machine), you can add new kernels by selecting the Evaluation -> Kernel Configuration Options... menu item. Select \"New\" to add a new Kernel, give the kernel any name you want and accept the default options. This new kernel will now be selectable from the Evaluation -> Notebooks Kernel menu.\n", "differential equations - Using physical dimensions in Mathematica DSolve": "\nIt is generally better to work in dimensionless units to start with. In your case, your a and b have units of $L^{-2}$, while eta is dimensionless. Taking fx''[x] + a*fx[x] == -I*eta*fy''[x] - b*fy[x] as an example, you could use $\\xi=x/L$, $\\alpha=a L^2$, $\\beta=b L^2$ (all of which are now dimensionless), whereupon your differential equation becomes $L^{-2}\\left(\\partial_{\\xi,\\xi}F_x(\\xi)+\\alpha F_x(\\xi)+i\\eta \\partial_{\\xi,\\xi}F_y(\\xi)+\\beta F_y(\\xi)\\right)=0$, where I have set $F_x(\\xi)=f_x(x)$ and similarly for $y$. Solving the equation in the brackets is what you really should do; no problems like you mention above can now arise.\nTo summarise, one should almost always switch to dimensionless units before numerically solving a problem.\n", "plotting - How to repeatedly show variations on a plot": "\nYou probably want Animate, if your intent is to show the plot varying for different n. Here's an example:\nAnimate[Plot[Sqrt[(1/n) x], {x, 0, 1}, PlotRange -> {All, {0, 1}}], {n, 1, 5}]\n\n\n", "graphics - Sizing cells in a GraphicsGrid/GraphicsRow": "\nOne way of doing it is to use Row instead of GraphicsRow and setting an explicit ImageSize. The solution also scales for different sizes. Setting the same ImagePadding on both plots will ensure that they are nicely aligned.  For example:\nWith[{size = 300}, \n Row[Show[#, ImageSize -> {Automatic, size}, \n     ImagePadding -> 20] & /@ {DensityPlot[\n     Sin[Norm[{x, y}]], {x, -10, 10}, {y, -10, 10}], colorbar[]}]]\n\n\n\nThe above plot still has excess spacing between the graphic and the color bar. The reason for this is because of the uniform padding of 20. So this translates to 20 for the right side of the first + 20 for the left side of the second which means a 40 total between the two. Using the {{left, right}, {bottom, top}} spacing specification for ImagePadding works very well in aligning color bars to a plot. For this case, modify the above code to: ImagePadding -> {{20, 0}, {20, 5}}, which results in \n\nYou can now set a separate right padding if you need to leave some more space between the two.\n", "calculus and analysis - recursive integration": "\nI think this should work:\nClearAll[r];\nr[0, t_] := Exp[-k*t]*Cos[t];\nr[n_, t_] := Integrate[r[0, t - td]*r[n - 1, td], {td, 0, t}]\n\neg\nr[2,t]\n\n(*\n(\\[ExponentialE]^(-k t) (2 \\[ExponentialE]^(k t) k^2 - \n   k (2 k + t + k^2 t) Cos[t] + (k - k^3 + t + k^2 t) Sin[t]))/(2 (1 +\n    k^2)^2)\n*)\n\n", "plotting - Remove tick labels, but retain tick marks in RegionPlot (and related functions)": "\nAn even simpler way that does not require you to figure out the tick positions, is to set the tick font opacity to 0 and the tick font size to 0 to avoid the excess margin where the ticks would have been. Here's an example:\nRegionPlot[Sin[x y] > 0, {x, -1, 1}, {y, -1, 1}, \n    FrameTicksStyle -> Directive[FontOpacity -> 0, FontSize -> 0]]\n\n\nAlternately, you could also use FontColor -> White, but note that it won't work with all backgrounds.\n", "plotting - How do I plot coordinates (latitude and longitude pairs) on a geographic map?": "\ndata:\nlatlong = {{32.6123, -117.041}, {40.6973, -111.9}, {34.0276, -118.046}, \n{40.8231, -111.986}, {34.0446, -117.94}, {33.7389, -118.024}, \n{34.122, -118.088}, {37.3881, -122.252}, {44.9325, -122.966},\n{32.6029, -117.154}, {44.7165, -123.062}, {37.8475, -122.47}, \n{32.6833, -117.098}, {44.4881, -122.797}, {37.5687, -122.254},\n{45.1645, -122.788}, {47.6077, -122.692}, {44.5727, -122.65}, \n{42.3155, -82.9408}, {42.6438, -73.6451}, {48.0426, -122.092},\n{48.5371, -122.09}, {45.4599, -122.618}, {48.4816, -122.659}, {42.3398, -70.9843}}\n\nTo put the data on latitude-longitude pairs on a map, yo will need to transform your data based on the projection method used by the map.\nFor example, \n coords = CountryData[\"UnitedStates\", \"Coordinates\"];\n\ngives the latitude-longitude data for US boundaries.\nTo use this data to put together a map with a specific projection method (say Mercator),\nyou need to transform your data \n Map[ GeoGridPosition[ GeoPosition[#], \"Mercator\"][[1]] & , {latlong}, {2}]\n\nwhich gives\n\n  {{{1.09884, 0.602677}, {1.18857, 0.778879}, {1.0813, \n   0.632239}, {1.18707, 0.781777}, {1.08315, 0.632597}, {1.08169, \n   0.62617}, {1.08057, 0.634228}, {1.00789, 0.704491}, {0.995431, \n   0.879708}, {1.09687, 0.602482}, {0.993756, 0.874393}, {1.00409, \n   0.714614}, {1.09785, 0.604149}, {0.998381, 0.868794}, {1.00786, \n   0.708463}, {0.998538, 0.88544}, {1.00021, 0.947273}, {1.00095, \n   0.870866}, {1.694, 0.816595}, {1.85624, 0.824365}, {1.01069, \n   0.958578}, {1.01072, 0.97155}, {1.0015, 0.892771}, {1.00079, \n   0.970088}, {1.90268, 0.817169}}}\n\n\nDoing this transformation for both your data and the latitude-longitude data for world countries inside Graphics:\n Graphics[{Red, Point /@ Map[ \n  GeoGridPosition[ GeoPosition[#], \n   \"Mercator\"][[1]] & , {latlong}, {2}], Gray, \n Polygon[Map[ GeoGridPosition[ GeoPosition[#], \"Mercator\"][[1]] & , \n  CountryData[#, \"Coordinates\"], {2}]] & /@ \n CountryData[\"Countries\"]}]\n\nyou get:\n\nNow I know I can focus on US:\n Graphics[{ Gray, \n Polygon[Map[ GeoGridPosition[ GeoPosition[#], \"Mercator\"][[1]] & , \n CountryData[\"UnitedStates\", \"Coordinates\"], {2}]], Red, \n PointSize[.02], Point /@ Map[ \n GeoGridPosition[ GeoPosition[#], \n   \"Mercator\"][[1]] & , {latlong}, {2}]}]\n\nto get\n\nA simpler method avoiding GeoPosition, GeoGridPosition ...  etc\nGet the coordinates of US:\n coords = CountryData[\"UnitedStates\", \"Coordinates\"];\n\nand use \n Graphics[{EdgeForm[Black], Polygon[Reverse /@ First[coords]], Red, \n Point /@ Reverse /@ latlong}]\n\nto get\n\n", "palindrome - How can I get the list of dates in the next $n$ years": "\nMight I suggest a different approach?\nAssuming that you are interested in dates in the format DD-MM-YYYY then:\nNeeds[\"Calendar`\"]\n\nTuples @ Range @ {31, 12};\n\nAppend[#, FromDigits@StringReverse[\"\" <> IntegerString[#, 10, 2]]] & /@ %;\n\npalindromicDates = Select[%, DateQ[Reverse@#] &]\n\nGives all valid palindromic dates.  You could filter out years below 1000 if you don't want those:\nCases[palindromicDates, {_, _, x_ /; x > 999}]\n\n", "graphics - Retrieving the ImagePadding in absolute units": "\nUpdate\nI created a paclet. Install the paclet with\nPacletInstall[\n    \"GraphicsInformation\",\n    \"Site\"->\"http://raw.githubusercontent.com/carlwoll/GraphicsInformation/master\"\n]\n\nand then load the paclet with\n<<GraphicsInformation`\n\nUse GraphicsInformation instead of graphicsInformation\nOriginal post\nHere is my attempt to create a function that returns reliable values for ImagePadding, ImageSize and PlotRange. It is inspired by the efforts of @LLlAMnYP in his answer to 83636 and @AlexeyPopkov in his answer to 18034\nThe basic idea is use ExportPacket to find out what the FrontEnd computes for these values. Not only is this what Rasterize uses under the hood, it allows one to support Scaled ImageSize settings as well by setting the WindowSize of the Notebook object fed to ExportPacket. For instance, @Heike's answer doesn't fair well when ImageSize->Full is used.\n\nImageSize /ImagePadding - Adding an Annotation wrapper to appropriate Rectangle objects added as an Epilog can be used to determine these values.\nPlotRange - Rather than using pure function Ticks, I used pure function GridLines. GridLines apply whether Frame/Axes are True or False.\n\nHere is the function:\ngraphicsInformation[gr_Graphics] := Module[{info},\n    info = Flatten @ Reap[\n        Rule @@@ ReplaceAll[\n            \"Regions\",\n            FrontEndExecute @ ExportPacket[\n                toNotebook[gr],\n                \"BoundingBox\",\n                Verbose->True\n            ]\n        ],\n        _,\n        #1->#2[[1]]&\n    ];\n    extract[info]\n]\n\ntoNotebook[gr_] := Notebook[\n    {\n    Cell[BoxData @ ToBoxes @ instrumentGraphics[gr],\n        \"Output\"\n    ]\n    },\n    WindowSize -> CurrentValue[EvaluationNotebook[], WindowSize],\n    Evaluator -> CurrentValue[EvaluationNotebook[], Evaluator]\n]\n\ninstrumentGraphics[gr_Graphics] := Show[\n    gr,\n    GridLines -> {sowRange[\"X\"], sowRange[\"Y\"]},\n    Epilog -> {\n        Annotation[\n            Rectangle[Scaled[{0,0}], Scaled[{1,1}]],\n            \"PlotRange\", \"Region\"\n        ],\n        Annotation[\n            Rectangle[ImageScaled[{0,0}], ImageScaled[{1,1}]],\n            \"ImageSize\", \"Region\"\n        ]\n    }\n]\n\nsowRange[label_] := Function[Sow[{##}, label]; None]\n\nextract[rules_] := Module[{pr, is, xr, yr},\n    {pr, is, xr, yr} = {{\"PlotRange\", \"Region\"}, {\"ImageSize\", \"Region\"}, \"X\", \"Y\"} /. rules;\n    {\n    \"ImagePadding\"->Abs[is-pr],\n    \"ImageSize\"->Abs[Subtract@@@is],\n    \"PlotRangeSize\"->Abs[Subtract@@@pr],\n    \"ImagePaddingSize\"->Total[Abs[is-pr],{2}],\n    \"PlotRange\"->{xr,yr}\n    }\n]\n\nHere are a couple examples:\ngraphicsInformation @ Plot[\n    Sin[x],\n    {x, 0, Pi},\n    ImagePadding -> {{1.1,2.2}, {3.3,4.4}}\n]\n\n\n{\"ImagePadding\" -> {{1.1, 2.2}, {3.3, 4.4}}, \"ImageSize\" -> {360., 228.153}, \n   \"PlotRangeSize\" -> {356.7, 220.453}, \"ImagePaddingSize\" -> {3.3, 7.7}, \n   \"PlotRange\" -> {{-0.0654498, 3.20704}, {-0.0555556, 1.05556}}}\n\nplot = Plot[\n    Sin[x],\n    {x, 0, Pi},\n    ImageSize -> Full,\n    ImagePadding -> {{1.1,2.2}, {3.3,4.4}}\n];\ngraphicsInformation[plot]\n\n\n{\"ImagePadding\" -> {{1.1, 2.2}, {3.3, 4.4}}, \"ImageSize\" -> {706., 441.992}, \n   \"PlotRangeSize\" -> {702.7, 434.292}, \"ImagePaddingSize\" -> {3.3, 7.7}, \n   \"PlotRange\" -> {{-0.0654498, 3.20704}, {-0.0555556, 1.05556}}}\n\nCompare to Heike's solution:\nheike[g_]:=BorderDimensions@Image[Show[g,LabelStyle->White,Background->White]]\nheike[plot]\n\n\n{{19, 4}, {5, 7}}\n\nOne final comment. It is possible to use a single call to ExportPacket to extract graphics information from multiple graphics objects. Since the call to ExportPacket is the most time consuming part of the code, using a single call to ExportPacket will be much quicker than using graphicsInformation on multiple Graphics objects. Here is a version that does this:\nClear[graphicsInformation, extract]\ngraphicsInformation[gr:{__Graphics}] := Module[{info, res},\n    info = Flatten @ Reap[\n        Rule @@@ ReplaceAll[\n            \"Regions\",\n            FrontEndExecute @ ExportPacket[\n                toNotebook[gr],\n                \"BoundingBox\",\n                Verbose->True\n            ]\n        ],\n        _,\n        #1->#2[[1]]&\n    ];\n    res = extract[info] /@ Range @ Length @ gr;\n    Thread @ Rule[\n        {\"ImagePadding\", \"ImageSize\", \"PlotRangeSize\", \"ImagePaddingSize\", \"PlotRange\"},\n        Thread @ ReplaceAll[\n            {\"ImagePadding\", \"ImageSize\", \"PlotRangeSize\", \"ImagePaddingSize\", \"PlotRange\"},\n            res\n        ]\n    ]\n]\ngraphicsInformation[gr_Graphics] := Replace[\n    graphicsInformation[{gr}],\n    Rule[a_, {b_}] :> a -> b,\n    {1}\n]\n\ntoNotebook[gr_] := Notebook[\n    {\n    Cell[BoxData @ ToBoxes @ instrumentGraphics[gr],\n        \"Output\"\n    ]\n    },\n    WindowSize -> CurrentValue[EvaluationNotebook[], WindowSize],\n    Evaluator -> CurrentValue[EvaluationNotebook[], Evaluator]\n]\n\ninstrumentGraphics[gr:{__Graphics}] := MapThread[\n    Show[#1,\n        GridLines -> {sowRange[\"X\" -> #2], sowRange[\"Y\" -> #2]},\n        Epilog -> {\n            Annotation[\n                Rectangle[Scaled[{0,0}], Scaled[{1,1}]],\n                \"PlotRange\", #2\n            ],\n            Annotation[\n                Rectangle[ImageScaled[{0,0}], ImageScaled[{1,1}]],\n                \"ImageSize\", #2\n            ]\n        }\n    ]&,\n    {gr, Range@Length@gr}\n]\n\ninstrumentGraphics[gr_Graphics] := instrumentGraphics[{gr}]\n\nsowRange[label_] := Function[Sow[{##}, label]; None]\n\nextract[rules_][k_] := Module[{pr, is, xr, yr},\n    {pr, is, xr, yr} = {{\"PlotRange\",k}, {\"ImageSize\",k}, \"X\"->k, \"Y\"->k} /. rules;\n    {\n    \"ImagePadding\"->Abs[is-pr],\n    \"ImageSize\"->Abs[Subtract@@@is],\n    \"PlotRangeSize\"->Abs[Subtract@@@pr],\n    \"ImagePaddingSize\"->Total[Abs[is-pr],{2}],\n    \"PlotRange\"->{xr,yr}\n    }\n]\n\n", "parallelization - How to distribute definitions when loading external *.m packages": "\nDon't ever call functions like Get inside ParallelTable because it will be difficult to control side effects.  Get should be evaluated only once per kernel to load definitions:  to achieve this, use either ParallelEvaluate[Get[...]] or ParallelNeeds (for proper packages).\nIt is good practice to only place definitions inside .m files, and not code that computes results.  If .m files contain calculations instead of definitions, they are bound to use global variables.  Handling these from parallel evaluations will be difficult and error prone.\n", "graphics - Plotting a set of trajectories (not a vector field) in 3D": "\nLet me add a few ideas, but be aware that this is unpolished code which was only hacked to show my points. I assume you have some kind of function $f(t;x_0,y_0,z_0)$ which gives you a trajectory starting at the initial point $(x_0,y_0,z_0)$ for $t=0$. I used $t$ only for convenience. Your function should be parametrized by the arc-lenc if you want a defined length for your field-lines\nLet's consider some arbitrary pde I stole from the examples of NDSolve and create a function which takes an initial point, a length l, the number of points n and returns a StreamLine object containing n points of the trajectory\nmakeStreamLine[{x0_, y0_, z0_}, l_, n_] :=\n Block[{x, y, z},\n  Block[{len = \n     Sqrt[(-3 (x[t] - y[t]))^2 + (-x[t] z[t] + 26.5 x[t] - \n          y[t])^2 + (x[t] y[t] - z[t])^2]},\n   With[\n    {sol = {x, y, z} /. First@NDSolve[{\n          x'[t] == -3 (x[t] - y[t])/len,\n          y'[t] == (-x[t] z[t] + 26.5 x[t] - y[t])/len,\n          z'[t] == (x[t] y[t] - z[t])/len,\n          x[0] == x0, z[0] == z0, y[0] == y0}, {x, y, z}, {t, 0, l}]\n     },\n    StreamLine[Table[Through[sol[t]], {t, 0, l, l/(n - 1.0)}]]\n    ]\n   ]\n  ]\n\nWhat you would maybe do in a first attempt is to take some random points from your domain of interest, use them as initial points, call the above function and get your StreamLines which you can draw as you like. \nThis is a bad idea for several reasons: First, the case where a random generator really creates nicely distributed seed points is really rare. Most of the times, the seed points are noticeably denser in some areas. But the real bad thing is, even if your seed points are nicely distributed, this does not mean that your stream-lines fill the space in a way it looks good.\nThe simple idea which solves this is to use a distance-transform. What you do is, you create exactly one StreamLine a a random place and then you calculate the next seed, by taking a point which is inside your domain, but as far as possible away from all already existing trajectory points.\nThe distance-transform is currently only available for images, so a very basic approach will help us out here. I sample the domain with Table, and use Nearest to calculate the seed with maximal distance. The function gets all previously calculated stream-lines, the domain and the number n of sampling points. \nfindNextSeedPoint[\n  streamlines : {_StreamLine ..}, {{x0_, x1_}, {y0_, y1_}, {z0_, \n    z1_}}, n_] := \n Block[{pts = Join @@ (streamlines /. StreamLine :> Sequence),\n   nearestfunc, seed, maxDist = -1},\n  nearestfunc = Nearest[pts];\n  Table[With[{dist = Norm[{x, y, z} - First@nearestfunc[{x, y, z}]]},\n    If[dist > maxDist,\n     maxDist = dist;\n     seed = {x, y, z}\n     ]\n    ],\n   {z, z0, z1, (z1 - z0)/(n - 1.0)},\n   {y, y0, y1, (y1 - y0)/(n - 1.0)},\n   {x, x0, x1, (x1 - x0)/(n - 1.0)}];\n  seed\n  ]\n\nWhat's left is the iteration of those two functions. The next function gets the domain, the length len of each stream-line, then number of stream-lines to create, the number of sampling points along each stream-line and the number of domain sampling points for the calculation of the next seed. As first initial point I use the center of the domain. \nmakeStreams[dim : {{x0_, x1_}, {y0_, y1_}, {z0_, z1_}}, len_, \n  nStreams_, nStreamPts_, regRes_] := Block[\n  {seed = {x1 - x0, y1 - y0, z1 - z0}/2.0, streams},\n  Nest[\n   Append[#, \n     makeStreamLine[findNextSeedPoint[#, dim, regRes], len, \n      nStreamPts]] &, {makeStreamLine[seed, len, nStreamPts]}, \n   nStreams - 1]\n  ]\n\nNow you can plot the streams like you want. I use here the tubed 3d arrows\nplotStreamLines[streams : {_StreamLine ..}] := \n Graphics3D[{ColorData[24, RandomInteger[{1, 12}]], \n     Arrow[Tube[#]]} & @@@ streams];\n\nplotStreamLines@\n makeStreams[{{-20, 20}, {-20, 20}, {-20, 20}}, 50, 20, 57, 20]\n\n\nHeike showed in her post, how to create several arrows along one trajectory. This is of course possible too. A StreamLine object is only a series of points and you can surely partition this into several sublists where each one is displayed as its own arrow\n\nThere are several other extensions which could be implemented.\n\nIt is not ensured, that a stream-line does not leave the domain. What needs to be done is simply going through all stream-lines and using all points from the start until the domain is left. If all points are in, fine, if not, then you have some arrow, which are shorter.\nWhile the seed points are nicely distributed, the stream-line itself can come really close to an already existing line. What could be useful is a function which cuts of stream-lines when they come too close to another one. With this you should get your domain filled without having the feeling, that there are too many arrows at some places\nI just assumed, that you want field-lines with a defined length. You can of course integrate your lines as long as possible in both directions: You stop when they either leave the domain, reach a singularity or come too close together. If you look at the first example in the help of StreamPlot you notice exactly this behaviour.\n\n", "cellular automata - Generate Chaotic Time Series using CellularAutomaton[]": "\nHere's a line right out of the help for CellularAutomaton.\nListLinePlot[Accumulate[(-1)^CellularAutomaton[30, \n  {{1}, 0}, {500, {{0}}}]]]\n\n\n", "graphics - Arranging connector lines": "\nThis method tries to find a minimum of the total length of all connecting lines by repeatedly swapping the endpoints of pairs of connecting lines if that reduces the total length of those two connecting lines until the list of edges doesn't change anymore. From the triangle inequality this then also guarantees that no two connecting lines will intersect each other.\nstart = RandomReal[1, {12, 2}];\nend = With[{dx = 0.1, dy = 0.1},\u00a0\n\u00a0 \u00a0 \u00a0 \u00a0{{-dx, 1 + dy}, {.25 - dx/4, 1 + dy}, {.75 + dx/4, 1 + dy},\u00a0\n\u00a0 \u00a0 \u00a0 \u00a0 {1 + dx, 1 + dy}, {1 + dx, .75 + dy/4}, {1 + dx, .25 - dx/4},\u00a0\n\u00a0 \u00a0 \u00a0 \u00a0 {1 + dx, -dy}, {.75 + dx/4, -dy}, {.25 - dx/4, -dy},\u00a0\n\u00a0 \u00a0 \u00a0 \u00a0 {-dx, -dy}, {-dx, .25 - dy/4}, {-dx, .75 + dy/4}}];\n\ncombis = Subsets[Range[12], {2}];\nlength[{b_, e_}] := EuclideanDistance[start[[b]], end[[e]]]\n\nnewedges = Transpose[{Range[12], Range[12]}];\nFixedPoint[\n Do[p = {#[[{1, 4}]], #[[{3, 2}]]} &@Flatten[newedges[[c]]];\n   If[Total[length /@ p] < Total[length /@ newedges[[c]]],\n    newedges[[c]] = p],\n   {c, combis}] &, newedges, 10]\n\nThen the before picture is this:\n\nand the after picture is:\nGraphics[{FaceForm[Lighter@Orange], \n  Polygon[{{0, 0}, {1, 0}, {1, 1}, {0, 1}}], \n  Line@Transpose[{start[[newedges[[All, 1]]]],\n     end[[newedges[[All, 2]]]]}], AbsolutePointSize[18], \n  Lighter@Orange, Point[end[[newedges[[All, 2]]]]], Black, \n  MapThread[Text, {Range[12], end[[newedges[[All, 2]]]]}]}, \n Frame -> True, FrameTicks -> None, \n PlotRange -> {{-.2, 1.2}, {-.2, 1.2}}]\n\n\n", "How to add vertex/edge labels to existing graph": "\nA random graph without any labeling:\ng = RandomGraph[{11, 21}]\n\n\nYou can use SetProperty to add labeling P.S. \nSetProperty[g, {EdgeLabels -> {3 \\[UndirectedEdge] 4 -> \"COOL\"}, \n  VertexLabels -> {1 -> \"STUFF\"}}]\n\n\n", "graphs and networks - VertexLabelStyle not found in Mathematica 8.0.0.0": "\nVertexLabelStyle was introduced in Mathematica 8.0.1.\nThe online documentation does not differentiate between the 8.0.x releases, but the in-product documentation does and has no mention of VertexLabelStyle in 8.0.0.\n", "Manipulate[] inside DialogInput[]": "\nTry using global variables. Return the value with DialogReturn.\nres = DialogInput[{\n         TextCell[\"Set value of e. Then click Proceed.\"],\n         Manipulate[Plot[Sin[e x], {x, 0, 2 \\[Pi]}], {e, 1, 10, \n              Appearance -> \"Open\" }, \n         LocalizeVariables -> False], \n         Button[\"Proceed\", DialogReturn[e]]\n                 }]\n\n\n", "numerics - Why round to even integers?": "\nIt is called bankers' rounding. The rationale is that the rounding behaves \"nicely\" even if you have negative numbers, i.e. rounding commutes with negation, which is nice.\n", "equation solving - Root finding in Mathematica": "\nThe canonical way to solve algebraic equations is to use Solve,  e.g. \n2 - 4 x - x^2 + 2 x^3 == 0 // Solve[#, x] &\n\n\n{{x -> 1/2}, {x -> -Sqrt[2]}, {x -> Sqrt[2]}}\n\n\nThe above  eqn //Solve[#,x]& is a so called postfix notation. \nThis is an infix notation:  eqn ~ Solve ~ x\nand  prefix :    Solve[ #, x]& @(eqn) \nIf you want to solve a transcendental equation e.g. x^2 == Cos[x] you can use Solve as well as Reduce, however one should specify the real domain because by default Mathematica working in the complex domain cannot find all solutions.\nReduce[x^2 == Cos[x], x, Reals]\n\n\nx == Root[{-Cos[#1] + #1^2 &, -0.82413231230252242296}] ||\nx == Root[{-Cos[#1] + #1^2 &, 0.82413231230252242296}]\n\n\nSolve[x^2 == Cos[x], x, Reals]\n\n\n{{x -> Root[{-Cos[#1] + #1^2 &, -0.82413231230252242296}]},\n {x -> Root[{-Cos[#1] + #1^2 &, 0.82413231230252242296}]}}\n\n\nIf you are interested in numerical values of solutions you could also choose FindRoot, it works like this :  \n FindRoot[ x^2 == Cos[x], {x, Pi/6}]\n\n\n{x -> 0.824132}\n\n\nIn general x0, here  Pi/6 is the point where it starts to search a numerical solution.\nNSolve also tackles equations numerically: \nNSolve[x^2 == Cos[x], x, Reals]\n\n{{x -> -0.824132}, {x -> 0.824132}}\n\n\nAnd here I briefly sketch a few samples of using  functions which you mentioned : \nRoots[ 2 - 4 x - x^2 + 2 x^3 == 0, x]\n\n\nx == Sqrt[2] || x == -Sqrt[2] || x == 1/2\n\n\nRoot[ 2 - 4 x - x^2 + 2 x^3, #] & /@ Range[3]\n\n\n{-Sqrt[2], 1/2, Sqrt[2]}\n\n\nReduce[ 2 - 4 x - x^2 + 2 x^3== 0, x]\n\n\n x == 1/2 || x == -Sqrt[2] || x == Sqrt[2]\n\n\n", "Pasting $\\LaTeX$ into a Mathematica notebook": "\nI'm prompted by Mathematica when pasting (using 8.0.4) so I don't have this issue. The following seems to do the trick though..\nToExpression[\"\\\\frac{1}{2}\", TeXForm]\n\nI would expect others might have more illuminating responses to this.\nEDIT:\nThe prompt I referred to  is controlled via GlobalOptions > MessageOptions > TeXPasteWarning in the Options Inspector which can be found under Edit > Preferences > Advanced. If this is set to False you won't get prompted as to how you would like to paste the input.\n", "finance - List all financial Assets data conditionally": "\nAs far as I know, FinancialData does not provide a way to query the length of data available for a particular stock. The only way of knowing it is to query the data and select those that have data for 20 years. First, let's get a list of all NYSE stocks with:\nstocks = FinancialData[\"NYSE:*\", \"Lookup\"];\n\nNow, I have multiple interpretations for your 20 year constraint, so I'll address them below.\n1. The stock existed 20 years ago\nThis does not take into account if the stock exists at present. So, first we get the exact date 20 years ago with\ndate20yAgo = DatePlus[DatePlus[0], {-20, \"Year\"}];\n\nand select those stocks that have data on that day. To account for that day being a Saturday/Sunday or any other public holiday, we retrieve data for the entire week:\nexisted20yAgo := ! FinancialData[#, {date20yAgo, DatePlus[date20yAgo, 7]}] === \n  Missing[\"NotAvailable\"] &;\n\nSelect[stocks[[ ;; 20]], existed20yAgo] // Quiet\n(* \nOut[1]= {\"NYSE:AA\", \"NYSE:AAI\", \"NYSE:AAN\", \"NYSE:AAR\", \"NYSE:AB\",\n    \"NYSE:ABA\", \"NYSE:ABK\", \"NYSE:ABK-PZ\", \"NYSE:ABM\", \"NYSE:ABN-PE\"}\n*)\n\nI've just retrieved for the first 20 so that it runs in a reasonable time when you're checking. For the full list, remove the call to Part.\n2. The stock has existed for the past 20 years\nYou can simply modify the above example a little as:\nexistedForPast20y[stock_] := \n   FreeQ[! (FinancialData[stock, {#, DatePlus[#, 7]}] === \n       Missing[\"NotAvailable\"]) & /@ {date20yAgo, DatePlus[-7]}, False]\n\nYou can do a quick check of the above with:\nexistedForPast20y /@ {\"AAPL\", \"GOOG\"}\n(* Out[2]= {True, False} *)\n\nYou can use Select[...] as before and use this function to test.\n3: The stock has 20 years of historical data (any date range)\nThis will unfortunately require pulling all the data for each stock, and will definitely be slower.\nhas20yData := DateDifference[Sequence @@ (First /@ \n        Through[{First, Last}[FinancialData[#, All]]]), \"Year\"][[1]] >= 20 &\n\nAgain, replace the test function in Select with has20yData. I'll leave the rest of the constraints for you to work on.\n", "functions - DiracDelta attributes": "\nYou're right, applying FullDefinition I see that DiracDelta lacks the NumericFunction attribute. And indeed, NumericQ[DiracComb[1]] yields True whereas NumericQ[DiracDelta[0]] doesn't. \nAlthough I'm not sure why that difference exists, you may perhaps be able to get the desired result (you didn't say what your bug was) by setting SetAttributes[DiracDelta, NumericFunction]. At least it then allows you to work with the knowledge that NumericQ[DiracDelta[0]] is True.\nActually, maybe it would be more correct to remove the NumericFunction from both... depends on what you want, I guess.\n", "graphs and networks - Truncate TreeForm to show only the top": "\nCan use something like this:\nClearAll[showTopTree];\nshowTopTree[expr_, level_] :=\n  Module[{myHold}, \n     SetAttributes[myHold, HoldAll];\n     Function[code,\n       TreeForm[Unevaluated@Unevaluated@code],\n       HoldAll] @@\n    (Hold[#] &@\n      DeleteCases[MapAll[myHold, expr], _, {2*level, Infinity}] //.\n           myHold[x__] :> x)];\n\nPretty ugly, but seems to work:\nexpr = Nest[1/(1 + #) (1 - #) &, w, 5]\nManipulate[showTopTree[expr, n], {n, 1, Depth[expr], 1}]\n\nGraphicsGrid[Partition[showTopTree[expr, #] & /@ Range[6], 3]]\n\n\n", "pattern matching - Extracting coefficients from a partial differential equation": "\nSo, this is a solvable problem, but my solution is hacky, not cookbook by any means. It involves using Apply to make algebraic expressions into lists of terms and factors, and it relies the optional levelspec arguments for Cases and DeleteCases being infinity. \nAlso note the use of Block to temporarily suspend the evaluation rules for Derivative, so that I can make things more regular by replacing F[x, y] with Derivative[0, 0][F][x, y]. This is a frequently useful trick when doing algebraic manipulations. \ncoeffRules = Block[{Derivative},\n  With[{terms = \n     Apply[List, eqn /. F[x, y] :> Derivative[0, 0][F][x, y]]},\n   Cases[\n    Flatten@Map[CoefficientRules[#, {x, y}] &, terms],\n\n    (pows_ -> rhs_) :> \n     With[{degs = \n        Flatten[Cases[rhs, Derivative[degs___][F][x, y] :> degs, \n          Infinity]]},\n      With[{args = Join[pows, degs]},\n        If[Length@args == 4, a @@ args, b @@ args]]\n       -> DeleteCases[rhs, Derivative[___][F][x, y], Infinity]]]]];\n\nHere, coeffRules is just a list of rules for the a and b coefficients you described:\n{a[0, 0, 0, 0] -> l^4 m^4, a[0, 0, 0, 0] -> -57 l^4 Lambda M^2, \n a[0, 1, 0, 1] -> l^4 m^4, a[0, 1, 0, 1] -> -4 l^2 M^2, \n a[0, 1, 0, 1] -> 57 l^4 Lambda M^2, b[0, 6, 0, 0, 0, 4] -> 4 M^2, \n b[0, 8, 0, 1, 0, 5] -> 2 M^2, a[0, 8, 2, 4] -> -4 M^2}\n\nYou can then verify that this answer is correct like so:\nIn[17]:= Total[coeffRules /. {\n             (a[i_, j_, k_, l_] -> coeff_) :> \n              coeff*x^i*y^j*Derivative[k, l][F][x, y],\n             (b[i_, j_, k_, l_, m_, n_] -> coeff_) :> \n              coeff*x^i*y^j*\n               Derivative[k, l][F][x, y] Derivative[m, n][F][x, y]}] - eqn\nOut[17]= 0 \n\nHopefully this is enough to get you started.\nEDIT to add: In reply to @sjdh's comment, you can collect all the terms with the same left-hand side using Map, GatherBy and Total:\nIn[69]:= gatheredRules = Map[\n          (#[[1, 1]] -> Total@#[[All, -1]]) &,\n          GatherBy[coeffRules, First]]\nOut[69]= {a[0, 0, 0, 0] -> l^4 m^4 - 57 l^4 Lambda M^2, \n          a[0, 1, 0, 1] -> l^4 m^4 - 4 l^2 M^2 + 57 l^4 Lambda M^2, \n          b[0, 6, 0, 0, 0, 4] -> 4 M^2, b[0, 8, 0, 1, 0, 5] -> 2 M^2, \n          a[0, 8, 2, 4] -> -4 M^2}\n\nIn order to verify that this matches the original equation, use Simplify:\nIn[70]:= Simplify[eqn - \n          Total[gatheredRules /. {\n            (a[i_, j_, k_, l_] -> coeff_) :> \n             coeff*x^i*y^j* Derivative[k, l][F][x, y], \n            (b[i_, j_, k_, l_, m_, n_] -> coeff_) :> \n             coeff*x^i*y^j*Derivative[k, l][F][x, y] Derivative[m, n][F][x, y]}]]\nOut[70]:= 0\n\nThe secret to doing these kind of algebraic manipulations in Mathematica is that algebraic expressions are just list structures with some fancy heads, and thus can be manipulated with exactly the same functions (like Map and Cases) as lists. Indeed, as you become more familiar with Mathematica, you'll discover that pretty much everything, from graphics to imported XML to notebooks themselves, can be manipulated this way.\n", "Switching off Dynamic updating on a cell by cell basis": "\nYou can click in the front-end\nEvaluation->Dynamic Updating Enabled\nto switch off dynamic updating of the cell.\nIn case you want to switch off evaluation of the cell, click \nCell->Cell Properties -> Evaluatable.\n", "import - Release the web camera after using CurrentImage[]": "\nTo turn the camera off you could use the undocumented function IMAQ`StopCamera[]. Similarly IMAQ`StartCamera[] will turn it back on again.\nAlternatively you can use the On/Off button on the control interface returned by ImageCapture[]:\n\n", "programming - Splitting up delimited data in lists": "\nThe first thing that comes to mind is:\nlist = {\"section 1\", \"a\", \"b\", \"c\", \"section 2\", \"d\", \"e\", \"f\"};\n\ndelimiterQ[s_String] := StringMatchQ[s, \"section \" ~~ __]\ndelimiterQ[_] := False\n\nSplitBy[list, delimiterQ][[2 ;; ;; 2]]\n\n\n{{\"a\", \"b\", \"c\"}, {\"d\", \"e\", \"f\"}}\n\n\n\nSzabolcs raised the concern that if the first element of list is not a delimiter this breaks.  If you know in advance that the first element is not a delimiter you can use [[;; ;; 2]] -- if it is uncertain you might use this rather ugly blob of code:\n#[[If[delimiterQ@#[[1, 1]], 2, 1] ;; All ;; 2]] & @ SplitBy[list, delimiterQ]\n\n\nIf you can create a list of all separators another option would be using Import.  With your data in splitdat.txt:\nRest@Import[\"splitdat.txt\", \"Table\", \n  \"LineSeparators\" -> {\"section 1\", \"section 2\"}, \n  \"FieldSeparators\" -> \"\\n\"]\n\n\n{{\"a\", \"b\", \"c\"}, {\"d\", \"e\", \"f\"}}\n\n\nLikewise ReadList, which is probably faster:\nReadList[\"splitdat.txt\",\n  Word,\n  WordSeparators -> \"\\n\",\n  RecordLists -> True,\n  RecordSeparators -> {\"section 1\", \"section 2\"}\n]\n\n", "customization - Customize front end to add notifications when evaluation finishes?": "\nHere's a quick solution. \nNote that it's only tested in Ubuntu - please test it in other operating systems and make any changes that are necessary.\nFirst we define a sendNotification command and then show how to create a style of input cell that automatically calls it. Also included is a palette that will modify any cell to have the appropriate CellEpilog option.\n\nsendNotification[txt_String, opts___] := \n Module[{text = \" \\\"\" <> txt <> \"\\\"\", icon},\n  icon = FileNameJoin[{$InstallationDirectory, \"SystemFiles\", \"FrontEnd\",\n     \"SystemResources\", Switch[$OperatingSystem, \n     \"Unix\", \"X\", \"MacOSX\", \"OSX\", \"Windows\", \"Windows\"], \"Mathematica.png\"}];\n  Switch[$OperatingSystem,\n   \"Unix\", \n   Run[\"(\" <> \"notify-send\" <> \" -i \" <> icon <> \" Mathematica\" <> text <> \")&\"],\n   \"MacOSX\", \n   Run[\"(\" <> \"growlnotify\" <> \" -n \\\"Mathematica.app\\\"\" <> \n     \" -a \\\"Mathematica\\\"\" <> text <> \")&\"],\n   \"Windows\", \n   Run[\"start /b \" <> \"growlnotify\" <> \" /s:true\" <> \" /p:2\" <> \n      \" /i:\" <> icon <> \" /t:Mathematica\" <> text]]]\n\nThe code assumes that: \n\nIn linux you have notify-send installed.\nin OSX you have Growl installed and growlnotify in your path (which it is by default)\nin Windows you have Growl for Windows installed and growlnotify in your path.    \n\nNotify-send (which in Ubuntu plugs into NotifyOSD) does not play with the GNTP so it can not easily be used to interact with other systems and mobile devices. An alternative is to use Growl on Linux with gntp-send.  In KDE there is also KNotify. For notify-send, another possible networking solution is this SO answer.\nIn Windows, you could also (maybe) use Snarl.\nYou can test the notifier using\nsendNotification[\"test\"]\n\n\nYou can create a modified Input style that automatically calls sendNotification after it has finished evaluating. Simply add the following style to your stylesheet\nCell[StyleData[\"InputNotify\", StyleDefinitions -> StyleData[\"Input\"]], \n  CellEpilog :> sendNotification[\"Evaluation of line \" <> ToString[$Line-1]\n     <> \" is complete\"],\n  MenuCommandKey -> \"-\",\n  CellDingbat->\"\\[LightBulb]\"]\n\nThen you can insert a InputNotify cell by pressing Alt--\n\n\nAlternatively, here's a palette that will modify a cell to have the appropriate CellEpilog. Run the code and then, if you want to keep the palette, you can install it via the palette menu.\nCreatePalette[{\n  Button[\"Make Cell Growl!\", SelectionMove[InputNotebook[], All, Cell];\n   With[{cell = NotebookSelection[InputNotebook[]]},\n    SetOptions[cell, TaggingRules -> Options[cell, {CellDingbat, CellEpilog}],\n     CellDingbat -> \"\\[LightBulb]\",\n     CellEpilog :> sendNotification[\"Evaluation of line \" \n                    <> ToString[$Line - 1] <> \" is complete\"]]]],\n  Button[\"Stop Cell Growling\", SelectionMove[InputNotebook[], All, Cell];\n   With[{opts = TaggingRules /. \n       Options[NotebookSelection[InputNotebook[]], TaggingRules]},\n    SetOptions[NotebookSelection[InputNotebook[]],\n     Sequence @@ opts, TaggingRules -> {}]]]}, \n Saveable -> False, WindowTitle -> \"Growl\"]\n\n", "programming - Are there any cases when For[] loops are reasonable?": "\nTo my mind, there are at least two cases when For loops are ok:\n\nInside Compile, or in code which is being written with Compile in mind\nWhen your inner loops are vectorized or made efficient by some other means, so that each iteration of the For loop is sufficiently intensive computationally\n\nMany efficient algorithms are procedural by nature and gain their efficiency by side effects and local mutations. When those algorithms contain nested loops, what matters the most is to speed up innermost loop(s). While we mostly tend to move away from For loops, I have no problem with a For loop being an outer loop in a program, as long as innermost loops are optimized. Also, For loops are more flexible than Map or Scan because you can use Break and Continue, and generally are not forced to iterate over all of the elements in a list in a prescribed order. \nThat said, I think we should recommend beginners to avoid For loops, just because this would allow them to change their mindset and get to the better understanding of Mathematica programming sooner. I'd say, it is ok to occasionally use For loops for experienced users, but beginners would be better off avoiding them entirely, until they get more experience with the language.\n", "programming - Can this be written well, without loops?": "\nThere are some features of this specific problem one can take advantage of.  The boundary of the x,y,z,n domain represented by val <= max is linear in x,y,z and only quadratic in n; furthermore val increases with each of the variables.  So basically the loops might be done in any order, and the limits might be solved for explicitly.\nWe'll start with the limit max and the expression val, which can be compiled for the sake of comparison.\nmax = 5000;\nval[x_, y_, z_, n_] := \n  2 (2 n^2 + (y - 2) (z - 2) + x (y + z - 2) + 2 n (x + y + z - 3));\nvalc = Compile[{{x, _Integer}, {y, _Integer}, {z, _Integer}, {n, _Integer}}, \n   2 (2 n^2 + (y - 2) (z - 2) + x (y + z - 2) + 2 n (x + y + z - 3))];\n\nWe can then solve for the limits on the indices z,y,x,n and save them in idxLimit[tag], where tag runs 1 through 4 and corresponds to z,y,x,n in that order.  (Here a function runs through the tags and sets up idxLimit, but it could have been set up with separate formulas just as easily, as in the output below the code.)\nFunction[{tag}, idxLimit[tag] =\n   Simplify[\n     Min[{y, x, {}, {}}[[tag]], {z, y, x, n}[[tag]] /. \n       Last@Solve[(val[x, y, z, n] /. Take[{z -> 1, y -> 1, x -> 1}, tag - 1]) == max,\n              {z, y, x, n}[[tag]] ]],\n     n >= 1]\n ] /@ Range[4];\n\n\nNext we make the table of the values\na = Normal@SparseArray[Rule @@@ #] &@\n    Tally[Flatten[\n      With[{i1 = {z, idxLimit[1]},\n        i2 = {y, idxLimit[2]},\n        i3 = {x, idxLimit[3]},\n        i4 = {n, idxLimit[4]}},\n       Table[valc @@ {x, y, z, n}, i4, i3, i2, i1] ] ]\n     ]; // AbsoluteTiming\n(* {1.536007, Null} *)\n\nBelow is a table of timings (in sec.) that compares using val instead of valc and ParallelTable (on a 2-core machine).  It also compares the timing of the OP's For-loop program, with and without a compiled val.  The last line are the timings for max = 20000.\n\nTable itself accounts for about 0.876687 sec. (10.003417 for 20K).  Most of the rest of the time is for evaluation valc (about 7-8 sec. in the 20K case) or val.  A smaller chunk is spent collecting the results.  It seemed while I was playing with the problem, that a[[r]]++ suffers from having to evaluate a[[r]] twice, once for reading and once for writing.  Perhaps it doesn't take that much time, but I felt like there was a limit to how fast I could accumulate results in a that way.  The Table way gains a little time at the expense of a lot more memory.\nIt's debatable whether solving for the limits (to get idxLimit) is clean.  The original val leads to the strange expressions.  Mainly it's a mathematical trick than a programming one, which allows a rather standard conversion of for loops to Table.  The rest of it are just tweaks.\n", "parallelization - Wolfram Light Weight Grid and parallel computing": "\nI've discovered (at least some of) the answer to this question.\n\nOne needs to install the Wolfram lightweight grid manager on local AND remote computers.  This seems a bit confusing as the title of the program that one sees during the installation, refers to this application as \"Wolfram gridMathematica Server with Wolfram Lightweight Grid Manager\".  A bit clearer nomenclature i.e. \"...server/client manager\" would, in my mind make this clearer.\nThe login on the \"Licensing\" tab of the Wolfram Lightweight Grid Manager\" that opens in a browser requires the user name \"admin\".  This also seems a bit confusing, because while they refer to this user name in the set up, the user does not enter it.  If only \"admin\" works as a user name in this instance why require the user to enter it at all?  I thought it wanted either the administrator's name for the computer or the login for the grid manager.  Also, I don't understand why it requires two sets of user names and passwords to setup and run the manager.\nApparently, while a desktop license of Mathematica includes 2 \"Controlling\" processes and  4 \"Computing\" process (see the following from the Wolfram User Portal:\n\n\nThe number of Processes allowed is formated as (X/Y), where X is the number of Controlling Processes and Y is the number of Computation Processes.\nA Controlling Process indicates the number of simultaneous network users of \"seats\" allowed.  A Controlling Process handles input, output, and scheduling for the Computation Processes.\nA Computation Process indicates the number of computations that may be\n  run simultaneously.)\n\nin discussing this with support earlier today, it appears Mathematica licensing requires  Computation Processes to reside on the same machine as the Controlling Process.\nIt seems one can have two copies of the same license installed on different machines, but one can only use one of the copies at a time and one can only access the Computation Processes for the license if they reside on the same machine as a copy of the license.\nThis seems a bit antiquated given Sun Micro Systems' (via John Gage's) recognition a couple of decades ago that \"The network is the computer.\"  Why should the location of the Computation Processes matter?\nSo if I have the correct information from support, to get access kernels on a remote machine one needs a full copy of Mathematica installed on the remote machine.\nUpdate: I just installed a full desktop version of Mathematica on my remote machine and can now see and access its 2 processors from the Preferences >> Lightweight Grid window and see them in action on the Parallel Kernel Status window:\n\nTo my mind, this licensing approach does not align well with the vision and promise of distributed processing, which sought to enable people to access computing resources anywhere on a network.  While advanced desktop machines have started to have 4 processors, I'd wager most machines still have only one or two.  Meanwhile lots of people may have a couple of desktops or some combination of desktops and laptops available.  Just a shame we can't make use of them.\nMaybe it makes sense to study up on CUDA and GPU.  \nHope this helps.\nJagra\n\nSome additional information from Mathematica support relative to my initial thoughts:\n\"One needs to install the Wolfram lightweight grid manager on local AND\nremote computers\". \n\nThis is incorrect, the lightweight grid manager is only needed on the\n  remote computers (or the computers that will be supplying the kernels\n  for parallel computation). The only time the lightweight grid manager\n  will be required on the local machine is if other machines will be\n  launching kernel from this local machine.\n\n\"...it appears Mathematica licensing requires Computation Processes to\nreside on the same machine as the Controlling Process\".\n\nThis is also incorrect. The controlling process is only required on\n  the job submission node. The computation nodes can reside across\n  multiple machines which do not need to have another controlling\n  process. (Basically, they have kernels and no front ends).\n\n\"It seems one can have two copies of the same license installed on\ndifferent machines.\" \n\nThis is incorrect as well. Unless you are running a license manager or\n  the lab version (which will not run gridMathematica), you cannot run\n  the same license on two machines at any one time. The passwords are\n  machine dependent. You will need to call us anytime you need to switch\n  machines.\n\n", "front end - How change order of items added to the Palettes menu?": "\nOkay, new approach.  My old answer is preserved below for reference.  \nI was not aware of this before posting, but there is a MenuPosition option in the Options Inspector, and it does take effect.  You will need to first check Editable so that you can edit the palette.  Here is the active screen:\n\n\nIn the header of a palette .nb file there is this section:\n(* Internal cache information:\nNotebookFileLineBreakTest\nNotebookFileLineBreakTest\nNotebookDataPosition[       145,          7]\nNotebookDataLength[     28489,        713]\nNotebookOptionsPosition[     27870,        688]\nNotebookOutlinePosition[     28422,        710]\nCellTagsIndexPosition[     28379,        707]\nMenuPosition->1000\nWindowTitle->Slide Show\nWindowFrame->Palette*)\n\nThe value of MenuPosition, if present determines the group and ordering of the palette in the menu.  That is, lower values appear higher in the list, and palettes with the same value will be placed in the same group.\n", "graphics - Point Renderings Slightly Off in Mathematica": "\nUpdate: simple work-around added at bottom of post.\nAnalysis of the problem\nThis appears to be an issue with the default PlotMarkers.  I do not see similar offsets using this:\nShow[\n ListPlot[{stationaryPoints, inflectionPoints}, Frame -> True, \n  PlotMarkers -> {{Graphics@{Red, Disk[]}, \n     0.05}, {Graphics@{Blue, Rectangle[]}, 0.05}}],\n Plot[f[x], {x, -Pi - 1, Pi + 1}],\n ImageSize -> 500\n]\n\n\nYou can see from this that the default PlotMarkers are actually font based, rather than Graphics primitives:\nGraphics`PlotMarkers[] // InputForm\nGraphics`PlotMarkers[][[1, 1]] // ToCharacterCode\n\nI believe that these font glyphs are inherently prone to misalignment with Graphics primitives, due to a different rendering pipeline.\n\nAddressing your question about (mis)alignment of PlotMarkers constructed from primitives, I believe this is the result of the chosen antialiasing scheme.  One can see by magnifying a screen capture that orthogonal lines use \"pixel snapping\" or \"hinting\".  This increases apparent sharpness, but sacrifices precise placement.\n\nOn my Windows system, a distinct \"judder\" is apparent in the following animation.  Both the placement and the shape of the rectangles changes with ImageSize.\nShow[ListPlot[{stationaryPoints, inflectionPoints}, \n          PlotMarkers ->\n              {{Graphics@{Red, Disk[]}, 0.05},\n               {Graphics@{Blue, Rectangle[]}, 0.05}}], \n     Plot[f[x], {x, -Pi - 1, Pi + 1}],\n     Ticks -> None,\n     ImageSize -> d\n] ~Animate~ {d, 200, 300, 1}\n\nI am not aware of a method to change the 2D antialiasing scheme.  However, one work-around is to rasterize the image at a higher resolution, and then resample to the target size.\n\nChanging the anti-aliasing method using Opacity\nI learned from Simon Woods that using Opacity, even with an effectively opaque value of .999 (but not 1), will change the anti-aliasing method that is used for font glyphs.  Therefore we can affect a work-around for this alignment problem by specifying: BaseStyle -> Opacity[.999] or BaseStyle -> {FontOpacity -> 0.999}.\nObserve:\nShow[Plot[f[x], {x, -Pi - 1, Pi + 1}], \n ListPlot[{stationaryPoints, inflectionPoints}, PlotStyle -> {{Red}, {Blue}}, \n  PlotMarkers -> {Automatic, 15}, BaseStyle -> Opacity[.999]]]\n\n\n", "How do I find the elements in a list that return the highest value for a function?": "\nWhile using Ordering as in Mr.Wizard's answer will most likely be the fastest non-compiled solution, it will not return all possible arguments that maximize the return value. Here's a simple way of writing a function that does this:\nlistMaxArg[f_, list_] := With[{max = f /@ list // Max}, Select[list, f@# == max &]]\n\nHere's an example that compares the two solutions:\na = {{1, 2, 3}, {10}, {6, 4}};\nlistMaxArg[Total, a] \n(* Out[1]= {{10}, {6, 4}} *)\n\nlistMaxArgMrWiz[Total, a]\n(*Out[2]= {{6, 4}} *)\n\n", "front end - How to sort cells in a notebook based on cell tags?": "\nThis is actually something I am working on for real at the moment. This is what i have got so far:\nnb = NotebookOpen[\"path/to/notebook.nb\"];\nSelectionMove[nb, All, Notebook];\ncontent = NotebookRead[nb];\nNotebookDelete[nb];\n\nFor searching based on the number listed as the first tag:\nsorted = SortBy[content, \n Cases[#, HoldPattern[\n     Rule[CellTags, {x_ /; StringMatchQ[x, NumberString], __}]] :> \n    ToExpression@x] &]\n\nand for searching based on the word in the second tag:\nsorted = SortBy[content, \n Cases[#, HoldPattern[Rule[CellTags, {_, x_, __}]] :> x] &]\n\nWith both of these methods the untagged cells are returned first ...which is ok. Then\nScan[NotebookWrite[nb, #] &, sorted];\nNotebookSave[nb];\nNotebookClose[nb];\n\nThis is a little bit slow but seems to be doing the job.\nEdit\nSo this code seems to be doing the job on the notebooks i needed to use this with. Would still be interested in suggestions from others.\nClearAll[sortNotebook];\n\nOptions[sortNotebook] = {\"sortby\" -> \"Number\"};\n\nsortNotebook[file_String, OptionsPattern[]] := \n Module[{nb, opt = OptionValue[\"sortby\"], sorted},\n\n  nb = NotebookOpen[file];\n  SelectionMove[nb, All, Notebook];\n  content = NotebookRead[nb];\n  NotebookDelete[nb];\n  Which[\n   opt === \"Number\", \n   sorted = \n    SortBy[content, \n     Cases[#, \n       HoldPattern[\n         Rule[CellTags, {x_ /; StringMatchQ[x, NumberString], __}]] :>\n         ToExpression@x] &],\n   opt === \"Task\", \n   sorted = \n    SortBy[content, \n     Cases[#, HoldPattern[Rule[CellTags, {_, x_, __}]] :> x] &],\n   opt =!= \"Number\" && opt =!= \"Task\", \n   Print[\"you messed up with the option names\"]\n   ];\n  Scan[NotebookWrite[nb, #] &, sorted];\n  NotebookSave[nb];\n  NotebookClose[nb];\n  ]\n\n", "options -  Saving a notebook without output lines": "\nIn Options Inspector you can change the EvaluationOptions for Selected Notebook or for Global Preferences by adding \n  {\"WindowClose\" :>  FrontEndExecute[FrontEndToken[\"DeleteGeneratedCells\"]]}\n\nto the NotebookEventActions line. \nScreenshots for changing the notebook evaluation options in Options Inspector:\nA notebook with Input and Output cells and the Evaluation Options page in Option Inspector \n\nAfter editing the NotebookEventActions line in Options Inspector or evaluating \nSetOptions[EvaluationNotebook[], NotebookEventActions -> {\"WindowClose\" :> \n FrontEndExecute[FrontEndToken[\"DeleteGeneratedCells\"]]}]; \n\ninside the notebook:\n\nAfter clicking X on the on the notebooks window frame:\n\nAfter clicking Yes on the dialog window:\n\nAlternative: you can add \n SetOptions[EvaluationNotebook[], NotebookEventActions -> {\"WindowClose\" :> \n FrontEndExecute[FrontEndToken[\"DeleteGeneratedCells\"]]}]; \n\nto a notebook's initialization cell.\n", "front end - How do I programmatically add to contextual menus?": "\nThere's an option ContextMenu, which you seem to be able to set at cell, notebook, or even box level. They all default to something like\nFEPrivate`FrontEndResource[\"ContextMenus\", \"something\"]\n\nThat info seems to be in the ContextMenus.tr file in the $InstallationDirectory, SystemFiles, FrontEnd, TextResources.\nIn any case, all that that option needs is a list of MenuItem[...]. You can look at that file (or at MenuSetup.tr) to get a hang on the syntax. Then it's just setting the option.\nApart from the brute force method of reading the file, creating your own, adding your Menus, and setting that option, I still haven't found a way to \"append\" the MenuItems. Only to replace... I'll edit if I find something\n", "Speeding up export of a matrix to a dat file": "\nI suggest you watch the presentation BigData: Demystifying Large Datasets in Mathematica\nby Nick Lariviere.  He discusses the various possibilities quite clearly.\n", "probability or statistics - Function for Autocorrelation": "\nFrom the help file for ListConvolve, to find the autocorrelation of a list:\ndata = Table[Mod[i^2, 17], {i, 100}];\nautocorrelation = ListConvolve[data, data, {1, 1}];\nListLinePlot[autocorrelation ]\n\n\n", "programming - Programmatically generate packages from notebook files?": "\nNot entirely on topic (and probably well-known), but starting with version 6 (I think) you can very comfortably work with the .m files within the frontend. The frontend parses the package and displays it just like any old notebook. You can use sections and do all the fancy typesetting, generate (temporary) output etc. This is also available under File -> New -> Package (.m).\nThe code is put into \"Code\" style cells which are Initialization cells, and these are saved (together with text and section information, see Pillsy\u00b4s post), stripping any output cells and leaving you with the plain package that works just fine. With the parsing, you also get some helpful formatting and additional gizmos (see image).\nSo you only maintain one set of packages directly, but with all the benefits of the frontend interface (notice: the parsing can take a few seconds when opening).\n\nAnd if you are annoyed by the linewrapping behaviour of the package stylesheet, have a look at this thread: Viewing packages in Mathematica\n", "graphs and networks - HITS centrality": "\nFor HITSCentrality you could try \nPick[Transpose[HITSCentrality[graph1]], VertexList[graph1], 1]\n\n", "programming - How to write a function-defining function which stores the function arguments in a stack?": "\nYou could name the patterns\nDefFn[f_[args___], body_] := \n  f[s : PatternSequence[args]] := WithStackFrame[{f, {s}}, body];\n\n", "performance tuning - Efficient way to turn a subset into a permutation": "\nTheoretically, this will have linear complexity:\nreshuffle[ab_, kvec_] :=\n  Module[{a, copy , bs = Drop[ab, Length[kvec]], n = 0},\n    copy = Table[a, {Length[ab]}];\n    copy[[kvec]] = Take[ab, Length[kvec]];\n    copy /. a :> bs[[++n]]]\n\nIn practice, however, I am pretty sure your solution is one of the fastest. A version of my solution can be compiled if your list is e.g. a list of integers or reals, in which case it may be faster.\nHere is a compiled version:\nreshuffleC =\n  Compile[{{ab, _Integer, 1}, {kvec, _Integer, 1}},\n     Module[{result, min = Min[ab], i = 1, ctr = 0, bs = Drop[ab, Length[kvec]]},\n       result = Table[min - 1, {Length[ab]}];\n       result[[kvec]] = Take[ab, Length[kvec]];\n       For[i = 1, i <= Length[ab], i++,\n         If[result[[i]] == min - 1,\n         result[[i]] = bs[[++ctr]]]];\n       result], CompilationTarget -> \"C\"]\n\nIf you have a general list as ab, you can use ab[[reshuffleC[Range[Length[ab]],kvec]]]. \nHere are some benchmarks:\nabtest = RandomInteger[{10000000},10000000];\nkvec = RandomSample[Range[10000000],5000000];\n(res1=reshuffleC[abtest ,kvec]);//Timing\n(res2=Reshuffle[abtest ,kvec]);//Timing\nres1==res2\n\n(* \n ==> {0.437,Null}\n     {2.797,Null}\n      True\n*)\n\n", "graphics - Too much vertical space in a CDF file": "\nYou can easily remove all white space around your CDF app. Simplest way - use CDF Web Deployment Wizard available in Mathematica version 8.0.4. It is designed to remove the white space around interactive content and embed it tigtly into a webpage. Follow File \u00bb Deploy \u00bb Embed in HTML\u2026 Here is the result of this workflow applied to the app from your file SimpleDemos.nb and embeding it into WordPress.\nThe CDF file can be downloaded from here\nAs you can see there is no horizontal or vertical white space around the app.\nI would also recommend controlling the size of embedded CDF with ImageSize->{w, h} option for your internal graphics in Manipulate[...]. Actual app size on the page will be slightly larger due to Manipulate[...] interface with dimensions provided by the wizard. If you would like detailed instructions follow this video.\n", "Reading from a stream of strings and numbers delimited by commas": "\nThis seems to work and doesn't require conversion\nstream = StringToStream[\n   \"Apple,Jack,1,123.456\\nOrange,Jill,2,456.789\\n\"];\n\nWhile[! EndOfFile === (data = \n      Read[stream, Riffle[{Word, Word, Number, Number}, Word],\n        TokenWords -> {\",\"}] /. {\",\" -> Sequence[]}), \n  Print[\"Fruit:\", data[[1]], \" Name:\", data[[2]], \" Integer:\", \n    data[[3]], \" Real:\", data[[4]]];];\n\nClose[stream];\n\n", "Formatting output of OpenAppend[] to match what Export[data,file,\".csv\"] would output?": "\nAs @WReach has noted, Export will accept a stream as its first argument so \nfile = OpenAppend[\"out.txt\"]\n\nExport[file, data, \"CSV\"];\nWriteString[file, \"\\n\"];\n\nClose[file]\n\nAlternatively you could first use ExportString to write the data into a string in the desired format, then send the string to the file to be appended to using WriteString.\nExample:\ndata = RandomInteger[100, {100, 3}]\n\nfile = OpenAppend[\"out.txt\"]\n\nstring = ExportString[data, \"CSV\"];\n\nWriteString[file, string]\nWriteString[file, \"\\n\"];\n\nClose[file]\n\n", "debugging - Mathematica Debuggability": "\nWhile I wait for better answers from some very knowledgeable people in the matter on the site, I'll write what I'm thinking...\nI think that most of your problems are due to lack of practice with functional thinking rather than lack of debugability itself.\n\nI think one that on the contrary, one of the advantages of programming functionally is that the state of the program is kept on the stack. If you know where you are, you know everything. In imperative programming its harder to know all the variables that keep the state at any point to understand the behaviour. If goto and label are worse for following the flow of a program versus normal loop structures, then functional seems another step ahead. You can always put a function like @LeonidShiffrin's ShowIt where you want to see what's going on, or something similar to print the stack (see the function Stack[_]):\nSetAttributes[ShowIt, HoldAll];\nShowIt[code_] := \n   Module[{y}, \n      Print[ToString[Unevaluated[code]], \" = \", y = code]; \n      y]\n\nYou answered yourself. Always remember that in Mathematica, code and expressions are the same, so you can always make a \"function\" that saves you all the boilerplate code if you think that certain solution can be done but its hard and makes you type a lot. (You could even take it to the extreme of brutally overload SetDelayed to always add a func[___]:=Throw, but I don't think that's recomended, hehe)\n\nAs to how to make the debugging simpler, well... \n\nBuild up from short declarative functions. Comment a lot, Test them before going on chaining 11 of them.\nUse Messages\nCheck out the debugger, at least the Workbench one. They let you add breakpoints, see the stack, and even break on messages\nUse functions such as that ShowIt from Leonid, or make your own.\nLearn to use Trace and family. I really like a version of it that I think I took from a post by @WReach\nTraceViewShort[expr_] := \n Module[{steps = {}, stack = {}, pre, post}, \n  pre[e_] := (stack = {steps, stack}; steps = {}); \n  post[e_, r_] := (steps = First@stack~Join~{{e, steps, HoldForm[r]}};\n     stack = stack[[2]]); SetAttributes[post, HoldAllComplete]; \n  TraceScan[pre, expr, ___, post]; \n  DynamicModule[{focus, show, substep, enter, exit}, focus = steps; \n   substep[{e_, {}, _}, _] := {Null, e, \n     Style[\"inert\", {Italic, Small}]}; \n   substep[{e_, _, r_}, \n     p_] := {Button[Style[\"show\", Small], enter[p]], e, \n     Style[Row[{\"-> \", r}], Small]}; \n   enter[{p_}] := PrependTo[focus, focus[[1, 2, p]]]; \n   exit[] := focus = Drop[focus, 1]; \n   show[{e_, s_, r_}] := \n    Column[{Grid[{{\"Expression\", \n         Column@Reverse@focus[[All, 1]]}, {Column[{\"Steps\", \n           focus /. {{_} :> Sequence[], _ :> \n              Button[\"Back\", exit[], ImageSize -> Automatic]}}], \n         Grid[MapIndexed[substep, s], Alignment -> Left]}, {\"Result\", \n         Column@focus[[All, 3]]}}, Alignment -> Left, Frame -> All, \n       Background -> {{LightCyan}}]}]; Dynamic@show@focus[[1]]]]\nSetAttributes[TraceViewShort, {HoldAllComplete}]\n\nCheck the function arguments. In some cases it may make more sense to use your f[___]:=Throw and in others leave it unevaluated\nConsider Assert, it works well with the debugger and doesn't make your code slower because you can turn it off...\n\nAnyway, Mathematica allows you to do almost anything you want. Most of the things you said are not Mathematica limitations but, in the worst case, limitations of the way you're using it. Sometimes that extra freedom has the disadvantage of not giving you guidelines as to what's best.\n", "parallelization - CUDA and GPU hardware and compatibility questions?": "\nInformation we received back from Wolfram Technical Support, which may help others better understand the issues originally raised around CUDA and OpenCL:\n\nIn general CUDA is much faster than CPU parallelization CONDITIONALLY and not limited by the limitation of our licenses.\n  However, the functions supported in CUDA are limited to numerical functions such as arithmetic operations and fast Fourier transformation, in particular those defined in math.h in C.\n  You will need to program most of the solvers by yourself or find the corresponding CUDA libraries from either developer zone or C++ extension\n  packages. \nThe worst drawback of CUDA code is data flow actually. It will take a\n  very long time for data to be copied from RAM to GPU memory. If data\n  flow in/out is what you want, you should do that just once or twice in\n  the whole process.\nSo far CUDA is only supported on a local machine, i.e. you cannot use\n  the graphics card on other machine. It is not recommended to use two\n  graphics cards even on the same machine so far since it is not mature\n  under current CUDA tech. \nOn the other hand, parallel cpu computation is less optimized in terms\n  of clock speed. The limitation comes from how CPU generates threads\n  and that the master kernel distributes tasks along the computation.\n  However, the parallel kernels using the gridMAtheamtica tech have\n  excellent scalability and support all internal functions inside\n  Mathematica. This, as a compensation for slower clock speed, saves\n  huge amount of time for programming.  Typically for a task involving\n  many different functions like nonlinear solver, plot, symbolic\n  computation, etc. \nSo here are the options:\n1) If you have your own solvers and source codes and you know exactly\n  how to program in terms CUDA C, typically the economical management\n  GPU/CPU memory, CUDA is recommended. \n2) otherwise, CPU parallelization is preferred. \nSomething that might be useful in your code: \na) If you know that the Newtonian method or the like can be applied to\n  solve the intersections, you can either specify that in your NSolve or\n  FindInstance. Another way is to simply write the code and generate\n  CUBIN inside Mathematica. \nref :: CUDALink/tutorial/Programming\nb) NProbabilty and NExpectation are gorgeous function since it is\n  functional and symbolic (even though they return numeric value).\n  However, they do take significant CPU seconds to compute and\n  performance is rather hard to improve. The only way is to distribute\n  them on subkernels/other CPU cores.\nNote that is not possible to convert functions codes unless there are\n  proper CUDA libraries released. \nLast thing about OpenCL and CUDA. CUDA is supposed to be faster than\n  OpenCL and more stable. CUDA definitely need NVIDA card while it is\n  optional to use GPU in OpenCL. But a OpenCL code without calling GPU\n  is a CPU code, which does no good at all.\n\n", "How do I clear all variables with subscripts?": "\nWell. You can always clear a certain value by using Unset\nSubscript[r, 3]=8;\nSubscript[r, 3]=.;\n\nNow, Clear and ClearAll won't work if you used regular = and assigned the values as Subscript's DownValues. But if you used UpValues, it could work\nr/:Subscript[r, 3]=8;\nClearAll[r];\n\n", "calculus and analysis - Definite and Indefinite integral give different results for piecewise function": "\nWhen the indefinite integral has discontunities (as is the case for your integrand for some values of q and alpha), substituting the endpoints in the indefinite integral expression gives incorrect results. To get the correct result you need to use the definite integral. \nPlease see the section Possible Issues subsection Definite Integral under Integrate in docs. The issue is also discussed at length in this Wolfram Blog entry: Mathematica and the Fundamental Theorem of Calculus.\n", "performance tuning - Considerations when determining efficiency of Mathematica code": "\nFirst off, Timing isn't as accurate as AbsoluteTiming because it has a tendency to ignore various things.  Here is a paticularly telling example. Keep in mind that neither will keep track of rendering time or formatting of output, this is purely time spent computing in the kernel.\nAbsoluteTiming[x = Accumulate[Range[10^6]]; Pause[x[[1]]]; resA = x + 3;]\n\n==> {1.045213, Null}\n\nTiming[x = Accumulate[Range[10^6]]; Pause[x[[1]]]; resB = x + 3;]\n\n==> {0.031200, Null}\n\nThese are identical calculations but Timing ignores Pause so it is way off.\nNow lets set up a toy example. Your tests for timings are what I would typically do first when looking for efficiency.\nf[x_Integer?Positive] := Accumulate[Range[x]]\n\ng[x_Integer?Positive] := \n   Block[{result = Array[0, x]},\n    result[[1]] = 1;\n    For[i = 2, i <= x, i++, result[[i]] = result[[i - 1]] + i];\n    result\n   ]\n\nThe AbsoluteTiming is quite different for these two approaches. Clearly the built in function is preferable in this case.\nAbsoluteTiming[resf = f[10^6];]\n\n==> {0.015600, Null}\n\nAbsoluteTiming[resg = g[10^6];]\n\n==> {3.432044, Null}\n\nAnd of course, we should test that these produce equivalent results..\nresf == resg\n\n==> True\n\nNow I will mention that there are times when Equal will return False.  This may be acceptable in some situations if say we are only really interested in very low precision, ball-park results.\nAs for memory consumption, I hope someone else might elaborate on this part. One way to test it is with MemoryInUse.\nm1 = MemoryInUse[];\nf[10^6];\nMemoryInUse[] - m1\n\n==> 8001424\n\nm1 = MemoryInUse[];\ng[10^6];\nMemoryInUse[] - m1\n\n==> 24000656\n\nAgain, the system function wins hands down.\nEdit: \nThe reason the second method showed such a substantial increase in MemoryInUse is because it doesn't produce a packed array. If we pack the output, it uses the same memory as the first.  This tells me that MemoryInUse only tells us how much memory the result uses and nothing about the amount of memory used in intermediate computations.\nm1 = MemoryInUse[];\nDeveloper`ToPackedArray@g[10^6];\nMemoryInUse[] - m1\n\n==> 8001472\n\nEdit 2: Here is a function I put together that I'm sure can be made more effective and efficient.  It uses a binary search technique with MemoryConstrained to find the amount of memory requested when evaluating an expression. \nSetAttributes[memBinarySearch, HoldFirst]\n\nmemBinarySearch[expr_, min_, max_] :=\n Block[{med = IntegerPart[(max - min)/2], low = min, high = max, \n   i = 1},\n  While[True,\n   If[MemoryConstrained[expr, med] === $Aborted,\n    low = med;\n    ,\n    high = med;\n    ];\n   med = IntegerPart[low + (high - low)/2];\n   If[Equal @@ Round[{low, med, high}, 2], Break[]];\n   ];\n  med\n  ]\n\nHere it is applied to f and g from above...\nmemBinarySearch[f[10^6], 1, 10^9]\n\n==> 16000295\n\nmemBinarySearch[g[10^6], 1, 10^9]\n\n==> 62499999\n\nNote that memBinarySearch is only accurate to 2 bytes. For some reason (probably related to IntegerPart) it doesn't like to find the exact byte count requested.\n", "How to turn a set of strings which represent a list into a 2D list": "\nAnother solution using StringSplit:\nlist = {\"{H, 1}\", \"{H, 2}\", \"{H, 3}\", \"{Mg, 1}\", \"{Mg, 1}\", \"{Mg, 1}\",\n   \"{C, 1}\", \"{C, 1, H, 1}\", \"{N, 1}\", \"{N, 1, H, 1}\"};\n\nStringTrim /@ StringSplit[list, {\"{\", \",\", \"}\"}]\n\n\n{{\"H\", \"1\"}, {\"H\", \"2\"}, {\"H\", \"3\"}, {\"Mg\", \"1\"}, {\"Mg\", \"1\"}, {\"Mg\", \"1\"}, \n {\"C\", \"1\"}, {\"C\", \"1\", \"H\", \"1\"}, {\"N\", \"1\"}, {\"N\", \"1\", \"H\", \"1\"}}\n\n\n", "Dbugging Mathmatica Cod - Mathmatica Stack Exchang": "\nI think you got 4 choices:\n\nWorkbench. Probably the most useful of the debuggers.\nMathematica has a small debugger: Evaluation -> Debugger\nThere is DebugTrace from David (perhaps there are other packages)\nUse Print, Trace(Scan)[], etc type of functions.\n\n", "Bold face formatting for vectors instead of overarrows like latex \\mathbf{}?": "\nI am not sure I understand your needs, but consider this:\nFormat[OverVector[v_]] := Style[HoldForm[v], FontFamily -> \"Arial Black\"]\n\n{q, r, OverVector[s], t, u, v}\n\n\n", "plotting - How do you define the domain of a plot?": "\nFor simple regions like your interval or a square region, you can just give the appropriate border, as shown by the earlier answers. For completeness, I repeat them here:\nDomain $[-3,3]$:\nPlot[f[x], {x, -3, 3}]\n\nDomain $[-3,3]\\times [-3,3]$:\nPlot3D[f[x,y], {x, -3, 3}, {y, -3,3}]\n\nFor more complex domains, you have several options:\nFirst, you can explicitly use a function with limited domain, e.g. for the domain $[-2,-1)\\cup(1,2]$:\nPlot[ConditionalExpression[Sin[x], Abs[x] > 1], {x, -2, 2}]\n\nOr for 2D:\nPlot3D[ConditionalExpression[Sin[x y],x<y], {x, -Pi, Pi}, {y, -Pi, Pi}]\n\nAnother possibility is to give the region in the plot command:\nPlot[Sin[x],{x,-2,2},RegionFunction->(Abs[#] > 1&)]\n\nPlot3D[Sin[x y],{x,-Pi,Pi},{y,-Pi,Pi},RegionFunction->(#1<#2&)]\n\nFinally, for 3D plot you might also use some parametrization of your domain resulting in a square parameter range and use ParametricPlot3D (you can, of course, do that for 2D plots as well, but there it's not as useful):\nParametricPlot3D[Module[{x=r Cos[phi],y=r Sin[phi]},{x, y, Sin[x y]}],\n                 {r, 1, 2}, {phi, 0, 3 Pi/2}]\n\nOf course you can also combine those methods, e.g.\nParametricPlot3D[Module[{x=r Cos[phi], y=r Sin[phi]}, {x, y, Sin[x y]}],\n                 {r, 1, 2}, {phi, 0, 3 Pi/2},\n                 RegionFunction->Function[{x, y, z, r, phi},\n                                          x < 1.5 && phi < (r-1) 3 Pi/2]]\n\n", "plotting - Changing the background color of the framed region of a plot": "\nYou can use the Prolog option with Scaled coordinates:\nPlot[Sin[x], {x, 0, 2 \u03c0}, Frame -> True,\n Prolog -> {LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}\n]\n\n\nNote: Using scaled coordinates lets this work for any PlotRangePadding, and with PlotRangePadding->False:\nPlot[Sin[x], {x, 0, 2 \u03c0}, Frame -> True, \n Prolog -> {LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}, \n PlotRangePadding -> .6]\n\n\nPlot[Sin[x], {x, 0, 2 \u03c0}, Frame -> True, \n Prolog -> {LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}, \n PlotRangePadding -> -.2, PlotRangeClipping -> False]\n\n\n", "Numrics with Mathmatica - Mathmatica Stack Exchang": "\nI think it is important to realize that switching off symbolics (also for numerics) would deprive you of some of the best optimizations Mathematica has to offer. When Mathematica tries to use symbolics on numerical input, that can mean things like term analysis or optimizations for the compiler. Just think about it, this would mean that the compiler, for example, cannot factor out common terms, NIntgrate could not integrate oscillatory integrals because it can not do analysis on the integrand. It does not matter if an analytical solution exists a symbolic analysis can never the less be very useful. Andrew made a good presentation about what is happening under the hood you might find Hybrid Computing interesting.\nSeen the benefits just mentioned and the fact that it is not impossible to figure out how to use Mathematica efficiently, make me feel that such a switch is undesirable. I can hopefully help you with a) see below. \nFor b) I feel that the typing _?NumericQ is not that bad especially compared to the downsides of not having symbolic analysis. \nc) In some functions you can switch that off via a Method option. You could set these in a file, system options or some such.\nMy suggestion for your switch is to collect the various items and set them in an init.m file.\nConcerning packed array you might find a visual PackedArrayForm helpful.\n$Post = Developer`PackedArrayForm\n\nThis then gives:\na = Range[20]\n\"PackedArray\"[Integer, \"<\" 20 \">\"]\n\nIf you then set\na[[1]]=1.;\na\n\nWill give you a list.\n{1., 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, \\\n20}\n\nThis allows for a relatively easy distinction between packed and non packed. For the automatic conversion to packed arrays consider this:\nTable[Pi, {5}]\n{\\[Pi], \\[Pi], \\[Pi], \\[Pi], \\[Pi]}\n\nIf you set (or some more clever variant)\n$Pre = Developer`ToPackedArray[N[#]] &\n\nand evaluate\nTable[Pi, {5}]\n\"PackedArray\"[Real, \"<\" 5 \">\"]\n\nAgain, for your switch you could have these in your init.m file.\n", "performance tuning - AbsoluteTiming affected by surrounding code": "\nAs Szabolcs pointed out, I was running into the resolution of the timer in my system in my attempts to micro benchmark.  Also, my attempts at micro benchmarking were incorrect I might add, but more on that later. \nI was able to see the light only after scratching my head for a number of days on Szabolcs' comment and working on a performance package, I finally came across $TimeUnit here. I got the idea to use Pause[10*$TimeUnit] as the code being tested in each case.  Clearly Pause[10*$TimeUnit] is above the resolution of the timer in my system.  Oh, in case you are curious, $TimeUnit is 1/100 on my system (2011 MBP 17\" running Lion).\nFor those of you who want to play along at home, the following is the updated micro benchmarking code: (btw it is still incorrect).\nPrintHeader[] :=\n  Print[\"        Total    Mean     Min      Max      StdDev \"];\n\nPrintStats[doTimes_List , mapTimes_List] :=\n (\n  Print[\"Do    \", \"  \", doTotal = Total[doTimes], \"  \", \n   doMean = Mean[doTimes], \"  \", Min[doTimes], \"  \", Max[doTimes], \n   \"  \", StandardDeviation[doTimes]];\n  Print[\"Map   \", \"  \", mapTotal = Total[mapTimes], \"  \", \n   mapMean = Mean[mapTimes] \"  \", Min[mapTimes], \"  \", Max[mapTimes], \n   \"  \", StandardDeviation[mapTimes]];\n  Print[\"Do-Map\", \"  \", doTotal - mapTotal, \"  \", doMean - mapMean, \n   \"\\n\"];\n  )\n\nPrintHeader[];\niterations = 1000;\nDo[(\n   doTimes = {};\n   Do[AppendTo[doTimes,\n     AbsoluteTiming[Pause[10*$TimeUnit]][[1]]]\n    , {iterations}];\n\n   mapTimes = Map[\n     AbsoluteTiming[Pause[10*$TimeUnit]][[1]]\n      &, Range[1, iterations]];\n\n   PrintStats[doTimes, mapTimes];\n   ), {5}];\n\n\nResults\n        Total    Mean     Min      Max      StdDev \nDo      100.339  0.100339  0.100027  0.101277  0.000330\nMap     100.343  0.100343  0.100035  0.101294  0.000330\nDo-Map  -0.004  -4.*10^-6\n\nDo      100.351  0.100351  0.100036  0.101276  0.000327\nMap     100.338  0.100338  0.100035  0.101247  0.000330\nDo-Map  0.013  0.000013\n\nDo      100.328  0.100328  0.100025  0.101328  0.000319\nMap     100.346  0.100346  0.100027  0.101280  0.000332\nDo-Map  -0.018  -0.000018\n\nDo      100.347  0.100347  0.100029  0.101238  0.000330\nMap     100.332  0.100332  0.100021  0.101235  0.000338\nDo-Map  0.015  0.000015\n\nDo      100.330  0.100330  0.100023  0.101258  0.000318\nMap     100.327  0.100327  0.100028  0.101238  0.000324\nDo-Map  0.003  3.*10^-6\n\nThe results are as expected, there is no longer a consistent difference between the Do an Map implementations.\nIncorrect Micro Benchmarking Method\nSo why are were my two implementations of micro benchmarking above incorrect? I wanted to capture timing values for each call of the code being tested over a large number of iterations so that I could perform various analytics on them (sum, mean, min, max, std dev, plotting, histogram, ...). \nI thought AbsoluteTiming was incredibly precise.  When I evaluated the simple expression 1, AbsoluteTiming[1] returned {0.000014, 1}.  0.000014 is way more precise than $TimeUnit on my system which was 0.01 right?  Wrong!\nLets look at two different ways of micro benching marking the expression 1 for 1000000 iterations. But first, lets establish a base case to help us understand the results.\n\nBase Case\niterations = 1000000;\noneTime = AbsoluteTiming[1][[1]];\nexpectation = oneTime*iterations;\n\nPrint[\"oneTime: \", oneTime, \"   expectation for \", iterations, \": \", expectation];\n\nResults:\noneTime: 0.000014   expectation for 1000000: 14.\n\n\nCollection of Individual AbsoluteTiming Values\nindividualTimes = Map[AbsoluteTiming[1][[1]] &, Range[1, iterations]];\n\nPrint[\"Total: \", Total[individualTimes], \"  Min: \", \n Min[individualTimes], \"  Max: \", Max[individualTimes], \"  Mean: \", \n Mean[individualTimes], \"  StdDev: \", \n StandardDeviation[individualTimes]];\n\nResults:\nTotal: 2.26236  Min: 0.  Max: 0.000167  Mean: 2.26236*10^-6  StdDev: 6.79631*10^-7\n\nFirst thing we notice is that the Total(2.26236) is less than our expectation(14.) .  Why the difference?  Well first look at the Min(0.) and Max(0.000167), they are out side our oneTime(0.000014), which is good.  If there are a significant number of individual times less than our oneTime value, that could explain the difference. It just so happened that Length[Select[individualTimes, # < oneTime & ]] returned 999939 .  \nAnyone know how Min can be 0. ? Is it because the expression was cached? If it was cached, it still would have taken some time.  Maybe the time it took is less than what AbsoluteTiming can observe, hmmmm.\n\nOne AbsoluteTiming Value for All Iterations\ntotalTime = AbsoluteTiming[Do [1, {iterations}]][[1]];\n\nPrint[\"totalTime: \", totalTime];\n\nResults:\ntotalTime: 0.015782\n\nWoe wait a minute, the totalTime(0.015782) is no where close to the Total of the individualTimes(2.26236) not to mention our expectation(14.)!  I must have messed something up. Okay let me think about this, could it be AbsoluteTime is not as precise as I originally thought? Ding ding, ding, give that man a cigar! \nAs the chaps at Wolfram said it here.  AbsoluteTiming does not have the precision past $TimeUnit. So the oneTime and all of the individually collected timing values were prone to error as a result of the resolution of the timer of the system.  Thanks again Szabolcs!\nThe the one timing value for all iterations also has the same error, but only since it is only called one time for 1000000 iterations and is less than $TimeUnit (0.01) it has a much smaller effect.  \nOkay, yeah I know, I should rerun the One AbsoluteTiming Value for All Iterations with iterations = 1000000000 to get a more accurate value. totalTime: 12.440098 which makes making one call to 1 take 1.2440098*10^-8 seconds, which is a much much much smaller number than $TimeUnit.  Poor AbsoluteTiming, it never stood a chance. ;)\n", "overriding the format of 'copy-as' latex?": "\nI don't know of a way to do this automatically on Copy as LaTeX.  I also do not know enough about LaTeX to know the right way to make changes.\nI should point out that vecX no longer appears in the output of Abs[vecX - vecX'] // TraditionalForm therefore you must base your output on boldVector[x] and not vecX, unless you want to work with a held expression, which I imagine you do not.\nThe best I can recommend is using your own convert-to-LaTeX function something like this:\nmyTeX =\n StringReplace[\n   ToString @ TeXForm[# /. boldVector -> bvTeX], \n   \"text{bvTeX}\" :> \"EXAMPLE\"\n ] &;\n\nAbs[vecX - vecX'] // myTeX\n\n\n\\left|\\EXAMPLE(x)-\\EXAMPLE(x)'\\right|\n\n\nI am sure this is gibberish.  I simply want to show how this may be approached.\n", "plotting - Creating overlapping histogram plots": "\nFirst method\nYou could make the one in front partially transparent:\nbc = RandomVariate[NormalDistribution[], 1000];\nbcx = RandomVariate[NormalDistribution[], 1000];\n\ng1 = Histogram[bc, ChartStyle -> {Red}];\ng2 = Histogram[bcx, ChartStyle -> {Directive[Blue, Opacity[.5]]}];\nShow[g1, g2, PlotRange -> All]\n\n\nDirect method\nThe same effect can be achieved by plotting the two distributions in the same plot directly:\nHistogram[{bc, bcx}, ChartStyle -> {Red, Blue}]\n\n", "programming - Brackets in output make unable to use output to identify matrix element": "\nAs far as I understand the question, the main issue is how to swap 2 elements in an array. This can be done using ReplacePart. Consider for example\narray = Partition[Range[10], 5]\n\n\n{{1, 2, 3, 4, 5}, {6, 7, 8, 9, 10}}\n\n\nand suppose you want to swap the elements at positions \npos1 = {1, 4};\npos2 = {2, 3};\n\nthen you could do something like\nReplacePart[array, Thread[{pos1, pos2} -> Extract[array, {pos2, pos1}]]]\n\n\n{{1, 2, 3, 8, 5}, {6, 7, 4, 9, 10}}\n\n\n\nAs for generating the permuted matrix, instead of using For loops you could consider a more functional approach. You could for example do something like this:\nSi = {{-1, -1, -1}, {1, -1, -1}, {-1, 1, -1}};\nii = 3; \njj = 3;\n\nswap[array_, pos1_, pos2_] := \n ReplacePart[array, \n  Thread[{pos1, pos2} -> Extract[array, {pos2, pos1}]]]\n\nchoice[{i_, j_}] := \n RandomChoice[{{i, Mod[j - 1, ii, 1]}, {Mod[i - 1, ii, 1], j}, {i, \n    Mod[j + 1, ii, 1]}, {Mod[i - 1, ii, 1], j}}]\n\nnewArray = Fold[swap[#1, #2, choice[#2]] &, Si, \n  Tuples[{Range[ii], Range[jj]}]]\n\nHere, swap is a function that will swap the elements in array at positions pos1 and pos2. The function choice chooses an arbitrary neighbouring position of position {i,j}. Finally, Fold is used to apply swap to all elements of Si and the resulting matrix is assigned to newarray. If you want to save all the intermediate results, you can replace Fold with FoldList. \n", "equation solving - Mathematica Can't Evaluate This?": "\nNo, Log is the name of the function and Log[x] is the function applied to x.  Using Log without the argument is accepted by the system because Log is a symbol just like any other, but it does not make any sense.\n\nThe correct way to write it is\nSolve[Log[x]/x^2 == y, x]\n\nor\nReduce[Log[x]/x^2 == y, x]\n\nThe latter tries to give you full solution information, while the former's result may only be valid for certain values of x and y (see below).  The differences are explained in this guide.\nThe first result you get from Solve is correct for some real values of y as you can check by numerical evaluation:\nx /. Solve[Log[x]/x^2 == y, x]\n\n(*\n==> {-(I Sqrt[ProductLog[-2 y]])/(Sqrt[2] Sqrt[y]), \n      (I Sqrt[ProductLog[-2 y]])/(Sqrt[2] Sqrt[y])}\n*)\n\n% /. y -> 0.05\n\n(* ==> {1.05751 + 0. I, -1.05751 + 0. I} *)\n\nLog[x]/x^2 /. x -> %[[1]]\n\n(* ==> 0.05 + 0. I *)\n\nThe second result is not correct for y == 0.05 but it is correct for other values such as y == 1.0 I for which the first result is incorrect.\nMathematica generally assumes that all variables are complex and tried to solve for the this general case.  While the expression does contain an explicit I, it will evaluate to a real value for some real x.\nReduce will try to generate conditions under which the solutions are valid.  We can also specify that we are interested in only positive real values of x:\nReduce[Log[x]/x^2 == y && x > 0, x]\n\n(*\n==> (y == 0 && x == 1) || (y < 0 && \n   x == E^(-(1/2) ProductLog[-2 y])) || (0 < y <= 1/(\n    2 E) && (x == E^(-(1/2) ProductLog[-1, -2 y]) || \n     x == E^(-(1/2) ProductLog[-2 y])))\n*)\n\n\nNote though that this function has no inverse even for $x \\in (0, \\infty)$:\nPlot[Log[x]/x^2, {x, 0, 10}]\n\n\n", "plotting - Gridlines of a framed plot with a background cannot be white?": "\nSlightly hackish, but you could use Epilog to get the curve on top of the grid, e.g.\npl = Plot[Sin[x], {x, 0, 2 Pi}][[1]];\n\nPlot[ Sin[x], {x, 0, 2 Pi}, \n PlotStyle -> None, Frame -> True,\n Method -> {\"GridLinesInFront\" -> True}, \n GridLines -> Automatic, \n GridLinesStyle -> Directive[AbsoluteThickness[2], White],\n Prolog -> {{LightGray, Opacity[0.5], Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}},\n Epilog -> pl]\n\n\nEdit\nFollowing Mr.Wizard's and Szabolcs' suggestions, an more elegant solution would be:\nplot = Plot[Sin[x], {x, 0, 2 Pi}, \n    Frame -> True, GridLines -> Automatic,\n    GridLinesStyle -> Directive[AbsoluteThickness[2], White]];\n\nGraphics[{}, Method -> {\"GridLinesInFront\" -> True},\n Epilog -> plot[[1]], \n Prolog -> {{LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}}, \n Sequence @@ Options[plot]]\n\nThis has the advantage that the plot is only generated once. It should work for any plot that doesn't have any Prolog's or Epilog's of itself.\nYou can even build it into a nice custom function:\nmyPlot[x_, range_List, opts : OptionsPattern[]] := \n With[{plot = \n    Plot[x, range, Frame -> True, GridLines -> Automatic, \n     GridLinesStyle -> Directive[AbsoluteThickness[2], White], \n     opts]},\n  Graphics[{}, Method -> {\"GridLinesInFront\" -> True}, \n   Epilog -> plot[[1]], \n   Prolog -> {{LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}},\n    Sequence @@ Options[plot] ] ]\n\nmyPlot[Cos[x], {x, 0, 2 Pi}, PlotStyle -> Red]\n\n\nOr an extended version:\nmyPlot[x_, type_, range_List, opts : OptionsPattern[]] := \n With[{plot = \n    Switch[type, Plot, \n     type[x, range, Frame -> True, GridLines -> Automatic, \n      GridLinesStyle -> Directive[AbsoluteThickness[2], White], \n      opts],\n     ParametricPlot, \n     type[x, range, Frame -> True, GridLines -> Automatic, \n      GridLinesStyle -> Directive[AbsoluteThickness[2], White], \n      opts],\n     ListPlot, \n     type[x, PlotRange -> range, Frame -> True, \n      GridLines -> Automatic, \n      GridLinesStyle -> Directive[AbsoluteThickness[2], White], \n      opts],\n     ListLinePlot, \n     type[x, PlotRange -> range, Frame -> True, \n      GridLines -> Automatic, \n      GridLinesStyle -> Directive[AbsoluteThickness[2], White], opts]\n     ]},\n  Graphics[{}, Method -> {\"GridLinesInFront\" -> True}, \n   Epilog -> plot[[1]], \n   Prolog -> {{LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}},\n    Sequence @@ Options[plot] ] ]\n\nmyPlot[RandomVariate[NormalDistribution[], \n  100], ListLinePlot, {Automatic, Full}, PlotStyle -> Red]\n\n\n", "evaluation - Why does ++++x return an increment of 2 when the value of x is only incremented by 1?": "\nTracePrint will show you what happens:\nPreIncrement takes it's argument x, evaluates it (let's call the result result), then evaluates x = result+1.  Note that PreIncrement has HoldFirst.\nNow ++(++x) evaluates ++x first yielding 2, then evaluates (++x) = 2+1 resulting in an error (trying to assign to PreIncrement) and returning 3.\nThis also explains why adding yet another layer of PreIncrement will increment the result again.\n\n\n\nHere's a self-implemented ++ to make the above more clear.  The behaviour is exactly the same:\n\n", "list manipulation - Simplifying nested If statements": "\nIn contrast to the very fast methods presented, let me give you a maybe more easy to understand solution (while this in the eye of the beholder). Basically it's sort of the way I would implement it in Haskell. \nAssume you want to solve your problem step by step and in each step you have your data in the form {res, in} where res is your current solution and in is the rest of the input which needs to be processed. The initial situation is that the list res contains your first element and in contains the rest of the input. Let's go through the two possible situations:\n\nSince res is your current output, you always want to compare the last element of this with the first element of your in list. When the absolute difference is larger then 5, you want to append this first element of in to your res list.\nIn all other cases, you just want to throw away the first element of in and leave res untouched.\n\nYou want to iterate this as long as there are elements in your input. Thats all, and you can write it directly down:\nstep[{res_, in_}] := {Append[res, First[in]], Rest[in]} /; \n  Abs[Last[res] - First[in]] > 5;\n\nstep[{res_, in_}] := {res, Rest[in]};\n\nNestWhile[step, {{100}, {102, 103, 99, 106, 107, 104, 112}}, \n Length[Last[#]] > 0 &]\n\n(* {{100, 106, 112}, {}} *)\n\nYou see that after your input list is empty, you have collected your result.\n", "fitting - Problem with NonlinearModelFit": "\nI have mentioned this in a comment already, but this seems like a good opportunity to provide some related discussion in the form of a full-fledged answer.\nIn Mathematica 8, we can take advantage of NMinimize to fit this data, using the Method -> NMinimize option of NonlinearModelFit. (This should also have worked in Mathematica 7, but unfortunately NMinimize was not recognised as a valid Method setting until version 8 due to a bug.) In particular, Storn-Price differential evolution, available to NonlinearModelFit using the option\nMethod -> {NMinimize, Method -> \"DifferentialEvolution\"}\n\nhas a lot to offer in this case, especially if you know a bit about how differential evolution works. This algorithm, as implemented in Mathematica, is documented at tutorial/ConstrainedOptimizationGlobalNumerical#24713453.\nFrom the documentation, we see that the scaling factor $s$ (called $F$ by Storn and Price in their publication on the method and usually elsewhere) acts as an amplification factor on the scale of the global search. Thus, a large value of $s$ encourages more expansive searching of the parameter space, while small values encourage more intense exploration around local minima. Classically, $s$ can take values between 0 and 2, although Mathematica doesn't enforce this restriction. In practice one finds that values larger than unity cause an extreme expansion of the parameter space under search, which may be counterproductive. A \"large\" value of $s$, then, is something close to 1, and this is what we need in the current case since we may suspect that the initial values chosen for the parameters might be rather far from the global optimum, and do not want to risk falling into some local minimum along the way.\nThe behaviour of differential evolution with respect to crossover probability, $\\rho$ (which, as pointed out by Daniel Lichtblau, is equal to Storn and Price's $1 - CR$), is also very important. Noting that two of the parameters, w and xc, are strongly correlated, and knowing that in such cases vigorous mutation is usually the most effective strategy, we might also consider setting $CR \\approx 1$, i.e. $\\rho \\approx 0$. While the default value of $\\rho = 0.5$ does work for this example, if more sine functions are introduced into the model, reducing $\\rho$ will be practically mandatory.\nPlenty of discussion (indeed, an extensive literature) on tuning the differential evolution parameters, including the (usually) less critical population size parameter, $m$ (a.k.a. $NP$), can be found elsewhere, if necessary. However, it's worth noting that the \"correct\" values may differ between Mathematica's implementation and others, especially for small populations, due to slight differences in the way that the three existing random points are chosen to produce new trial search points.\nSo, writing down our conclusions from the above, we have:\ndata = Import[\"dat.csv\"]; (* with thanks to @Szabolcs *)\n\nfit = NonlinearModelFit[\n  data,\n  y0 + A Sin[Pi (x - xc)/w],\n  {y0, xc, A, w}, x,\n  Method -> {NMinimize,\n    Method -> {\"DifferentialEvolution\",\n      \"ScalingFactor\" -> 0.9, \"CrossProbability\" -> 0.1,\n      \"PostProcess\" -> {FindMinimum, Method -> \"QuasiNewton\"}\n    }\n  }\n]\n\nWhere one should note the undocumented in this context, albeit rather obviously existent, Method option for FindMinimum as used by NMinimize as used by NonlinearModelFit (yes, that's right: we are setting a Method's Method's Method!). This serves to hone the parameter values produced by differential evolution given that the latter is, by design in this case, not as efficient for local optimization as other methods. Here \"QuasiNewton\" corresponds to the method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS), but \"LevenbergMarquardt\" could also have been used.\nThis gives us:\n\nOr, as a list of rules:\n{y0 -> 30.4578, xc -> 120.008, A -> 3.62443, w -> -752.712}\n\nThis a result consistent (up to the sign of w and the value of the phase factor xc) with that given by Origin. Was it achieved without effort (if this is considered important)? While this is inherently a subjective question, in my opinion, the answer is yes. No manually chosen initial values in sight!\nA plot of the resulting model also makes it clear that this is a reasonable outcome (although evidently one could do better with a more involved model):\n\n", "inverse - Changing variables algebraically": "\nTo visualize y[z] without having to go through inversion, you can use ParametricPlot:\n Manipulate[\n ParametricPlot[{y[x, a, b, c], z[x, a, r]}, {x, 0, 1}, \n AxesLabel -> {z, y}, AspectRatio -> 1, \n PlotRange -> {{-10, 10}, Automatic}], \n {{a, 1}, 0, 5, .1}, {{b, 1},  0, 5, .1}, {{c, 1}, 0, 5, .1}, \n Delimiter, {{r, 1}, .5, 2, .1}, \n ControlPlacement -> Left]\n\n\n", "combinatorics - How to apply a permutation to a symmetric square matrix?": "\nHow about:\nord = {1, 4, 5, 2, 3}\nmatrix[[ord, ord]]\n\n(You can convert any permutation (including Cycles) to an index list using PermutationList.)\n", "calculus and analysis - Inverting a function in a certain region": "\nSomething like this is helpful : \nInverseFunction[ConditionalExpression[#1^2, 2 > #1 > 0] &]\n\nyields\nConditionalExpression[Sqrt[#1], 0 <= #1 <= 4] &\n\nThen you can use it as an ordinary function, e.g. :\nIntegrate[%[x], {x, 1/2, 3/2}]\n\n\n1/6 (-Sqrt[2] + 3 Sqrt[6]) \n\n\nor\nD[ConditionalExpression[Sqrt[#1], 1/4 <= #1 <= 9/4] &[x], x]\n\n\nConditionalExpression[1/(2 Sqrt[x]), 1/4 <= x <= 9/4]\n\n\nPlot[ConditionalExpression[Sqrt[#1], 1/4 <= #1 <= 9/4] &[x],\n                         {x, 1/4, 9/4}, AxesOrigin -> {0, 0}]\n\n\n", "graphics - Multiple panel figure from combination of plots": "\nSince you give no example, I'm only guessing:\nip = {{30, 10}, {30, 50}};\na = ListContourPlot[\n   Table[Sin[i + j^2], {i, 0, 3, 0.1}, {j, 0, 3, 0.1}], \n   ImageSize -> 200, ImagePadding -> ip];\nb = ListContourPlot[\n   Table[{x = RandomReal[{-2, 2}], y = RandomReal[{-2, 2}], \n     Sin[x y]}, {1000}], \n   FrameLabel -> {\"abc\", \"def\", Style[\"BIG TEXT\", 30]}, \n   ImageSize -> 200, ImagePadding -> ip];\nc = ListContourPlot[RandomReal[1, {10, 10}], InterpolationOrder -> 3, \n   ImageSize -> 200, ImagePadding -> ip];\nGraphicsGrid[{{a, b, c}}, Spacings -> {-30, Automatic}]\n\n\nHere I played with:\n\nImagePadding -> to make padding around each plot independent of\ntheir legends and labels\nSpacings     -> to approach the plots to each other on the grid (see here)\n\nBut there are other ways of doing it. If you give an example, I can probably be more specific...\n", "plotting - How to create a histogram of annual events, such as cherry blossom time": "\nHere are two approaches.  \nWe'll create a second dataset by shifting the given data by two months:\nblossom = {{4, 3}, {4, 22}, {4, 15}, {4, 2}, {4, 18}, {4, 20}, {4, \n    12}, {3, 30}, {4, 4}, {4, 24}, {4, 26}, {3, 4}, {4, 26}, {4, \n    13}, {5, 1}, {4, 4}, {4, 8}, {4, 18}, {4, 9}, {4, 19}, {4, \n    10}, {4, 20}, {4, 3}, {4, 4}, {3, 21}, {4, 19}, {4, 15}, {4, \n    17}, {4, 9}, {4, 17}, {4, 9}, {4, 8}, {4, 23}, {4, 17}, {4, \n    1}, {4, 10}, {4, 15}, {4, 15}, {4, 11}, {4, 15}, {4, 19}, {4, \n    22}, {4, 11}, {4, 4}, {4, 12}, {3, 27}, {3, 24}, {4, 26}, {3, \n    28}, {4, 16}};\nripen = TranslationTransform[{2, 0}][blossom];    \n\n\nThe first method converts the {month, day} into the number of the day in the year (1 for January 1st, 32 for February 1st, etc...) and creates a histogram from that.\nDayOfYear[{m_, d_}] := \n First[DateDifference[{2011, 12, 31}, {2012, m, d}, \"Day\"]]\n\n{DayOfYear[{1, 1}], DayOfYear[{2, 1}], DayOfYear[{3, 1}]}\n\n\n{1, 32, 61}\n\n\nHistogram[{DayOfYear /@ blossom, DayOfYear /@ ripen}, 20]\n\n\n\n\n\nThe second approach is more involved.  We convert the {month, day} values into absolute times, and then use HistogramList on the combined datasets to get bins and counts without yet constructing the graphic.  We then create a corresponding DateListPlot of the data, for the sole purpose of  getting access to how it creates date axes.  Finally we combine the ticks from the DateListPlot with an actual Histogram, reusing the bins but recalculating the bins for the different datasets, to get the final graphic.\nMonthDayToTime[{m_, d_}] := AbsoluteTime[{2012, m, d}]\n\nblossomtimes = MonthDayToTime /@ blossom;\nripentimes = MonthDayToTime /@ ripen;\n\n{bins, counts} = HistogramList[Join[blossomtimes, ripentimes], 20]\n\npoints = Transpose[{Riffle[bins, bins], ArrayPad[Riffle[counts, counts], 1]}];\ndateplot = DateListPlot[points, Frame -> False, Axes -> True, Joined -> True]\n\nShow[Histogram[{blossomtimes, ripentimes}, {bins}], Options[dateplot, Ticks]]\n\n\n\n\n", "graphics - How to create word clouds?": "\nHere's what I came up with\n\nHow I did it\nFirst we need a list of words. Here, I've taken the original list ordered by size.\ntally = Tally@\n   Cases[StringSplit[ExampleData[{\"Text\", \"AliceInWonderland\"}], \n     Except@LetterCharacter], _?(StringLength@# > 4 \\[And] # =!= \n         \"Alice\" &)];\ntally = Cases[tally, _?(Last@# > 10 &)];\ntally = Reverse@SortBy[tally, Last];\nrange = {Min@(Last /@ tally), Max@(Last /@ tally)};\n\nwords = Style[First@#, FontFamily -> \"Cracked\", FontWeight -> Bold, \n     FontColor -> \n      Hue[RandomReal[], RandomReal[{.5, 1}], RandomReal[{.5, 1}]], \n     FontSize -> Last@Rescale[#, range, {12, 70}]] & /@ tally;\n\nThe words are rasterised and cropped to make sure the bounding box is as tight as possible.\nwordsimg = ImageCrop[Image[Graphics[Text[#]]]] & /@ words;\n\nTo produce the image the words are added one by one using a Fold loop where the next word is placed as close to the centre of the existing image as possible. This is done by applying a max filter to the binarized version of the original image thus turning forbidden pixels white and looking for the black point that is closest to the centre of the image.\niteration[img1_, w_, fun_: (Norm[#1 - #2] &)] := \n Module[{imdil, centre, diff, dimw, padding, padded1, minpos},\n  dimw = ImageDimensions[w];\n  padded1 = ImagePad[img1, {dimw[[1]] {1, 1}, dimw[[2]] {1, 1}}, 1];\n  \n  imdil = MaxFilter[Binarize[ColorNegate[padded1], 0.01], \n    Reverse@Floor[dimw/2 + 2]];\n  centre = ImageDimensions[padded1]/2;\n  \n  minpos = Reverse@Nearest[Position[Reverse[ImageData[imdil]], 0], \n      Reverse[centre], DistanceFunction -> fun][[1]];\n  diff = ImageDimensions[imdil] - dimw;\n  padding[pos_] := Transpose[{#, diff - #} &@Round[pos - dimw/2]];\n  \n  ImagePad[#, (-Min[#] {1, 1 }) & /@ BorderDimensions[#]] &@\n   ImageMultiply[padded1, ImagePad[w, padding[minpos], 1]]]\n\nFold[iteration, wordsimg[[1]], Rest[wordsimg]]\n\nYou can play around with the distance function. For example for a distance function\nfun = Norm[{1, 1/2} (#2 - #1)] &\n\nyou get an ellipsoidal shape:\nFold[iteration[##, fun]&, wordsimg[[1]], Rest[wordsimg]]\n\n\n\nUpdated version\nThe previous code places new words in the image by approximating them with rectangles. This works fine for horizontally or vertically oriented words, but not so well for rotated words or more general shapes. Luckily, the code can be easily modified to deal with this by replacing the MaxFilter with a ImageCorrelate:\niteration2[img1_, w_, fun_: ( Norm[#1 - #2] &)] := \n Module[{imdil, centre, diff, dimw, padding, padded1, minpos}, \n  dimw = ImageDimensions[w];\n  padded1 = ImagePad[img1, {dimw[[1]] {1, 1}, dimw[[2]] {1, 1}}, 1];\n  imdil = Binarize[ImageCorrelate[Binarize[ColorNegate[padded1], 0.05], \n     Dilation[Binarize[ColorNegate[w], .05], 1]]];\n  centre = ImageDimensions[padded1]/2;\n  minpos = \n   Reverse@Nearest[Position[Reverse[ImageData[imdil]], 0], \n      Reverse[centre], DistanceFunction -> fun][[1]];\n  Sow[minpos - centre]; (* for creating vector plot *)\n  diff = ImageDimensions[imdil] - dimw;\n  padding[pos_] := Transpose[{#, diff - #} &@Round[pos - dimw/2]];\n  ImagePad[#, (-Min[#] {1, 1}) & /@ BorderDimensions[#]] &@\n   ImageMultiply[padded1, ImagePad[w, padding[minpos], 1]]]\n\nTo test this code we use a list of rotated words. Note that I'm using ImagePad instead of ImageCrop to crop the images. This is because ImageCrop seems to clip the words sometimes.\nwords = Style[First@#, FontFamily -> \"Times\", \n     FontColor -> \n      Hue[RandomReal[], RandomReal[{.5, 1}], RandomReal[{.5, 1}]], \n     FontSize -> (Last@Rescale[#, range, {12, 150}])] & /@ tally;\n\nwordsimg = ImagePad[#, -3 - \n  BorderDimensions[#]] & /@ (Image[\n   Graphics[Text[Framed[#, FrameMargins -> 2]]]] & /@ words);\n\nwordsimgRot = ImageRotate[#, RandomReal[2 Pi], \n  Background -> White] & /@ wordsimg;\n\nThe iteration loop is as before:\nFold[iteration2, wordsimgRot[[1]], Rest[wordsimgRot]]\n\nwhich produces\n\nSecond update\nTo create a vector graphics of the previous result, we need to save the positions of the words in the image, for example by adding Sow[minpos - centre] to the definition of iteration2 somewhere towards the end of the code and using Reap to reap the results. We also need to keep the rotation angles of the words, so we'll replace wordsimgRot with\nangles = RandomReal[2 Pi, Length[wordsimg]];\n\nwordsimgRot = ImageRotate[##, Background -> White] & @@@ \n   Transpose[{wordsimg, angles}];\n\nAs mentioned before, we use Reap to create the position list\nposlist = Reap[img = Fold[iteration2, wordsimgRot[[1]], \n  Rest[wordsimgRot]];][[2, 1]]\n\nThe vector graphics can then be created with\nGraphics[MapThread[Text[#1, Offset[#2, {0, 0}], {0, 0}, {Cos[#3], Sin[#3]}] &,\n  {words, Prepend[poslist, {0, 0}], angles}]]\n\n", "programming - Metaprogramming in Mathematica": "\nWhat this answer is and is not\nTo avoid some confusion and misunderstanding, let me state right away what is the intended status of this answer.\nThis answer is not\n\nA tutorial to the subject\nA systematic, or complete, introduction to the subject\nAn authoritative answer putting the final word on the subject\n\nThis answer hopefully is\n\nAn (subjective!) overview of various meta-programming techniques in Mathematica, in the way they are known to me. I want to explicitly state that I am not trying to convey any kind of the \"common wisdom\" here, since the answer is largely based on my own experiences, and I have not seen an overwhelming number of meta-programming examples in Mathematica-related resources I had a chance to get acquainted with (so I may have no idea what the common wisdom is :)).\nA collection of (hopefully relevant) links with some minimal explanations, which would allow the reader to see some examples and applications of metaprogramming in Mathematica, or at least examples of what I consider meta-programming in Mathematica.\nA possible stub for some future answers, so that this larger one could be eventually rewritten and/or split into more focused and narrow ones, as the interest towards some particular forms of metaprogramming in Mathematica is being developed in our community.\n\nPreamble\nOk, let me give it a shot. I'll start by claiming that Mathematica is very well suited for meta-programming, and one can write much more powerful programs in Mathematica by utilizing it. However, while it allows for very interesting and powerful meta-programming techniques, it does not IMO provide a convenient layer of tools to make these techniques more standard and effortless. Particularly painful is the evaluation control (preventing pieces of code from premature evaluation), because of the absence of the true quotation mechanism (here I will disagree with some other answers), the infinite evaluation model of Mathematica, and a quite complex core evaluator.\nEnumerating some meta-programming techniques\nThere are several forms of meta-programming, so let me give a partial list first, and discuss afterwards\n\nIntrospection-based metaprogramming\nReflection-based metaprogramming (like in say, Java)\nRun-time code generation\nMacros (like in Lisp)\nDSL (domain-specific-language) creation\n...?\n\nIn addition to these, Mathematica has its own meta-programming devices, such as rule-based metaprogramming and the Block-related techniques.\nIntrospection\nMathematica is IMO very strong here. There are a couple of reasons for this:\n\nHomoiconic language (programs written in own data structures - Mathematica expressions. This is code-as-data paradigm, like Lisp which uses lists for this)\n\nOne can access global definitions for symbols stored in OwnValues, DownValues, SubValues, UpVaulues, etc, and various other global properties, programmatically.\n\nRule-based destructuring techniques (using Cases etc) seriously simplify many introspection-related operations\n\nMathematica code is \"over-transparent\" - even pure functions are expressions, available to introspection and destructuring, rather than black boxes. This has its downsides (for example, making a functional abstraction leaky in Mathematica, see the end of this answer), but it also allows for things like withGlobalFunctions macro from this answer, where global function definitions are expanded inside pure functions (that macro also illustrates other meta-programming techniques).\n\n\nAutomatic dependency tracking\nI will give a single simple explicit example of what I mean by introspection here, and supply some references to more involved cases. The following line of code gives all the symbols used to build a given expression expr, kept unevaluated:\nCases[Unevaluated[expr],s_Symbol:>HoldComplete[s],{0,Infinity},Heads->True]\n\nNote that this will work for any Mathematica expression, including a piece of (perhaps unevaluated) Mathematica code.\nA good illustration of introspection-based meta-programming is the symbol dependency analysis. I gave it a shot here, where I fully used all of the above-mentioned features (homoiconic language,  low-level access to symbol's properties, rule-based destructuring). A simpler but practical application of dependency analysis can be found e.g. in the getDependencies function from this answer, where I do use the dependencies to dynamically construct a set of symbols which are encapsulated (not easily available on the top-level) but whose definitions must be saved during the serialization of the list object being constructed.\nWorking around some language limitations\nSometimes, introspection-based metaprogramming can be also used to go around certain limitations of the language, or to make the language constructs behave in the way you want while minimally affecting them. Some examples off the top of my head: changing the default behavior of SaveDefinitions option for Manipulate,  making patterns to match only children of certain elements, and also two functions from this answer: a function casesShielded which implements a version of Cases that shields certain sub-expressions (matching specific pattern) from the pattern-matcher. and a (rather hacky) function myCases which implements a modified depth-first search, where the head is inspected before the elements (this is not what is happening in standard Cases, which sometimes has unwanted consequences). Yet another example here is the tiny framework I wrote to deal with the leaks of standard lexical scoping mechanism in Mathematica, which can be found here.\nSummary\nTo conclude this section, I think that introspection-based meta-programming is a very useful and powerful technique in Mathematica, and the one that is relatively easy to implement without engaging in a fight with the system. I am also positive that it is possible to factor out the most useful introspection primitives and have a higher-level introspection-based metaprogramming library, and hope such a library will emerge soon.\nReflection - based metaprogramming\nThis may probably be considered a subset of the introspection-based metaprogramming, but it is particularly powerful for languages which impose more rigid rules on how code is written, particularly OO languages (Java for example). This uniform and rigid structure (e.g. all code is in classes, etc) allows for automatic querying of, for example, the methods called on the object, etc. Mathematica per se is not particularly powerful  here, because \"too many ways of doing things\" are allowed for this to be effective, but one can surely write frameworks and / or DSLs in Mathematica which would benefit from this meta-programming style.\nRun-time code generation\nThis type of meta-programming can be used relatively easily and brings a lot to the table in Mathematica.\nAutomation and adding convenient syntax\nI will give a small example from this answer, where an ability to generate a pure function (closure) at run-time allows us to easily define a version of SQL select with a more friendly Mathematica syntax, and based on the in-memory Mathematica representation of an SQL table as a nested list:\nClearAll[select, where];\nSetAttributes[where, HoldAll];\nselect[table : {colNames_List, rows__List}, where[condition_]] :=\n  With[{selF = Apply[Function, Hold[condition] /.\n      Dispatch[Thread[colNames -> Thread[Slot[Range[Length[colNames]]]]]]]},\n  Select[{rows}, selF @@ # &]];\n\nPlease see the aforementioned answer for examples of use. Further developments of these ideas (also based on meta-programming) can be found in this and this discussions.\nMaking JIT-compiled functions, and using Compile in more flexible ways\nAn important class of applications of run-time code-generation is in improving the flexibility of Compile. A simple example would be to create a JIT-compiled version of Select, which would compile Select with a custom predicate:\nClearAll[selectJIT];\nselectJIT[pred_, listType_] :=\n  selectJIT[pred, Verbatim[listType]] = \n    Block[{lst},\n     With[{decl = {Prepend[listType, lst]}},\n      Compile @@ \n       Hold[decl, Select[lst, pred], CompilationTarget -> \"C\", \n          RuntimeOptions -> \"Speed\"]]];\n\nThis function actually illustrates several techniques, but let me first show how it is used:\ntest = RandomInteger[{-25, 25}, {10^6, 2}];\nselectJIT[#[[2]] > 0 &, {_Integer, 2}][test] // Short // AbsoluteTiming \nselectJIT[#[[2]] > 0 &, {_Integer, 2}][test] // Short // AbsoluteTiming\n\n(*\n\n ==> {0.4707032,{{-6,9},{-5,23},{-4,4},{13,3},{-5,7},{19,22},<<489909>>,{11,25},{-6,5},\n          {-24,1},{-25,18},{9,19},{13,24}}}\n\n ==> {0.1250000,{{-6,9},{-5,23},{-4,4},{13,3},{-5,7},{19,22},<<489909>>,{11,25},{-6,5},\n          {-24,1},{-25,18},{9,19},{13,24}}}\n*)\n\nThe second time it was several times faster because the compiled function was memoized. But even including the compilation time, it beats the standard Select here:\nSelect[test,#[[2]]>0&]//Short//AbsoluteTiming\n\n(*\n  ==> {1.6269531,{{-6,9},{-5,23},{-4,4},{13,3},{-5,7},{19,22},<<489909>>,{11,25},{-6,5},\n    {-24,1},{-25,18},{9,19},{13,24}}}\n*)\n\nThe other techniques illustrated here are the use of constructs like Compile@@Hold[...] to fool the variable-renaming scheme (see e.g. this answer for a detailed explanation), and the use of With and replacement rules (pattern-based definitions) as a code-injecting device (this technique is used very commonly). Another example of a very similar nature is here, and yet another, very elegant example is here.\nCustom assignment operators and automatic generation of function's definitions\nAnother class of run-time code-generation techniques (which is somewhat closer to macros in spirit) is to use custom assignment operators, so that you can generate rather complex or large (possibly boilerplate) code from relatively simple specifications. Applications range from relatively simple cases of adding some convenience/ syntactic sugar, such as e.g. here (where we define a custom assignment operator to allow us to use option names directly in code), to somewhat more complex cases like making replacements in definitions at the definition-time, as say in the function lex from this answer (see also the code for a LetL macro below), to quite sophisticated generation of boilerplate code, happening e.g. in JLink behind the scenes (which, for JLink, is a big deal, because this (plus of course the great design of JLink and Java reflection) is the reason why JLink is so much easier to use than Mathlink).\nAutomating error-handling and generating boilerplate code\nYet another use for run-time code generation (similar to the previous) is to automate error-handling. I discussed one approach to that here, but it does not have to stop there - one can go much further in factoring out (and auto-generating) the boilerplate code from the essential code.\nA digression: one general problem with various meta-programming techniques in Mathematica\nThe problem with this and previous classes of use cases however is the lack of composition: you can not generally define  several custom assignment operators and be sure that they will always work correctly in combinations. To do this, one has to write a framework, which would handle composition. While this is possible to do, the development effort can rarely be justified for simple projects. Having a general library for this would be great, provided that this is at all possible. In fact, I will argue that the lack of composibility (\"out of the box\") is  plaguing many potentially great meta-programming techniques in Mathematica, particularly macros.\nNote that I don't consider this being a fundamental core language-level problem, since the relevant libraries / frameworks can surely be written. I view it more as a consequence of the extreme generality of Mathematica and it being in a transition from a niche scientific language to a general-purpose one (in terms of its typical uses, not just capabilities), so I am sure this problem has a solution and will eventually be solved.\nProper (macro-like) run-time generation of Mathematica code\nA final use case for the run-time code generation I want to mention is, well, run-time Mathematica code generation. This is also similar to macros (as they are understood in Lisp) in spirit, in fact probably the closest to them from all techniques I am describing here. One relatively simple example I discuss here, and a similar approach is described here. A more complex case involving generation of entire packages I used for the real-time cell-based code highlighter described here. There are also more sophisticated techniques of run-time Mathematica code generation - one of which (in a very oversimplified form) I described here\nSummary\nTo summarize this section, I view run-time code generation as another meta-programming technique which is absolutely central to make non-trivial things with Mathematica.\nMacros\nFirst, what I mean by macros is probably not what is commonly understood by macros in other languages. Specifically, by macro in Mathematica I will mean a construct which:\n\nManipulates pieces of Mathematica code as data, possibly preventing them from (premature) evaluation\nExpands code at run-time (not \"read-time\" or \"compile-time\", which are not so well defined in Mathematica)\n\nSome simple examples\nHere is the simplest macro I know of, which allows one to avoid introducing an intermediate variable in cases when something must be done after the result has been obtained:\nSetAttributes[withCodeAfter,HoldRest];\nwithCodeAfter[before_,after_]:=(after;before)\n\nThe point here is that the argument before is computed before being passed in the body of withCodeAfter, therefore evaluating to  the result we want, while the code after is being passed unevaluated (due to the HoldRest attribute), and so is evaluated already inside the body of withCodeAfter. Nevertheless, the returned result is the value of before, since it stands at the end.\nEven though the above macro is very simple, it illustrates the power of macros, since this kind of code manipulation requires special support from the language and is not present in many languages.\nTools used for writing macros\nThe main tools used for writing macros are tools of evaluation control, such as\n\nHold*- attributes,\nEvaluate and Unevaluated\ncode injection using With and / or replacement rules\nPure functions with Hold - attributes\n\nEven in the simple example above, 2 of these tools were used (Hold-attribute and replacement rules, the latter hidden a bit by using global replacement rules / definitions). The discussion of the evaluation control constructs proper is outside the scope of the present discussion but a few places you can look at are here and here\nTypical classes of macros\nMacros can widely range in their purpose. Here are some typical classes\n\nMaking new scoping constructs or environments (very typical use case)\nUsed in combination with run-time code generation to inject some unevaluated code\nUsed in combination with some dynamic scoping, to execute code in some environments where certain global rules are modified. In this case, the \"macro\" - part is used to delay the evaluation until the code finds itself in a new environment, so strictly speaking these are rather custom dynamic scoping constructs.\n\nExamples of new scoping constructs / environments\nThere are plenty of examples of the first type of macros available in the posts on StackOverlflow and here. One of my favorite macros, which I will reproduce here, is the LetL macro which allows consecutive bindings for With scoping construct:\nClearAll[LetL];\nSetAttributes[LetL, HoldAll];\nLetL /: Verbatim[SetDelayed][lhs_, rhs : HoldPattern[LetL[{__}, _]]] :=\n   Block[{With}, Attributes[With] = {HoldAll};\n     lhs := Evaluate[rhs]];\nLetL[{}, expr_] := expr;\nLetL[{head_}, expr_] := With[{head}, expr];\nLetL[{head_, tail__}, expr_] := \n  Block[{With}, Attributes[With] = {HoldAll};\n    With[{head}, Evaluate[LetL[{tail}, expr]]]];\n\nWhat it does is to expand a single declaration like LetL[{a=1,b=a+1,c = a+b},a+b+c] into a nested With at run-time, and it also works for function definitions. I described in more fully here (where some subtleties associated with it are also described), and used it extensively e.g. here. A very similar example can be found in this answer. Yet another example I already mentioned - it is the macro withGlobalFunctions from this answer, which expands all generically-defined (via patterns) global functions. The last example I want to include here (although it also is relevant for the third use case) is a macro for performing a code cleanup, discussed here, and I particularly like the version by @WReach, which I will reproduce here:\nSetAttributes[CleanUp, HoldAll]\nCleanUp[expr_, cleanup_] :=\n  Module[{exprFn, result, abort = False, rethrow = True, seq}, \n    exprFn[] := expr;\n    result = \n      CheckAbort[\n         Catch[Catch[result = exprFn[]; rethrow = False; result], _, \n           seq[##] &], abort = True];\n    cleanup;\n    If[abort, Abort[]];\n    If[rethrow, Throw[result /. seq -> Sequence]];\n    result]\n\nIt is not fully \"bullet-proof\", but does a really good job in the majority of cases.\nExamples of run-time code generation / new functionality\nActually, many of the above examples also qualify here. I'll add just one more here (in two variations): the abortable table from this answer (I will reproduce the final version here):\nClearAll[abortableTableAlt];\nSetAttributes[abortableTableAlt, HoldAll];\nabortableTableAlt[expr_, iter : {_Symbol, __} ..] :=\n  Module[{indices, indexedRes, sowTag, depth =  Length[Hold[iter]] - 1},\n   Hold[iter] /. {sym_Symbol, __} :> sym /. Hold[syms__] :> (indices := {syms});\n   indexedRes =  Replace[#, {x_} :> x] &@ Last@Reap[\n      CheckAbort[Do[Sow[{expr, indices}, sowTag], iter], Null],sowTag];\n   AbortProtect[\n      SplitBy[indexedRes, Array[Function[x, #[[2, x]] &], {depth}]][[##,1]] & @@ \n      Table[All, {depth + 1}]\n   ]];\n\n(it accepts the same syntax as Table, including the multidimensional case, but returns the partial list of accumulated results in the case of Abort[] -  see examples of use in the mentioned answer), and its version for a conditional Table, which only adds an element is certain condition is fulfilled - it is described here.  There are of course many other examples in this category.\nExamples of dynamic environments\nDynamic environments can be very useful when you want to modify certain global variables or, which is much less trivial, functions, for a particular piece of code, so that the rest of the system remains unaffected. The typical constructs used to achieve this are Block and Internal`InheritedBlock.\nThe simplest and most familiar dynamic environment is obtained by changing the values of $RecursionLimit and / or $IterationLimit inside a Block. Some examples of use for these are in my answer in the discussion of tail call optimization in Mathematica. For a more complex example, see my suggestion for the recent question on convenient string manipulation. Some more examples can be found in my answer to this question. An example of application of this to profiling can be found here.\nAgain, there are many more examples, many of which I probably missed here.\nProblems with writing macros in Mathematica\nTo my mind, the main problems with writing  and using macros consistently in Mathematica are these:\n\nHard to control evaluation. No real quotation mechanism (Hold and HoldComplete don't count because they create extra wrappers, and Unevaluated does not count since it is not permanent ans is stripped during the evaluation)\nMacros as described above are expanded from outside to inside. Coupled with the lack of real quotation mechanism, this leads to the absence of true macro composition out of the box. This composition can be achieved, but with some efforts\nThe lack of the real compilation stage (The definition-time does not fully count since most definitions are delayed).\n\nTo circumvent these issues, one has to apply various techniques, such as\n\nTrott - Strzebonski in-place evaluation technique to evaluate parts of held expressions in-place (see also this answer for some more details on that)\nA technique which I call (for the lack of a better name) \"inverse rule-dressing\", which exploits the properties of delayed rule substitution (delayed, plus intrusive), to inject some unevaluated code. I used it in the first solution in this answer, in more complex way in the SavePointers function in this answer, and in a number of other cases. It has also been used very elegantly  in this answer.\nusing a custom Hold-like wrapper which is first mapped on (possibly all) parts of an expression, and later removed using rules. Two examples of this techniques are here and here\n...\n\nDespite all these techniques being useful, and in total covering most of the needs for macro-writing, the need to use them (often in combinations) and the resulting code complexity shows, to my mind, the serious need for a generic library which would provide simpler means for macro-writing. I would prefer to be able to nest macros and not think about zillion of things that may go wrong because of some unwanted evaluation, but rather about things that really matter (such as variable captures).\nSummary\nMacros are another very powerful meta-programming technique. While it is possible to write them in Mathematica, it is, as of now, a rather involved undertaking, and composing macros is an even harder task. Because composition in the key, I attribute the fact that macros are not in widespread use in Mathematica programming, to this lack of composition, plus the complexity of writing individual macros. That said, I think this is a very promising direction, and hope that some time soon we will have the tools which would make writing macros a more simple and automatic process.\nDSL creation\nI won't say almost anything here, except noting that this is entirely possible in Mathematica, and some nice syntax can be added easily via UpValues.\nFinal remarks\nI think that meta-programming is one of the most important and promising directions in the present and future of Mathematica programming. It is also rather complex, and IMO, largely unexplored in Mathematica still. I hope that this justifies this post being so long.\nI tried to summarize various approaches to meta-programming in Mathematica, which I am aware of, and give references to examples of these approaches, so that the reader can look for him/herself. Since meta-programming is a complex topic, I did not attempt to write a tutorial, but rather tried  to summarize various experiences of myself and others to produce a kind of a reference.\nOne may notice that the references are dominated by the code I wrote. One reason for that is that I am a heavy user of meta-programming in Mathematica. Another reason is that everyone remembers own code the most. I have to apologize for not including some other references which did not come to my mind right away. I invite everyone to edit this post and add more references, which I missed.\n", "Reference request for neural network programming in Mathematica": "\nI've had an interest (as one can see in my other posts) in a wide range of distributed processing and parallel computing approaches and while not seen in any of my posts machine learning approaches as well.  I looked at neural networks some years ago, and while they didn't suit the problems I worked on at the time I remembered the article Duncan and Tweney wrote as useful. A couple of others might also prove useful.\nThree references follow:\nAI AND STATISTICAL APPLICATIONS\nMathematica: A flexible design environment for neural networks\nFrom the Journal:\nBehavior Research Methods, Instruments, & Computers 1997,29 (2). 194-199\nhttps://doi.org/10.3758/BF03204810\nFrom 1997, a few years more recent than Freeman's.\nFreely available as a pdf article:\n\nAbstract:\nSeveral neural networks were developed in Mathematica in order to\nexplore the role of \"spiky\" neurons in neural network memory\nsimulations. Using Mathematica for this task confirmed its value as a\npowerful tool for neural network development: It exhibited distinct\nadvantages over other environments in programming ease, flexibility\nof data structures, and the graphical assessment of network\nperformance.\n\nOne of its authors: Sean C. Duncan has moved from Bowling Green University to Miami University.  He has a website: https://se4n.org/\nIts other author: Ryan Tweney remains at Bowling Green University and has his own website: http://personal.bgsu.edu/~tweney/ (Update: Ryan Tweney passed away in 2020; an archived snapshot of his website is available in the Wayback Machine.)\nYou can find contact information for each of them on their respective websites.  I've always found academics generous with what they know.  The article or contacting them might lead you to better sources of information on this.\nMathematica Neural Networks package.\nYou can download the pdf of the manual for the Mathematica Neural Networks package.  Pretty extensive, indeed.\nThe Power of Neural Networks\nA review in which Brian Cogan briefly assesses NeuroSolutions from NeuroDimension, and Neural Networks, a Mathematica add-on, from Scientific Computing World March/April 2003\nhttp://www.neurosolutions.com/resources/scw.pdf\n", "programming - Very long Refine/Solve batch run": "\nI've found with some of my own code that putting in the simplifying equations INTO the solve function speeds things up (sometimes significantly, in the \"I don't know if this is going to finish\" -> seconds timeframe). That is, instead of writing:\nSolve[{EquationToSolve==0},{a,b,c}]//Simplify[#,a>0 && b<0 && c>=0]\n\nWrite\nSolve[{EquationToSolve==0, a>0, b<0, c>=0},{a,b,c}]\n\nI think this has something to do with Mathematica trying to simplify things immediately as it finds solutions, and since it can start simplifying early, the final answer turns out much faster. \nObviously this is not useful if you're looking for a general solution, but in many cases you can look at many more \"specific\" solutions in the same amount of time it would take you to solve for the general one. \n", "plotting - Mathematica envelope for the bottom of a plot, a generic function": "\nYou can also create a moving min (and max) and use BSplineCurve to render a smoothed curve.\nThese could be made more efficient. They find the min and max over a window.\nwindowMin[data_, w_][pt_] := {pt, \n  Min[Cases[data, {x_, y_} /; pt - w <= x <= pt + w][[All, 2]]]}\n\nwindowMax[data_, w_][pt_] := {pt, \n  Max[Cases[data, {x_, y_} /; pt - w <= x <= pt + w][[All, 2]]]}\n\nThis function plots the original data with the BSplineCurve envelope. The parameter w sets the window width.\nf[w_] := With[{data = Transpose[{xaxis, yaxis}]}, \n  Show[ListLinePlot[data, \n    PlotStyle -> Directive[{Blue, Opacity[.2]}]], \n   With[{pts = Table[windowMin[data, w][t], {t, 0, 10, w - w/10}]}, \n    Graphics[{Red, BSplineCurve[pts]}]], \n   With[{pts = Table[windowMax[data, w][t], {t, 0, 10, w - w/10}]}, \n    Graphics[{Red, BSplineCurve[pts]}]]]]\n\nSome examples...\nf[.2]\n\n\nf[.1]\n\n\nf[.025]\n\n\nEdit: In response to the comment, here is a more general form of f which allows for a list of xdata and a list of ydata provided they are of equal length. The min and max of the Tables are chosen to be the range of the x data.\nf[xdata_, ydata_, w_] /; Length[xdata] == Length[ydata] := \n Block[{data = Transpose[{xdata, ydata}], xmin = Min[xdata], \n   xmax = Max[xdata]}, \n  Show[ListLinePlot[data, \n    PlotStyle -> Directive[{Blue, Opacity[.2]}]], \n   With[{pts = \n      Table[windowMin[data, w][t], {t, xmin, xmax, \n        w - w/(xmax - xmin)}]}, Graphics[{Red, BSplineCurve[pts]}]], \n   With[{pts = \n      Table[windowMax[data, w][t], {t, xmin, xmax, \n        w - w/(xmax - xmin)}]}, Graphics[{Red, BSplineCurve[pts]}]]]]\n\n", "numerical integration - Compute integral symbolically or numerically": "\nFor the symbolic attempt I'd first rationalize to get exact input.\ne1 = ((0.000245587 + 0.0000651908 I) E^(-I kx) kx ky (kz^2 - \n        4 \\[Pi]^2))/((kx^2 + ky^2) kz) - ((4.00033*10^-17 - \n        3.51178*10^-18 I) E^(-I kx) (kx^3 kz + kx ky^2 kz + \n        kx^2 kz^2 + 4 ky^2 \\[Pi]^2))/((kx^2 + ky^2) kz);\ne2 = Rationalize[e1, 0]\n\nOut[5]= ((245587/1000000000 + (162977 I)/2500000000) E^(-I kx)\n   kx ky (kz^2 - 4 \\[Pi]^2))/((kx^2 + ky^2) kz) - (1/((kx^2 + \n    ky^2) kz))(1/24997937670142213 - I/\n    284755878785117533) E^(-I kx) (kx^3 kz + kx ky^2 kz + kx^2 kz^2 + \n    4 ky^2 \\[Pi]^2)\n\nI believe this does the transformation you do in a different way.\ne3 = \n e2*k^2*Sin[a]*Cos[a] /. {kx -> k*Sin[a]*Cos[b], \n    ky -> k*Sin[a]*Sin[b], kz -> k*Cos[a]} /. k -> 2*Pi\n\nWith this, we can now do as below.\nIn[26]:= Timing[ii = Integrate[e3, {a, 0, Pi/4}, {b, 0, 2*Pi}]]\n\nOut[26]= {158.87, \n Integrate[(8/284755878785117533 + (8*I)/24997937670142213)*Pi^3*\n       (-2*I*Pi*BesselJ[2, 2*Pi*Sin[a]]*Cos[a]^2*Sin[a] + \n\n     BesselJ[1, 2*Pi*Sin[a]]*(I*(1 + Cos[a]^2) + Pi*Sin[a]*Sin[2*a])), \n     {a, 0, Pi/4}]}\n\nIn[28]:= N[ii]\n\nOut[28]= 7.85307*10^-16 + 1.11299*10^-15 I\n\nWhether this is accurate will depend on cancellation error and other vagaries of the quadrature.\n", "How can I get Mathematica to solve an equation with multiple variables?": "\nIf I understand the question correctly, you are looking for the solution of the differential equation \n$$ y''(t)+3y'(t) = 2t^4 $$\nin the form\n$$ y(t) = t(A_0t^4+A_1t^3+A_2t^2+A_3t+A_4). $$\nThat is, you need to find the values of the $A_i$ constants that satisfy this equation.  Please clarify if this is what you are asking.\n\nTo do this in Mathematica, we can define\ny[t_] := t (t^4 Subscript[A, 0] + t^3 Subscript[A, 1] + \n            t^2 Subscript[A, 2] + t Subscript[A, 3] + Subscript[A, 4])\n\nthen use SolveAlways:\nSolveAlways[y''[t] + 3 y'[t] == 2 t^4, t]\n\n\n", "import - How to manipulate web pages on Mathematica?": "\nThe first thing we need to do is to determine how the initial page assembles the parameters and transmits the request to the server.  One way to do this would be to open the initial page using the developer tools in the web browser.  But since this is a Mathematica forum, let's try to use the tools it makes available to us.\nWe could load the page text and then try to extract the information we need using string manipulation functions.  However, this can get tricky as we must account for line breaks in inconvenient locations, decode HTML entities, and so on.  Instead, we will examine the page's Document Object Model (DOM).  In Mathematica, the DOM is accessed by importing the page using \"XMLObject\" format:\n$initialUrl = \"http://www.fundamentus.com.br/buscaavancada.php\";\n$dom = Import[$initialUrl, \"XMLObject\"];\n\nFewer and fewer pages these days are using simple HTML forms to send requests to the server -- let's see if this page contains any FORM elements:\n$forms = Cases[$dom, XMLElement[\"form\", ___], Infinity];\nLength @ $forms\n\n\n2\n\nWe are in luck.  Let's look at the attributes of the forms:\nCases[$forms, XMLElement[_, attrs_, _] :> attrs]\n\n\n{\n  \u00a0{enctype->application/x-www-form-urlencoded,method->get,\n  \u00a0\u00a0\u00a0\u00a0class->busca,action->detalhes.php},\n  \u00a0{enctype->application/x-www-form-urlencoded,method->post,\n  \u00a0\u00a0\u00a0\u00a0class->avancada,name->formbusca,action->resultado.php}\n  }\n\nThe first form (\"detalhes\") uses HTTP GET to get its results.  The second (\"resultado\") uses POST.  Resultado sounds promising.  Let's extract the input elements for that form:\nCases[$forms[[2]], XMLElement[\"input\", ___], Infinity] // Column\n\n\nXMLElement[input,{type->text,name->pl_min},{}]\n  XMLElement[input,{type->text,name->pl_max},{}]\n  XMLElement[input,{type->text,name->pvp_min},{}]\n... lines omitted ...\n  XMLElement[input,{type->text,name->roe_min},{}]\n  XMLElement[input,{type->text,name->roe_max},{}]\n  XMLElement[input,{type->text,name->liq_min},{}]\n  XMLElement[input,{type->text,name->liq_max},{}]\n... lines omitted ...\n\nYes, this looks like the form that we are interested in.  Let's assemble the components of a request:\n$resultUrl = StringReplace[$initialUrl, \"buscaavancada.php\" -> \"resultado.php\"]\n\n\nhttp://www.fundamentus.com.br/resultado.php\n\n$parameters = {\n  \"roe_min\" -> \"0.1\"\n, \"liq_min\" -> \"500000\"\n, \"liq_max\" -> \"800000\"\n};\n\n... and transmit the request using HTTP POST:\n$results = Import[\n  $resultUrl\n, \"Data\"\n, \"RequestMethod\" -> \"POST\"\n, \"RequestParameters\" -> $parameters\n]\n\n\n{{{{P\u00e1gina inicial,Investimento consciente,Entre em\n  contato},{Detalhes,{Balan\u00e7o patrimonial,Demonstrativos de\n  resultados,Indicadores fundamentalistas},{Balan\u00e7os em\n  Excel,Proventos},Hist\u00f3rico de\n  cota\u00e7\u00f5es}},{{Papel,Cota\u00e7\u00e3o,P/L,P/VP,PSR,Div.Yield,P/Ativo,P/Cap.Giro,P/EBIT,P/Ativ\n  Circ.Liq,EV/EBIT,Mrg Ebit,Mrg. L\u00edq.,Liq.\n  Corr.,ROIC,ROE,Liq.2meses,Patrim. L\u00edq,D\u00edv.Brut/ Patrim.,Cresc.\n  Rec.5a},{{PRTX3,2,72,-38,34,-255,71,905,562,0,00%,1,977,-5,52,-63,14,-2,42,-72,49,-1.434,22%,-2.361,99%,0,35,-3,96%,666,96%,537.768,00,-10.557.000,00,-59,73,0,00%}\n... and more ...\n\nThis time we have imported using the \"Data\" format which let's Mathematica do all the hard work of extracting the HTML TABLE elements out of the web page.\nAt this point, we have successfully imported all of the data into Mathematica.  We can now use the usual Mathematica tools to extract and reformat those parts that interest us.  After a bit of experimentation, we can see that the interesting data is the the second element of the first row:\n$interesting = $results[[1, 2]];\n$interesting // TableForm\n\n \nWe can extract the property names:\n$propertyNames = $interesting[[1, 2;;]]\n\n\n{Cota\u00e7\u00e3o,P/L,P/VP,PSR,Div.Yield,P/Ativo,P/Cap.Giro,P/EBIT,P/Ativ\n  Circ.Liq,EV/EBIT,Mrg Ebit,Mrg. L\u00edq.,Liq.\n  Corr.,ROIC,ROE,Liq.2meses,Patrim. L\u00edq,D\u00edv.Brut/ Patrim.,Cresc. Rec.5a}\n\n... and the ticker symbols:\n$symbols = $interesting[[2, All, 1]]\n\n\n{PRTX3,BRTO3,FHER3,PINE4}\n\n... and the data itself:\n$data = $interesting[[2, All, 2;;]]\n\n\n{{2,72,-38,34,-255,71,905,562,0,00%,1,977,-5,52,-63,14,-2,42,-72,49,-1.434,22%,-2.361,99%,0,35,-3,96%,666,96%,537.768,00,-10.557.000,00,-59,73,0,00%},{12,15,3,87,0,68,0,771,2,46%,0,256,4,35,2,62,-0,85,2,97,29,44%,19,90%,1,22,12,50%,17,68%,750.626,00,10.699.600.000,00,0,53,-3,53%},{12,25,4,48,1,38,0,135,0,00%,0,201,-12,78,1,64,-2,14,3,72,8,25%,3,02%,0,98,22,47%,30,87%,686.507,00,429.309.000,00,2,52,7,74%},{12,39,7,58,1,21,0,000,7,39%,0,000,0,00,0,00,0,00,0,00,0,00%,0,00%,0,00,0,00%,15,91%,509.960,00,1.015.080.000,00,0,00,-10,02%}}\n\nSince the numbers and percentages were not in a format that Mathematica recognizes, they were imported as strings.  We need to convert those strings into Mathematica syntax so that we can parse them:\nparse[s_String] /; StringMatchQ[s, __~~\"%\"] :=\n  parse[StringDrop[s, -1]] / 100\n\nparse[s_String] /; StringMatchQ[s, (DigitCharacter|\"-\"|\",\"|\".\")..] :=\n  ToExpression[StringReplace[s, {\",\" -> \".\", \".\" -> \"\"}]]\n\nparse[s_] := s\n\n$data2 = $data /. s_String :> parse[s]\n\n\n{{2.72,-38.34,-255.71,905.562,0.00,1.977,-5.52,-63.14,-2.42,-72.49,-1434.22,-2361.99,0.35,-3.96,666.96,537768.00,-10557000.00,-59.73,0.00},{12.15,3.87,0.68,0.771,2.46,0.256,4.35,2.62,-0.85,2.97,29.44,19.90,1.22,12.50,17.68,750626.00,10699600000.00,0.53,-3.53},{12.25,4.48,1.38,0.135,0.00,0.201,-12.78,1.64,-2.14,3.72,8.25,3.02,0.98,22.47,30.87,686507.00,429309000.00,2.52,7.74},{12.39,7.58,1.21,0.000,7.39,0.000,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,15.91,509960.00,1015080000.00,0.00,-10.02}}\n\nNote that percentages were converted into fractions.\nWe can now display the data or manipulate it as we see fit, for example:\nTableForm[Transpose @ $data2, TableHeadings -> {$propertyNames, $symbols}]\n\n\n", "front end - Opening new notebooks with a non-default window size": "\nThe default window size can be controlled from two different places.  The first is the Global $FrontEnd WindowSize, set through the Option Inspector > Global Preferences or with:\nSetOptions[$FrontEnd, WindowSize -> {300, 900}]\n\nThe second is the WindowSize of the style sheet itself.  If it is defined, the WindowSize of the style sheet will overrule the setting above.  You set the style sheet size through the Option Inspector > Selected Notebook or by evaluating this inside the style sheet itself:\nSetOptions[EvaluationNotebook[], WindowSize -> {300, 900}]\n\nTo select the default style sheet, click the button to the right of the setting name, and use the file browser:\n\n", "performance tuning - Finding all elements within a certain range in a sorted list": "\nAs you said, essentially you need binary search, since you have a sorted list and binary search has a logarithmic complexity.  However, since \n\nthe limiting numbers may not be present in the list\nsome numbers may be present more than once\n\nwe'd need modified binary search. Here is a possible implementation:\n(* maximum number smaller than or equal to the limit *)\nbsearchMin[list_List, elem_] :=\n  Module[{n0 = 1, n1 = Length[list], m},\n    While[n0 <= n1,\n     m = Floor[(n0 + n1)/2];\n     If[list[[m]] == elem, \n         While[list[[m]] == elem, m++]; \n         Return[m - 1]];\n     If[list[[m]] < elem, n0 = m + 1, n1 = m - 1]\n    ];\n    If[list[[m]] < elem, m, m - 1] \n  ];\n\nand\n(* minimum number larger than or equal to the limit *)\nbsearchMax[list_List, elem_] :=\n  Module[{n0 = 1, n1 = Length[list], m},\n    While[n0 <= n1,\n      m = Floor[(n0 + n1)/2];\n      If[list[[m]] == elem, \n         While[list[[m]] == elem, m--]; \n         Return[m + 1]];\n      If[list[[m]] < elem, n0 = m + 1, n1 = m - 1]\n    ];\n    If[list[[m]] > elem, m, m + 1] \n  ];\n\nWith the help of these:\nwindow[list_, {xmin_, xmax_}] :=\n  With[{minpos = bsearchMax[list, xmin], maxpos =  bsearchMin[list, xmax]},\n    Take[list, {minpos, maxpos}] /; ! MemberQ[{minpos, maxpos}, -1]\n  ];\nwindow[__] := {};\n\nFor example:\nlst = {1, 4, 4, 4, 6, 7, 7, 11, 11, 11, 11, 13, 15, 18, 19, 22, 23, 25, 27, 30}\n\nwindow[lst, {4, 11}]\n\n(* ==> {4, 4, 4, 6, 7, 7, 11, 11, 11, 11} *)\n\nYou can Compile functions bsearchMin and bsearchMax, if you expect lots of duplicate elements (this will speed an inner While loop). Compiling them per se won't improve the speed much (unless you call these very often), since the complexity is logarithmic in any case.\nThis is certainly generally more efficient than Nearest for sorted lists (perhaps unless you have lots of repeated elements, but then you can compile), because Nearest is a general algorithm which can not take into account the sorted nature of the list. I tried on 10^7 elements list,  and it took something 0.0003 seconds for that.\nCompiled version\nCompiled versions speed up bsearchMin and bsearchMax, but seem not to improve the performance of window[]. See discussion in comments section.  \nbsearchMax = Compile[{{list, _Complex, 1}, {elem, _Real}},\n  Block[{n0 = 1, n1 = Length[list], m = 0},\n    While[n0 <= n1,\n      m = Floor[(n0 + n1)/2];\n      If[list[[m]] == elem,\n        While[m >= n0 && list[[m]] == elem, m--]; Return[m + 1]  ];\n      If[list[[m]] < elem, n0 = m + 1, n1 = m - 1]];\n    If[list[[m]] > elem, m, m + 1]\n  ]\n  ,\n  RuntimeAttributes -> {Listable},\n  CompilationTarget -> \"C\"\n]\n\nbsearchMin = Compile[{{list, _Complex, 1}, {elem, _Real}},\n  Block[{n0=1,n1=Length[list],m = 0},\n    While[n0<=n1,\n      m=Floor[(n0+n1)/2];\n      If[list[[m]]==elem,\n        While[m<=n1 && list[[m]]==elem,m++]; Return[m-1]  ];\n      If[list[[m]]<elem, n0=m+1, n1=m-1]];\n    If[list[[m]]<elem,m,m-1]\n  ]\n  ,\n  RuntimeAttributes -> {Listable},\n  CompilationTarget -> \"C\"\n]\n\n", "functions - Max of a table/list with indeterminate values": "\nThe first approach would be: \nMax@Cases[tab, Except[Indeterminate]]\n\n\n3.\n\n\nIf I understand your second need, that would be:\ntab /. Indeterminate -> 0.0\n\n\n{1., 2., 3., 0.}\n\n\nEdit\nOleksandr's approach  is indeed very fast, for very long lists seems to be over 3-4  times faster then others. Since my first approach was quite straightforward, it is resonable to add another one obvious method which will be very handy (possibly the fastest) when we work with non-numeric lists : \nMax@DeleteCases[l, Indeterminate]\n\nThis approach is only a bit slower for numeric lists than that by Oleksandr and probably the best for non-numeric data (when Indeterminates are exceptional cases rather than common).\nTo test prerformance issues we take a slightly more natural data, namely lists of real numbers with appended Indeterminate's :\nl = RandomChoice[RandomReal[100, 20000]~Append~Indeterminate, {10^7}]; \n\nand use AbsoluteTimings to compare methods, starting with the most efficient :\nmaxNoIndeterminate[l] // AbsoluteTiming                   (*Oleksandr*)\n\n\n{0.7070000, 99.9945}\n\n\n Max@DeleteCases[l, Indeterminate] // AbsoluteTiming       (*Artes II *)\n\n\n{1.1150000, 99.9945}\n\n\n  Max@Cases[l, Except[Indeterminate]] // AbsoluteTiming     (*Artes I *)\n\n\n {2.7720000, 99.9945}\n\n\n  Max[l /. Indeterminate -> -Infinity] // AbsoluteTiming   (*cormullion*)\n\n\n {2.8870000, 99.9945}\n\n\n  Max@Select[l, NumberQ] // AbsoluteTiming                (*David Skulsky*)\n\n\n {3.5120000, 99.9945}\n\n\n", "plotting - Mathematica2tikz an equivalent function": "\nThis is not a full answer, just a starting point:\n\nI would first write some functions that convert Mathematica graphics to a representation that is really close to the structure TikZ uses (similar to how Mathematica represents C using SymbolicC).  I don't know TikZ, so this should be designed by someone who is quite familiar with it.\n\nThen I'd write a set of functions that can convert this representation to a string that is syntactically correct TikZ code.\n\n\n\nExamples:\nExtracting lines from a Plot:\nThis will extract the two lines from the plot:\nlines = Cases[Plot[{Sin[x], Cos[x]}, {x, 0, 10}], Line[coords_] :> coords, Infinity]\n\nKnowing exactly what sort of Graphics object Plot likes to generate, we can extract the style too:\nCases[Plot[{Sin[x], Cos[x]}, {x, 0, 10}], {style_, _Line}, Infinity]\n\nConverting a symbolic representation to a string:\nLooking at your example TikZ input, we can make something like the coordinate section using\ncoordList2TikZ[data_?MatrixQ] :=\n \"coordinates{\\n\" <>\n  StringJoin[\n   \"(\" <> ToString[#1, CForm] <> \",\" <> ToString[#2, CForm] <> \")\" & @@@ data] <>\n  \"\\n};\"\n\n(StringForm will be useful here as well.)\nThis will take a list of coordinates and output some TikZ code:\ncoordList2TikZ[{{1, 2}, {3, 4}}]\n\n(* ==>\ncoodinates{\n(1,2)(3,4)\n};\n*)\n\nYou can try coordList2TikZ /@ lines as well.  I do not know what sort of scientific notation TikZ uses, so I just used the C-style 1.23e-5 one.\n", "import - Data of badly formatted file": "\nMaybe you could do something like this:\nFirst the data is imported as a list of strings. \nimport = Import[\"exampleFile.txt\", \"List\"];\n\npos is the position of all lines containing the substring \"Ion\". The data of interest is located 3 lines below the lines containing \"Ion\". Therefore we omit the last four lines of import when searching.\npos = Flatten[Position[import[[;; -4]], a_String /; StringMatchQ[a, \"*Ion*\"], 1]];\n\nNext we split the strings using the character \"\u00b3\" as the delimiter, and we transform the strings into numbers by replacing \"E\" in each substring with \"*10^\" and applying ToExpression.\nstrings = StringTrim /@ StringSplit[import[[pos + 3]], \"\u00b3\"];\ndata = Cases[strings, a_ /; Length[a] >= 5 :> ToExpression[\n      StringReplace[a[[3 ;; 5]], \"E\" -> \"*10^\"]]];\n\nThe first few entries for data are then\ndata[[;; 5]]\n\n\n{{7618.6, -0.3894, 0.2726}, {3353.6, -0.0124, 0.03758}, \n   {15268., 64.08, -8.825}, {13317., 38., 16.98}, {5654.9, 0.08338, 0.01426}}\n\n\nwhich seems to match the screenshot.\n", "List all the directories under the current one": "\nMaybe something like\nSelect[FileNames[\"*\", \"\", Infinity], DirectoryQ]\n\n", "graphics - Poor rendering of fractals": "\nI think the lower quality you see has to do with the downscaling of the image. It is generated at 512x512 pixels which you can check if you right mouse click on the image, but it isn't displayed that way. So, if I change this to:\nOpenCLFractalRender3D[ImageSize -> 512]\n\nI get\n.\nAs to your second question: of course you can use Mathematica to generate 2D fractals. It has a rich set of drawing primitives. Examples can be found in the manual (for instance, here).\n", "parallelization - Nesting Parallel processes": "\nThis limitation exists, and as far as I can see we have to live with it for now.  It does indeed make it impractical to use Parallel operations inside functions---the functions won't work in parallel kernels.\nI recommend you parallelize at the top level unless you have a specific reason to do it at lower levels.  The longer the a \"unit calculation\" that is run in a subkernel, the less parallelization overhead will matter.  This overhead can be significant if you are running the subkernels on different machines from your main kernel (as you seem to be based on your Lightweight Grid question).  Could you give some indication of how long it takes for your functions to finish, and how long the list dataLists is?  If dataLists is long enough compared to the number of processors you have available, then probably parallelization at the highest level will be most efficient.\nAlternatively you could just use Off[ParallelMap::subpar].\n", "packages - Using GRTensorM 1.2 in Mathematica 8.0": "\nI don't have that package, so is a more or less wild guess. There seems to be a fucntion \ngrtG`Ndim[metricName]\n\nand it seems as if that does not evaluate. Is kerr a supported metric name? You could look at the NDim funciton and see if you can spot a problem. Maybe ??grt`Ndim gives a clue. Perhaps you know the dimension and can set it outside the package.\n", "calculus and analysis - How to specify assumptions before evaluation?": "\nIntegrate can take the option Assumptions.\nIntegrate[1/Sqrt[z^2 + u^2], {z, -l, l}, \n  Assumptions -> u > 0 && l > 0 && Element[u | l, Reals]]\n\n ==> 2 Log[(l + Sqrt[l^2 + u^2])/u]\n\nAlternatively use Assuming.\nAssuming[u > 0 && l > 0 && Element[u | l, Reals], \n Integrate[1/Sqrt[z^2 + u^2], {z, -l, l}]]\n\n==> 2 Log[(l + Sqrt[l^2 + u^2])/u]\n\n", "image processing - Adding controls for multiple functions in Manipulate": "\nSince I don't have access to your image I'll use the built in ExampleData test image \"Lena\". The following should accomplish what you want.\nhelix = ExampleData[{\"TestImage\", \"Lena\"}];\n\nManipulate[\n w = GaussianFilter[\n   Sharpen[ImageAdjust[helix, {contrast, brightness, gamma}], \n    sharpen], gfilter], {{contrast, 0}, -1, 5, 0.01, \n  Appearance -> \"Labeled\"}, {{brightness, 0}, -1, 5, 0.01, \n  Appearance -> \"Labeled\"}, {{gamma, 1}, 1, 10, 1, \n  Appearance -> \"Labeled\"}, {{sharpen, 1}, 1, 15, \n  Appearance -> \"Labeled\"}, {{gfilter, 1}, 1, 15, \n  Appearance -> \"Labeled\"}, Delimiter, \"Histogram\", \n Dynamic[ImageHistogram[w, Appearance -> \"Separated\", \n   ImageSize -> 250]], ControlPlacement -> Left]\n\nNotice that the functions are added just by nesting them.  This could probably be accomplished in a variety of ways but this seems most direct. The added controls are nearly verbatim to the pre-existing ones.\nHere is what it produces...\n\n", "probability or statistics - Showing the correlation of two variables using a plot": "\nYou can also calculate the Coefficient of Determination, R Squared.\nThis is the same as the correlation squared, but by making use of LinearModelFit you can create some additional graphics.\nTo make a sample distribution you can use this:\nCreateDistribution[] := DynamicModule[{savepts = {{-1, -1}}},\n  Dynamic[\n   EventHandler[\n    ListPlot[pts, AxesOrigin -> {0, 0}, \n     PlotRange -> {{0, 7}, {0, 5}}], \n    \"MouseDown\" :> (savepts = \n       pts = DeleteCases[\n         Append[pts, MousePosition[\"Graphics\"]], {-1, -1}])],\n   Initialization :> (pts = savepts)]]\n\nCreateDistribution[]\n\nJust click to add some points.  The data is collected in the variable pts.\n\nThen calculate R Squared:\nlm = LinearModelFit[Sort@pts, a, a]; r2 = lm[\"RSquared\"];\nShow[Plot[lm[x], {x, 0, 7}], ListPlot[pts], AxesOrigin -> {0, 0}, \n PlotRange -> {{0, 7}, {0, 5}}, \n PlotLabel -> \n  \"The correlation is \" <> \n   If[D[lm[\"BestFit\"], a] < 0, \"negative\", \"positive\"], \n Epilog -> \n  Inset[Style[\n    \"\\!\\(\\*SuperscriptBox[\\\"R\\\", \\\"2\\\"]\\) = \" <> ToString[r2], \n    11], {1.5, 4.5}]]\n\n\nWhether the correlation is positive or negative is obtained here from the derivative of the BestFit.\nYou can add standard deviation bands for sigma = 1, 2 & 3 like this.\nlm = LinearModelFit[Sort@pts, {1, x (*, x^2 *)}, x];\n{bands68[x_], bands95[x_], bands99[x_]} = \n  Table[lm[\"SinglePredictionBands\", \n    ConfidenceLevel -> cl], {cl, {0.6827, 0.9545, 0.9973}}];\nShow[ListPlot[Sort@pts], \n Plot[{lm[x], bands68[x], bands95[x], bands99[x]}, {x, -0.15, 7.2}, \n  Filling -> {2 -> {1}, 3 -> {2}, 4 -> {3}}], AxesOrigin -> {0, 0}, \n PlotRange -> {{0, 7}, {0, 5}}, ImageSize -> 480, Frame -> True]\n\n\nUncomment x^2 for a quadratic fit.\n\nAdded note\nThe linear band calculation steps are detailed here: How to derive SinglePredictionBands\n", "functions - Problem when defining variable in Mathematica": "\nUse:\ndomain := {n, 0, 10};\nPlot[n, Evaluate[domain]]\n\nPlot has the HoldAll attribute which prevents domain from evaluating:\nAttributes[Plot]\n{HoldAll, Protected}\n\n", "interpolation - Implicit Interpolating function in Mathematica and its explicit form in small sections": "\nRegarding your second question, f may be obtained in general via f=Interpolation[points]. Its derivative is given by f'[.3] (say) This, however, fails for your example because two points with the same x-coordinate appear (as it is a circle). \nFor instance, try f = Interpolation[Table[{i, Sin[i]}, {i, 0, 10, .1}]] and then Plot[f'[x], {x, 0, 2 Pi}].\nPerhaps you could explain what it is you're actually trying to do.\nEDIT: OK, you can do this for f1:\nQuiet[f1 = FunctionInterpolation[Sqrt[1 - y^2], {y, -1, 1}]];\n\nand for your F (that I randomly renamed to func)\nfunc = FunctionInterpolation[-1 + 1*(x^2 + y^2), {x, -1.5, \n   1.5}, {y, -1.5, 1.5}]\n\nNote that this is some function that vanishes on the unit circle. If all you want is that F(x,y) vanishes on (eg) the unit circle, there are infinitely many functions satisfying this; one of them is the one you gave.\n", "Delete duplicate elements from a list": "\nYou can use DeleteDuplicates to remove the duplicate elements while preserving the original order:\nDeleteDuplicates[{a, 1, 5, 3, 5, x^2, x^2}]\n(* {a, 1, 5, 3, x^2} *)\n\n", "equation solving - How to solve for an Z-Score of a T-Distribution?": "\nHave you tried FindRoot? It's a numerical function looking for a root given some starting location. In addition to that, you can get around integrating by using CDF instead of PDF in the first place:\nFindRoot[CDF[StudentTDistribution[49], y] == 0.95, {y, 1}]\n\n\n{y -> 1.67655}\n\n\nIf you're interested, the reason why your first approach doesn't work: NIntegrate cannot use placeholders, it has to evaluate to a number in all cases. What you're trying to do is equivalent to NIntegrate[x*y, {x,0,1}], and the program complains that it does not know the full integrand since y is undefined, therefore it cannot be evaluated. The fact that you've wrapped a Solve, which inserts the missing variable (x in your case) after NIntegrate has been evaluated, does not have any impact on that.\n", "Selective blurring of areas of image to make seamless tiles": "\nimg = ExampleData[{\"TestImage\", \"Mandrill\"}];\n\nThis \"rotates\" the image like you did:\nrot[img_] := \n Image@RotateLeft[ImageData[img], Round[Reverse@ImageDimensions[img]/2]]\n\n\nLet's make a mask ...\nmask[img_, margin_] := \n ImagePad[Graphics[{}, ImageSize -> (ImageDimensions[img] - 2 margin),\n    Background -> Black], margin, White]\n\n\n... and inpaint it:\nInpaint[rot[img], Blur[rot[mask[img, 10]], 3]]\n\n\nAdjust the parameters (mask thickness, blur radius) to your liking.\nIt will work better for texture-like images:\nimg = ExampleData[{\"Texture\", \"Bricks3\"}]\n\nInpaint[rot[img], rot[mask[img, 5]]]\n\n\nNote: often it is better to trace the mask manually, paying attention to features in the image.  Right click the image, and choose Graphics Editing -> Drawing Tools.  Draw the mask.  Then again right click, and choose Graphics Editing -> Create Mask.  I like to use the Freehand Line tool with a very thick line and round caps and joins---it's almost like painting with a brush in a photo editor.\n", "time series - Function to calculate and plot sample variogram": "\nLag differences are not the same as second-differencing etc, so Differences is not the right approach. \ntest2 = Array[f, 10]\n\nIn[23]:= Differences[test2, 3]\n\n\nOut[23]= {-f[1] + 3 f[2] - 3 f[3] + f[4], -f[2] + 3 f[3] - 3 f[4] + \n        f[5], -f[3] + 3 f[4] - 3 f[5] + f[6], -f[4] + 3 f[5] - 3 f[6] + \n        f[7], -f[5] + 3 f[6] - 3 f[7] + f[8], -f[6] + 3 f[7] - 3 f[8] + \n        f[9], -f[7] + 3 f[8] - 3 f[9] + f[10]}\n\nBuilding on kguler's answer, here is an alternative way of getting lag-differences. I have written it up as a separate function because it has more general utility than this specific application.\nlagdif[l_List, k_Integer?Positive] /; k < Length[l] := \n  Drop[l, k] - Drop[l, -k]\n\nWe can then use a similar approach:\ndif[list_] := Table[lagdif[list, k], {k, Length[list] - 1}];\ndbar[list_] := Mean /@ dif[list];\nvar[list_] := Variance /@ (Most@(dif[list]));\nvariogram[list_] := ((Rest@#)/First@#) &@var[list];\n\nTesting with I(1) data (i.e. non-stationary with a single unit root): \n$y_t = y_{t-1} + \\epsilon_t$\ndata = Accumulate[RandomReal[{-1, 1}, 20]];\n\nGraphicsRow[{ListLinePlot[data], ListLinePlot[variogram[data]]}]\n\n\nThis makes me wonder how powerful the variogram is for data with shocks that have bounded support.\n", "Locators and Table within a Manipulate are not behaving": "\nOk, I figured it out, sort-of. Here is what was in my original code for the curved Arrow that indicates the angle for the second vector:\nangleArrow2 = \n  Graphics[Arrow[Table[{x1 + Min[0.5 Sqrt[x2^2 + y2^2], 0.5] Cos[i], \n      y1 + Min[0.5 Sqrt[x2^2 + y2^2], 0.5] Sin[i]}, {i, 0, theta2, \n      1/100}]]];\n\nThe problem was not necessarily with Table, but with the Table iterator. I kept asking myself why the commented-out definition of angleArrow2 worked when the definition with Table did not. I realized that the only difference between the two versions of angleArrow2 was the number of elements in the list within Arrow. So I started to play with the step size in the Table iterator. As I made the step size larger to reduce the number of elements in the list I started to see a hint of correct behavior. In other words, moving the Locator for the second vector DID move only the second vector, but only for a short \"time\". Once I moved the Locator beyond a certain distance (that seemed to depend on the step size in Table) the unwanted behavior appeared again. I.e. the second Locator moved along with the first Locator and changed the size and direction of the first vector instead of the second.\nWith a fixed step size such as 1/100 as I originally had, or even 1/10 as I eventually tried, the unwanted behavior eventually appeared. So I decided to try a relative step size base on the angle (theta2) and changed my code to read:\nangleArrow2 = \n  Graphics[Arrow[Table[{x1 + Min[0.5 Sqrt[x2^2 + y2^2], 0.5] Cos[i], \n      y1 + Min[0.5 Sqrt[x2^2 + y2^2], 0.5] Sin[i]}, {i, 0, theta2, \n      theta2/20}]]];\n\nNow it works beautifully! When one Locator is moved only its associated vector is changed. \nNow, I haven't quite figured out why this works, but a little more thinking may help. If anyone has any ideas on why an absolute step size resulted in the unwanted behavior while a relative step size worked correctly I would love to hear from you. However, I think you really need to evaluate my code at various absolute step sizes to see what I mean. With an absolute step size like 1/10 when you move the second Locator you initially see only the second vector changing, but then suddenly the first vector starts changing instead. Weird!\nIf you do evaluate my code be sure to Show the two vectors and the angle for the second vector:\nShow[{vector1, vector2, angleArrow2}, PlotRange -> {{-4.1, 4.1}, {-4.1, 4.1}}, \n ImageSize -> 500]\n\nThank you everyone for your suggestions!\n", "programming - Lexicographic ordering of strings in Mathematica": "\nI believe you are looking for Order and Ordering.\nThe 1 indidcates that \"aaa\" comes before \"aaaab\" in canonical ordering:\nOrder[\"aaa\", \"aaaab\"]\n\n\n1\n\n\nHere Ordering is used to get the position of the first element in the sorted list and the that element is extracted from the list.  This is equivalent to a \"Min\" function.\nlist = {\"aaaa\", \"deaaaf\", \"dfeef\", \"a\"};\nlist ~Extract~ Ordering[list, 1]\n\n\n\"a\"\n\n\nAnd a \"Max\" function:\nlist ~Extract~ Ordering[list, -1]\n\n\n\"dfeef\"\n\n\n", "programming - Effective matrix power like algorithm": "\nNote:  The method I describe below does not find the optimal solution (i.e. the minimal number of multiplications), but it usually does better than the binary approach, and more importantly: it is very easy to extend it and optimize it for special cases.  We could easily pre-compute those exponents for which it does worse than the simple binary method to say up to 1000 and special case those.\nAccording to the Wikipedia article on the topic:\n\n... the determination of a shortest addition chain seems quite difficult:\n  no efficient optimal methods are currently known for arbitrary\n  exponents, and the related problem of finding a shortest addition\n  chain for a given set of exponents has been proven NP-complete.\n\nTherefore trying to compute the optimial solution within the function (as opposed to precomputing it and making a lookup table) defeats the purpose of using this for optimization.\n\nI did a version of this with C++ template metaprogramming here.\nThis is a direct translation:\nLet f be an associative function, then:\nClear[pow]\n(* Syntax: pow[exponent][base] *)\npow[n_][a_] /; Mod[n, 2] == 0 := With[{t = pow[n/2][a]}, f[t, t]]\npow[n_][a_] /; Mod[n, 3] == 0 := With[{t = pow[n/3][a]}, f[f[t, t], t]]\npow[n_][a_] := f[pow[n - 1][a], a]\npow[1][a_] := a\n\nTesting:\nf[x_, y_] := (Print[\"x\"]; x y)\n\nThen pow[10][2] gives\nDuring evaluation of In[389]:= x\n\nDuring evaluation of In[389]:= x\n\nDuring evaluation of In[389]:= x\n\nDuring evaluation of In[389]:= x\n\nOut[389]= 1024\n\ni.e. it was done in four multiplications.  You can think a bit about which is the best subdivision (to 3 or to 2) for different numbers.  It can be manually verified that for exponents under 100, in the case of 33 and 69 (and exponents reducible to these such as $67 = 2\\times 33 +1$) it's better not to subdivide into 3 first.  We can easily special-case pow for these by adding the following to the beginning of pow's definition:\npow[33][a_] := f[pow[32][a], a]\npow[69][a_] := f[pow[68][a], a]\n\nSimilarly, in the case of e.g. 82 it's better not to subdivide into 2 because $82 - 1 = 3^4$, but use\npow[82][a_] := f[pow[81][a], a]\n\nAnother example is that in the case of 85 and 95 it's better to subdivide into 5 first:\npow[85][a_] := pow[13][ pow[5][a] ]\n\nBut most of these are just tweaks that will not make a huge difference.\nI believe that the value of my implementation lies in the ease of its extension for special cases like these for small exponents.\n\nFor the adventurous with a lot of free time, see this paper on Pippenger's algorithm.\n", "string manipulation - Position of a particular substring in an imported HTML file": "\nThe string \"Flux Light Curve\" does not appear as an element of s.  If you are looking for a substring you will need a different function.\nIf you only want to know the positions of strings which contain \"Flux Light Curve\" as a substring, you might use:\nPosition[ s, x_ /; StringMatchQ[x, __ ~~ \"Flux Light Curve\" ~~ __] ]\n\nIn this ~~ stands for StringExpression.\nThe output from this:\nStringPosition[s, \"Flux Light Curve\"]\n\nis a list with many empty lists as elements, because most elements in s do not contain the substring.  You can further process the result as needed.  For example:\nx = StringPosition[s, \"Flux Light Curve\"];\n\nPosition[x, {__Integer}]\n\nDeleteCases[x, {}]\n\n", "syntax - Head and everything except Head?": "\nPoint #1\nPart always wraps element sequences with the original head of the expression.\nexpr = Hold[1 + 1, 2 + 2, 3 + 3, 4 + 4, 5 + 5];\n\nexpr[[{2, 3}]]\n\n\nHold[2 + 2, 3 + 3]\n\n\nFor this purpose a single part e.g. 1 is not a sequence but {1} and 1 ;; 1 are:\nexpr[[1]]\n\nexpr[[{1}]]\n\nexpr[[1 ;; 1]]\n\n\n2\n\nHold[1 + 1]\n\nHold[1 + 1]\n\n\nThis applies at every level of the extraction:\nexp2 = g[h[1, 2], i[3, 4]];\n\nexp2[[  2 , 1  ]]\nexp2[[ {2}, 1  ]]\nexp2[[  2 ,{1} ]]\nexp2[[ {2},{1} ]]\n\n\n3\n\ng[3]\n\ni[3]\n\ng[i[3]]\n\n\nI used this nontrivially for Elegant manipulation of the variables list.\nPoint #2\nConsider instead using Extract which wraps sequences in List:\nExtract[expr, {{2}, {3}}]\n\n\n{4, 6}\n\n\nThe third argument of Extract can be used to specify a function to apply to individual elements before they are evaluated:\nExtract[expr, {{2}, {3}}, HoldForm]\n\n\n{2 + 2, 3 + 3}\n\n\nIf you want all parts you can also use Level:\nLevel[(a + b + c), {1}, Heads -> True]\n\n\n{Plus, a, b, c}\n\n\nOr Cases:\nCases[(a + b + c), _, Heads -> True]\n\n\n{Plus, a, b, c}\n\n\nOr Replace/ReplaceAll:\n(a + b + c) /. head_[body___] :> {head, body}\n\n\n{Plus, a, b, c}\n\n\nPoint #3\nThe last point is more tricky and I had to check it myself.  There is a behavior that I also did not expect:\nRange[5][[0 ;; 5]]\n\n\n{}\n\n\nWhat I expected was an error as seen here:\nRange[5][[0 ;; 4]]\n\nand here:\nRange[5][[0 ;; 6]]\n\nWhen Span is used in Part[x, 0 ;; n] where n is the length of x, Part returns the head of the expression.  Therefore (a + b + c)[[0;;3]] returns Plus[] and Plus[] evaluates to 0.\n\nI believe Span behaves this way because of how it handles non-positive values, and zero-length spans.  Consider:\nRange[10][[-2 ;; 10]]\n\n\n{9, 10}\n\n\nYou can see that it wraps around.  Now consider:\nRange[10][[5 ;; 4]]\n\n\n{}\n\n\nAn empty span returns the head of the expression with no arguments.\nUsing 0 ;; n where n is the last element in the list, or 0 ;; -1, is also an empty span wrapping around the open end of the list.\nRange[10][[0 ;; -1]]\n\n\n{}\n\n\n", "How to impose custom style to the edges of a graph": "\nFor the first part of your question you can use a custom function for the EdgeShapeFunction option of Graph:\nLet\n   edgeshape[e_, ___] := {Arrowheads[Large], Red, Thick, Arrow[e, 0.2]}\n\nand use as\n Show[Graph[node, edges, VertexCoordinates -> vertexposition, \n VertexSize -> {\"Scaled\", .02}, VertexLabels -> \"Name\", \n EdgeShapeFunction -> edgeshape], Frame -> True, FrameTicks -> True, \n ImageSize -> 600]\n\nto get\n\nGraph also takes Graphics options, so you can use\n Graph[node, edges, VertexCoordinates -> vertexposition, \n VertexSize -> {\"Scaled\", .02}, VertexLabels -> \"Name\", \n EdgeShapeFunction -> edgeshape, Axes -> True, Ticks -> Automatic, \n TicksStyle -> Directive[Orange, 12], PlotRangePadding -> .1, \n  AxesOrigin -> {0, 0}]\n\nto get\n\nUpdate: Using Szabolcs's revised answer, adding Frame->True, FrameTicks->All to options\n Graph[node, edges, VertexCoordinates -> vertexposition, \n VertexSize -> {\"Scaled\", .02}, VertexLabels -> \"Name\", \n EdgeShapeFunction -> edgeshape, Frame -> True, Axes -> False, \n FrameTicks -> All, FrameTicksStyle -> Directive[Orange, 12]]!\n\n\nYou can also define your custom  tick function. e.g. \n ticks[min_, max_] := \n Table[If[EvenQ[i], {i, i, {.01, 0}, Red}, {i, i, {.01, 0},  Blue}], {i, Floor[min],   Floor[max], 10}]\n\nand use it with FrameTicks\n Graph[node, edges, VertexCoordinates -> vertexposition, \n VertexSize -> {\"Scaled\", .02}, VertexLabels -> \"Name\", \n  EdgeShapeFunction -> edgeshape, Frame -> True, Axes -> False, \n FrameTicks -> ticks, FrameTicksStyle -> Directive[Orange, 12], \n PlotRangePadding -> 5, ImagePadding -> 30]\n\nto get\n\nFrom the above answers to your first and third questions, you should be glad that i am not attempting to answer your second question.\n", "graphics - Generate a Unit Circle Trigonometry": "\nThere are a couple tricky points here.  Here's a start, which I imagine you can finish.\nmarkings[t_] := Module[{o={0,0},p={Cos[t],Sin[t]}, \n  t2=Together[t],tFormat, rot},\n  tFormat = If[Denominator[t2]=!=1, \n    Row[{Numerator[t2],\"/\",Denominator[t2]}]];\n  rot = If[TrueQ[Pi/2<Mod[t,2Pi]<3Pi/2],t+Pi,t];\n    {{Opacity[0.3],Line[{o,p}]},\n     Rotate[Inset[Style[\n       Row[{t(180/Pi)Degree, \" = \",tFormat}],\n     FontSize->18], p/2],rot], \n     Text[{Cos[t],Sin[t]},p,-1.3p]}\n];\nGraphics[{\n  Circle[{0,0},1],\n  Table[markings[t],{t,{Pi/6,Pi/4,2Pi/3}}]\n}]\n\n\nIn addition to finishing it, logical enhancements would include: Making the Circle thicker, adjusting the size and/or format of the point labels, adding Points on the boundary, and/or making it dynamic.\nHave fun!\n", "Is there any way to allow a message to appear more than three times before General::stop shuts it off?": "\nYou can do something like this:\nresetMessages[symbol_] := \n With[{mysymbol = symbol}, \n  Unprotect[$MessageList]; $MessageList = \n   DeleteCases[$MessageList, HoldForm[MessageName[mysymbol, _]]]; \n  Protect[$MessageList];]\n\nAnd you will have to call it after each function...\nSqrt[a, b, c, d]; Exp[a, b]; resetMessages[Exp]; Sqrt[a, b, c, d]; \\\nExp[a, b]; resetMessages[Exp]; Sqrt[a, b, c, d]; Exp[a, b]; \\\nresetMessages[Exp]; Sqrt[a, b, c, d]; Exp[a, b]; resetMessages[Exp]; \\\nSqrt[a, b, c, d]; Exp[a, b]; resetMessages[Exp]; Sqrt[a, b, c, d]; \\\nExp[a, b]; resetMessages[Exp]; Sqrt[a, b, c, d]; Exp[a, b]; \\\nresetMessages[Exp];\n\nSqrt::argx: Sqrt called with 4 arguments; 1 argument is expected. >>\n\nExp::argx: Exp called with 2 arguments; 1 argument is expected. >>\n\nSqrt::argx: Sqrt called with 4 arguments; 1 argument is expected. >>\n\nExp::argx: Exp called with 2 arguments; 1 argument is expected. >>\n\nSqrt::argx: Sqrt called with 4 arguments; 1 argument is expected. >>\n\nGeneral::stop: Further output of Sqrt::argx will be suppressed during this calculation. >>\n\nExp::argx: Exp called with 2 arguments; 1 argument is expected. >>\n\nExp::argx: Exp called with 2 arguments; 1 argument is expected. >>\n\nExp::argx: Exp called with 2 arguments; 1 argument is expected. >>\n\nExp::argx: Exp called with 2 arguments; 1 argument is expected. >>\n\nExp::argx: Exp called with 2 arguments; 1 argument is expected. >>\n\n", "A problem with Deploy and Locator in a Manipulate": "\nThis seems to work:\nManipulate[\n DynamicModule[{vector},\n  vector = \n   Graphics[{Green, Arrow[{{0, 0}, Dynamic[p]}], \n     Locator[Dynamic[p, (p = #; x = p[[1]]; y = p[[2]]) &]]}];\n  Deploy@Show[vector,\n    PlotRange -> {{-2.1, 2.1}, {-2.1, 2.1}}, ImageSize -> 500]],\n\n Row[{\"Ax\", Manipulator[Dynamic[x, (x = #; p[[1]] = x) &], {-2, 2}], \n   Spacer[4], Dynamic[x]}], \n Row[{\"Ay\", Manipulator[Dynamic[y, (y = #; p[[2]] = y) &], {-2, 2}], \n   Spacer[4], Dynamic[y]}],\n {{p, {1, 1}}, None},\n {{x, 1}, None},\n {{y, 1}, None}, TrackedSymbols -> {x, y, p}]\n\nThe only difference with the original code is that I've wrapped p with Dynamic in Arrow.\nBy the way, since p == {x,y}, you can actually replace p with {x, y} making the code a bit more elegant in this case:\nManipulate[\n DynamicModule[{vector},\n  vector = \n   Graphics[{Green, Arrow[{{0, 0}, Dynamic[{x, y}]}], \n     Locator[Dynamic[{x, y}]]}];\n  Deploy@Show[vector,\n    PlotRange -> {{-2.1, 2.1}, {-2.1, 2.1}}, ImageSize -> 500]],\n {{x, 1, \"Ax\"}, -2, 2, Appearance -> \"Labeled\"},\n {{y, 1, \"Ay\"}, -2, 2, Appearance -> \"Labeled\"}]\n\n", "front end - CellEvaluationFunction or $PreRead stripping inline cells from text cells": "\nYou're not going to get this to work on raw TextData cells. The FE evaluates TextData cells using EnterTextPacket, which merely sends a string along. And, so, the contents must be encoded as a string. Which means you're going to lose all of your typesetting structure. So, let's assume that you've embedded the above cell in a typeset cell where we'll have some more choices.  E.g.,\nCell[BoxData[Cell[TextData[{\n  \"hello \",\n  Cell[BoxData[\n   FormBox[\n    FractionBox[\"3\", \"x\"], TraditionalForm]]]\n }]]], \"myText\",\n Evaluatable->True,\n CellEvaluationFunction->myEvalFun]\n\nNow the FE is going to send an EnterExpressionPacket which maintains the full box structure, including inline cells, and that we can work with. From that starting point, I wrote a version of myEvalFun which works for your sample input. It's not very robust...in particular, it assumes that the cell contains one TextData cell with, at most, one level of BoxData cells inside of it. And that the contents of the TextData cell contain nothing other than strings and BoxData cells (other valid TextData contents include StyleBoxes, ButtonBoxes, and TextData cells). But I think it'll give you a good starting point to work from.\nmyEvalFun[boxes_, form_] := Module[{inlineExprs, val, topExpr},\n  inlineExprs = \n   Cases[boxes, \n    Cell[val : BoxData[_], ___] :> \n     \"PP\" <> ToString[TeXForm[ToExpression[val, form]]] <> \"PP\", \n    Infinity];\n  topExpr = boxes[[1]] /. Cell[_BoxData, ___] :> \"``\";\n  topExpr = \n   topExpr /. {Cell[TextData[{val___String}], ___] :> StringJoin[val],\n      Cell[val_String] :> val};\n  If[StringQ[topExpr], StringForm[topExpr, Sequence @@ inlineExprs], \n   \"Error\"]]\n\n", "front end - Creating a TeXForm/TraditionalForm/etcForm": "\nThis is far from fully integrated into the system but it is a first order approximation of the behavior of other forms.  Perhaps it will inspire someone else with a better method.\nformfunc =\n  StringReplace[\n    ToString @ #,\n    {\"[\" -> \"(\", \"]\" -> \")\", x : DigitCharacter .. :> \"-->\" <> x <> \"<--\"}\n  ] &;\n\nMakeBoxes[myForm[expr_], StandardForm] := \n  InterpretationBox[#, expr] & @ ToBoxes @ formfunc @ expr\n\nToString[expr_, myForm] ^:= formfunc[expr]\n\nThis provides output that can be re-evaluated to recover the original expression:\n2^(1/2) // myForm\n\n\n\"Sqrt(-->2<--)\"\n\n\nThis produces a normal String:\nToString[2^(1/2), myForm]\n\n\n\"Sqrt(-->2<--)\"\n\n\n", "front end - Getting the complete Cell expression some input would generate as output": "\nI believe that ToBoxes (or possibly MakeBoxes) does what you want.  You would need to wrap the result in a valid Cell expression like this:\ncelldata = Cell[BoxData @ ToBoxes @ #, \"Output\"] &;\n\nSqrt[2^x] // celldata\n\n\nCell[BoxData[SqrtBox[SuperscriptBox[\"2\", \"x\"]]], \"Output\"]\n\n\n", "plotting - Export to PDF - scaling grids of plots and text size": "\nYou should investigate in the Scaled function:\nlots = GraphicsGrid[\n   Table[With[{a = RandomInteger[{1, 17}], \n      b = RandomInteger[{1, 17}]}, \n     ParametricPlot[Sin[t^2] {Cos[a t], Sin[b t]}, {t, 0, 2 \\[Pi]}, \n      PlotRange -> {{-1, 1}, {-1, 1}}, Frame -> True, \n      ImageSize -> Scaled[1]]], {15}, {7}]];\nExport[\"lots.pdf\", lots]\n\n\n", "evaluation - Defining a ForEach function": "\nThe key here is learning about evaluation control.  Please see the tutorials linked from this page.\n\nUse TracePrint to see how it is evaluated and you'll understand.\nIn\nForEach[{m, 3}, {n, 3}]@ToString[m n] \n\nToString[m n] is evaluated to \"m n\" before ForEach even sees it.  Also, if m or n have values, this'll break.  Set a HoldAll attribute in the function:\nClearAll[ForEach]\nSetAttributes[ForEach, HoldAll]\nForEach[iterators__] := Function[arg, Table[arg, iterators], HoldAll]\n\n\nFor the second part simply requires learning about option handling:\nClearAll[ForEach]\nSetAttributes[ForEach, HoldAll]\nOptions[ForEach] = {Pre -> Null}\nForEach[iterators__, OptionsPattern[]] := \n  Function[arg, Table[OptionValue[Pre]; arg, iterators], HoldAll]\n\nk = 0\nForEach[{n, 3}, {m, 3}, Pre :> k++][ToString@{m, n, k}]\n\n\nMaking this is good as a learning exercise, but I find this construct problematic and fragile.  If you want to use this to solve actual problems, other approaches are better.  Why don't you describe the problem that you want to solve?\n", "How get Singular.m package to interact with Singular itself?": "\nI found the same issue and resolved it by changing the name of SingularCommand from just Singular to it's full path at line 245 of the Singular.m package.  On my Mac, this was /usr/local/bin/Singular but your system may be different.\n", "list manipulation - Select/Delete with Sublist elements?": "\nI would use either\nCases[data, {x_, y_} /; Abs[x - y] > 4]\n\nor\nWith[{diff = Abs[data[[All, 1]] - data[[All, 2]]] - 4}, \n   Pick[data, UnitStep[diff]*Unitize[diff], 1]\n]\n\nThe first clearly demonstrates what you are trying to do, the second is much faster...\ndata = RandomInteger[{0, 100}, {10^6, 2}];\n\n(m1 =  Cases[data, {x_, y_} /; Abs[x - y] > 4]); // AbsoluteTiming\n\n==> {2.8393092, Null}\n\n(m2 = \n    With[{diff = Abs[data[[All, 1]] - data[[All, 2]]] - 4}, \n     Pick[data,UnitStep[diff]*Unitize[diff], 1]]); // AbsoluteTiming\n\n==> {0.1248024, Null}\n\nm1 == m2\n\n==> True\n\nAssuming you are working with random data and don't expect equality, the second method can be simplified to...\nPick[data, UnitStep[Abs[data[[All, 1]] - data[[All, 2]]] - 4], 1]\n\nEdit: \nOf course if you want to delete elements where Abs[x-y] > 4 you can modify the Cases definition as \nCases[data, {x_, y_} /; Abs[x - y] <= 4]\n\nAnd the Pick method by swapping out the 1 in the last argument with 0.\n", "programming - How to distinguish between lists and values?": "\nHow about putting the results in a list and then removing unneeded braces.?\na = 76.5\nb = {4, 5, 12.3}\nFlatten[{a}]\nFlatten[{b}]\n\n\nThat way you are always dealing with a list of values.\n\nOr simply place braces around numbers (that are not already in a list):\nIf[NumericQ[x], x = {x}]\n\n", "functions - How to cancel floating point factors?": "\nThe problem is that symbolic computation doesn't mix well with floating point. If you use Rationalize first to convert to an exact representation, Simplify (or the faster Cancel) will be able to do it's job.\n", "calculus and analysis - Finding critical points of a function": "\nSlightly more generally than the solution by @Sjoerd, you may look for roots of the reciprocal function - if you are interested in pole-like or root-like singularities:\nf[x_] := (1 - 2 x)/(2 Sqrt[x - x^2])\n\nReduce[1/f[x] == 0, x]\n\n(*\n  ==> x == 0 || x == 1\n*)\n\n", "front end - automatic coloring of function names": "\nThe difference in color depends on whether or not it is a recognized symbol: black indicates it is recognized, blue indicates that it is not.  For a symbol to be recognized, it has had to have been input to the kernel, i.e. it has to have been included in an executed cell.  I have had problems in the past when quitting and restarting the kernel where the highlighter doesn't begin to work again, so every user defined symbol is blue regardless of its state.  But, I don't think I encountered it very often in v.7; it was more of a v.6 problem. (I just started using v.8, so I have no experience with it.)\n", "plotting - MatrixPlot with Tooltips": "\nThis is just an elaboration of faleichik's answer. To create a MatrixPlot with tooltip labelling and highlighting of the selected square similar to for example BarChart or BubbleChart you could do something like\nmatPlot[mat_, opts : OptionsPattern[]] :=\n With[{dim = Dimensions[mat]},\n  DynamicModule[{pt = {0, 0}, ij, xy, label, direction},\n   direction = 1 - 2 Boole[Thread[# > dim/2]] &;\n   LocatorPane[Dynamic[pt],\n    Dynamic[xy = Floor[pt];\n     ij = {dim[[1]], 1} + Cross[xy];\n     label = If[Nand @@ Thread[1 <= ij <= dim], {},\n       (* else *)\n       {{FaceForm[], EdgeForm[{Thick, LightGray}], Rectangle[xy]},\n        Text[Framed[mat ~Extract~ ij, Background -> White],\n         direction[xy] + xy, -1.2 direction[xy]]}];\n     MatrixPlot[mat, Epilog -> label, opts]],\n    AutoAction -> True,\n    Appearance -> None]\n   ]]\n\nScreenshot\nmat = RandomReal[1, {30, 40}];\nmatPlot[mat, ColorFunction -> \"DeepSeaColors\"]\n\n\n", "graphics - How to hide Box in Graphics3D?": "\nThis should work as you need to feed the option Boxed -> False to Graphics3D and option should be given after the argument in a function.\nsplot1 = SphericalPlot3D[\nCos[\u03b8], {\u03b8, 0, Pi}, {\u03d5, 0, Pi}, Mesh -> None, \nPlotPoints -> 80];\naGraphicsComplex = splot1[[1]];\nGraphics3D[{Lighting -> {{\"Point\", RGBColor[1, .9, .9], {2, 2, 4}}}, \naGraphicsComplex /. \nGraphicsComplex[pts_, objs__] :> \nGraphicsComplex[\n With[{r = 4 Sin[11 (ArcTan[#[[1]], #[[2]]] + #[[3]])]}, {r, r, \n      2} #] & /@ pts, objs]}, Boxed -> False]\n\n\n", "interoperability - How do I call a 32-bit DLL using .NET/Link and a 64-bit version of Mathematica?": "\nThe solution is forcing .NET/Link to load its 32-bit executable instead of the 64-bit one.  Since Mathematica communicated with the .NET/Link process through MathLink, it does not matter if the Mathematica kernel is 64 bit and the .NET/Link executable is a 32 bit version.  They are separate processes.  However, the .NET/Link executable must match the DLL that is being loaded.\nThere is an undocumented option to force loading the 32-bit version of .NET/Link:\nUninstallNET[]\nInstallNET[\"Force32Bit\" -> True]\n\nNow 32-bit DLLs can be loaded through .NET/Link, but 64-bit ones cannot.\n", "evaluation - How to make Mathematica re-evaluate a cell after some event?": "\nThe simplest solution IMHO is using Manipulate. Almost no change in your code is necessary:\nManipulate[\n d = 10000; l1 = {};\n rc := RandomChoice[{a, b} -> {0, 1}];\n c = 1; While[c <= d, AppendTo[l1, rc]; c++];\n Column[\n  {\n   e = ((Count[l1, _] - Count[l1, 0])/d)*100 // N,\n   f = 100 - e\n   }\n  ],\n {a, 2}, {b, 5000},\n TrackedSymbols -> {a, b}\n ]\n\n\n", "graphics - Packed Graph or GraphPlot output with non-square layout?": "\nWell, this is just a workaround.  Let's make a graph:\ng = Graph@Table[i -> Mod[i^3, 300], {i, 1, 300}];\n\nIt looks like this:\nGraphPlot[g, PackingMethod -> \"ClosestPackingCenter\"]\n\n\nLet's break it into two components, distributing connected components of similar sizes equally between the two:\ncc = SortBy[ConnectedComponents@UndirectedGraph[g], Length];\n\nc1 = Flatten[cc[[1 ;; ;; 2]]];\nc2 = Flatten[cc[[2 ;; ;; 2]]];\n\nNow let's show them size by side:\nGraphicsRow[\n GraphPlot[Subgraph[g, #], PackingMethod -> \"ClosestPackingCenter\", \n    PlotRangePadding -> 0] & /@ {c1, c2},\n Spacings -> 0\n ]\n\n\nNot perfect, but might be good enough for a paper or presentation.   This will only look good with the ClosestPackingCenter option but that is what you were asking for specifically.\n\nAlternatively, you can use Heike's packing algorithm.  I used the simplest version because it was faster, but you should use the updated version which produces vector images (it'll be a bit more work though).\nimages = ImageCrop@\n     Rasterize[#, \"Image\", ImageSize -> 50, \n      ImageResolution -> 4 72] & /@ (GraphPlot[Subgraph[g, #], \n       PlotRangePadding -> 0] &) /@ Reverse[cc];\n\npadimg = ImagePad[#, 5, White] & /@ images;\n\niteration[img1_, w_, fun_: (Norm[#1 - #2] &)] := \n Module[{imdil, centre, diff, dimw, padding, padded1, minpos},\n  dimw = ImageDimensions[w];\n  padded1 = ImagePad[img1, {dimw[[1]] {1, 1}, dimw[[2]] {1, 1}}, 1];\n\n  imdil = MaxFilter[Binarize[ColorNegate[padded1], 0.01], \n    Reverse@Floor[dimw/2 + 2]];\n  centre = ImageDimensions[padded1]/2;\n\n  minpos = Reverse@Nearest[Position[Reverse[ImageData[imdil]], 0], \n      Reverse[centre], DistanceFunction -> fun][[1]];\n  diff = ImageDimensions[imdil] - dimw;\n  padding[pos_] := Transpose[{#, diff - #} &@Round[pos - dimw/2]];\n\n  ImagePad[#, (-Min[#] {1, 1 }) & /@ BorderDimensions[#]] &@\n   ImageMultiply[padded1, ImagePad[w, padding[minpos], 1]]]\n\nfun = Norm[{1, 1/2} (#2 - #1)] &;\n\nFold[iteration[##,fun]&, padimg[[1]], Rest[padimg]]\n\n\nMost of the code here is directly copied from her post.\n\nIf we make some effort to preserve sizes as well, we get this:\n\nI used this code to generate the images for this (with some manual tweaking):\nplots = GraphPlot[Subgraph[g, #]] & /@ Reverse[cc];\n\nimages = ImageCrop@\n     Image@Show[#, PlotRange -> 2.5 {{-0.1, 1}, {-0.1, 1}}, \n       ImageSize -> 100] & /@ plots;\n\npadimg = ImagePad[#, 5, White] & /@ images;\n\n", "list manipulation - Conditional Data Selection, efficiency": "\nEDIT\nApparently, I have misunderstood the problem. Here is the solution which, for smaller tests, produces the results identical to the original one:\ngetDistantPoints = \n  Compile[{{pts, _Real, 2}, {delta, _Real}},\n     Module[{res = Table[{0., 0.}, {Length[pts]}], ctr = 1},\n        res[[1]] = pts[[1]];\n        Do[\n          If[Norm[pts[[i]] - res[[ctr]]] > delta, \n            res[[++ctr]] = pts[[i]]\n          ], \n          {i, Length[pts]}];\n        Take[res, ctr]],\n     CompilationTarget -> \"C\", RuntimeOptions -> \"Speed\"]\n\n\nClear[GZFastAlt];\nGZFastAlt[delta_, data_] :=\n  Module[{ldata = data},\n     ParallelTable[\n       Table[\n          getDistantPoints[ldata [[subNO, dispNo, All, ;; 2]], delta],\n          {dispNo, Range[Length[ldata [[subNO]]]]}\n       ], {subNO, Range[5]}]];\n\nand runs in about 2 seconds on my 6 cores:\n(res = GZFastAlt[0.1,allGazesX]);//AbsoluteTiming\n{2.2451172,Null}\n\nEND EDIT\nAs a bonus, this keeps things packed, which is a big deal for your data - even in packed form, the computation consumes quite a bit of memory. \n", "output formatting - How to draw a pane with rounded corners?": "\nComments that are answers should be posted as such.\nFramed[\n  Pane @ Style[\"text is here\", Bold, FontColor -> GrayLevel[0.2]],\n  Background -> Red,\n  RoundingRadius -> 10,\n  FrameStyle -> None,\n  FrameMargins -> 0\n]\n\n\n", "mathematical optimization - Why is this minimization with Boole functions failing?": "\nIt switches to NMinimize (a numerical solver) automatically because you have inexact numbers in the expression, which don't go well with symbolic calculations.\nUse Rationalize to convert them to exact numbers.\nlabmda = 1\n\nMinimize[Rationalize[(x1*1 - 1)^2 + (x1*0.823202 + x2*1 - 0.7551)^2 + \n   lambda*(Boole[x1 != 0] + Boole[x2 != 0])], {x1, x2}]\n\n{420574853802/419415383201, {x1 -> 405399957550/419415383201, x2 -> 0}}\n\nActually I am surprised that Minimize can handle things as general as Boole.\n", "Plotting Partial Sums of Fourier Series": "\nIn the definition of s you're summing from k==0. Since the summand has a term 1/k this gives a divide-by-zero error when calculating the partial sums. The sum should in fact start from k==1 (the zeroth coefficient is taken care of by the constant term in front of the sum). The first few approximations then look like\ns[n_, x_] := \n 8/4 + 3/(9 \u03c0) Sum[(6 (-1)^k)/(k \u03c0) Cos[(k \u03c0 x)/\n        2] + (16 (-1)^k + 13)/(\u03c0 k) Sin[(k \u03c0 x)/2], {k, 1, n}]\n\npartialsums = Table[s[n, x], {n, 1, 5}];\nPlot[Evaluate[partialsums], {x, -4, 4}]\n\n\nTo compare this with f we plot the s[5,x] and f in the same plot:\nPlot[{s[5, x], f[x]}, {x, -2, 2}]\n\n\nwhich doesn't seem right to me, so I suspect you made a mistake somewhere in calculating the coefficients.\nCalculating coefficients by hand\nWe could use FourierSeries to calculate the partial sums, but this is very slow, and  doesn't give produce the general equation for the coefficients. Therefore it's better to calculate the coefficients by hand. The $n$-th coefficient can be calculated according to\ncoeff[0] = 1/4 Integrate[f[x], {x, -2, 2}];\ncoeff[n_] = 1/4 Integrate[f[x] Exp[I Pi n x/2], {x, -2, 2}]\n\n\n(1/(2 n^4 \u03c0^4))E^(-I n \u03c0) (-48 + 48 E^(I n \u03c0) - \n 48 I n \u03c0 + 28 n^2 \u03c0^2 - 6 E^(I n \u03c0) n^2 \u03c0^2 + \n 2 E^(2 I n \u03c0) n^2 \u03c0^2 + 12 I n^3 \u03c0^3 - \n I E^(I n \u03c0) n^3 \u03c0^3 - I E^(2 I n \u03c0) n^3 \u03c0^3)\n\n\nThen the partial sums are given by\nseries[m_, x_] := Sum[Exp[-I Pi n x/2] coeff[n], {n, -m, m}]\n\nPlotting the first few approximations:\nPlot[Evaluate[Table[series[j, x], {j, 0, 5}]], {x, -6, 6}]\n\n\nTo see how this compares with the original function f:\nPlot[Evaluate[{series[5, x], f[Mod[x, 4, -2]]}], {x, -4, 4}]\n\n\nwhich looks a lot better than the before.\nEdit: Real coefficients\nHere, coeff[n] are the coefficients for the Fourier series in exponential form, but these can be easily converted to the coefficients for the $\\cos$ and $\\sin$ series, a_n and b_n, by doing something like\na[0] = coeff[0];\na[n_] = Simplify[ComplexExpand[coeff[n] + coeff[-n]]];\nb[n_] = Simplify[ComplexExpand[I (coeff[n] - coeff[-n])]];\n\n", "plotting - How to improve this code for exploring large matrices?": "\nUsing mtrxPlot2 from my answer to the cited question inside Pane\n   Pane[mtrxPlot2[A, ImageSize -> 9 m, Mesh -> All], {500, 500}, \n   Scrollbars -> True]\n\none cane exploit the built-in tooltip and copy features of the Get Coordinates Tool (clicking on the graph and hitting \".\" or using the context menu).\nmtrxPlot2[mat_, opts : OptionsPattern[]] := \nWith[{dims = Dimensions[mat], \nindx = {Clip[Floor[#1[[1]] - #2[[2]]] + 1, {1, #1[[1]]}], \nClip[Floor[#2[[1]]] + 1, {1, #1[[2]]}]} &}, \nWith[{copiedvalues = \"CopiedValueFunction\" -> Function[pt,\n{indx[dims, pt], Extract[mat, indx[dims, pt]]}], \ncoordtooltips = \"DisplayFunction\" -> Function[pt,\nRow[{\"mat[[\", Row[indx[dims, pt], \",\"], \"]]  =  \", \nExtract[mat, indx[dims, pt]]},\n Background -> White, ImageSize -> {Automatic, 30}, \n ImageMargins -> {{5, 5}, {10, 10}}, Alignment -> Center]]}, \nMatrixPlot[mat, opts, \nCoordinatesToolOptions -> {coordtooltips, copiedvalues}]]]\n\nScreenshot:\n\n", "list manipulation - What is the right way to rotate an array?": "\nI realise that this doesn't fully answer the question, but for the special case of square matrices, there's already a suitable function: Image`MorphologicalOperationsDump`SquareMatrixRotate (which, no doubt, is how Sjoerd's suggestion works internally). This is undocumented, of course!\nThe implementation is the following (modulo some bugs I've fixed--i and j were not localized in the original, leading to problems if you want to rotate a matrix containing these symbols, there were no conditions on the arguments, and [admittedly, a minor point] the rotation matrix was numericized only after inversion, which is inefficient):\nSquareMatrixRotate[mat_?MatrixQ, angle_?NumericQ] /; Equal @@ Dimensions[mat] :=\n Module[{\n   inv, dim, ct,\n   i, j,\n   ii, jj\n  },\n  inv = Inverse@RotationMatrix@N[angle];\n  dim = First@Dimensions[mat];\n  ct = (dim + 1)/2;\n  Table[\n   {ii, jj} = MapThread[\n     Clip[#1, {1, #2}, {1, 1}] &,\n     {Round[inv.{i - ct, j - ct} + {ct, ct}], {dim, dim}}\n   ];\n   mat[[ii, jj]],\n   {i, dim}, {j, dim}\n  ]\n ]\n\nIs it in any sense better than your existing methods? Well, you can rotate by an arbitrary angle, although the results may not make much sense for angles for which no \"natural\" rotation is possible. Other than that, I would say no: personally, I would have used Reverse as you did.\n", "scoping - Notation for specifying transformation rules": "\nI am not an expert on scoping constructs... Replacement rules aren't very respectful of inner scoping constructs, of the expression in which they are replacing. They seem to be respectful however of the scoping constructs of the expression they are building.\nSo, for example\nHold[val /. x_ /; cond :> res] /. cond :> x\n\nreturns\nHold[val /. x_ /; x :> res]\n\nbut, like your example\n{1, x>0, -x}/.{val_,cond_,res_}:>(val/. x_/;cond:>res)\n\nreturns\n1/. x$_/;x>0:>-x\n\nIn any case, we need to avoid the rescoping. Many ways to do this, but one would be to simply prevent the replacer to see your x_ as a scoped variable when it does the replacing\nAttributes[f] = {HoldRest};\nf[val_, cond_, res_] := val /. Pattern @@ Hold[x, _] /; cond :> res\n\nIn place of Pattern @@ Hold[x, _] you can put anything that evaluates to x_ without having it explicitly. You coudl make your own function, write Pattern[x, Sequence[], _], Union@Pattern[x, _, _], Identity[Pattern][x, _], Evaluate[Pattern][x, _], Reverse[Pattern[_, x]], ToExpression[\"x_\"], Pattern @@ (x _) (notice the space, could be a +). In those cases that don't hold its arguments, however, you would need to add an Unevaluated to avoid problems if x is defined\n@WReach's good suggestions in the comments are based on this too, on hiding the x_ as a scoped variable when the replacement is done, by injecting them later\nEdit\nThings like Pattern[x, 1 _^1+0] or stuff like that with the same structure (head Pattern2 arguments, won't work because it recognises it as a pattern)\nOk, I said there are many ways, so I'll give another example... Another way to implement the above is to lexically scope your Pattern so it isn't a pattern but you can type it as such. It probably only makes sense if your rhs is big and the lhs is small, but it also has the advantage of working when the pattern is inside held constructs. By the way, I never saw this done so I reserve the right to be suggesting something stupid and abstruse. In any case, its instructive and you wanted to learn, hehe\nAttributes[f] = {HoldRest};\nWith[{rp = Pattern}, Module[{Pattern},\n  f[rp[val, _], rp[cond, _], rp[res, _]] := Unevaluated@\n     (val /. x_ /; cond :> res)\n    /. Pattern :> rp]]\n\nSo, when you write your code, you can use x_ as you wish, because it will be interpreted as some Pattern$ASk that's not a scoping contruct. You use rp for those that you wish to become real patterns at definition time and _ those who you want to turn into patterns at execution time.\nAnother idea is, instead of hiding the scoping variable, hide the scoping constructs until runtime\nAttributes[f] = {HoldRest};\nWith[{Condition = Hold[Condition], RuleDelayed = Hold[RuleDelayed], \n  ReplaceAll = Hold[ReplaceAll]},\n SetDelayed @@ \n  Hold[f[val_, cond_, res_], ReleaseHold[val /. x_ /; cond :> res]]\n ]\n\nIn order for the With to work you need to do something like that SetDelayed@@ because that's another scoping construct that With won't go into willingly. So, in this example, you see two layers of the trick.\n", "plotting - How to plot Venn diagrams with Mathematica?": "\nBased on that outdated notebook, I did the following function:\nVennDiagram2[n_, ineqs_: {}] := \n Module[{i, r = .6, R = 1, v, grouprules, x, y, x1, x2, y1, y2, ve},\n  v = Table[Circle[r {Cos[#], Sin[#]} &[2 Pi (i - 1)/n], R], {i, n}];\n  {x1, x2} = {Min[#], Max[#]} &[\n    Flatten@Replace[v, \n      Circle[{xx_, yy_}, rr_] :> {xx - rr, xx + rr}, {1}]];\n  {y1, y2} = {Min[#], Max[#]} &[\n    Flatten@Replace[v, \n      Circle[{xx_, yy_}, rr_] :> {yy - rr, yy + rr}, {1}]];\n  ve[x_, y_, i_] := \n   v[[i]] /. Circle[{xx_, yy_}, rr_] :> (x - xx)^2 + (y - yy)^2 < rr^2;\n  grouprules[x_, y_] = \n   ineqs /. \n    Table[With[{is = i}, Subscript[_, is] :> ve[x, y, is]], {i, n}];\n  Show[\n   If[MatchQ[ineqs, {} | False], {},\n    RegionPlot[grouprules[x, y],\n     {x, x1, x2}, {y, y1, y2}, Axes -> False]\n    ],\n   Graphics[v]\n   , PlotLabel -> \n    TraditionalForm[Replace[ineqs, {} | False -> \u2205]], \n   Frame -> False\n   ]\n  ]\n\nWhich can have as inequallity any logical expression with subscripts:\n\n\n\nEDIT: It works with more than 3 groups!\n\nEDIT2: As Brett says, some cases of 5 doesn't work, like VennDiagram2[5, Subscript[A, 1] && ! (Subscript[A, 2] || Subscript[A, 5]) && Subscript[A, 3] && Subscript[A, 4]], but for example if you change the order to something else it works: VennDiagram2[5, Subscript[A, 1] && ! (Subscript[A, 3] || Subscript[A, 4]) && Subscript[A, 2] && Subscript[A, 5]]. So an intelligent way of sorting the circles should be needed for complex cases.\n", "graphics - Create a \"perspective animation\"": "\nIt could be something like this?\noutersquare = {{-1, -.8}, {1, .8}};\n\ninnersquare = outersquare/10. + {-.1, 0};\n\ncorners[sq_] := {sq[[1]], {sq[[1, 1]], sq[[2, 2]]}, \n   sq[[2]], {sq[[2, 1]], sq[[1, 2]]}};\n\nlines[sq_] := Partition[corners[sq], 2, 1, 1];\n\npointOfSquare[sq_, side_, i_, n_] := \n  With[{line = lines[sq][[side]]}, \n   line[[1]] + (n - i)/n (line[[2]] - line[[1]])];\n\nalllines := \n  With[{n = 20}, \n   Flatten@Table[\n     Line[{pointOfSquare[innersquare, side, i, n], \n       pointOfSquare[outersquare, side, i, n]}], {side, 4}, {i, 0, \n      n}]];\n\nrectangle[i_, n_] := \n  With[{factor = Log[i]/Log[n]}, \n   Rectangle @@ (factor innersquare + (1 - factor) outersquare)];\n\nAnimate[Graphics[{Red, alllines, EdgeForm[Red], FaceForm[Transparent],\n    Table[rectangle[i, 10], {i, 1 + ministep, 10, 1}]}], {ministep, \n  .99, 0, -.01}]\n\n\nEDIT: Adding \"moving background\":\nalllines2[shift_] := \n  With[{n = 20}, \n   Flatten@Table[\n     Line[{pointOfSquare[innersquare, side, i, n], \n       pointOfSquare[outersquare, side, i, n]}], {side, 4}, {i, shift,\n       n, 1}]];\n\nAnimate[Graphics[{Red, alllines2[ministep], EdgeForm[Red], \n   FaceForm[Transparent], \n   Table[rectangle[i, 10], {i, 1 + ministep, 10, \n     1}]}], {ministep, .99, 0, -.01}]\n\nEDIT2: Adding moving points (if you want to take out the red lines, get rid of alllines).\npointInLine[linepoints_, i_, shift_, n_] := \n If[i + shift < n, \n  With[{factor = Log[i + shift]/Log[n]}, \n   Point[linepoints[[1, \n       1]] + (1 - factor) (linepoints[[1, 2]] - \n        linepoints[[1, 1]])]], {}]\n\nallPoints[linesperside_, shift_, n_] := \n  With[{lines = \n     Flatten@Table[\n       Line[{pointOfSquare[innersquare, side, i, linesperside], \n         pointOfSquare[outersquare, side, i, linesperside]}], {side, \n        4}, {i, 0, linesperside}]},\n   Flatten[\n    Table[pointInLine[line, i, shift, n], {line, lines}, {i, n}]]];\n\nAnimate[Graphics[{Red, alllines, Blue, PointSize[Medium], \n   allPoints[4, ministep, 10], EdgeForm[Red], FaceForm[Transparent], \n   Table[rectangle[i, 10], {i, 1 + ministep, 10, \n     1}]}], {ministep, .99, 0, -.01}]\n\nIn conclusion, I use as \"move\" factor Log[i+shift]/Log[n], so for each frame, the change from the previous one is that shift value (between 0 and 1).\n", "graphics - Drawing Rotated views while ignoring the Bounding box": "\nThe variation in size is due to variation in camera position and viewing angle. Since ViewPoint uses special coordinates which depend on the bounding box it's better to use ViewVector instead (or even ViewMatrix if you can make it work). To keep the viewing angle fixed you should give an explicit value for ViewAngle. To place the object at the right position in the field of view you could use ViewCentre. For the example above you could do something like\ncubes = Table[\n  Graphics3D[{Rotate[cube, x, {1, 1, 1}, {0, 0, 0}]}, \n   ViewVector -> {3, 1/2, -2}, \n   ViewAngle -> 35 Degree,\n   ViewCenter -> {.5, .5, .5},\n   ViewVertical -> {1, 1, 1}, Boxed -> False],\n  {x, 0, 2 Pi/3 - Pi/48, Pi/24}]\n\n", "front end - Opening a context menu (with the Menu key)": "\nThis isn't a full answer, but maybe those with more knowledge can take it from here. \nTo capture key presses of a particular key, one can do the following:\nk=0;\nSetOptions[$FrontEndSession, \n FrontEndEventActions -> {{\"KeyDown\", \"q\"} :> (++k), PassEventsDown -> True}\n]\n\nThe previous example increments k each time the letter q is pressed. Note: the \"PassEventsDown\" is important. Without it, q won't ever actually show up in your notebook. \nTo do more fun things, you can try to call a front end element with the following:\nFrontEndTokenExecute[\"CellContextDialog\"]\n\nThis automatically launches the front end dialog that is mentioned. A full list of Front End Tokens is available here. Putting things together:\nSetOptions[$FrontEndSession, \n FrontEndEventActions -> {{\"KeyDown\", \"q\"} :> (++k; \n     FrontEndTokenExecute[\"CellContextDialog\"]), \n   PassEventsDown -> True}\n]\n\nThere are two problems here:\n\nI don't know if there is a FrontEndToken corresponding to the \"Right Click\" / \"Contxt\" menu\nI don't know if there is a name for the Menu Key\nI have no idea what I'm doing with the SetOptions[$FrontEndSession]... I might have broken other things. \n\nMaybe you can hack together something from this!\n", "undocumented - What is the complete list of valid Front End Tokens?": "\nI got a request to post here the undocumented tokens I already posted in an old answer on SO.\nFor completion, I merged my list (which is also in the link provided by @Chris) with @Rojo's list. Later, the list was merged with Vladimir's list below and two more tokens were included, so as to have here a repository of all known FE tokens.\nPlease feel free to update this answer as new tokens are found. \n{\n\"AboutBoxDialog\",\n\"Above\",\n\"AlignBottoms\",\n\"AlignCentersHorizontally\",\n\"AlignCentersVertically\",\n\"AlignLeftSides\",\n\"AlignRightSides\",\n\"AlignTops\",\n\"AllWindowsFront\",\n\"BackgroundDialog\",\n\"Balance\",\n\"Below\",\n\"BringToFront\",\n\"CellContextDialog\",\n\"CellGroup\",\n\"CellLabelsToTags\",\n\"CellMerge\",\n\"CellSplit\",\n\"CellTagsEditDialog\",\n\"CellTagsEmpty\",\n\"CellTagsFind\",\n\"CellUngroup\",\n\"Clear\",\n\"ClearCellOptions\",\n\"ClearNoAutoScroll\",\n\"Close\",\n\"CloseAll\",\n\"CloseMain\",\n\"ColorSelectorDialog\",\n\"ColorsPanel\",\n\"CompleteSelection\",\n\"Copy\",\n\"CopyCell\",\n\"CopySpecial\",\n\"CreateCounterBoxDialog\",\n\"CreateGridBoxDialog\",\n\"CreateHyperlinkDialog\",\n\"CreateInlineCell\",\n\"CreateValueBoxDialog\",\n\"Cut\",\n\"CycleNotebooksBackward\",\n\"CycleNotebooksForward\",\n\"DebuggerAbort\",\n\"DebuggerClearAllBreakpoints\",\n\"DebuggerContinue\",\n\"DebuggerContinueToSelection\",\n\"DebuggerFinish\",\n\"DebuggerResetProfile\",\n\"DebuggerShowProfile\",\n\"DebuggerStep\",\n\"DebuggerStepIn\",\n\"DebuggerStepInBody\",\n\"DebuggerStepOut\",\n\"DebuggerToggleBreakpoint\",\n\"DebuggerToggleWatchpoint\",\n\"DeleteBibAndNotes\",\n\"DeleteBibReference\",\n\"DeleteGeneratedCells\",\n\"DeleteIndent\",\n\"DeleteInvisible\",\n\"DeleteNext\",\n\"DeleteNextExpression\",\n\"DeletePrevious\",\n\"DeletePreviousWord\",\n\"DistributeBottoms\",\n\"DistributeCentersHorizontally\",\n\"DistributeCentersVertically\",\n\"DistributeLeftSides\",\n\"DistributeRightSides\",\n\"DistributeSpaceHorizontally\",\n\"DistributeSpaceVertically\",\n\"DistributeTops\",\n\"DuplicatePreviousInput\",\n\"DuplicatePreviousOutput\",\n\"EditBibNote\",\n\"EditStyleDefinitions\",\n\"EnterSubsession\",\n\"Evaluate\",\n\"EvaluateCells\",\n\"EvaluateInitialization\",\n\"EvaluateNextCell\",\n\"EvaluateNotebook\",\n\"EvaluatorAbort\",\n\"EvaluatorHalt\",\n\"EvaluatorInterrupt\",\n\"EvaluatorQuit\",\n\"EvaluatorStart\",\n\"ExitSubsession\",\n\"ExpandSelection\",\n\"ExpirationDialog\",\n\"ExplainBeepDialog\",\n\"ExplainColoringDialog\",\n\"ExpressionLinewrap\",\n\"FileNameDialog\",\n\"FindDialog\",\n\"FindEvaluatingCell\",\n\"FindNextMatch\",\n\"FindNextMisspelling\",\n\"FindNextWarningColor\",\n\"FindPreviousMatch\",\n\"FinishNesting\",\n\"FixCellHeight\",\n\"FixCellWidth\",\n\"FontColorDialog\",\n\"FontFamilyB\",\n\"FontPanel\",\n\"FontSizeDialog\",\n\"Fraction\",\n\"FrontEnd`ButtonNotebook[]\",\n\"FrontEnd`EvaluationNotebook[]\",\n\"FrontEndHide\",\n\"FrontEnd`InputNotebook[]\",\n\"FrontEnd`MessagesNotebook[]\",\n\"FrontEnd`Private`nb\",\n\"FrontEndQuit\",\n\"FrontEndQuitNonInteractive\",\n\"FrontEndToken[FrontEnd`ButtonNotebook[],\\\"HyperlinkGo\\\",`distance`]\",\n\"GenerateImageCaches\",\n\"GenerateNotebook\",\n\"GeneratePalette\",\n\"GraphicsAlign\",\n\"GraphicsBoxOptionsImageSize\",\n\"GraphicsCoordinatesDialog\",\n\"GraphicsOriginalSize\",\n\"GraphicsPlotRangeAll\",\n\"GraphicsPlotRangeAutomatic\",\n\"GraphicsPlotRangeFixed\",\n\"GraphicsRender\",\n\"Group\",\n\"HandleShiftReturn\",\n\"HeadersFootersDialog\",\n\"HelpDialog\",\n\"HyperlinkGo\",\n\"HyperlinkGoBack\",\n\"HyperlinkGoForward\",\n\"ImageToAutomatic\",\n\"ImageToBinary\",\n\"ImageToBit\",\n\"ImageToBit16\",\n\"ImageToByte\",\n\"ImageToCMYK\",\n\"ImageToggleAlphaChannel\",\n\"ImageToggleInterleaving\",\n\"ImageToGrayscale\",\n\"ImageToHSB\",\n\"ImageToReal\",\n\"ImageToReal32\",\n\"ImageToRGB\",\n\"Import\",\n\"ImportPictures\",\n\"ImportStyleDefinitions\",\n\"Indent\",\n\"InsertBibAndNotes\",\n\"InsertBibNote\",\n\"InsertBibReference\",\n\"InsertClipPlane\",\n\"InsertMatchingBraces\",\n\"InsertMatchingBrackets\",\n\"InsertMatchingParentheses\",\n\"InsertNewGraphic\",\n\"InsertObject\",\n\"InsertRawExpression\",\n\"InsertSoftReturn\",\n\"InsertSplitBreak\",\n\"LicAuthFailureDialog\",\n\"Linebreak\",\n\"MacintoshOpenDeskAccessory\",\n\"MakeSelectionNotSpan\",\n\"MakeSelectionSpan\",\n\"MenuListBoxFormFormatTypes\",\n\"MenuListCellEvaluators\",\n\"MenuListCellTags\",\n\"MenuListCommonDefaultFormatTypesInput\",\n\"MenuListCommonDefaultFormatTypesInputInline\",\n\"MenuListCommonDefaultFormatTypesOutput\",\n\"MenuListCommonDefaultFormatTypesOutputInline\",\n\"MenuListCommonDefaultFormatTypesText\",\n\"MenuListCommonDefaultFormatTypesTextInline\",\n\"MenuListConvertFormatTypes\",\n\"MenuListDisplayAsFormatTypes\",\n\"MenuListExportClipboardSpecial\",\n\"MenuListFonts\",\n\"MenuListFontSubstitutions\",\n\"MenuListGlobalEvaluators\",\n\"MenuListHelpWindows\",\n\"MenuListNotebookEvaluators\",\n\"MenuListNotebooksMenu\",\n\"MenuListPackageWindows\",\n\"MenuListPalettesMenu\",\n\"MenuListPaletteWindows\",\n\"MenuListPlayerWindows\",\n\"MenuListPlugInCommands\",\n\"MenuListPrintingStyleEnvironments\",\n\"MenuListQuitEvaluators\",\n\"MenuListRelatedFilesMenu\",\n\"MenuListSaveClipboardSpecial\",\n\"MenuListScreenStyleEnvironments\",\n\"MenuListStartEvaluators\",\n\"MenuListStyleDefinitions\",\n\"MenuListStyles\",\n\"MenuListStylesheetWindows\",\n\"MenuListTextWindows\",\n\"MenuListWindows\",\n\"ModifyBoxFormFormatTypes\",\n\"ModifyDefaultFontProperties\",\n\"ModifyEvaluatorNames\",\n\"ModifyFontSubstitutions\",\n\"ModifyNotebooksMenu\",\n\"ModifyRelatedFiles\",\n\"MoveBackward\",\n\"MoveExpressionEnd\",\n\"MoveForward\",\n\"MoveLineBeginning\",\n\"MoveLineEnd\",\n\"MoveNext\",\n\"MoveNextCell\",\n\"MoveNextExpression\",\n\"MoveNextLine\",\n\"MoveNextPlaceHolder\",\n\"MoveNextWord\",\n\"MovePrevious\",\n\"MovePreviousExpression\",\n\"MovePreviousLine\",\n\"MovePreviousPlaceHolder\",\n\"MovePreviousWord\",\n\"MoveToBack\",\n\"MoveToFront\",\n\"New\",\n\"NewCDFNotebook\",\n\"NewColumn\",\n\"NewPackage\",\n\"NewRow\",\n\"NewText\",\n\"NextFunctionTemplate\",\n\"NotebookMail\",\n\"NotebookMailSelection\",\n\"NotebookOneNote\",\n\"NotebookOneNoteSelection\",\n\"NotebookStatisticsDialog\",\n\"NudgeDown\",\n\"NudgeLeft\",\n\"NudgeRight\",\n\"NudgeUp\",\n\"Open\",\n\"OpenCloseGroup\",\n\"OpenFromNotebooksMenu\",\n\"OpenFromNotebooksMenuEmpty\",\n\"OpenFromPalettesMenu\",\n\"OpenFromRelatedFilesMenu\",\n\"OpenHelpLink\",\n\"OpenSelection\",\n\"OpenSelectionParents\",\n\"OpenURL\",\n\"OptionsDialog\",\n\"Otherscript\",\n\"PasswordDialog\",\n\"Paste\",\n\"PasteApply\",\n\"PasteApplyNoAutoScroll\",\n\"PasteDiscard\",\n\"PasteDiscardNoAutoScroll\",\n\"PasteSpecial\",\n\"Placeholder\",\n\"PlainFont\",\n\"PreferencesDialog\",\n\"PreviousFunctionTemplate\",\n\"PrintDialog\",\n\"PrintOptionsDialog\",\n\"PrintSelectionDialog\",\n\"PublishToPlayer\",\n\"Radical\",\n\"RebuildBibAndNotes\",\n\"RebuildHelpIndex\",\n\"RecordSoundDialog\",\n\"RefreshDynamicObjects\",\n\"RelatedFilesMenu\",\n\"RemoveAdjustments\",\n\"RemoveFromEvaluationQueue\",\n\"Replace\",\n\"ReplaceAll\",\n\"ReplaceFind\",\n\"ReplaceParent\",\n\"ResetDefaultsText\",\n\"ReverseQuote\",\n\"Revert\",\n\"RunColorDialog\",\n\"RunEdgeColorDialog\",\n\"RunFaceColorDialog\",\n\"Save\",\n\"SaveRename\",\n\"SaveRenameSpecial\",\n\"ScrollLineDown\",\n\"ScrollLineUp\",\n\"ScrollNotebookEnd\",\n\"ScrollNotebookStart\",\n\"ScrollPageBottom\",\n\"ScrollPageDown\",\n\"ScrollPageFirst\",\n\"ScrollPageLast\",\n\"ScrollPageNext\",\n\"ScrollPagePrevious\",\n\"ScrollPageTop\",\n\"ScrollPageUp\",\n\"SelectAll\",\n\"SelectGeneratedCells\",\n\"SelectionAnimate\",\n\"SelectionBrace\",\n\"SelectionBracket\",\n\"SelectionCloseAllGroups\",\n\"SelectionCloseUnselectedCells\",\n\"SelectionConvert\",\n\"SelectionConvertB\",\n\"SelectionDisplayAs\",\n\"SelectionDisplayAsB\",\n\"SelectionHelpDialog\",\n\"SelectionOpenAllGroups\",\n\"SelectionParenthesize\",\n\"SelectionSaveSpecial\",\n\"SelectionScroll\",\n\"SelectionSetFind\",\n\"SelectionSpeak\",\n\"SelectionSpeakSummary\",\n\"SelectionUnbracket\",\n\"SelectLineBeginning\",\n\"SelectLineEnd\",\n\"SelectNext\",\n\"SelectNextExpression\",\n\"SelectNextLine\",\n\"SelectNextWord\",\n\"SelectNotebookWindow\",\n\"SelectPrevious\",\n\"SelectPreviousExpression\",\n\"SelectPreviousLine\",\n\"SelectPreviousWord\",\n\"ServerText\",\n\"SetCitationStyle\",\n\"SetDefaultGraphic\",\n\"ShortNameDelimiter\",\n\"SimilarCellBelow\",\n\"SoundPlay\",\n\"SpellCheckerDialog\",\n\"StackWindows\",\n\"Style\",\n\"StyleDefinitionsOther\",\n\"StyleOther\",\n\"Subscript\",\n\"SubsessionEvaluateCells\",\n\"Superscript\",\n\"SystemPrintOptionsDialog\",\n\"Tab\",\n\"TemplateSelection\",\n\"TestEvaluateNotebook\",\n\"TileWindowsTall\",\n\"TileWindowsWide\",\n\"ToggleAlignmentGuides\",\n\"ToggleDebugFlag\",\n\"ToggleDynamicUpdating\",\n\"ToggleGrayBox\",\n\"ToggleOptionListElement\",\n\"ToggleShowExpression\",\n\"ToggleTestingFlag\",\n\"TrustNotebook\",\n\"Undo\",\n\"Ungroup\",\n\"WelcomeDialog\",\n\"WindowMiniaturize\",\n\"XInfoDialog\",\n\"ZoomWindow\",\n\"$CellContext`inputnb$$\",\n\"$CellContext`sourceNotebook$$\"\n}\n\nQuoting John Fultz when he gave the list in Jan 2009:\n\nThe list is comparatively complete, excepting option names (which can\n  also be used as tokens)\nThe MenuList tokens don't do anything.  They're just menu\n  placeholders.  Here's something interesting you can do with them...\nDynamicModule[{font}, \n Row[{PopupMenu[Dynamic[font], \n    FE`Evaluate[FEPrivate`GetPopupList[\"MenuListFonts\"]]], Spacer[20],\n    Style[\"The quick brown fox\", 20, FontFamily -> Dynamic[font]]}]]\n\nFE`Evaluate[FEPrivate`GetPopupList[#]]& returns values appropriate\n  for  PopupMenu, and several FE interfaces take advantage of this, so\n  it's unlikely to  change in the future (although I wouldn't be\n  surprised if such useful  functionality makes its way into much\n  simpler a top-level function some day).\n\nEdit by Jacob\nLet's call the list that was here before I made my edit originalList. The list found by Vladimir (vladimirList), contains most of the items in originalList. The items that were in originalList, but not in vladimirList (Complement[originalList, vladimirList]) are the following.\n{\"FrontEnd`ButtonNotebook[]\",\"FrontEnd`EvaluationNotebook[]\",\n\"FrontEnd`InputNotebook[]\",\"FrontEnd`MessagesNotebook[]\",\n\"FrontEnd`Private`nb\",\n\"FrontEndToken[FrontEnd`ButtonNotebook[],\\\"HyperlinkGo\\\",`distance`]\",\n\"$CellContext`inputnb$$\",\"$CellContext`sourceNotebook$$\"}\n\nI am not sure how these items work and they seem to be different from other tokens. Probably reading the quote by John Fultz is a good first step towards understanding them. \nThe vladimirList contains a lot of tokens that were not present in the original list. So great work by Vladimir. Even if you do not understand/like the \"special tokens\" that are in Complement[originalList, vladimirList], please realise that vladimirList is not exhaustive anyway, as it also does contain\n{\"SelectNextExpression\", \"SelectPreviousExpression\"};\n\n", "equation solving - Solve in terms of specific variables": "\nWell, I'm not an expert on this and I always fight when I do these stuff, but this is what I think.\nYou are using symbols in your equations. To Mathematica, this probably means that they are something unkown but that something could be anything. If you put the symbols as last arguments, those are the ONLY symbols it will try to \"generate conditions\" to make the equations fit, for ANY value of the other symbols... (this is a generality. Read the long help then. You can set domain specifications, or quantifiers like Exists)\nSo, for example, \nSolve[x == y && x == -y, x]\n\nwill give an empty list even though y=0 is a solution. So in that case you have two options. Either specify y as a symbol to solve too\nIn[22]:= Solve[x == y && x == -y, {x, y}]\n\nOut[22]= {{x -> 0, y -> 0}}\n\nor use some version that will generate the conditions on y\nSolve[x == y && x == -y]\n\n\n{{x -> 0, y -> 0}}\n  or\n\nReduce[x == y && x == -y]\n\n\ny == 0 && x == 0\n\nYou could also explicitly ask solve to eliminate y\nSolve[x == y && x == -y, x, {y}]\n\nwhich is equivalent to\nSolve[Exists[y, x == y && x == -y], x]\n\n\n{{x -> 0}}\n  Back to your case. Conclusion: either use reduce or add more symbols to the variable list. I can definitely find values for a2x, T, m1, g, that make the last two equations impossible to be satisfied.\n\n", "performance tuning - Are there rules of thumb for knowing when RandomVariate is more efficient than RandomReal?": "\nIn general you should use RandomVariate for distributions and RandomReal for uniforms. Often RandomVariate calls RandomReal or RandomInteger under the hood but it varies on a distribution by distribution basis. After loading any necessary symbols, on evaluation, any timing differences should be negligible. \nRandomVariate is intended to give the flexibility to not have to think of whether the distribution is continuous or discrete (or mixed), it has also been optimized for each distribution in the system. One should always be able to use RandomInteger or RandomReal if the type is known ahead of time (and is not mixed or fuzzy in some way e.g. EmpiricalDistribution) but again, most of the overhead is in initializing the generator so if you are generating a large number of random numbers you shouldn't notice a big difference in timings after evaluating both RandomVariate and RandomReal/RandomInteger.\n", "How to extract and assign output of Free-Form input to a variable?": "\nYou can use a slightly different query: (convert 1 atm to pascals)/pascals\n\nThe number in this case is a regular number (not a string or some other exotic construction.)\n\nIf you instead use Wolfram|Alpha query (shortcut ==), you get a lot of results:\n\nwith a + icon on the right of each.  Clicking on the + gives a menu where you can choose a format:\n\nIn particular the 'Number data' format will then paste something like\nWolframAlpha[\"convert 1 atm to pascals\", {{\"Result\", 1}, \"NumberData\"}]\n\n\n101325\n\n\ninto the notebook.  This doesn't help you much the first time, but can be used programmatically for subsequent calculations.\n", "differential equations - PDE Boundary Conditions": "\nYou may be able to to this with an \"EventLocator\". Have a look at the documentation: tutorial/NDSolveEventLocator. Unfortunately, you do not give all information in your post, i.e the all functions. Those, however, would be needed to give a definite answer.\n", "output formatting - Rearranging a Polynomial": "\nYou were definitely on the right track with MonomialList. Here is a solution. Others will probably find nicer ways. Using the trick found here, we first define a Format that looks like \"Plus\" but doesn't rearrange things:\nFormat[myPlus[expr__]] := Row[Riffle[{expr}, \"+\"]]\n\nWith this format in hand, we can wrap your original function in the following:\nmyPolynomial[n_Integer] := myPlus @@ RotateRight[Sort@MonomialList[psd[n]], n]\n\nThe Sort places things in what MMA considers canonical order. Lucky for us, it happens to put all the $\\sigma_{1,2} w_1w_2$-like terms together first. Then we rotate the list using RotateRight. Since we know there will be n functions of the type $w_1^2\\sigma_1^2$, we rotate it that many places. Using the non-rearranging form of plus, we get the desired result!\n", "linear algebra - Trying to simplify Root expressions from the output of Eigenvalues": "\nThe reason why you can't get a simple expression for eigenvalues is that the characterisitc polynomial of matrixA is not factorizable (in general) to lower order polynomials, unlike for matrixB.   \nCharacteristicPolynomial[matrixA, x] // Factor\n\n\nCharacteristicPolynomial[matrixB, x] // Factor\n\n\nThere is no general method of solving sixth order polynomial equations, unlike for forth order ones. \nIn general, you can still simplify a bit the expression for eigenvalues of matrixA adding an option Quartics -> True to Eigenvalues :\nEigenvalues[matrixA, Quartics -> True]\n\n\n", "design patterns - How can one define a custom data object?": "\nFormat is what you are looking for: Create a data structure, something like this:\nmkMyData[d1_, d2_] := MyData[d1, d2]\nGetD1[a_MyData] := a[[1]]\nGetD2[a_MyData] := a[[2]]\nFormat[MyData[d1_, d2_]] := \"MyData[<\" <> ToString[Length[d1] + Length[d2]] <> \">]\"\n\nCall the constructor:\ndata = mkMyData[Range[5], q]\n\n(*\n    \"MyData[<5>]\"\n*)\nCall a selector:\nGetD1[data]\n\n(*\n    {1, 2, 3, 4, 5}\n*)\n", "list manipulation - Count number of sublists with a total not greater than a given max": "\nThis is not really the same algorithm, but\nClearAll[v];\nv[t_, data_] :=\n   Block[{v},\n     v[_?Negative, _] := 0;\n     v[_, 0] := 1;\n     v[tl_, n_] := v[tl, n] =\n        v[tl - data[[n]], n - 1] + v[tl, n - 1];\n     v[t, Length[data]]\n   ];\n\nYou may need to increase the $RecursionLimit for larger lists.\n", "combinatorics - Advanced Tupling": "\nHere's a moderately parallelizable solution.  It constructs the tuples sequentially so that, at the end, you can be assured the first element is from the first list, the second from the second, etc. \nnewTuples[t_, x_] := Flatten[\n    ParallelTable[Append[s, #] & /@ Complement[x, s], {s, t}], 1];\nTiming[ts = Fold[newTuples, {{}}, {a, b, c, d, e, f}];]\n\nLet's unwind this. Fold builds the output one step at a time.  After processing a, the output is just a list of the elements of a, each as a singleton vector (\"1-tuple\"):\n{{1}, {2}, {3}, {4}, {5}, <<...>> {26}, {28}}\n\nTo process b, newTuples will loop (via ParallelTable) over all the 1-tuples it has just created.  For each such 1-tuple s, Complement obtains the elements of b that would not cause any duplication (\"x\" refers to b at this stage, and later to c, d, etc.).  Each of these elements is systematically tacked on to the current 1-tuple (via Append) to create a set of unique new 2-tuples.  For example, when working on the 1-tuple {2}, the first thing we do is remove 2 from b.  Then each remaining element of b is tacked on to {2}, giving {{2,3}, {2,4}, <<...>>, {2,41}}.\nOnce ParallelTable has augmented each 1-tuple into a list of 2-tuples in this manner, Flatten restructures the table of lists of 2-tuples as a single list: \n{{1,2},  {1,3},  {1,4}, <<...>>,  {1,41},\n         {2,3},  {2,4}, <<...>>,  {2,41},\n {3,2},          {3,4}, <<...>>,  {3,41},\n<<...>>\n {28,2}, {28,3}, {28,4}, <<...>>, {28,41}}\n\nFold then repeats this procedure, augmenting each 2-tuple with new elements of c, then augmenting the resulting 3-tuples with elements of d, etc, until it has processed all six lists.\nWhen there is lots of duplication among lists, this sequential strategy will be more sparing of RAM (and CPU cycles) than a more direct method, because it avoids creating a large list from which the qualifying 6-tuples will be selected: at each stage, the list of intermediate tuples is as small as possible.\nTiming was 37 seconds (3.33 GHz Xeon 3580) and RAM usage was approximately 1.5 GB.  (It goes a little faster if you process the smaller lists first.)  The output has 12,336,674 elements.  Testing on short lists gave correct results.  Try, for example,\nFold[newTuples, {{}}, {{0, 1}, {2, 3, 4}, {5}, {6, 7}, {6, 7}, {6, 7, 8}}] \n\nIt should produce 2*3*1*2*1*1 = 12 6-tuples and indeed it does.\n\nBTW, before attempting such a procedure generally it's a good idea to estimate how large the output might be, as in\nTimes @@ (Length /@ {a, b, c, d, e, f})\n\nThe output, 15874232, is the number of tuples that would be generated with duplicates allowed.  Much larger answers would indicate extreme caution is needed, lest Mathematica grab all your RAM in its effort to complete the calculation.\n", "probability or statistics - Efficient way to generate random points with a predefined lower bound on their pairwise Euclidean distance": "\nThis is not an efficient answer but it is fun to play with so I thought I'd post it. For efficiency the use of Nearest might provide a good starting point.\ng[n_, {low_, high_}, minDist_, step_: 1] := \n Block[{data = RandomReal[{low, high}, {n, 2}], temp, happy, sdata, \n   hdata},\n\n  While[True,\n   temp = ((Nearest[data][#, 2][[-1]] & /@ data));\n   happy = \n    Boole@Thread[MapThread[EuclideanDistance, {temp, data}] > minDist];\n   hdata = Pick[data, happy, 1];\n   sdata = Pick[data, happy, 0];\n   If[sdata === {}, Break[]];\n   sdata += RandomReal[{-step, step}, {Length[sdata], 2}];\n   data = Join[sdata, hdata];\n   ];\n  data\n  ]\n\nThe idea is to do an initial sampling and then allow the points that are too close to \"walk\" somewhere else. The function takes a desired number of points n, a low and high value for the data range, the minimum acceptable distance between points minDist and a step argument which allows points to \"walk\" up to a certain distance in the x and y directions.\nIts especially fun to watch dynamically.\ng[150, {0, 30}, 1.5, 1]\n\nEdit: Per suggestion of Yves Klett the points are colored by relative happiness (green being more happy, red being less happy).\n\nEdit 2: \nNow for a more serious attempt at something efficient..\nfindPoints =\n  Compile[{{n, _Integer}, {low, _Real}, {high, _Real}, {minD, _Real}},\n   Block[{data = RandomReal[{low, high}, {1, 2}], k = 1, rv, temp},\n    While[k < n,\n     rv = RandomReal[{low, high}, 2];\n     temp = Transpose[Transpose[data] - rv];\n     If[Min[Sqrt[(#.#)] & /@ temp] > minD,\n      data = Join[data, {rv}];\n      k++;\n      ];\n     ];\n    data\n    ]\n   ];\n\nAnd to test it for benchmarking...\nnpts = 350;\nminD = 3;\nlow = 0;\nhigh = 100;\n\nAbsoluteTiming[pts = findPoints[npts, low, high, minD];]\n\n==> {0.0312004, Null}\n\nCheck that the min distance is less than the threshold.\nMin[\n  MapThread[\n   EuclideanDistance, {pts, Nearest[pts][#, 2][[-1]] & /@ pts}]] > minD\n\n==> True\n\nCheck that I generated the correct number of points..\nLength[pts] == npts\n\n==> True\n\n", "Defining an integer-valued function on an integer domain": "\nTry \nf[x_ /; MemberQ[Range@12, x]] := Switch[x, 2, 28, 4 | 6 | 9 | 11, 30, _, 31]\n\n", "plotting - Labels and tickmarks inside Frame": "\nYou could do something like this:\nPlot[Sin[x], {x, 0, 10}, Frame -> True,\n Epilog -> {Table[Text[i, {i, -1}, {0, -1}], {i, Range[0, 10, 2]}],\n  Table[Text[NumberForm[i, {2, 1}], {0, i}, {-1, 0}], {i, Range[-1, 1, .5]}]},\n FrameTicksStyle -> (FontOpacity -> 0),\n ImagePadding -> {{1, 1}, {1, 1}}]\n\n\n", "front end - What is modifying an init.m that changes menu Palettes order?": "\nmathStatica does not alter, nor seek to alter, the MenuSortingValue. In fact, mathStatica does not alter or seek to alter, in any way, how or where the mathStatica palette is listed in the palette menu... this is left entirely to default Mathematica behaviour.\nThe reason the mathStatica palette appears out of alphabetical order in the Palettes menu seems to be simply because all the other palettes start with an Upper case letter, whereas the mathStatica palette starts with a lower case 'm'. Stated simply: this appears to be a bug in Mathematica's menu sorting algorithm.\nThe mathStatica palette name is set under:\n  Preferences --> Notebook options  -->  Window properties -->  WindowTitle -> \"mathStatica\"\n\nIf this setting is changed from lower case \"mathStatica\" to upper case \"MathStatica\", and no other change is made, then the \"MathStatica\" palette appears alphabetically in the palette menu, as Prof Murray Eisenberg desires it to appear, rather than at the end of the palette list. If Wolfram 'update' their menu sorting algorithm, the desired menu appearance should be attained automatically.\n(If anyone wants an adjusted palette with upper case WindowTitle MathStatica, just let me know, and I can send you a copy.)\n", "front end - How does AutoStyleWords work?": "\nA very similar question came up internally at WRI, so I have a nearly ready-made answer. In that case, the fellow wanted to highlight certain loop constructs, like Do and For in his code automatically. Here's how I responded.\nIn a fresh notebook, Format->Edit Stylesheet..., then paste and interpret the\ncells below at the bottom of the stylesheet.  And voila, you'll got purple Dos and Fors in the notebook the stylesheet modified.\n{\nCell[StyleData[\"Input\"],\n AutoStyleWords->{\"Do\"->\"MyStyle\", \"For\"->\"MyStyle\"}],\n\nCell[StyleData[\"MyStyle\"],\n FontColor->RGBColor[0.5, 0, 0.5]]\n}\n\nSome caveats about using this:\n\nThe thing on the rhs of the rule must be a named style (a slightly archaic and embarrassing limitation in a modern FE, but that's the way it is in v8).\nThere's a bug (fixed for future versions) in the validation of this option which can cause a crash if you feed it values formatted in any way other than this.\nThis will only work in typeset cells\nThis will only work to style things which are lexically word-type tokens. You cannot, for example, auto-style two words in sequence, a subexpression with an operator, or a substring of a word token.\n\n", "Conditional numerical integration boundaries": "\nA better option than using Boole would be to use Piecewise. Using that you can define a function that returns 0 when your conditions aren't met and otherfunc otherwise. \nSo, define a function otherfunc2 and integrate that:\notherfunc2[x_, y_, z_, t_] := \n Piecewise[\n  {\n   {otherfunc[x, y, z, t],\n    z1[t] <=z<= z2[t] && y1[t, z] <=y<= y2[t, z] && x1[t, z, y] <=x<= x2[t, z, y]},\n   {0, True}\n   }\n  ] \n\n", "packages - Differential geometry add-ons for Mathematica": "\nAtlas 2 for Mathematica is the add-on for doing modern differential geometry calculations.\nThe tool is available on DigiArea website and Wolfram Research website.\nThe tool works with Mathematica 8 and Mathematica 9. \nCalculations are coordinate free\n\nFirst of all in the atlas tool all calculations are coordinate free. That means calculations are performed in terms of tensors, vectors and p-forms. \nNot their components!\nFor example conformally flat metric tensor of sphere is presented as:\n\nwhere  are coframe 1-forms and symbol - tensor product operator.\n\n\nStandard differential geometry notations\n\nSecondly, the package uses standard differential geometry notations for exterior derivative, covariant differentiation, tensor product etc. It is really helpful to see the same results/formulas on the screen and in my textbooks.\n\nExample with Lie derivative calculation:\n\n\n\nExample with exterior derivative calculation:\n\n\n\nExample with tensor product calculation:\n\n\nAtlas is very user-friendly and doesn't bog down with a lot of programming which is really importance for people interested in learning.\nThere are a lot of predefined operators to declare various DG objects. \nJust for example Invariants operator automatically calculates invariants of a mapping:    \n\nfor an embedding of a curve - the curve's normalized moving frame and the curve's curvatures\nfor an embedding or immersion - the second fundamental form and mean curvature vector\nfor a submersion - A and T invariants, the mean curvature vector of corresponding fibers, the integrability obstruction of corresponding horizontal distribution and the riemannian obstruction (if the submersion is not a riemannian one).\n\n\n\nVisualization of n-dimensional objects\n\nThe package has Visualize function that visualizes n-dimensional differential geometry objects using different Mathematica plot functions. The function allows quickly visualize an object and its projections. See some examples.\nFor example visualization of projections for Mobius strip.\n\n\n\n\nDifferential Geometry Library\n\nThe tool gives access to Differential Geometry Library directly from Mathematica.The library has over 550 objects for differential geometry and its applications and frequently updated. The are hundreds of Exact Solutions of Einstein's Field Equations and atlas's graphical user interface (see below) allows calculate any of the objects/Exact Solutions just in few seconds.\nCurrently, the library has 6 categories:\n\n2D Coordinate Systems\n3D Coordinate Systems\nPlane Curves\nSpace Curves\nSurfaces\nExact Solutions of Einstein's Field Equations\n\n\nFor instance:\n\n\n\n\n\n\nGraphical user interfaces\n\nThere is a bunch of neat applications which included into the tool: \n\n\nAtlas palette - Mathematica palette, allows manipulate, visualize and calculate entities for any of the objects from the library.\n\n\nextends the keyboard with typesetting of characters and atlas symbols\ngives access to the differential geometry library\ngenerates notebook for any of the library objects that fully prepared to calculate differential geometry quantities for this entity\n\nAtlas Wizard - solves differential geometry problems on the fly even if you have a little knowledge in the topic.\n\n\nVideo and Screencasts\n\nExact Solutions of Einstein's Equations with Atlas 2 for Mathematica\nAtlas Palette Usage - Differential Geometry Library Usage\nAtlas Palette Usage - Code generation and Typesetting\n2D Coordinate System changing\n\n", "How to set up new types for pattern matching strings?": "\nI suggest to use lexical environments, in particular the function makeCustomEnvironment which I posted in this answer\nClearAll[makeCustomEnvironment];\nSetAttributes[makeCustomEnvironment, HoldAll];\nmakeCustomEnvironment[values : (_Symbol = _) ..] := \n      Function[code, With @@ Hold[{values}, code], HoldAll];\n\nnow, define a custom environment:\nenv = makeCustomEnvironment[Consonant = _?ConsonantQ, Vowel = _?VowelQ]\n\nAnd use it:\nenv@StringReplace[\"badge\",\n    Shortest[pre__]~~c:Consonant..~~v:Vowel~~EndOfString:>pre<>\"-[\"<>c<>\"]-[\"<>v<>\"]\"]\n\n(*\n  ==> \"ba-[dg]-[e]\"\n*)\n\nNote that the literals Consonant and Vowel don't acquire any global values, and have special meaning only for the code literally present inside the env environment. You can view this solution as a simple example of Mathematica meta-programming.\nEDIT\nAnother alternative (which I like less, but still) is to use UpValues:\nClearAll[Consonant, Vowel]\nConsonant /: f_[left___, Consonant, right___] := \n    f[left, _?ConsonantQ, right];\nVowel /: f_[left___, Vowel, right___] := f[left, _?VowelQ, right];\n\nIn this case, you can run your code without any wrappers, but I personally would still go for local environments (note that I defined the above pretty carelessly for any f - for example, you won't be able to Clear Consonant or Vowel easily now. If you choose this method, you may want to narrow the set of f-s in the above).\nAnd of course, you can just simply use assignments\nClearAll[Consonant, Vowel]\nConsonant = _?ConsonantQ;\nVowel     = _?VowelQ;\n\nbut this will likely exclude the use of symbols Consonant and  Vowel in other capacities in some other pieces of your code, since they now have global values. This may also not work if they are used inside functions which hold their arguments, since they are replaced by their values as a result of their evaluation, in this method. \n", "packages - Compile for deployment": "\nI am not aware of such functionality \"out of the box\", but you can use various symbol dependency frameworks (I have my version published here, although at present it does contain some bugs), to figure out a set of symbols being used. You will need a few auxiliary functions to extract all symbols used in a notebook, and prepare boxed form of the code for them, from their global properties. \nHere is some code which can get you started:\nClearAll[getCodePieces];\ngetCodePieces[nb : (_NotebookObject | Automatic) : Automatic] :=\n  With[{nbl = If[nb === Automatic, EvaluationNotebook[], nb]},\n    Flatten@\n      Cases[NotebookGet[nbl], Cell[BoxData[boxes_], \"Input\", ___] :>\n         ToExpression[boxes, StandardForm, HoldComplete], Infinity]];\n\nClearAll[getDependentSymbols];\ngetDependentSymbols[nb : (_NotebookObject | Automatic) : Automatic] :=  \n  Union@Flatten[depends /@ getCodePieces[nb]]; \n\nClearAll[createCodeBoxes];\ncreateCodeBoxes[HoldComplete[sym_Symbol]] :=\n  Module[{optionCode, attributeCode, dsocode, ocode, ucode, boxDefs},\n   optionCode = \n     If[# === {}, {}, MakeBoxes[Options[sym] = #]] &@\n        Options[Unevaluated[sym]];\n   attributeCode = \n     If[# === {}, {}, MakeBoxes[SetAttributes[sym, #]]] &@\n        Attributes[sym];\n   boxDefs[defOper_] :=\n     If[# === {}, {},\n        Replace[#, (Verbatim[HoldPattern][lhs_] :> rhs_) :> \n             MakeBoxes[defOper[lhs, rhs]], {1}] &@#\n     ] &;   \n   dsocode = \n     boxDefs[SetDelayed][\n        Flatten[{OwnValues[sym], DownValues[sym], SubValues[sym]}]];\n   ucode = boxDefs[UpSetDelayed][UpValues[sym]];\n   If[# === {}, {}, RowBox[Join[#, {\";\", \"\\n\"}]]] &@\n      Flatten@\n         Riffle[Flatten[{optionCode, attributeCode, ucode,dsocode }], \n            {\";\", \"\\n\"}]];\n\nClear[makeNbCode];\nmakeNbCode[nb : (_NotebookObject | Automatic) : Automatic] :=\n  Cell[BoxData[#], \"Input\"] &@\n     RowBox[Flatten[createCodeBoxes /@ getDependentSymbols[nb]]];\n\nThis depends on my dependency-tracking framework, particularly the depends function, from the mentioned answer. You use it as (I assume the evaluation notebook for simplicity):\nCellPrint@makeNbCode[]\n\nNote that the above code is not complete and will miss certain definitions (e.g. those for Format, default values, etc) - so treat this as a starting point. I tested this on a few examples, seems to work fine. Note also that this will keep the symbol names, including the namespaces / contexts they belong to. Finally, not that one can not fully reconstruct the original code from global properties, bacause the global properties do not encode the information on whether or not the definition was given as immediate or delayed. This should not matter much here, since definitions are used in the way they are stored in the global rule base, though.\nAn alternative approach would be to get the set of symbols your notebook depends on, as above, but then, rather than reconstructing code from in-memory definitions, find the set of packages you need, load them as Get[...,\"HeldExpressions\"], and then search the held code of those packages. This may be somewhat more robust, but a little more complex to implement well (although not really very difficult).\nBoth approaches rely on the fact that your kernel state reflects the fully-working (loaded into memory) functionality that you want to extract - so the recommended use is to first load everything and run your functionality, and then use any of the above methods. If you want to have more \"static analysis\", this is also possible, but again a bit more complex, and your notebook must be self-contained (loading all needed packages, etc).\n", "graphics - Avoiding white lines inside filled area in RegionPlot exported as PDF or PS": "\nThe suggestion to use Antialiasing->False doesn't really solve the problem. I don't have a single solution that's appropriate in all cases, but I think one of the approaches I list on the following web page will work: \nAvoiding artifacts in shaded contour and density plots\nEdit:\nThe following method from the linked article solves the problem:\nInstead of exporting the image (assumed to be stored in im1), export the modified graphics\nim1 /. {EdgeForm[], r_?(MemberQ[{RGBColor, Hue, CMYKColor, GrayLevel}, Head[#]] &), i___} :> {EdgeForm[r], r, i}\n\nThis replaces the invisible edges of the polygons (EdgeForm[]) in your graphic (called im1 here) by edges of default thickness and with a color matching at least one of the neighboring polygons. The new edges then help fill any empty space between the shaded areas.\nEdit 2\nMy solution relies on finding colored polygons without colored edges by looking for EdgeForm[] followed by a color in the graphic im1. \nBased on the answer by Mr. Wizard and kguler here, one can also make the above work better with custom colors and future additions to the built-in color choices:\ncolorQ = FreeQ[Quiet@Darker@#, Darker] &;\nim1 /. {EdgeForm[], r_?colorQ, i___} :> {EdgeForm[r], r, i}\n\nEdit 3\nThanks to @becko for pointing out that there is a new command ColorQ in version 10 that can do the same as above. So you can replace colorQ in the previous edit with ColorQ.\n", "differential geometry - Shape operator vs second fundamental form": "\nFor the sake of clarity I will restrict my answer to the special case of (regular, embedded) surfaces in $\\mathbb R^3$.\nThe difference between shape operator and second fundamental form is that the first is an operator, while the second is a bilinear form. Specifically, if $n$ is the outward normal to your surface $S \\subset \\mathbb R^3$, we may define the shape operator $S$ by the rule $$S(X) = D_X n$$ while the second fundamental form is given by $$II(X,Y) = D_X n \\cdot Y$$\nHere $D_x n$ is the directional derivative of $n$ in the direction $X$. Note that some authors use a negative sign in the definition of shape operator, and may also use the same name for both objects. If you know about tensors and type change, then the second fundamental form is what you get when you change the type of the shape operator from $(1,1)$ to $(0,2)$.\nIf you are interested in coordinate formulas and/or other applications, I would recommend Ted Shifrin's book, available on his website: \"Differential Geometry: A first Course in Curves and Surfaces\".\n", "list manipulation - Efficiently Visualising Very Large Data Sets (without running out of memory)": "\nShowing humongous data by screen-fulls can be done using Manipulateas follows:\n(* generate some data to show *)\nres = Tuples[{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}, 7];\n\n(* size of the data*)\nByteCount[res]\n\n(* ==> 1003290792 *)\n\nscreenNumbers = 100;\nManipulate[\n Take[res, {i screenNumbers + 1, (i + 1) screenNumbers}], {i, 0, \n  Length[res]/screenNumbers - 1, 1}\n]\n\n\nSince the slider slides over 100,000's of values in a short distance you can slow down its movement using the modifier keys when you drag the slider.\n\nThe resulting slider can be finely manipulated by holding down the Alt key (or Option on Macintosh) while dragging the mouse. This causes the slider to move at 1/20 the rate of the mouse. The slider can be even more finely manipulated by also holding the Shift and/or Ctrl keys. [Last bullet of the More Information part of the Slider doc page]\n\nScrolling through the 1GB of data is almost instantaneous.\n", "random - RandomVariate from 2-dimensional probability distribution": "\nMathematica v8 does not provide support for automated random number generation from multivariate distributions, specified in terms of its probability density functions, as you have already discovered it. \nAt the Wolfram Technology conference 2011, I gave a presentation \"Create Your Own Distribution\", where the issue of sampling from custom distribution is extensively discussed with many examples. \nYou can draw samples from the particular distribution at hand by several methods. Let\ndi = ProbabilityDistribution[\n   Beta[3/4, 1/2]/(Sqrt[2] Pi^2) 1/(1 + x^4 + y^4), {x, -Infinity, \n    Infinity}, {y, -Infinity, Infinity}];\n\nConditional method\nThe idea here is to first generate the first component of the vector from a marginal, then \na second one from a conditional distribution:\nmd1 = ProbabilityDistribution[\n   PDF[MarginalDistribution[di, 1], x], {x, -Infinity, Infinity}];\n\ncd2[a_] = \n  ProbabilityDistribution[ \n   Simplify[PDF[di, {a, y}]/PDF[MarginalDistribution[di, 1], a], \n    a \\[Element] Reals], {y, -Infinity, Infinity}, \n   Assumptions -> a \\[Element] Reals];\n\nThen the conditional method is easy to code:\nClear[diRNG];\ndiRNG[len_, prec_] := Module[{x1, x2},\n  x1 = RandomVariate[md1, len, WorkingPrecision -> prec];\n  x2 = Function[a, RandomVariate[cd2[a], WorkingPrecision -> prec]] /@\n     x1;\n  Transpose[{x1, x2}]\n  ]\n\nYou can not call it speedy:\nIn[196]:= AbsoluteTiming[sample1 = diRNG[10^3, MachinePrecision];]\n\nOut[196]= {20.450045, Null}\n\nBut it works:\n\nTransformed distribution method\nThis is somewhat a craft, but if such an approach pans out, it typically yields the best performing random number generation method. We start with a mathematical identity\n$$\n\\frac{1}{1+x^4+y^4} = \\int_0^\\infty \\mathrm{e}^{-t(1+x^4+y^4)} \\mathrm{d} t = \\mathbb{E}_Z( \\exp(-Z (x^4+y^4))) \n$$\nwhere $Z \\sim \\mathcal{E}(1)$, i.e. $Z$ is exponential random variable with unit mean.\nThus, for a random vector $(X,Y)$ with the distribution in question we have\n$$\n   \\mathbb{E}_{X,Y}(f(X,Y)) = \\mathbb{E}_{X,Y,Z}\\left( f(X,Y) \\exp(-Z X^4) \\exp(-Z Y^4) \\right)\n$$\nThis suggests to  introduce $U = X Z^{1/4}$ and $V = Y Z^{1/4}$. It is easy to see, that the probability density function for $(Z, U, V)$ factors:\n$$\nf_{Z,U,V}(t, u, v) = \\frac{\\operatorname{\\mathrm{Beta}}(3/4,1/2)}{\\sqrt{2} \\pi^2} \\cdot \\frac{1}{\\sqrt{t}} \\mathrm{e}^{-t} \\cdot \\mathrm{e}^{-u^4} \\cdot \\mathrm{e}^{-v^4}\n$$\nIt is easy to generate $(W, U, V)$, since they are independent. Then $(X,Y) = (U, V) W^{-1/4}$, where $f_W(t) =  \\frac{1}{\\sqrt{\\pi}} \\frac{1}{\\sqrt{t}} \\mathrm{e}^{-t}$, i.e. $W$ is $\\Gamma(1/2)$ random variable.\nThis gives much more efficient algorithm:\ndiRNG2[len_, \n  prec_] := (RandomVariate[NormalDistribution[], len, \n       WorkingPrecision -> prec]^2/2)^(-1/4) RandomVariate[\n   ProbabilityDistribution[\n    1/(2 Gamma[5/4]) Exp[-x^4], {x, -Infinity, Infinity}], {len, 2}, \n   WorkingPrecision -> prec]\n\nNoticing that $|W|$ is in fact a power of gamma random variable we can take it much further:\nIn[40]:= diRNG3[len_, prec_] := \n Power[RandomVariate[GammaDistribution[1/4, 1], {len, 2}, \n     WorkingPrecision -> \n      prec]/(RandomVariate[NormalDistribution[], len, \n        WorkingPrecision -> prec]^2/2), 1/4] RandomChoice[\n   Range[-1, 1, 2], {len, 2}]\n\nIn[42]:= AbsoluteTiming[sample3 = diRNG3[10^6, MachinePrecision];]\n\nOut[42]= {0.7230723, Null}\n\nRejection method\nHere the idea is to sample from a relatively simple to draw from hat distribution. It is again a craft to choose a good one. Once the one is chosen, we exercise the rejection sampling algorithm:\n\nIn the case at hand, a good hat is the bivariate T-distribution with 2 degrees of freedom, \nas it is easy to draw from, and it allows for easy computation of the scaling constant:\nIn[49]:= Maximize[(1/(1 + x^4 + y^4))/\n  PDF[MultivariateTDistribution[{{1, 0}, {0, 1}}, 2], {x, y}], {x, y}]\n\nOut[49]= {3 Pi, {x -> -(1/Sqrt[2]), y -> -(1/Sqrt[2])}}\n\nThis gives another algorithm:\ndiRNG4[len_, prec_] := Module[{dim = 0, bvs, u, res},\n  res = Reap[While[dim < len,\n      bvs = \n       RandomVariate[MultivariateTDistribution[{{1, 0}, {0, 1}}, 2], \n        len - dim, WorkingPrecision -> prec];\n      u = RandomReal[3/2, len - dim, WorkingPrecision -> prec];\n      bvs = \n       Pick[bvs, \n        Sign[(Total[bvs^2, {2}]/2 + 1)^2 - u (1 + Total[bvs^4, {2}])],\n         1];\n      dim += Length[Sow[bvs]];\n      ]][[2, 1]];\n  Apply[Join, res]\n  ]\n\nThis one proves to be quite efficient as well:\nIn[77]:= AbsoluteTiming[sample4 = diRNG4[10^6, MachinePrecision];]\n\nOut[77]= {0.6910000, Null}\n\n", "evaluation - Exporting held expressions through JSON": "\nThe short answer is that, as @FJRA noted in the comment, only certain types are supported. Which types? Enter the long answer.\nWhy the converter behaves as it does\nLong answer: JSON supports only certain types, and their nested combinations, as defined e.g. here. Mathematica converter maps JSON objects to lists of rules, arrays to lists, strings to strings, plus has some special cases for True, False and Null. Once Mathematica JSON converter sees a general expression, it does not know what to do with it.\nThe problem with the \"obvious\" solution to convert to string and store as a string is that there will be no automatic way (without imposing some additional conventions) to tell which strings are really strings and which are stringified Mathematica expressions. So, IMO, the converter is doing the right thing.\nDigging deeper\nYou can actually quite easily trace the execution the the functions of interest. If we use my debug function (from here), as\ndebug@Export[\n   Environment[\"USERPROFILE\"] <> \"\\\\AppData\\\\Local\\\\test.json\", \n   HoldComplete[{1, 2, 3}], \"JSON\"]\n\nIt will quickly tell us to look at the function  System`Convert`JSONDump`iexportJSON, which in turn points to System`Convert`JSONDump`toString. Inspecting the DownValues of the latter, you will see the procedure I described above.\nMaking the JSON import - export more liberal (for illustration purposes only !)\nIf you really want to make the JSON import - export more liberal, so that, upon seeing an unrecognized general expression, it somehow converts it to string for export, and back to expression during import, here is one way:\nClearAll[withLiberalJsonTostring];\nSetAttributes[withLiberalJsonTostring, HoldAll];\nwithLiberalJsonTostring[code_] :=\n   Block[{dv = DownValues[System`Convert`JSONDump`toString], \n         System`Convert`JSONDump`toString},\n      DownValues[System`Convert`JSONDump`toString] = Most[dv];\n      System`Convert`JSONDump`toString[expr_, _Integer] :=\n       StringJoin[\n          \"StringifiedOpen\",\n          StringReplace[ToString[FullForm@expr],\n            {\"[\" :> \"EscapeOpen\", \"]\" :> \"EscapeClose\", \",\" :> \"EscapeComma\"}],\n          \"StringifyClose\"\n       ];\n      code];\n\nand the import counterpart:\nClearAll[withLiberalJsonImport];\nSetAttributes[withLiberalJsonImport, HoldAll];\nwithLiberalJsonImport[code_] :=\n   With[{result = code},\n      result /. \n        s_String :> \n          StringReplace[\n             s, \n            {\"EscapeOpen\" :> \"[\", \"EscapeClose\" :> \"]\", \"EscapeComma\" :> \",\"}\n          ] /. \n        s_String /; StringMatchQ[s, \"StringifiedOpen\" ~~ __ ~~ \"StringifyClose\"] :>\n            ToExpression@ StringReplace[s, \"StringifiedOpen\" | \"StringifyClose\" :> \"\"]\n   ]; \n\nNote that the escaping strings are arbitrary, and this will break if these particular strings are also used in different capacities in the JSON expression.\nWith this, we can do:\nwithLiberalJsonTostring[\n  Export[Environment[\"USERPROFILE\"] <> \"\\\\AppData\\\\Local\\\\test.json\", \n  {1, 2, HoldComplete[{1, 2, 3}]}, \n  JSON\"]]\n\nand\nwithLiberalJsonImport@\n   Import[Environment[\"USERPROFILE\"] <> \"\\\\AppData\\\\Local\\\\test.json\", \"JSON\"]\n\n(* \n  ==> {1, 2, HoldComplete[{1, 2, 3}]}\n*)\n\nNote that I don't really recommend this method as robust, just posted this code for an illustration, and to aid the understanding of the matter. This is not robust on many grounds, incuding dependence on implementation details, the escaping procedure being arbitrary and not really robust, etc.\nA robust solution would be to write an alternative converter (importer / exporter) to JSON, which would do the thing you want, and use that intead. Also, please have a look at the solution by @celtschk, which is a lot cleaner and simpler.\nEDIT\nAs @celtschk pointed out in the comments, escaping is not really necessary if we add extra string quatation marks. The mechanism to distinguish strings from stringified expressions (to be converted back to expressions during import) is still needed however.\n", "programming - What does the construct f[x_] := f[x] = ... mean?": "\nIt is a simple way to implement Memoization. The trick is that if you define a function as\nf[x_]:=f[x]=ExpensiveFunctionOf[x]\n\nthen when you for the first time call e.g. f[3], it will evaluate as\nf[3]=ExpensiveFunctionOf[3]\n\nwhich will evalulate the expensive function, and assign the result to f[3] (in addition to giving it back, of course). So if e.g. ExpensiveFunctionOf[3] evaluates to 7, it will assign f[3]=7.\nThe next time you call f[3], it will find that newly created definition of f[3] and use that in preference to the general rule. This means it will return the value 7 without calculating ExpensiveFunctionOf[3] a second time.\n", "evaluation - How to pass a symbol name to a function with any of the Hold attributes?": "\nHow about this:\nlist = {1, 2, 3};\nToExpression[\"list\", InputForm, Hold] /. Hold[v_] :> AppendTo[v, 3]\n\n\n{1, 2, 3, 3}\n\nlist\n\n\n{1, 2, 3, 3}\n\n", "graphics - Labeling a bar chart, changing how rotated labels are centered": "\nBy default the Axis position that you're using centers the label under the bar along the axis. For long text that's rotated at a slant, it generally looks bad.  (It works fine for horizontal and vertical text, however.)\n\nHere's one approach, using a different second argument for Placed:\nModule[{\n    labels = {\"Learning focused\", \"Positively oriented\", \"Continuous\", \n              \"Timely\", \"Clear criteria\", \"Flexible\", \"Suited to student level\"}, \n    data = {8, 6, 4, 5, 5, 9, 9}\n    }, \n    BarChart[data, \n        ChartLabels -> Placed[\n            labels, \n            {{0.5, 0}, {0.9, 1}}, \n            Rotate[#, (2/7) Pi] &\n            ], \n        PlotRange -> {Automatic, {0, 10}}, Ticks -> {None, Range[0, 10, 2]}, \n        ImagePadding -> {{20, 0}, {95, 0}}\n    ]\n]\n\n\nThe first part of the argument, {0.5, 0}, says to place the label halfway across the bar, at the bottom.\nThe second part of the argument, {0.9, 1}, says what part of the label at the first part. In this case it's near, but not quite at, the right-top corner.  \nIt's not exactly at the corner, because I think it looks better if the top of the \"ink\" is centered below the bars, and that won't be the actual corner unless your label ends with \">\" or something similar.\n\nHere's a second approach, using a different third argument of Placed:\nModule[{\n    labels = {\"Learning focused\", \"Positively oriented\", \"Continuous\", \n              \"Timely\", \"Clear criteria\", \"Flexible\", \"Suited to student level\"}, \n    data = {8, 6, 4, 5, 5, 9, 9}\n    }, \n    BarChart[data, \n        ChartLabels -> Placed[\n            labels, \n            Axis, \n            Block[{text = Rotate[#, (2/7) Pi]}, \n                Row[{text, Invisible[text]}, \n                    \"\\[NegativeMediumSpace]\"]\n            ]&\n            ], \n        PlotRange -> {Automatic, {0, 10}}, Ticks -> {None, Range[0, 10, 2]}, \n        ImagePadding -> {{20, 0}, {95, 0}}\n    ]\n]\n\nThis uses the normal axes positioning, but for each label, it creates an object that has the label and an invisible copy of the label side-by-side so that the center of the object is the end of the visible label. (I used a negative space between the objects, because again I think it looks better.) The nice thing about this approach is that the basic idea can be used for labels for ticks on axes that don't otherwise allow specific placements.\n\n", "graphics - ErrorBars with BarChart, ChartLabels are not working?": "\nIn the original code, chartData is of the form {{value1 -> error1}, {value2 -> error2}, ... }, but it should be of the form {value1 -> error1, value2 -> error2, ... }. To get the right labels you could do something like (note the missing brackets in chartData)\nchartData = \n MapThread[#1 -> #2 &, {RandomReal[1, 10], RandomReal[0.1, 10]}];\n\nBarChart[chartData, \n ChartElementFunction -> errorBar[\"Rectangle\"], \n ChartLabels -> Placed[labels, Axis, Rotate[#, Pi/2] &]]\n\n\n", "import - How do you skip missing data values in a data file?": "\nMissing data is encoded in Mathematica using the inert function Missing. It can take  several forms (Missing[\"reason\"]):\n\nTypical examples of \"reason\" include \"NotApplicable\", \"Unknown\",\n  \"NotAvailable\", \"Nonexistent\", \"Indeterminate\", \"Variable\",\n  \"Disputed\", or \"TooLarge\"\n\nYou can filter your data using DeleteCases:\nDeleteCases[data, _Missing]\n\nLists with empty fields can be cleaned as follows:\nDeleteCases[{1, 2, , 3, 4}, Null]\n\n(*\n==> {1, 2, 3, 4}\n*)\n\n", "groebner bases - Equation solving with GroebnerBasis": "\n\"[O]nly a little\"?? You just went from a system of 6 equations in 6 variables to a 20 x 20 system. I have to wonder what a big enlargement might be.\nYou might try\nsoln = NSolve[polys]\n\nBut that also could well hang.\nA better possibility in terms of likelihood of completing might be to use local methods such as FindRoot, provided you have some idea of where the relevant (for your purposes) solutions might live.\nFollowup:\nNSolve gave a result after a couple of hours.\nIn[13]:= Timing[soln = NSolve[polys];]\n\nNSolve::sfail: Subsystem could not be solved for \n    152533 g[1][1, 1]   14327 g[1][1, 2]   171802 g[1][2, 1]\n    ----------------- + ---------------- + ----------------- - \n         122535              17505              122535\n     113492 g[1][2, 2]   24775 g[1][3, 1]   1475 g[1][3, 2]\n     ----------------- + ---------------- - --------------- + <<11>> + \n          122535              24507              1167\n     38732 h[2][1, 2]   22301 h[2][2, 1]   145171 h[2][2, 2]\n     ---------------- - ---------------- + ----------------- at value \n          24507              17505              122535\n                                        17        -20\n    6.6504175107872416688377351747276 10   + 0. 10    I\n    . The likely cause is failure to detect zero due to low precision. The\n     likely effect is the loss of one or more solutions. Increasing\n     WorkingPrecision might prevent some solutions from being lost.\n\nOut[13]= {7651.893734, Null}\n\nIn[14]:= soln//Length\n\nOut[14]= 110\n\nI believe some of the solutions are numeric gibberish. Others seem plausible though I've not tested them all. Here is one that appears to be reasonable.\n{g[1][2, 1] -> 0.877177885546412, g[1][2, 2] -> -0.731787453222285, \n g[2][2, 1] -> 1.514048096489015, g[2][2, 2] -> 4.056151212079698, \n g[1][3, 1] -> -0.2520687271834896, g[2][3, 1] -> 0.19110251804564718, \n g[1][3, 2] -> 5.450124929865966, g[2][3, 2] -> 5.157856942595859, \n g[1][1, 1] -> -0.3067458899627449, g[2][1, 1] -> 0.11152252700132087, \n g[1][1, 2] -> 1.4198327350185431, g[2][1, 2] -> 0.9644105684773703, \n h[1][2, 1] -> -0.06568699865868881, h[1][2, 2] -> 1.1040449897211426, \n h[2][2, 1] -> 0.016672054541611605, h[2][2, 2] -> 0.94417450922692, \n h[1][1, 1] -> 0.877177885546412, h[1][1, 2] -> -0.731787453222285, \n h[2][1, 1] -> 1.514048096489015, h[2][1, 2] -> 4.056151212079698}\n\nResiduals are on the order of 10^(-14) and smaller.\n", "linear algebra - Obtaining a thin/compact SVD": "\nYou can find the full svd, then use the number of nonzero singular values to recover the thin svd.\nthinSVD[mat_] := Module[\n  {u, w, v, wprime, len},\n  {u, w, v} = SingularValueDecomposition[mat];\n  wprime = DeleteCases[w, {_?(# == 0 &) ..}];\n  len = Length[wprime];\n  wprime = wprime[[All, 1 ;; len]];\n  {u[[All, 1 ;; len]], wprime, v[[All, 1 ;; len]]}\n  ]\n\nHere is a fairly standard example.\nIn[66]:= m = N[{{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}];\n{ut, wt, vt} = thinSVD[m]\nChop[ut.wt.Transpose[vt] - m](*want zeros*)\n\nOut[67]= {{{-0.214837, -0.887231}, {-0.520587, -0.249644}, {-0.826338,\n    0.387943}}, {{16.8481, 0.}, {0., 1.06837}}, {{-0.479671, \n   0.776691}, {-0.572368, 0.0756865}, {-0.665064, -0.625318}}}\n\nOut[68]= {{0, 0, 0}, {0, 0, 0}, {0, 0, 0}}\n\n", "workbench - MUnit creating a hierarchy of TestSuites": "\nHere are two ideas: \n\nIn the documentation there is an example of how to write a test suite, a collection of tests.\nTry to load the MUnit package (I think it is somewhere in Workbench) from Mathematica. Then define\nrunTests[] := Map[TestRun, FileNames[\"path/to/testFiles/*.mt\"]]\n\n\nand call \nrunTests[]\n\n", "front end - How to copy hyperlink addresses using the keyboard": "\nWhat will trigger it\nselect a hyperlink and use a shortcut, in case of wrong selection you will get Beep[]\nWhat will happen\nIf[\n   MatchQ[#, {_}], \n   CopyToClipboard[First[#]], \n   Beep[]\n] &[\n     Cases[\n        CurrentValue[\"SelectionData\"], \n        _[ButtonData, {x_, _}] :> x, \n        Infinity\n     ]\n]\n\nHow to implement it\n\nWith joker.m from the Shortcuts` package\nAnalogous steps like in Wrapping highlighted text in chosen brackets. Is there no keyboard command for this?\nThe second solution is your initial approach, editing KeyEventTranslations.tr\nAt the moment of loading those files the FrontEnd doesn't know @:>_ and all other fancy syntactic features. So we have to put there crude expressions:\n\n\n Item[  \n    KeyEvent[\"r\", Modifiers -> {Control}],\n    KernelExecute[ \n        Function[\n            If[\n                MatchQ[Slot[1], List[Blank[]]], \n                CopyToClipboard[First[Slot[1]]], \n                Beep[]\n            ]\n        ][\n        Cases[\n            CurrentValue[\"SelectionData\"], \n            RuleDelayed[\n               Blank[][ButtonData, List[Pattern[x, Blank[]], Blank[]]],  \n               x\n            ],\n            Infinity\n        ]]      \n    ], MenuEvaluator -> Automatic\n],\n\nThis works well.\n\nShort 2.\nOr just put there\n KernelExecute[ Needs[\"MyShortcuts`\"]; MyShortcuts`CopyAdress[] ]\n\nafter saving MyShortcuts.m with this definition somewhere on $Path.\nShortcuts` package uses this approach.\n\n", "evaluation - How to inject an evaluated expression into a held expression?": "\nHere are a couple of alternatives to Trott-Strzebonski in @R.M's answer:\nHold[{3,4,5|6}] /.\n  Verbatim[Alternatives][x__] :> RuleCondition@RandomChoice@List@x\n\n\nHold[{3, 4, 5}]\n\nHold[{3,4,5|6}] /.\n  Verbatim[Alternatives][x__] :> Block[{}, RandomChoice@List@x /; True]\n\n\nHold[{3, 4, 6}]\n\nThey operate on the same principle as Trott-Strzebonski (i.e. RuleCondition), but express the effect in different ways.\n", "performance tuning - Working with large data, pass-by-reference, compiled functions": "\nAs Leonid already commented, your code should not be especially slow. However one reason why your code may be slow is that you use Part to extract values, do some calculations and then insert the result. I would try using a wholesale approach and calculate all nodes at the same time by doing, e.g. (may need tweaking since I don't know the structure of your objects),\nti = 3.0*bulkMod*dilitation/volState*refMagState;\ntd = 15.0*shearMod/volState*devElongState;\nforceState = ti + td;\n\ninternalForce += Total /@ forceState*volumes[[families]];\ninternalForce[[families]] -= forceState*volumes;\n\nThis way you do everything at once. I can try and help some more if you post examples of the data structures, especially what families and volumes return.\n", "programming - How to efficiently Append a result of an operation on each element of a list to itself": "\nMy proposition:\nlist = RandomReal[1., {100000, 3}];\n\nnewlist = Transpose[{Sequence @@ Transpose[list],\n    list[[All, 2]] list[[All, 3]]}];\n\nA little benchmark using other answers:\nIn[51]:= list = RandomReal[1., {1000000, 3}];\n\nIn[52]:= newlist = \n   Transpose[{Sequence @@ Transpose[list], \n     list[[All, 2]] list[[All, 3]]}]; // AbsoluteTiming\n\nOut[52]= {0.056405, Null}\n\nIn[53]:= newlist2 = {##, Times[##2]} & @@@ list; // AbsoluteTiming\n\nOut[53]= {0.970229, Null}\n\nIn[54]:= newlist3 = \n   Append[#, #[[2]] #[[3]]] & /@ list; // AbsoluteTiming\n\nOut[54]= {0.454465, Null}\n\nIn[55]:= insertHereThis[list_List, here_Integer, this_] := \n Insert[#, this[#], here] & /@ list\n\nIn[56]:= newlist4 = \n   insertHereThis[list, 2, #[[2]] #[[3]] &]; // AbsoluteTiming\n\nOut[56]= {0.438192, Null}\n\nIn[57]:= func = Join[#, Partition[#[[All, -1]] #[[All, -2]], 1], 2] &;\n\nIn[58]:= newlist5 = func[list]; // AbsoluteTiming\n\nOut[58]= {0.053084, Null}\n\nIn[60]:= newlist6 = \n   ArrayFlatten[{{#, Transpose[{times[#, 2, 3]}]}}] &[\n    list]; // AbsoluteTiming\n\nOut[60]= {0.022477, Null}\n\nEDIT: Added new answer (Mr.Wizard's), which now is the fastest in my machine.\nEDIT2: Added Leonid's compiled version, and he is right, it is twice faster!\n", "programming - How to match two sets of data over 1 or more identifier, of unequal length?": "\nI don't know sql and the formats for set1 and set2 are somewhat unclear to me so I could be completely missing the point but maybe you could do something like this for the Inner Join query\nintersect[set1_, set2_] := Module[{expCodes},\n  expCodes = Intersection[set2[[All, 1]], set1[[All,1]]];\n  Reap[Sow[#2, #1] & @@@ set1;\n     Sow[#2, #1] & @@@ set2, expCodes, Flatten[{#1, #2}, 1] &][[2, \n     All, 1]]]\n\nand this for the Left Join query\njoin[set1_, set2_] := Module[{expCodes},\n  expCodes = set1[[All, 1]];\n  PadRight[Reap[Sow[#2, #1] & @@@ set1;\n     Sow[#2, #1] & @@@ set2, expCodes, Flatten[{#1, #2}, 1] &][[2, \n     All, 1]],\n   Automatic, Null]]\n\nExample data:\nset1 = Table[{i, RandomInteger[10, 3]}, {i, 10}]\nset2 = Table[{i, \"Type \" <> ToString[i]}, {i, RandomSample[Range[10], 3]}]\n\n\n{{1, {9, 0, 4}}, {2, {3, 9, 4}}, {3, {9, 2, 5}}, {4, {1, 10, 5}}, \n   {5, {6, 4, 6}}, {6, {2, 1, 4}}, {7, {6, 5, 6}}, {8, {7, 3, 1}}, \n   {9, {9, 4, 9}}, {10, {6, 6, 2}}}\n\n{{5, \"Type 5\"}, {3, \"Type 3\"}, {7, \"Type 7\"}}\n\n\nThen intersect gives\nintersect[set1, set2]\n\n\n{{3, {9, 2, 5}, \"Type 3\"}, {5, {6, 4, 6}, \"Type 5\"}, {7, {6, 5, 6}, \"Type 7\"}}\n\n\nand join\njoin[set1, set2]\n\n\n{{1, {9, 0, 4}, Null}, {2, {3, 9, 4}, Null}, {3, {9, 2, 5}, \"Type 3\"}, \n   {4, {1, 10, 5}, Null}, {5, {6, 4, 6}, \"Type 5\"}, {6, {2, 1, 4}, Null}, \n   {7, {6, 5, 6}, \"Type 7\"}, {8, {7, 3, 1}, Null}, {9, {9, 4, 9}, Null}, \n   {10, {6, 6, 2}, Null}}\n\n\nThis should be expandable to selection on multiple columns by adjusting the definition of expCodes in the definitions of intersect and join.\n", "replacement - How to implement a regular grammar?": "\nThe following code defines the function randomSentence.  It uses recursive descent to generate a sentence from a grammar expresssed as rules:\nClearAll[randomSentence, randomCount]\nrandomCount[] := RandomVariate[GeometricDistribution[0.5]]\n\nSetAttributes[randomSentence, HoldAll]\nrandomSentence[rules_, expr_] :=\n  Module[{generate}\n  , SetAttributes[generate, HoldAll]\n  ; Replace[#[[1, 1]] :> #& /@ GatherBy[rules, First], (_ :> r_) :> r, {3}] /.\n      (a_ :> {b___}) :> (generate[a] := generate[Alternatives[b]])\n  ; generate[a_Alternatives] :=\n      generate @@ RandomChoice[List @@ Hold /@ Unevaluated @ a]\n  ; generate[(r:(Repeated|RepeatedNull))[e_]] :=\n      Hold @@ Evaluate @ ConstantArray[0, randomCount[] + Boole[r===Repeated]] /.\n        0 :> generate[e] /.\n        Hold -> Composition[generate, List]\n  ; generate[l_List] := StringJoin @@ generate /@ Unevaluated @ l\n  ; generate[x:_[___]] := generate /@ Unevaluated @ x\n  ; generate[x_] := x\n  ; generate[expr]\n  ]\n\nHere is the species grammar, adapted (sic) to the form required by randomSentence:\nClearAll[f, g, h, i]\nf[x___] := x <> \"er\";\ng[x___] := x <> \"ed\";\nh[x___] := x <> \"ing\";\ni[x___] := x <> \"y\";\n\n$rules =\n  { \"Species\" :> \"Animal\" | \"Plant\"\n  , \"Species\" :> f@\"Action\"\n  , \"Species\" :> {\"Color\" | \"Type\", \"-\", \"Species\"}\n\n  , \"Attribute\" :> \"Type\" | \"Color\"\n  , \"Attribute\" :> {\"Animal\", \"-\", f@\"Action\"}\n  , \"Attribute\" :> {\"Color\" | \"Type\", \"-\", g@\"Part\"}\n  , \"Attribute\" :> i@\"Plant\"\n  , \"Attribute\" :> {\"Plant\" | \"Animal\", \"-\", h@\"Action\"}\n\n  , \"Animal\" :> \"warble\"|\"shrew\"|\"whale\"|\"caiman\"|\"babuin\"|\"bat\"|\"bug\"\n  , \"Plant\" :> \"bush\"|\"moss\"|\"fern\"|\"grass\"|\"squash\"|\"seed\"\n  , \"Part\" :> \"back\"|\"head\"|\"finger\"|\"tail\"|\"ear\"|\"wing\"|\"thorn\"\n  , \"Color\" :> \"black\"|\"red\"|\"white\"|\"blue\"|\"silver\"|\"crimson\"|\"dark\"\n  , \"Type\" :>  \"long\"|\"cross\"|\"sharp\"|\"thick\"|\"heavy\"|\"fluffy\"|\"big\"|\"wild\"\n  , \"Action\" :> \"jump\"|\"kill\"|\"stalk\"|\"sting\"|\"climb\"|\"crawl\"|\"eat\"\n  };\n\nHere is a sample use of the function (note that there is no need to explicitly specify the terminals, non-terminals and functions):\nTable[randomSentence[$rules, {{\"Attribute\", \" \"}..., \"Species\"}], {10}] // Column\n\n\nbug\n  bat-climbing moss\n  red-heavy-cross-dark-thick-stalker\n  babuin\n  squashy heavy-killer\n  killer\n  seed\n  squashy white-fingered heavy-red-whale\n  climber\n  squashy thick-winged stinger\n\nHow It Works\nThe trickiest part of this problem is to make sure that none of the function expressions in the grammar are evaluated until they are needed -- and even then they may require some preprocessing of their arguments.  To make this possible, randomSentence must not evaluate the rules or sentence form passed to it:\nSetAttributes[randomSentence, HoldAll]\nrandomSentence[rules_, expr_] :=\n\nWe are going to use a helper function called generate.  Again, it must not evaluate any expressions prematurely:\n  Module[{generate}\n  , SetAttributes[generate, HoldAll]\n\ngenerate will be able to convert any grammar expression into a string.  There are many types of grammar expressions.  First, we will teach generate how to deal with each of the non-terminal symbols.  We group all of the rules into lists, one for each nonterminal.  Then we convert each of those groups into definitions for generate as if\nthey had been specified using Alternatives in the original grammar:\n  ; Replace[#[[1, 1]] :> #& /@ GatherBy[rules, First], (_ :> r_) :> r, {3}] /.\n      (a_ :> {b___}) :> (generate[a] := generate[Alternatives[b]])\n\nAlternatives expressions are processed by selecting a random alternative from the list and then applying generate to that choice:\n  ; generate[a_Alternatives] :=\n      generate @@ RandomChoice[List @@ Hold /@ Unevaluated @ a]\n\nRepeated expressions are processed by generating the repeated expression a random number of times.  RepeatedNull allows zero occurrences whereas Repeated will have at least one.  The tortured logic in this operation is due to the need to make sure that each repetition is not evaluated before it has been duly interpreted as a grammar expression.  Also, it is important to ensure that each repetition is generated independently:\n  ; generate[(r:(Repeated|RepeatedNull))[e_]] :=\n      Hold @@ Evaluate @ ConstantArray[0, randomCount[] + Boole[r===Repeated]] /.\n        0 :> generate[e] /.\n        Hold -> Composition[generate, List]\n\nEach grammar expression in a list is evaluated independently and then the results are joined together:\n  ; generate[l_List] := StringJoin @@ generate /@ Unevaluated @ l\n\nAny function call must be made after the arguments have been individually generated:\n  ; generate[x:_[___]] := generate /@ Unevaluated @ x\n\nAnything else is passed unchanged (presumably strings):\n  ; generate[x_] := x\n\nNow that generate is defined, all that remains is to use it:\n  ; generate[expr]\n  ]\n\nrandomSentence uses the helper function randomCount to generate a random repetition counts.  For this example, we are using a geometric distribution where the probability of each successive count is half that of its predecessor.  Adjust this distribution to suit your taste.\nrandomCount[] := RandomVariate[GeometricDistribution[0.5]]\n\n", "front end - Is there a way to require confirmation for execution of certain cells?": "\nPerhaps there are better ways, but one I am aware of is by using CellEvaluationFunction option for a given cell. Here is code to generate some example cell with the behavior similar to what you presumably desire:\nCellPrint[\n   Cell[BoxData[RowBox[{\"100\", \"!\"}]], \"Input\", \n     CellEvaluationFunction -> \n       (Module[{res = ChoiceDialog[\"Evaluate this cell?\"]}, \n          If[res, ToExpression[#]]] &)\n   ]\n]\n\nA very informative account on CellEvaluationFunction, and the one I originally learned about it from, is this answer by @WReach.\nEDIT\nHere is a more elaborate version, which would also highlight the cell in question:\nmakeCell[] :=\n With[{tag = ToString[Unique[]] <> DateString[]},\n    CellPrint[\n      Cell[BoxData[RowBox[{\"100\", \"!\"}]], \"Input\", CellTags -> tag,\n        CellEvaluationFunction ->\n          ( \n             Module[{result = Null, thiscell, oldbackgr},\n               NotebookLocate[tag];\n               thiscell = NotebookSelection[];\n               oldbackgr =  Background /. Options[thiscell] /. Background -> None;                   \n               SetOptions[thiscell, Background -> LightGreen];\n               If[ChoiceDialog[\"Evaluate this cell?\"], result = ToExpression[#]];\n               SetOptions[thiscell, Background -> oldbackgr];\n               SelectionMove[EvaluationNotebook[], After, Cell];\n               result\n             ] &)\n      ]]]\n\nYou can execute makeCell[] to see what this does.\n", "random - Going Beyond Pseudorandom Numbers": "\nYou cannot, by principle, get true randomness through a deterministic algorithm, no matter how sophisticated. If you need true random numbers, you'll have to collect some physical randomness. I don't know about an OS-independent way to do that, but on Linux, the pseudo-file /dev/random collects entropy from various sources.\nOf course, unless you are implementing cryptography, you'll most likely not really need true randomness (and even there you generally only need it to seed the cryptographically secure pseudo-random number generator, unless you are generating an one-time pad).\n", "list manipulation - Clustering of space-time data": "\nFinding the cluster centers is the hard part.  There are zillions of ways to do this, such as standardizing $(x,y,t)$ and applying some (almost any) kind of cluster analysis.  But these data are special: the eye movement has a measurable speed.  The gaze is resting if and only if the speed is low.  The threshold for \"low\" is physically determined (but can also be found in a histogram of the speeds: there will be a break just above 0).  That yields the very simple solution: fixations occur at the points of low speed. \nIt's a good idea to smooth the original data slightly before estimating the speeds:\ndata = Transpose[Import[\"f:/temp/gazeSeq_1.dat\"]];\nsmooth = MovingAverage[#, 5] & /@ data;\ndelta = Differences /@ smooth;\nspeeds = Prepend[Norm[Most[#]]/Last[#] & /@ Transpose[delta], 0];\nHistogram[Log[# + 0.002] & /@ speeds]\n\n\nThe bimodality is clear.  The gap is around $\\exp(-6)-0.002\\approx 0.0005$.  Whence\nw = Append[smooth, speeds];\nListPlot[#[[1 ;; 2]] & /@ Select[Transpose[w], Last[#] < 0.0005 &], \n PlotStyle -> PointSize[0.015]]\n\n\nThere are the gaze fixations.  having found them, the clustering is (almost) trivial to do (because each fixation now exists as a contiguous sequence of observations in the original data, from which it is readily split off: this respects the time component as well as the spatial ones).  This method works beautifully for all seven of the sample datasets.\nOne advantage of this approach is that it can detect clusters of very short gaze fixations, even those of just two points in the dataset.  These would likely go unnoticed by most general-purpose or ad hoc solutions.  Of course you can screen them out later if they are of little interest.\n", "parallelization - Filling global arrays in parallel calculations": "\nPlease see the answer I gave here.\n\nParallelization works well and reliable only if you use constructs with no side effects.    This is an essential point when using Mathematica's parallel computing tools.  If you are not sure what a side effect is, please read about it.\nThis explains why For won't be auto-parallelized.\n\nThe reason why the function b does not seem to change f is that f will be changed only on the parallel kernels, but the results won't be sent back to the main kernel.  It is not even clear which f should be sent back.  The one on kernel 1 or the one on kernel 2?  (Obviously you want them merged in a special way, but there is no way for the computer to guess how.)  I discuss this issue as well here.\n\nYou can use SetSharedVariable[f] to force all accessed to f to be synchronized through the main kernel.  This will give you the desired result, but it will hurt performance because of the constant communication between the main kernel and subkernels.  It is also a potential source of errors because two different subkernels might change the same value in f.\nI recommend you never change any \"global\" variables from parallel calculations.  This is always a potential source of mistakes and when done properly, it will reduce performance.  Instead formulate your problem without using side effects.  Your specific example would look like ParallelTable[k+1, {k, num}].  Think about if you can do this with your actual problem as well.\n", "graphics - Generating graphs interactively (GUI)": "\nYou could do create a simple graph editing tool to create a graph from scratch by doing something like this. To add edges you just click and drag.\nDynamicModule[{pt1, pt2, ind1, ind2, pts = {}, edges = {}, cedge = {}},\n Manipulate[\n  EventHandler[\n   Dynamic@Graphics[\n     {Line[pts[[#]] & /@ edges],\n      cedge, {Red, PointSize[Medium], Point[pts]}}, PlotRange -> 1],\n   {\"MouseDown\" :>\n     (pt2 = pt1 = Round[MousePosition[\"Graphics\"], 0.1];\n      ind1 = PadRight[Flatten[Position[pts, pt1]], 1, Length[pts] + 1][[1]]),\n    \"MouseDragged\" :>\n     (pt2 = Round[MousePosition[\"Graphics\"], 0.1]; \n      cedge = {Gray, Dashed, Line[{pt1, pt2}]}),\n    \"MouseUp\" :>\n     (pt2 = Round[MousePosition[\"Graphics\"], 0.1];\n      If[ind1 == Length[pts] + 1, AppendTo[pts, pt1]];\n      ind2 = PadRight[Flatten[Position[pts, pt2]], 1, Length[pts] + 1][[1]];\n      If[ind2 == Length[pts] + 1, AppendTo[pts, pt2]];\n      If[ind1 =!= ind2, AppendTo[edges, {ind1, ind2}]];\n      cedge = {})}],\n\n  Row[{Button[\"Paste\",\n     Print[Graph[Range[Length[pts]], edges, VertexCoordinates -> pts]]],\n   Button[\"Clear\", pts = {}; edges = {}]}]]]\n\nScreenshot:\n\nPasted graph:\n\n", "programming - Cycles of length N in a graph": "\nWith the following obvious replacements for the two graphs: PetersenGraph[5, 2] --> yourgraph, and CycleGraph[5] --->CycleGraph[n] for general n where \n  yourgraph=AdjacencyGraph[yourAdjacencyMatrix]\n\nYou can use the first example from the docs on SubGraph section Applications: \n  {g, h} = {PetersenGraph[5, 2], CycleGraph[5]};\n  Grid[{{g, h}}]\n\n\nSelect the subgraphs isomorphic to CycleGraph[5]:\n  s = Subsets[Range[VertexCount[g]], {VertexCount[h]}];\n  Select[Subgraph[g, #] & /@ s, IsomorphicGraphQ[#, h] &];\n\nand view\n  Grid[Partition[\n  HighlightGraph[g, #] & /@ \n  Select[Subgraph[g, #] & /@ s, IsomorphicGraphQ[#, h] &], {5}]]\n\n\nEDIT: A function to select cyclic subgraphs with k vertices\n ClearAll[cyclicSubgraphs];\n cyclicSubgraphs[grph_Graph, k_Integer] := \n Select[Subgraph[grph, #] & /@ Subsets[Range[VertexCount[grph]], {k}], \n IsomorphicGraphQ[#, CycleGraph[k]] &]\n\nExample:\nRow[HighlightGraph[SetProperty[GraphData[{\"Antiprism\", 6}], {VertexLabels -> \"Name\", \n VertexSize -> Medium, ImagePadding -> 20, ImageSize -> 300}], #] & /@ \n cyclicSubgraphs[GraphData[{\"Antiprism\", 6}], 8])]\n\n\n", "polynomials - Gr\u00f6bner basis on a particular set of equations": "\nYour question cannot realistically be answered. One almost never knows what specifically comprises such an impediment.\nHere is a Groebner basis for your system of polynomials, computed for degree reverse lexicographic order. It takes some time to do this. Not sure if it will run in reasonable time directly; I used a numeric approximation and rationalized (have not validated the result but I'm fairly sure it is correct).\ngb2 = {a[15], (-3*a[12])/2 + a[8]*a[12] + a[16]/2 + (3*a[20])/2, a[6]/2 + a[6]*a[8] - (3*a[10])/2 - a[19]/2, \n (-17*a[6])/18 - (35*a[7])/9 + (23*a[10])/6 + a[8]*a[10] + (29*a[19])/6 - (61*a[8]*a[19])/9, \n (17*a[12])/18 + (35*a[13])/9 + (35*a[16])/18 - (61*a[8]*a[16])/9 - (29*a[20])/6 + a[8]*a[20], \n -a[12]/3 + (5*a[13])/6 + a[8]*a[13] + (7*a[16])/6 - (8*a[8]*a[16])/3 - a[20]/2, \n a[6]/3 - (11*a[7])/6 + a[7]*a[8] + a[10]/2 + (3*a[19])/2 - (8*a[8]*a[19])/3, -(a[6]*a[12]) + a[10]*a[12] + a[12]*a[19], \n (52*a[12])/21 - a[3]*a[12] + a[9]*a[12] + (125*a[13])/21 + (52*a[16])/21 - (208*a[8]*a[16])/21 + a[12]*a[18] - (52*a[20])/7, \n -(a[6]*a[12]) + a[6]*a[16] + a[12]*a[19], -(a[12]*a[19]) + a[6]*a[20], (52*a[6])/21 - a[3]*a[6] + (125*a[7])/21 + a[6]*a[9] - \n  (52*a[10])/7 + a[6]*a[18] - (52*a[19])/7 + (208*a[8]*a[19])/21, -(a[7]*a[12]) + a[6]*a[13], \n (24*a[6])/7 - a[3]*a[6] + (115*a[7])/28 + a[6]*a[9] - (183*a[10])/28 - (211*a[19])/28 + a[3]*a[19] + (101*a[8]*a[19])/14, \n (-202*a[6])/63 - (1805*a[7])/252 - a[6]*a[9] + (787*a[10])/84 + a[3]*a[10] + (871*a[19])/84 - (1679*a[8]*a[19])/126, \n (20*a[12])/21 - a[9]*a[12] - (155*a[13])/84 - (235*a[16])/84 + a[3]*a[16] + (113*a[8]*a[16])/42 + (25*a[20])/28, \n (-46*a[12])/63 - a[3]*a[12] + a[9]*a[12] - (305*a[13])/252 - (121*a[16])/252 + (431*a[8]*a[16])/126 + (163*a[20])/84 + \n  a[3]*a[20], (-47*a[12])/42 - a[4]*a[12] - (199*a[13])/42 + a[3]*a[13] - (34*a[16])/21 + (136*a[8]*a[16])/21 + (34*a[20])/7, \n (-47*a[6])/42 - a[4]*a[6] - (199*a[7])/42 + a[3]*a[7] + (34*a[10])/7 + (34*a[19])/7 - (136*a[8]*a[19])/21, \n (22*a[6]^2)/105 + (a[6]*a[7])/3 - (19*a[6]*a[10])/35 - (92*a[6]*a[19])/105 + a[10]*a[19] + a[19]^2/3, \n (a[6]*a[12])/3 - (a[7]*a[12])/3 - a[12]*a[19] + (a[16]*a[19])/3 + a[19]*a[20], \n (121*a[6])/84 - (a[3]*a[6])/2 + (a[4]*a[6])/2 + (253*a[7])/168 - (137*a[10])/56 - (137*a[19])/56 + (169*a[8]*a[19])/84 + \n  a[9]*a[19], (377*a[6])/84 - (a[3]*a[6])/2 - (a[4]*a[6])/2 + (1277*a[7])/168 + a[6]*a[9] - (649*a[10])/56 - (649*a[19])/56 + \n  (1193*a[8]*a[19])/84 + a[18]*a[19], (a[6]*a[12])/2 - (a[7]*a[12])/2 - a[12]*a[19] + a[13]*a[19], \n (23*a[6]^2)/70 - (a[6]*a[7])/2 + (6*a[6]*a[10])/35 - (29*a[6]*a[19])/35 + a[7]*a[19], \n (26627*a[6])/8064 - (a[3]*a[6])/2 - (a[4]*a[6])/2 + (73307*a[7])/16128 + a[6]*a[9] - (39499*a[10])/5376 - \n  (39499*a[19])/5376 + a[4]*a[19] + (65243*a[8]*a[19])/8064, (227*a[6]^2)/315 - (4*a[6]*a[7])/9 - (134*a[6]*a[10])/105 + \n  a[10]^2 - (52*a[6]*a[19])/315 - a[19]^2/9, (-2*a[6]*a[12])/3 - (a[7]*a[12])/3 + a[10]*a[16] + a[12]*a[19] + (a[16]*a[19])/3, \n (-4*a[6]*a[12])/9 + (4*a[7]*a[12])/9 - (a[16]*a[19])/9 + a[10]*a[20], (-713*a[6])/252 + (a[3]*a[6])/2 - (a[4]*a[6])/2 - \n  (2789*a[7])/504 - a[6]*a[9] + (1321*a[10])/168 + a[9]*a[10] + (1321*a[19])/168 - (2537*a[8]*a[19])/252, \n (263*a[6])/252 - (a[3]*a[6])/2 + (a[4]*a[6])/2 + (1619*a[7])/504 - (631*a[10])/168 + a[10]*a[18] - (631*a[19])/168 + \n  (1367*a[8]*a[19])/252, -(a[6]*a[12])/2 - (a[7]*a[12])/2 + a[10]*a[13] + a[12]*a[19], \n (47*a[6]^2)/70 - (a[6]*a[7])/2 - (41*a[6]*a[10])/35 + a[7]*a[10] - (6*a[6]*a[19])/35, \n (-86531*a[6])/24192 + (a[3]*a[6])/2 - (a[4]*a[6])/2 - (329051*a[7])/48384 - a[6]*a[9] + (159307*a[10])/16128 + a[4]*a[10] + \n  (159307*a[19])/16128 - (304859*a[8]*a[19])/24192, (22*a[12]^2)/105 + (a[12]*a[13])/3 - (92*a[12]*a[16])/105 + a[16]^2/3 - \n  (19*a[12]*a[20])/35 + a[16]*a[20], (169*a[12])/84 + (a[3]*a[12])/2 - (a[4]*a[12])/2 - a[9]*a[12] + (277*a[13])/168 + \n  (23*a[16])/168 - (361*a[8]*a[16])/84 + a[9]*a[16] - (233*a[20])/56, (121*a[12])/84 - (a[3]*a[12])/2 + (a[4]*a[12])/2 + \n  (253*a[13])/168 - (73*a[16])/168 - (169*a[8]*a[16])/84 + a[16]*a[18] - (137*a[20])/56, \n (23*a[12]^2)/70 - (a[12]*a[13])/2 - (29*a[12]*a[16])/35 + a[13]*a[16] + (6*a[12]*a[20])/35, \n -(a[6]*a[12])/2 - (a[7]*a[12])/2 + a[7]*a[16] + a[12]*a[19], (6659*a[12])/8064 + (a[3]*a[12])/2 - (a[4]*a[12])/2 - \n  a[9]*a[12] - (22693*a[13])/16128 - (27947*a[16])/16128 + a[4]*a[16] + (14629*a[8]*a[16])/8064 + (437*a[20])/5376, \n (227*a[12]^2)/315 - (4*a[12]*a[13])/9 - (52*a[12]*a[16])/315 - a[16]^2/9 - (134*a[12]*a[20])/105 + a[20]^2, \n (263*a[12])/252 - (a[3]*a[12])/2 + (a[4]*a[12])/2 + (1619*a[13])/504 + (841*a[16])/504 - (1367*a[8]*a[16])/252 - \n  (631*a[20])/168 + a[9]*a[20], (-89*a[12])/252 - (a[3]*a[12])/2 - (a[4]*a[12])/2 + a[9]*a[12] + (211*a[13])/504 + \n  (137*a[16])/504 + (41*a[8]*a[16])/252 + (73*a[20])/168 + a[18]*a[20], \n (47*a[12]^2)/70 - (a[12]*a[13])/2 - (6*a[12]*a[16])/35 - (41*a[12]*a[20])/35 + a[13]*a[20], \n (a[6]*a[12])/2 - (a[7]*a[12])/2 - a[12]*a[19] + a[7]*a[20], (-26627*a[12])/24192 - (a[3]*a[12])/2 - (a[4]*a[12])/2 + \n  a[9]*a[12] - (41051*a[13])/48384 - (11989*a[16])/48384 + (65243*a[8]*a[16])/24192 + (39499*a[20])/16128 + a[4]*a[20], \n (2*a[12])/7 + (a[3]*a[12])/2 - (a[4]*a[12])/2 - a[9]*a[12] + a[13]/14 + a[9]*a[13] + (2*a[16])/7 - (8*a[8]*a[16])/7 - \n  (6*a[20])/7, (-26*a[6])/21 + (a[3]*a[6])/2 - (a[4]*a[6])/2 - (125*a[7])/42 - a[6]*a[9] + a[7]*a[9] + (26*a[10])/7 + \n  (26*a[19])/7 - (104*a[8]*a[19])/21, 1733/1602 - (641*a[3])/534 + (95*a[3]^2)/801 + (3775*a[4])/801 - (440*a[3]*a[4])/267 + \n  (94481*a[6]^2)/100926 - (7325*a[6]*a[7])/14418 - (182*a[8])/89 + (182*a[8]^2)/89 + (67*a[9])/178 + (424*a[3]*a[9])/801 - \n  (803*a[8]*a[9])/267 + a[9]^2 - (7201*a[6]*a[10])/16821 + (94481*a[12]^2)/100926 - (7325*a[12]*a[13])/14418 - \n  (72878*a[12]*a[16])/50463 + (7325*a[16]^2)/7209 - (1405*a[18])/534 + (424*a[3]*a[18])/801 + (803*a[8]*a[18])/267 - \n  (346*a[9]*a[18])/267 + a[18]^2 - (72878*a[6]*a[19])/50463 + (7325*a[19]^2)/7209 - (7201*a[12]*a[20])/16821, \n (26*a[12])/21 - (a[3]*a[12])/2 - (a[4]*a[12])/2 + a[9]*a[12] + (125*a[13])/42 + (26*a[16])/21 - (104*a[8]*a[16])/21 + \n  a[13]*a[18] - (26*a[20])/7, (58*a[6])/21 - (a[3]*a[6])/2 - (a[4]*a[6])/2 + (253*a[7])/42 + a[6]*a[9] - (58*a[10])/7 + \n  a[7]*a[18] - (58*a[19])/7 + (232*a[8]*a[19])/21, -5455/12816 + (1931*a[3])/4272 - (169*a[3]^2)/6408 + (1627*a[4])/1602 - \n  (572*a[3]*a[4])/267 - (39349*a[6]^2)/807408 + (23765*a[6]*a[7])/57672 + (881*a[8])/1068 - (881*a[8]^2)/1068 - \n  (2169*a[9])/1424 + (7489*a[3]*a[9])/6408 + a[4]*a[9] + (2311*a[8]*a[9])/2136 - (97787*a[6]*a[10])/269136 - \n  (39349*a[12]^2)/807408 + (23765*a[12]*a[13])/57672 + (372059*a[12]*a[16])/807408 - (23765*a[16]^2)/28836 - \n  (1885*a[18])/4272 + (7489*a[3]*a[18])/6408 + a[4]*a[18] - (2311*a[8]*a[18])/2136 - (610*a[9]*a[18])/267 + \n  (372059*a[6]*a[19])/807408 - (23765*a[19]^2)/28836 - (97787*a[12]*a[20])/269136, \n (47*a[12]^2)/70 - (3*a[12]*a[13])/2 + a[13]^2 - (6*a[12]*a[16])/35 - (6*a[12]*a[20])/35, \n (a[6]*a[12])/2 - (3*a[7]*a[12])/2 + a[7]*a[13], (-26*a[12])/21 + (a[3]*a[12])/2 - (3*a[4]*a[12])/2 - (125*a[13])/42 + \n  a[4]*a[13] - (26*a[16])/21 + (104*a[8]*a[16])/21 + (26*a[20])/7, (47*a[6]^2)/70 - (3*a[6]*a[7])/2 + a[7]^2 - \n  (6*a[6]*a[10])/35 - (6*a[6]*a[19])/35, (-26*a[6])/21 + (a[3]*a[6])/2 - (3*a[4]*a[6])/2 - (125*a[7])/42 + a[4]*a[7] + \n  (26*a[10])/7 + (26*a[19])/7 - (104*a[8]*a[19])/21, -63037/230688 + (24473*a[3])/76896 - (5191*a[3]^2)/115344 + \n  (77081*a[4])/57672 - (10073*a[3]*a[4])/4806 + a[4]^2 - (20304931*a[6]^2)/581333760 + (7875295*a[6]*a[7])/33219072 + \n  (9641*a[8])/19224 - (9641*a[8]^2)/19224 - (3891*a[9])/2848 + (131599*a[3]*a[9])/115344 + (29083*a[8]*a[9])/38448 - \n  (78341821*a[6]*a[10])/387555840 - (20304931*a[12]^2)/581333760 + (7875295*a[12]*a[13])/33219072 + \n  (316245187*a[12]*a[16])/1162667520 - (7875295*a[16]^2)/16609536 - (46891*a[18])/76896 + (131599*a[3]*a[18])/115344 - \n  (29083*a[8]*a[18])/38448 - (2864*a[9]*a[18])/2403 + (316245187*a[6]*a[19])/1162667520 - (7875295*a[19]^2)/16609536 - \n  (78341821*a[12]*a[20])/387555840, -3/4 + (3*a[3])/4 + (3*a[6]^2)/8 + 2*a[8] - (3*a[3]*a[8])/2 - (3*a[8]^2)/2 + a[8]^3 + \n  (3*a[8]*a[9])/4 - (3*a[6]*a[10])/8 - (3*a[12]^2)/8 + (3*a[12]*a[16])/8 - (3*a[18])/4 + (3*a[8]*a[18])/4 - (3*a[6]*a[19])/8 + \n  (3*a[12]*a[20])/8, -3/4 + (3*a[3])/4 + 2*a[8] - a[3]*a[8] - 2*a[8]^2 + a[3]*a[8]^2 - a[9]/4 - (a[8]*a[9])/2 - (3*a[18])/4 + \n  (a[8]*a[18])/2, (-5*a[6])/4 - (5*a[7])/2 + (15*a[10])/4 + (15*a[19])/4 - (11*a[8]*a[19])/2 + a[8]^2*a[19], \n (-5*a[12])/4 - (5*a[13])/2 - (3*a[16])/4 + (7*a[8]*a[16])/2 + a[8]^2*a[16] + (15*a[20])/4, \n 11501/4272 - (4217*a[3])/1424 + (575*a[3]^2)/2136 + (122405*a[4])/1068 - (19585*a[3]*a[4])/89 - (1007425*a[6]^2)/38448 + \n  (1106575*a[6]*a[7])/38448 - (1821*a[8])/356 + (93*a[3]*a[8])/2 + (435*a[4]*a[8])/4 - (14733*a[8]^2)/356 - \n  (49223*a[9])/1424 + (12895*a[3]*a[9])/2136 + 180*a[4]*a[9] - (14135*a[8]*a[9])/712 + a[8]^2*a[9] + (135*a[9]^2)/4 - \n  (16525*a[6]*a[10])/6408 + (12989045*a[12]^2)/269136 + (1106575*a[12]*a[13])/38448 - (1310755*a[12]*a[16])/67284 - \n  (1106575*a[16]^2)/19224 - (159373*a[18])/1424 + (469465*a[3]*a[18])/2136 - (80917*a[8]*a[18])/712 - (80585*a[9]*a[18])/356 + \n  (132125*a[6]*a[19])/2403 - (1106575*a[19]^2)/19224 - (3455845*a[12]*a[20])/44856, \n -15817/4272 + (3829*a[3])/1424 + (2165*a[3]^2)/2136 - (126565*a[4])/1068 + (19685*a[3]*a[4])/89 + (6846695*a[6]^2)/269136 - \n  (1085975*a[6]*a[7])/38448 + (2997*a[8])/356 - (93*a[3]*a[8])/2 - (435*a[4]*a[8])/4 + (13557*a[8]^2)/356 + \n  (51123*a[9])/1424 - (18035*a[3]*a[9])/2136 - 180*a[4]*a[9] + (14527*a[8]*a[9])/712 - (135*a[9]^2)/4 + \n  (125855*a[6]*a[10])/44856 - (13194325*a[12]^2)/269136 - (1085975*a[12]*a[13])/38448 + (1398125*a[12]*a[16])/67284 + \n  (1085975*a[16]^2)/19224 + (163481*a[18])/1424 - (474605*a[3]*a[18])/2136 + (79101*a[8]*a[18])/712 + a[8]^2*a[18] + \n  (81385*a[9]*a[18])/356 - (1806065*a[6]*a[19])/33642 + (1085975*a[19]^2)/19224 + (3466025*a[12]*a[20])/44856, \n 227/534 - (199*a[3])/178 + (185*a[3]^2)/267 - (35*a[4])/1068 + (80*a[3]*a[4])/89 - (665*a[6]^2)/9612 - \n  (3445*a[6]*a[7])/9612 - (14*a[8])/89 - a[4]*a[8] + (14*a[8]^2)/89 + a[4]*a[8]^2 + (647*a[9])/356 - (425*a[3]*a[9])/267 - \n  (121*a[8]*a[9])/89 + (685*a[6]*a[10])/1602 - (665*a[12]^2)/9612 - (3445*a[12]*a[13])/9612 - (695*a[12]*a[16])/2403 + \n  (3445*a[16]^2)/4806 + (163*a[18])/356 - (425*a[3]*a[18])/267 + (121*a[8]*a[18])/89 + (160*a[9]*a[18])/89 - \n  (695*a[6]*a[19])/2403 + (3445*a[19]^2)/4806 + (685*a[12]*a[20])/1602, 70657/4272 - (18737*a[3])/1424 - (7223*a[3]^2)/2136 + \n  (814915*a[4])/1068 - (130405*a[3]*a[4])/89 - (6698009*a[6]^2)/38448 + (7374425*a[6]*a[7])/38448 - (6401*a[8])/178 + \n  (1227*a[3]*a[8])/4 + a[3]^2*a[8] + (2885*a[4]*a[8])/4 - (96757*a[8]^2)/356 - (339915*a[9])/1424 + (105425*a[3]*a[9])/2136 + \n  1200*a[4]*a[9] - (84397*a[8]*a[9])/712 + (873*a[9]^2)/4 - (14092*a[6]*a[10])/801 + (12304915*a[12]^2)/38448 + \n  (7374425*a[12]*a[13])/38448 - (2465245*a[12]*a[16])/19224 - (7374425*a[16]^2)/19224 - (1063001*a[18])/1424 + \n  (3136943*a[3]*a[18])/2136 - (541451*a[8]*a[18])/712 - (538343*a[9]*a[18])/356 + (7036217*a[6]*a[19])/19224 - \n  (7374425*a[19]^2)/19224 - (1639945*a[12]*a[20])/3204, 22159/1424 - (18573*a[3])/1424 - (1793*a[3]^2)/712 + (61120*a[4])/89 - \n  (117345*a[3]*a[4])/89 - (14078993*a[6]^2)/89712 + (2211575*a[6]*a[7])/12816 - (2994*a[8])/89 + (1113*a[3]*a[8])/4 + \n  (2595*a[4]*a[8])/4 - (87081*a[8]^2)/356 - (305731*a[9])/1424 + (31507*a[3]*a[9])/712 + 1080*a[4]*a[9] - \n  (76705*a[8]*a[9])/712 + a[3]*a[8]*a[9] + (783*a[9]^2)/4 - (29209*a[6]*a[10])/1869 + (3685885*a[12]^2)/12816 + \n  (2211575*a[12]*a[13])/12816 - (737155*a[12]*a[16])/6408 - (2211575*a[16]^2)/6408 - (955761*a[18])/1424 + \n  (940553*a[3]*a[18])/712 - (487199*a[8]*a[18])/712 - (484237*a[9]*a[18])/356 + (14780009*a[6]*a[19])/44856 - \n  (2211575*a[19]^2)/6408 - (491455*a[12]*a[20])/1068, 21011/1424 - (17097*a[3])/1424 - (1957*a[3]^2)/712 + (121735*a[4])/178 - \n  (117285*a[3]*a[4])/89 - (14083381*a[6]^2)/89712 + (2217475*a[6]*a[7])/12816 - (2871*a[8])/89 + (1113*a[3]*a[8])/4 + \n  (2595*a[4]*a[8])/4 - (87573*a[8]^2)/356 - (307439*a[9])/1424 + (31903*a[3]*a[9])/712 + 1080*a[4]*a[9] - \n  (74405*a[8]*a[9])/712 + (783*a[9]^2)/4 - (29978*a[6]*a[10])/1869 + (25796807*a[12]^2)/89712 + (2217475*a[12]*a[13])/12816 - \n  (5137241*a[12]*a[16])/44856 - (2217475*a[16]^2)/6408 - (952869*a[18])/1424 + (940237*a[3]*a[18])/712 - \n  (489499*a[8]*a[18])/712 + a[3]*a[8]*a[18] - (484469*a[9]*a[18])/356 + (14802853*a[6]*a[19])/44856 - (2217475*a[19]^2)/6408 - \n  (3443261*a[12]*a[20])/7476, 416159/25632 - (116359*a[3])/8544 - (33541*a[3]^2)/12816 + (560560*a[4])/801 - \n  (717005*a[3]*a[4])/534 - (258204115*a[6]^2)/1614816 + (10125205*a[6]*a[7])/57672 - (37475*a[8])/1068 + (2269*a[3]*a[8])/8 + \n  (2641*a[4]*a[8])/4 + a[3]*a[4]*a[8] - (530873*a[8]^2)/2136 - (622243*a[9])/2848 + (577657*a[3]*a[9])/12816 + \n  1099*a[4]*a[9] - (468767*a[8]*a[9])/4272 + (801*a[9]^2)/4 - (8433875*a[6]*a[10])/538272 + (474432137*a[12]^2)/1614816 + \n  (10125205*a[12]*a[13])/57672 - (190926397*a[12]*a[16])/1614816 - (10125205*a[16]^2)/28836 - (5840587*a[18])/8544 + \n  (17241661*a[3]*a[18])/12816 - (2975533*a[8]*a[18])/4272 - (1479353*a[9]*a[18])/1068 + (541709855*a[6]*a[19])/1614816 - \n  (10125205*a[19]^2)/28836 - (252645959*a[12]*a[20])/538272, -a[6]^2/140 + (a[6]*a[7])/2 - (69*a[6]*a[10])/140 + \n  (a[6]*a[19])/140 - a[19]^2/2 + a[8]*a[19]^2, -(a[16]*a[19])/2 + a[8]*a[16]*a[19], \n a[12]^2/140 - (a[12]*a[13])/2 - (a[12]*a[16])/140 - a[16]^2/2 + a[8]*a[16]^2 + (69*a[12]*a[20])/140, \n 1360511/68352 - (393735*a[3])/22784 - (89653*a[3]^2)/34176 + (14068805*a[4])/17088 - (2248755*a[3]*a[4])/1424 - \n  (809530465*a[6]^2)/4306176 + (127195375*a[6]*a[7])/615168 - (120847*a[8])/2848 + (21441*a[3]*a[8])/64 + \n  (49875*a[4]*a[8])/64 - (1666555*a[8]^2)/5696 - (5861477*a[9])/22784 + (1813747*a[3]*a[9])/34176 + 1290*a[4]*a[9] - \n  (1500619*a[8]*a[9])/11392 + (15215*a[9]^2)/64 + a[8]*a[9]^2 - (3368215*a[6]*a[10])/179424 + (1487977835*a[12]^2)/4306176 + \n  (127195375*a[12]*a[13])/615168 - (298805105*a[12]*a[16])/2153088 - (127195375*a[16]^2)/307584 - (18304903*a[18])/22784 + \n  (54059773*a[3]*a[18])/34176 - (9329613*a[8]*a[18])/11392 - (9279521*a[9]*a[18])/5696 + (849949045*a[6]*a[19])/2153088 - \n  (127195375*a[19]^2)/307584 - (198195455*a[12]*a[20])/358848, 774529/68352 - (216953*a[3])/22784 - (61835*a[3]^2)/34176 + \n  (8144155*a[4])/17088 - (1303885*a[3]*a[4])/1424 - (469418015*a[6]^2)/4306176 + (73766225*a[6]*a[7])/615168 - \n  (69697*a[8])/2848 + (12447*a[3]*a[8])/64 + (28845*a[4]*a[8])/64 - (968389*a[8]^2)/5696 - (3414171*a[9])/22784 + \n  (1066061*a[3]*a[9])/34176 + 750*a[4]*a[9] - (846901*a[8]*a[9])/11392 + (8721*a[9]^2)/64 - (1956065*a[6]*a[10])/179424 + \n  (861334549*a[12]^2)/4306176 + (73766225*a[12]*a[13])/615168 - (172485487*a[12]*a[16])/2153088 - (73766225*a[16]^2)/307584 - \n  (10600697*a[18])/22784 + (31355075*a[3]*a[18])/34176 - (5422259*a[8]*a[18])/11392 - (5385759*a[9]*a[18])/5696 + \n  a[8]*a[9]*a[18] + (492890795*a[6]*a[19])/2153088 - (73766225*a[19]^2)/307584 - (114808177*a[12]*a[20])/358848, \n 1461919/153792 - (421379*a[3])/51264 - (98891*a[3]^2)/76896 + (7264295*a[4])/19224 - (580030*a[3]*a[4])/801 - \n  (840225875*a[6]^2)/9688896 + (65497975*a[6]*a[7])/692064 - (260135*a[8])/12816 + (1233*a[3]*a[8])/8 + (1425*a[4]*a[8])/4 - \n  (1715131*a[8]^2)/12816 - (2015183*a[9])/17088 + (1871267*a[3]*a[9])/76896 + (1777*a[4]*a[9])/3 - (1531063*a[8]*a[9])/25632 + \n  a[4]*a[8]*a[9] + (431*a[9]^2)/4 - (25581925*a[6]*a[10])/3229632 + (1536148885*a[12]^2)/9688896 + \n  (65497975*a[12]*a[13])/692064 - (619177235*a[12]*a[16])/9688896 - (65497975*a[16]^2)/346032 - (18884147*a[18])/51264 + \n  (55781771*a[3]*a[18])/76896 - (9625265*a[8]*a[18])/25632 - (2392367*a[9]*a[18])/3204 + (1757197525*a[6]*a[19])/9688896 - \n  (65497975*a[19]^2)/346032 - (817706845*a[12]*a[20])/3229632, (320*a[12])/63 - a[12]^3 + (640*a[13])/63 + (320*a[16])/63 - \n  (1280*a[8]*a[16])/63 + a[12]^2*a[16] - (320*a[20])/21 + a[12]^2*a[20], (a[6]^2*a[12])/2 - (a[6]*a[7]*a[12])/2 - \n  a[6]*a[12]*a[19] + a[12]*a[19]^2, -(a[6]*a[12]^2)/2 + (a[7]*a[12]^2)/2 + a[12]*a[16]*a[19], \n (-608*a[12])/147 + a[12]^3/2 - (1216*a[13])/147 - (a[12]^2*a[13])/2 - (608*a[16])/147 + (2432*a[8]*a[16])/147 - \n  a[12]^2*a[16] + a[12]*a[16]^2 + (608*a[20])/49, (-2141*a[12])/588 - (3*a[3]*a[12])/4 + (a[3]^2*a[12])/2 + (a[4]*a[12])/4 - \n  (a[3]*a[4]*a[12])/2 + a[9]*a[12] - a[3]*a[9]*a[12] + a[9]^2*a[12] - (1144*a[13])/147 - (572*a[16])/147 + \n  (2288*a[8]*a[16])/147 + (572*a[20])/49, (-221*a[12])/588 - (3*a[3]*a[12])/4 + (a[3]^2*a[12])/2 + (a[4]*a[12])/4 - \n  (a[3]*a[4]*a[12])/2 + a[9]*a[12] - a[3]*a[9]*a[12] + a[4]*a[9]*a[12] - (184*a[13])/147 - (92*a[16])/147 + \n  (368*a[8]*a[16])/147 + (92*a[20])/49, (320*a[6])/63 - a[6]^3 + (640*a[7])/63 - (320*a[10])/21 + a[6]^2*a[10] - \n  (320*a[19])/21 + a[6]^2*a[19] + (1280*a[8]*a[19])/63, (-608*a[6])/147 + a[6]^3/2 - (1216*a[7])/147 - (a[6]^2*a[7])/2 + \n  (608*a[10])/49 + (608*a[19])/49 - a[6]^2*a[19] - (2432*a[8]*a[19])/147 + a[6]*a[19]^2, \n (419*a[6])/588 - (3*a[3]*a[6])/4 + (a[3]^2*a[6])/2 + (a[4]*a[6])/4 - (a[3]*a[4]*a[6])/2 + (136*a[7])/147 + a[6]*a[9] - \n  a[3]*a[6]*a[9] + a[6]*a[9]^2 - (68*a[10])/49 - (68*a[19])/49 + (272*a[8]*a[19])/147, \n (97*a[6])/196 - (3*a[3]*a[6])/4 + (a[3]^2*a[6])/2 + (a[4]*a[6])/4 - (a[3]*a[4]*a[6])/2 + (24*a[7])/49 + a[6]*a[9] - \n  a[3]*a[6]*a[9] + a[4]*a[6]*a[9] - (36*a[10])/49 - (36*a[19])/49 + (48*a[8]*a[19])/49, \n 8117/5340 - (711*a[3])/356 + (1972*a[3]^2)/1335 - a[3]^3 - (404*a[4])/267 + (121*a[3]*a[4])/89 - (591149*a[6]^2)/1177470 - \n  (4625*a[6]*a[7])/19224 - (1363*a[8])/445 + (1363*a[8]^2)/445 + (597*a[9])/356 - (2452*a[3]*a[9])/1335 + a[3]^2*a[9] + \n  (1207*a[8]*a[9])/890 + (1165907*a[6]*a[10])/1569960 - (591149*a[12]^2)/1177470 - (4625*a[12]*a[13])/19224 + \n  (1231471*a[12]*a[16])/4709880 + (4625*a[16]^2)/9612 + (5399*a[18])/1780 - (2452*a[3]*a[18])/1335 + a[3]^2*a[18] - \n  (1207*a[8]*a[18])/890 + (64*a[9]*a[18])/89 + (1231471*a[6]*a[19])/4709880 + (4625*a[19]^2)/9612 + \n  (1165907*a[12]*a[20])/1569960, -1166467/128160 + (75307*a[3])/8544 - (13609*a[3]^2)/64080 + a[3]^3/2 - \n  (9488027*a[4])/25632 + (3035287*a[3]*a[4])/4272 - (a[3]^2*a[4])/2 + (9522942379*a[6]^2)/113037120 - \n  (85692415*a[6]*a[7])/922752 + (200153*a[8])/10680 - (6003*a[3]*a[8])/40 - 351*a[4]*a[8] + (175331*a[8]^2)/1335 + \n  (101651*a[9])/890 - (34595*a[3]*a[9])/1602 - a[3]^2*a[9] - 579*a[4]*a[9] + (79729*a[8]*a[9])/1335 - (546*a[9]^2)/5 + \n  a[3]*a[9]^2 + (649585639*a[6]*a[10])/75358080 - (17589529901*a[12]^2)/113037120 - (85692415*a[12]*a[13])/922752 + \n  (14184418127*a[12]*a[16])/226074240 + (85692415*a[16]^2)/461376 + (3856139*a[18])/10680 - (5693467*a[3]*a[18])/8010 + \n  (392947*a[8]*a[18])/1068 + (7821119*a[9]*a[18])/10680 - (40040526433*a[6]*a[19])/226074240 + (85692415*a[19]^2)/461376 + \n  (18724567159*a[12]*a[20])/75358080, 95051/64080 - (4277*a[3])/4272 + (143*a[3]^2)/8010 - a[3]^3/2 + (10019*a[4])/25632 + \n  (161*a[3]*a[4])/4272 + (a[3]^2*a[4])/2 - (34854541*a[6]^2)/113037120 - (509585*a[6]*a[7])/922752 - (39503*a[8])/10680 + \n  (39503*a[8]^2)/10680 + (1837*a[9])/2848 + (28481*a[3]*a[9])/64080 + (9557*a[8]*a[9])/21360 + \n  (64852469*a[6]*a[10])/75358080 - (34854541*a[12]^2)/113037120 - (509585*a[12]*a[13])/922752 - \n  (55139243*a[12]*a[16])/226074240 + (509585*a[16]^2)/461376 + (46669*a[18])/42720 + (28481*a[3]*a[18])/64080 - \n  (9557*a[8]*a[18])/21360 - (907*a[9]*a[18])/2136 + a[3]*a[9]*a[18] - (55139243*a[6]*a[19])/226074240 + \n  (509585*a[19]^2)/461376 + (64852469*a[12]*a[20])/75358080, -6752417/4101120 + (669701*a[3])/273408 - \n  (2671829*a[3]^2)/2050560 + a[3]^3/2 - (9574447*a[4])/205056 + (1532833*a[3]*a[4])/17088 - (a[3]^2*a[4])/2 + \n  (3850112213*a[6]^2)/361718784 - (85429445*a[6]*a[7])/7382016 + (468209*a[8])/170880 - (24069*a[3]*a[8])/1280 - \n  (11259*a[4]*a[8])/256 + (1098001*a[8]^2)/68352 + (17558459*a[9])/1367040 - (1087453*a[3]*a[9])/2050560 - a[3]^2*a[9] - \n  (887*a[4]*a[9])/12 + a[3]*a[4]*a[9] + (1735367*a[8]*a[9])/227840 - (17219*a[9]^2)/1280 + (3499277*a[6]*a[10])/3767904 - \n  (7057018279*a[12]^2)/361718784 - (85429445*a[12]*a[13])/7382016 + (1435487737*a[12]*a[16])/180859392 + \n  (85429445*a[16]^2)/3691008 + (61578841*a[18])/1367040 - (182293411*a[3]*a[18])/2050560 + (10473297*a[8]*a[18])/227840 + \n  (31283207*a[9]*a[18])/341760 - (4018077509*a[6]*a[19])/180859392 + (85429445*a[19]^2)/3691008 + \n  (936921757*a[12]*a[20])/30143232, (-6791*a[6])/896 + (3*a[6]^3)/4 - (24959*a[7])/1792 - (3*a[6]^2*a[7])/4 + \n  (38541*a[10])/1792 - (a[6]*a[12]^2)/4 + (a[7]*a[12]^2)/4 + (38541*a[19])/1792 - a[6]^2*a[19] - (24959*a[8]*a[19])/896 + \n  a[16]^2*a[19] + a[19]^3, (-6791*a[12])/896 - (a[6]^2*a[12])/4 + (a[6]*a[7]*a[12])/4 + (3*a[12]^3)/4 - (24959*a[13])/1792 - \n  (3*a[12]^2*a[13])/4 - (11377*a[16])/1792 + (24959*a[8]*a[16])/896 - a[12]^2*a[16] + a[16]^3 + a[16]*a[19]^2 + \n  (38541*a[20])/1792, 183097/16020 - (70685*a[3])/8544 - (500621*a[3]^2)/128160 + (3*a[3]^3)/4 + (52935505*a[4])/102528 - \n  (4229873*a[3]*a[4])/4272 - (3*a[3]^2*a[4])/4 - (7564272227*a[6]^2)/64592640 + (481295435*a[6]*a[7])/3691008 - \n  (1095331*a[8])/42720 + (67419*a[3]*a[8])/320 + (63033*a[4]*a[8])/128 - (15810211*a[8]^2)/85440 - (9377989*a[9])/56960 + \n  (18900251*a[3]*a[9])/512640 - a[3]^2*a[9] + (12879*a[4]*a[9])/16 - (1468459*a[8]*a[9])/17088 + (98233*a[9]^2)/640 + a[9]^3 - \n  (572265257*a[6]*a[10])/43061760 + (98006554411*a[12]^2)/452148480 + (481295435*a[12]*a[13])/3691008 - \n  (78095727247*a[12]*a[16])/904296960 - (481295435*a[16]^2)/1845504 - (86272807*a[18])/170880 + \n  (127300691*a[3]*a[18])/128160 - (21963923*a[8]*a[18])/42720 - (174955669*a[9]*a[18])/170880 + \n  (31973884679*a[6]*a[19])/129185280 - (481295435*a[19]^2)/1845504 - (104643496799*a[12]*a[20])/301432320, \n -840029/256320 + (65447*a[3])/17088 - (19399*a[3]^2)/64080 - a[3]^3/4 - (18158765*a[4])/102528 + (91111*a[3]*a[4])/267 + \n  (a[3]^2*a[4])/4 + (18218466373*a[6]^2)/452148480 - (166368295*a[6]*a[7])/3691008 + (251057*a[8])/42720 - \n  (23043*a[3]*a[8])/320 - (21561*a[4]*a[8])/128 + (5650367*a[8]^2)/85440 + (3127683*a[9])/56960 - (5157367*a[3]*a[9])/512640 - \n  (4463*a[4]*a[9])/16 + (491297*a[8]*a[9])/17088 - (33081*a[9]^2)/640 + (1441099843*a[6]*a[10])/301432320 - \n  (33949317947*a[12]^2)/452148480 - (166368295*a[12]*a[13])/3691008 + (27138403619*a[12]*a[16])/904296960 + \n  (166368295*a[16]^2)/1845504 + (29704589*a[18])/170880 - (21831221*a[3]*a[18])/64080 + (1884709*a[8]*a[18])/10680 + \n  (60124613*a[9]*a[18])/170880 + a[9]^2*a[18] - (77197165021*a[6]*a[19])/904296960 + (166368295*a[19]^2)/1845504 + \n  (36219622723*a[12]*a[20])/301432320, -354851893/36910080 + (24762505*a[3])/2460672 - (22134121*a[3]^2)/18455040 + \n  (3*a[3]^3)/4 - (652538555*a[4])/1845504 + (104303741*a[3]*a[4])/153792 - (3*a[3]^2*a[4])/4 + \n  (1312270017869*a[6]^2)/16277345280 - (5868675745*a[6]*a[7])/66438144 + (29456641*a[8])/1537920 - (183161*a[3]*a[8])/1280 - \n  (85671*a[4]*a[8])/256 + (381222601*a[8]^2)/3075840 + (439571293*a[9])/4101120 - (356475041*a[3]*a[9])/18455040 - \n  a[3]^2*a[9] - (19933*a[4]*a[9])/36 + (70233365*a[8]*a[9])/1230336 - (394573*a[9]^2)/3840 + a[4]*a[9]^2 + \n  (5231480819*a[6]*a[10])/678222720 - (2415218261551*a[12]^2)/16277345280 - (5868675745*a[12]*a[13])/66438144 + \n  (488696352013*a[12]*a[16])/8138672640 + (5868675745*a[16]^2)/33219072 + (4231973069*a[18])/12303360 - \n  (12508156079*a[3]*a[18])/18455040 + (2157110207*a[8]*a[18])/6151680 + (2146869467*a[9]*a[18])/3075840 - \n  (1375047787697*a[6]*a[19])/8138672640 + (5868675745*a[19]^2)/33219072 + \n(321086984923*a[12]*a[20])/1356445440};\n\nYou can check, e.g. via NSolve, that the solution set has positive dimension.\nIn[93]:= Timing[sol = NSolve[gb2];]\n\nDuring evaluation of In[93]:= NSolve::infsolns: Infinite solution set has dimension at least 1. Returning intersection of solutions with (78848 a[3])/86491-(52050 a[4])/86491+(57827 a[6])/86491+(148851 a[7])/172982+(101463 a[8])/172982+(188769 a[9])/172982-(191343 a[10])/172982-(89087 a[12])/86491+(78339 a[13])/86491+(140033 a[15])/172982-(83945 a[16])/86491-(56554 a[18])/86491+(83206 a[19])/86491-(107131 a[20])/172982 == 1. >>\n\nDuring evaluation of In[93]:= NSolve::infsolns: Infinite solution set has dimension at least 2. Returning intersection of solutions with (67842 a[3])/95609-(184441 a[4])/191218-(97766 a[6])/95609-(184729 a[7])/191218+(93018 a[8])/95609-(59375 a[9])/95609+(147179 a[10])/191218+(81420 a[12])/95609-(60031 a[13])/95609+(156301 a[15])/191218+(130811 a[16])/191218+(94526 a[18])/95609-(2863 a[19])/2854+(54539 a[20])/95609 == 1. >>\n\nDuring evaluation of In[93]:= NSolve::infsolns: Infinite solution set has dimension at least 3. Returning intersection of solutions with -((81281 a[3])/77135)+(86849 a[4])/77135-(65291 a[6])/77135+(177769 a[7])/154270-(76583 a[8])/77135-(130181 a[9])/154270-(15303 a[10])/15427+(54742 a[12])/77135+(64317 a[13])/77135+(83022 a[15])/77135+(70919 a[16])/77135-(30099 a[18])/30854-(80873 a[19])/77135-(70654 a[20])/77135 == 1. >>\n\nDuring evaluation of In[93]:= General::stop: Further output of NSolve::infsolns will be suppressed during this calculation. >>\n\nOut[93]= {3.13, Null}\n\nIn[94]:= sol\n\nOut[94]= {{a[15] -> 0., a[10] -> 0., a[20] -> 34.7986, \n  a[13] -> 34.7986, a[7] -> 12.0763, a[18] -> 11.9732, \n  a[4] -> 11.9732, a[16] -> 0., a[19] -> 12.0763, a[9] -> 0., \n  a[8] -> 0., a[3] -> 12.9732, a[6] -> 12.0763, \n  a[12] -> 34.7986}, {a[15] -> 0., a[10] -> -1.32805, \n  a[20] -> -1.52477, a[13] -> -1.52477, a[7] -> -1.32805, \n  a[18] -> -0.727061, a[4] -> -0.727061, a[16] -> -1.52477, \n  a[19] -> -1.32805, a[9] -> -0.727061, a[8] -> 0.5, \n  a[3] -> -0.954122, a[6] -> -2.65611, \n  a[12] -> -3.04955}, {a[15] -> 0., a[10] -> 1.47403, a[20] -> 0., \n  a[13] -> 1.84961, a[7] -> 1.47403, a[18] -> 0., a[4] -> 0.644773, \n  a[16] -> 1.84961, a[19] -> 0., a[9] -> 0.644773, a[8] -> 1., \n  a[3] -> 1.64477, a[6] -> 1.47403, a[12] -> 1.84961}}\n\nIf you run NSolve directly on the original set, it might in fact go to completion. But expect it to take considerable time-- I've had it running for a few hours now, with the end only dimly in sight.\n", "sorting - Ordring problm - Mathmatica Stack Exchang": "\nThis is probably because by default Sort doesn't just use numerical values, it includes structure information as well. From the doc:\n\nNumeric expressions are sorted by structure as well as numerical value:\n\nIn[1]:= Sort[{Sqrt[2], 1, 2, 1/Sqrt[2]}]\n\nOut[1]= {1, 2, 1/Sqrt[2], Sqrt[2]}\n\n\nSort by numerical value only:\n\nIn[2]:= Sort[{Sqrt[2], 1, 2, 1/Sqrt[2]}, Less]\n\nOut[2]= {1/Sqrt[2], 1, Sqrt[2], 2}\n\nalong with the following doc:\n\nSort usually orders expressions by putting shorter ones first, and then comparing parts in a depth-first manner. \n\ngives us a hint why. If you run TreeForm /@ {0, 20 Sqrt[5], 40 Sqrt[5], 20 Sqrt[5], 20 Sqrt[10]}, you'll see that the last layer (Rational) is the same for all four Sqrts. Then the next depth down is the Power, in which 10 is the outlier, and is greater than 5, so will be placed last. Finally, comparing {20, 40, 20} will give the ordering {1, 3, 2}, which when put together with the original list gives you the ordering:\nIn[77]:= Ordering[{0, 20 Sqrt[5], 40 Sqrt[5], 20 Sqrt[5], 20 Sqrt[10]}]\n\nOut[77]= {1, 2, 4, 3, 5}\n\n", "animation - Incorporating an additional graphics element when using Animate and ParametricPlot3D": "\nI think the simplest way is to include a Show:\nAnimate[\n  Show[\n    ParametricPlot3D[{{Cos[\u03b1 t], Sin[\u03b1 t], \n      Sqrt[1 - \u03b1^2] t}, {Cos[\u03b1 t], \n      Sin[\u03b1 t], -Sqrt[1 - \u03b1^2] t}}, {\u03b1, -1, 1}, \n    PlotRange -> {{-1, 1}, {-1, 1}, {-2 \u03c0, 2 \u03c0}}], \n\n    Graphics3D[Cylinder[{{0, 0, -2 \u03c0}, {0, 0, 2 \u03c0}}, 1]]\n  ], \n{t, 0, 2 \u03c0}, AnimationRunning -> False]\n\n\nShow returns a graphics object that can be further customized in a similar way to ParametricPlot3D.\nEDIT I really liked the animation, but think the Cylinder by default masks the function. Perhaps the following is easier to see:\nAnimate[\n  Show[\n    ParametricPlot3D[{{Cos[\u03b1 t], Sin[\u03b1 t], \n      Sqrt[1 - \u03b1^2] t}, {Cos[\u03b1 t], \n      Sin[\u03b1 t], -Sqrt[1 - \u03b1^2] t}}, {\u03b1, -1, 1}, \n      PlotRange -> {{-1, 1}, {-1, 1}, {-2 \u03c0, 2 \u03c0}}, \n      Axes -> False, BoxStyle -> Opacity[0]], \n    Graphics3D[{EdgeForm[None], Yellow, Opacity[0.2], \n      Cylinder[{{0, 0, -2 \u03c0}, {0, 0, 2 \u03c0}}, 1]}]\n  ], \n{t, 0, 2 \u03c0}, AnimationRunning -> False]\n\n\n", "evaluation - Mathematica rule substitution memory": "\nWhile I am not able to explain why there is a difference between the two methods, I would like to suggest using\nt = Block[{x=0, y=0}, p];\n\nBlock will set a value to x and y only temporarily, and avoids the use of Clear.\nSome more things that can be useful for you:\n\nWhen you start working, use $HistoryLength = 0 to avoid remembering past results and wasting memory (note that Mathematica sometimes remembers full results even when the input was ended in a semicolon!)\nUse Share[] occasionally.  It seems that with your polynomial this will help a lot more than in other cases.  After reading in the polynomial, it frees 60 MB for me immediately.\n\n", "calculus and analysis - Why does Mathematica give the wrong answer when integrating?": "\nLooks like a bug that ran off in the development version of Mathematica.\nIn[1]:= Integrate[Exp[I Cos[b - c]] Cos[b], {b, 0, 2 Pi}]//InputForm\n\nOut[1]//InputForm= (2*I)*Pi*BesselJ[1, 1]*Cos[c]\n\nIn[2]:= %/.c->.5\n\nOut[2]= 0. + 2.42645 I\n\n", "programming - Are there advantages to using additional arguments of common functions rather than alternative ways of calculating with lists?": "\nI can think of several main advantages of additional arguments:\n\nEfficiency\nMore concise and readable code\nBetter abstraction level\nLess chances for bugs.\n\nIn brief, I think that the first reason is bad most of the time, the second and third are valid, and the last may or may not be valid. Let us now consider these arguments.\nI start with efficiency. My opinion here is that, on one hand, this is one of the major factors in real-life Mathematica programming (or at least, in my experience), while on the other hand, it should not be. I really blame the execution model of Mathematica here (yes, I know many reasons why  with Mathematica it can not currently be the other way, but, from the pragmatic point of view of the user of it as a general-purpose programming language - as opposed to a computer algebra system or rewrite engine - I could not care less), because the performance differences between implemented in C built-in functions and top-level user-defined functions are often huge, and this makes performance non-uniform and hard to understand. We all spend lots of time on micro-benchmarking, while that time could have been spent much more productively on some really important things. So, while in practice the performance factor often dominates the decision to use these extra arguments (or even introduce them in the function's syntax), I think this is conceptually wrong one and should have a status of a widely used work-around to compensate for  the current language limitations regarding performance. A real way out would IMO be to extend Compile so that much wider subset of the language could become compiled rather than interpreted, which is of course a much harder task.\nNext point is concise and readable code. This one is a very valid one IMO. However, using extra arguments does not always lead to that, because often what they do is rather obscure. So, I think that some balance is needed here. It also depends on how well these extra arguments are designed, in the sense that it should be relatively easy to understand what they do in some code, perhaps by consulting the docs. In any case, there are IMO many use cases where the use of extra arguments may be justified from this point of view. Good examples here are IMO SortBy and SplitBy, particularly with their extended (multi-level) functionality (they also may improve performance, but I don't view this as  their major advantage).\nWhat I mean by better abstraction level is that extra arguments may allow to group a lot of related functionality into one \"super-function\" (e.g. Partition), which means that the code using it does recognize in the particular use of it an instance of a more general operation, conceptually. This may be useful in the same way as abstract classes are useful in OOP. This however requires a really careful and very well thought out design for such functions. There are quite a few Mathematica functions which, I think, satisfy this criteria.\nLess chances for bugs: since built-ins are used (assuming that built-ins are having on the average less bugs than the code you write, which is probably true for most users, because built-ins were written by experts, and had more chances to be tested, being exposed to many users and undergone the QA precess). This may not be as clear-cut, however, in cases when these extra arguments are hard to understand, since using them may induce more bugs because of that.\nSo, my conclusions would be these: if the code using those arguments is more readable, natural and concise (this is subjective, of course), they are probably worth using, in that particular piece of code. I have seen many instances where this is indeed the case. But, if all they give is a speed increase, especially at the expense of code clarity, they are probably not worth using (or at least, it is not worth to spend excessive amounts of time searching for them and reorganizing code), except when this piece of code is speed-critical. \nA very large class of use cases when they are used to only boost the performance I view as a necessary evil, but, while I think that the expert-level performance-tuning skills must currently include the knowledge of these arguments / use cases, I also think that this is unfortunate and leads to massive learning / memorizing effort on the side of a practitioner,  which could be better spent elsewhere, were the language performance model more uniform. I actually don't think that this problem is characteristic to Mathematica only, most high-level languages probably have similar issues. What makes  Mathematica stand out IMO is that, being extremely high-level,  it has a very large range of the possible performance differences between different solutions, which may easily span several orders of magnitude.\n", "graphics - Effects of single-point and multi-point calls of Point on plot range": "\nI'm tempted to blame this on AbsoluteOptions, because it is known to be buggy (I filed a bug report on it in January). I also tried the following\nFullGraphics@Show[pl1, Frame -> True]\n\n\nwhich shows that the incorrect PlotRange value is in fact used internally, making this a pretty significant bug. \nI would suggest filing a bug report blaming it on AbsoluteOptions (it's just a guess, but hey - we don't have the source code...)\nUpdate\nI think the case against AbsoluteOptions is becoming stronger with the following tests. That means, I'm now pretty confident that the issue in this question is not inherent to the argument-list version of Point. \nConsider the three-dimensional version of the question, with \npts = RandomReal[10, {30, 3}];\npl1 = Graphics3D[Point@pts];\npl2 = Graphics3D[Point /@ pts];\n\nThe results of AbsoluteOptions[pl1, PlotRange] and AbsoluteOptions[pl2, PlotRange] show the same discrepancy as in the 2D case. \nIf I now replace the 3D points by spheres, I can use the same two methods of feeding it the points:\nsph1 = Graphics3D[Sphere[pts, .05]];\nsph2 = Graphics3D[Sphere[#, .05] & /@ pts];\n\nHowever, the results of \nAbsoluteOptions[sph1, PlotRange]\n\nand \nAbsoluteOptions[sph2, PlotRange]\n\nnow both show the incorrect result {PlotRange -> {{0., 1.}, {0., 1.}, {0., 1.}}}. What I would infer from this is that it is not the listability property itself that is causing a wrong PlotRange calculation. Note: I say \"infer\" - not \"conclude\", because it's not conclusive...\nUpdate 2\nFor completeness, I sent a bug report to Wolfram in which I gave these examples and stated that AbsoluteOptions doesn't work properly here. Wolfram support confirmed the bug.\n", "Deleting parts of a large list": "\nI think that one of the reasons your code isn't working is that Delete doesn't actually modify the original list so during every iteration in your Table you're actually working with the original list, not the one that was returned from the previous iteration. One way to solve this is to set CompleteQuarterlyStatData to the result of Delete in every iteration but a more functional way would be to do something like this instead\nDeleteCases[CompleteQuarterlyStatData, {_, {}}, {3}]\n\nI would suggest that you familiarise yourself with the use of Patterns in Mathematica. \nEdit\nThis is probably not the most efficient method, but you could try something like. It seems to work for the example posted by the OP at least.\nlist = {\n        {\n         {{{\"Australia\", \"GDP\"}, {}}, {{\"Korea\", \"GDP\"}, -2.45}, \n          {{\"USA\", \"GDP\"}, -2.34}}, \n         {{{\"Australia\", \"GDP\"}, 2.34}, {{\"Korea\", \"GDP\"}, 1.23}, \n          {{\"USA\", \"GDP\"}, 1.45}}}, \n        {\n         {{{\"Greece\", \"Imports\"}, 3.25}, {{\"Turkey\", \"Imports\"}, {}}, \n          {{\"USA\", \"Imports\"}, -2.64}}, \n         {{{\"Greece\", \"Imports\"}, -1.23}, {{\"Turkey\", \"Imports\"}, 3.56}, \n          {{\"USA\", \"Imports\"}, -1.56}}\n        }\n       };   \n\nDeleteCases[list, Alternatives @@ Cases[list, {a_, {}} :> {a, _}, {3}], {3}]\n\n\n{\n   {\n    {{{\"Korea\", \"GDP\"}, -2.45}, {{\"USA\", \"GDP\"}, -2.34}}, \n    {{{\"Korea\", \"GDP\"}, 1.23}, {{\"USA\", \"GDP\"}, 1.45}}}, \n   {\n    {{{\"Greece\", \"Imports\"}, 3.25}, {{\"USA\", \"Imports\"}, -2.64}}, \n    {{{\"Greece\", \"Imports\"}, -1.23}, {{\"USA\", \"Imports\"}, -1.56}}\n   }\n  }\n\n\n", "evaluation - How to REALLY Hold arguments and capture FullForm?": "\nOk, what you have here is some classic example of what is called \"Evaluation leaks\". So, first, the corrected code:\nClearAll[capture]\nSetAttributes[capture, HoldAllComplete];\ncapture[expr_ /; AtomQ[Unevaluated[expr]]] := \n    {Head[Unevaluated[expr]], expr};\ncapture[head_[args___]] := {head, capture /@ Unevaluated[{args}]};\n\nNow, you can inspect it and compare to your version, to see that you had three such \"leaks\": in the pattern-testing AtomQ (which does not hold its arguments), in the r.h.s. Head[expr], since Head also does not hold them, and, perhaps most importantly, in capture/@{args}, since Map does not hold its arguments either. \nSo, evaluation leaks are cases when some code which wasn't supposed to evaluate, actually does. Some most frequent situations which lead to evaluation leaks are either when the code is being passed to / anylized by a function which does not hold it properly, or when some parts of held code are extracted during destructuring (e.g. by Cases), not being wrapped in a holding wrapper head.\nThe standard thing to do to prevent the evaluation once is to wrap your code in Unevaluated, which I did above. To prevent evaluation in a  persistent manner, we usually wrap an expression in Hold, HoldComplete, or perhaps some custom holding wrappers with Hold-attributes, but in such cases you have to take care to strip the holding wrapper when no longer needed. \nSome more involved examples of parse-like functions which avoid evaluation leaks can be found in this answer (function depends) and also here (function parse). The problem of evaluation leaks is a very frequent one once you start working with pieces of unevaluated code, which is particularly common when writing parser-like functions, macros, and other metaprogramming-related functions. You can look at some references in my recent answer on metaprogramming, for some more links to code where prevention of evaluation leaks was essential.\n", "programming - Listing subgraphs of G isomorphic to SubG": "\nUpdate: I now recommend using the IGraph/M package instead of the R interface. It offers the following functions for finding subgraphs:\n\nIGSubisomorphicQ tests for subgraph isomorphism, supports multigraphs as well.\nIGVF2FindSubisomorphisms lists all matching subgraphs found, supports vertex and edge coloured graphs.\nIGLADFindSubisomorphisms lists all matching subgraphs founds, supports vertex colouring, supports looking only for induced sugraphs.\n\n\nDaniel is completely correct that this is a hard problem and will usually take a very very long time.  However, the igraph library does have a function for it and you can call it through this package.  Please read the instructions on how to set up the package, then do this:\n{g, subG} = {PetersenGraph[5, 2], EdgeAdd[CycleGraph[5], 5 <-> 6]}\n\nres = IGraph[\"graph.get.subisomorphisms.vf2\"][g, subG];\n\nHighlightGraph[g, Subgraph[g, #]] & /@ Round[res + 1]\n\n\nUse graph.count.subisomorphisms.vf2 to just count the subgraphs but not retrieve them.\n", "evaluation - Efficiently evaluating a held expression directly from a list": "\nWhat costs you so much time is your unnecessary packaging of ReleaseHold into an anonymous function. ReleaseHold[#]& is semantically identical to ReleaseHold but much more time expensive. If you replace it with ReleaseHold, the map version is only slightly slower than the direct version (and I guess that's because of the Map logic which has to work with lists of arbitrary length).\nHere's what I get after removing the unnecessary anonymous function:\nDo      total: 22.849438   per iteration: 2.2849438*10^-6\nDoMap   total: 24.159825   per iteration: 2.4159825*10^-6\n\n", "Undocumented Dynamic Function question": "\nAfter your last comment, maybe you should assing the value of cyL[change[x]] to another variable in the dynamic, and use it outside. Something like this:\n\n", "version 8 - Wavelet Packet Transform in Mathematica 7 and 8": "\nAfter consulting a friend of mine P.M. I can tell you this. First of all as @Szabolcs @ruebenko already mentions - in order to get a comparison with Wavelet explorer (v7) to v8, you can go to the following link in the documentation center which shows how the syntax has changed:\nhttp://reference.wolfram.com/mathematica/Compatibility/tutorial/WaveletExplorer.html\nFor the problem at hand, if you want location of the spike, perhaps using continuous wavelet transform might give the result easily. Here is an example:\ndata = N@Table[Sin[4 \\[Pi] t] + 2 Exp[-10^5 (1/3 - t)^2], {t, 0, 1, 0.001}];\ncwd = ContinuousWaveletTransform[data, PaulWavelet[5], {8, 8}];\nws = WaveletScalogram[cwd, ColorFunction -> \"AvocadoColors\"];\nposData = Abs[{3, 1} /. cwd[{3, 1}]];\npositionOfSpike = Position[posData, Max[posData]];\nPrint[\"Spike is at  \" <> ToString[positionOfSpike[[1, 1]]]]\nRow[{ws, ListLinePlot[posData, PlotRange -> All]}]\n\n\nHowever, for multiple spikes, he may have to make careful use of a local FindMaximum. Another useful thing is this:\ndata = N@Table[\n    Sin[4 \\[Pi] t] + 2 Exp[-10^5 (1/3 - t)^2], {t, 0, 1, 0.001}];\ndwd = DiscreteWaveletPacketTransform[data, Automatic, 5];\nManipulate[\n tmp = WaveletThreshold[\n   WaveletBestBasis[dwd, {\"Threshold\", bestBasisThreshold}], {\"Hard\", \n    waveletThreshold}];\n recon = InverseWaveletTransform[tmp];\n GraphicsRow[{ListLinePlot[recon, PlotLabel -> \"Reconstruction\"], \n   ListLinePlot[data - recon, PlotLabel -> \"Error\"]}, \n  ImageSize -> 500], {bestBasisThreshold, 0.001, 0.99, \n  Appearance -> \"Labeled\"}, {waveletThreshold, 0.001, 0.99, \n  Appearance -> \"Labeled\"}]\n\n\nThe manipulate above shows the interplay between wavelet best basis and wavelet threshold. For more information, we would recommend going to the documentation page:\nWaveletBestBasis > Applications > Compressions.\nand go through the examples.\n", "syntax - Explanation on why Compile statement works only if input and output sizes work": "\nThis had been piquing my curiosity for a few days, but I finally found why!\nThe reason is a tiny sentence hidden in the documentation of Compile, which has drastic consequences I had not realized before:\n\nOrdinary Mathematica code can be called from within compiled code. Results obtained from the Mathematica code are assumed to be approximate real numbers, unless specified otherwise by the third argument of Compile.\n\nSo, there you have it: if you use\nCompile[{{m, _Real, 2}}, Fourier[m]]\n\nthen compilation assumes that Fourier returns a real values. When you evaluate this, and the returned values turn out to be complex, you get your error message:\n\nCompiledFunction::cfex: Could not complete external evaluation at instruction 1; proceeding with uncompiled evaluation.\n\nWhen you specify that Fourier returns complex values, using the third argument to Compile, \nthings work better as you found out.\n\nAlso, you can fully confirm that the issue here is with the number type (i.e. real vs. complex) rather than the rank, by trying your first code with FourierDST, which returns real numbers and does not emit the error:\nCompile[{{m, _Real, 2}}, FourierDST[m]] @ Table[N[i - j], {i, 4}, {j, 4}]\n\n", "plotting - Plot Indefinite integral": "\nYou could do the indefinite integral and put in the limits\nafterwards. E.g., on Linux I get a speed-up of about 14 for \none integral (I have no time to do more right now ...)\nMathematica 8.0 for Linux x86 (64-bit)\nCopyright 1988-2011 Wolfram Research, Inc.\n\nIn[1]:= !!i\nPrint[\"timing 1: \", \nFirst @ AbsoluteTiming[\n  Pw3 = ExpandAll[(Exp[-0.25/t]/t)*\n     Integrate[\n      Exp[-((Tan[60*Degree]^2*\n           (z + 30)^2)/(4*t))]*\n       (1 + 2*Sum[Exp[-(n^2*Pi^2*t)/\n            100^2]*Cos[0.8*n*Pi]*\n           Cos[n*(Pi/2) - n*Pi*\n            (z/100)], {n, 1, 100}]), \n      {z, -50, 50}]]; ]\n];\nPrint[\"timing 2 : \", \nFirst @ AbsoluteTiming[\n  nPw3 = Expand[(Exp[-0.25/t]/t)*\n     ((#1 /. z -> 50) - (#1 /. \n         z -> -50) & )[\n      ParallelMap[(ExpandAll[Integrate[#1, z]] & ),\n       (TrigToExp[Expand[\n          Exp[-((Tan[60*Degree]^2*\n            (z + 30)^2)/(4*t))]*\n           (1 + 2*Sum[Exp[-(n^2*Pi^2*\n            t)/100^2]*Cos[0.8*n*Pi]*\n            Cos[n*(Pi/2) - n*Pi*\n            (z/100)], {n, 1, \n            100}])]])]] ]; ]\n]\nPrint[\"check \", Chop[Pw3 - nPw3]]\n\nIn[1]:= <<i\ntiming 1: 75.121517\nLaunching kernels...       Mathematica 8.0 for Linux x86 (64-bit) Copyright 1988-2011 Wolfram Research, Inc.                                                                                                            \ntiming 2 : 5.255553                                                                                                                    \ncheck 0                                                                                     \n\n", "graphics - How to partition a disk into individually spaced bricks?": "\nThis is far from perfect, but can be easily improved. The method is simple: building up the disk line-by-line by finding enough words of appropriate sizes to fill up each line. There is plenty of room to optimize spacing, but since it already gives a densely packed circle, I leave it as it is for the moment.\nUpdated code: now it runs much faster as only a minimal amount of image processing is involved.\nFirst, specify style, number of rows and a set of words:\nstyle = {FontFamily -> \"Helvetica\", \n   FontSize -> 12}; (* list of style specifications for framed words *)\ncolorStyle = \"BlueGreenYellow\"; (* color background of bricks *)\nmargins = 3; (* frame margins for bricks *)\nrows = 20; (* number of rows of bricks *)\nwords = RandomSample[DictionaryLookup[{\"Latin\", \"*\"}], 200];\n\nUnfortunatly, to measure the exact length of words, one has to convert them to raster images, as there is no direct font-to-curve conversion is available out of the box, and font vectorization is even slower than simply rasterizing each word. However, thanks to Pillsy's clever shortcut, this part can be made lightning fast too:\ngetTextLength[texts_List] := \n  With[{data = Rasterize[Column@texts, \"Data\"]},\n   With[{black = {0, 0, 0}}, Cases[data, \n      line : {black, black, __} :> Count[line, black]]][[1 ;; ;; 2]]];\n\nlengths = getTextLength@(Framed[#, FrameMargins -> margins, \n      BaseStyle -> style] & /@ words); (* word lengths in pixels *)\nwordHeight = Last@ImageDimensions@Rasterize@\n    Framed[First@words, FrameMargins -> margins, \n     BaseStyle -> style];(* word height in pixels - this is assumed to be the same for each word *)\nlineHeight = N[2/rows]; (* disk is in the {-1, 1} interval,total height is 2 *)\nwordLengths = (#*(lineHeight/wordHeight)) & /@ lengths;\n(* convert pixel lengths to coordinate lengths *)\n\nThe following two functions help on positioning and finding suitable words, respectively:\n(* get width of each line of bricks in the disk *)\ngetX[y_] := Sqrt[1 - (y - lineHeight/2)^2];\nlineWidths = \n  Table[{(getX@y)*2, -getX@y, y - lineHeight/2}, {y, -1 + lineHeight, \n    1, lineHeight}];\n\n(* function to find a word that fits a given width w, and removes word from word & length lists *)\ngetWord[w_] := Module[{word, length, pos, coord},\n   pos = Position[wordLengths, a_ /; a <= w, 1, 1][[1, 1]];(* \n   find a word that fits the given width *)\n   word = words[[pos]];\n   length = wordLengths[[pos]];\n   words = Delete[words, pos];(* remove word from global list *)\n   wordLengths = Delete[wordLengths, pos]; (* \n   remove length from global list *)\n   {word, length}\n   ];\n\nNow iterate through each line of the disk and fill them up with words:\nwordCoordinates = \n  Module[{defW, space, x, y, pos, word, length, coord, found = {}, \n      evenly},\n     {defW, x, y} = #;\n     space = defW;\n     While[(* \n      look for words in lexicon until given width is filled up *)\n      space > 0 \\[And] Min@wordLengths <= space,\n      {word, length} = getWord@space;\n      AppendTo[found, {word, {x + length/2 + defW - space, y}}];\n      space = Max[0, space - length];\n      ];\n     evenly = \n      Table[{0, {space*i/(Length@found - 1), 0}}, {i, 0, \n        Length@found - 1}];(* shift entries if there is leftover space *)\n     found + evenly\n     ] & /@ lineWidths;\n\nPut everything together. Note, that choosing an appropriate image size is important:\ndiskBricks = Graphics[{\n   Module[{color = Lighter@ColorData[colorStyle]@RandomReal[]},\n      Mouseover[\n\n       Text[\n        Framed[First@#, FrameMargins -> margins, \n         BaseStyle -> Prepend[style, FontColor -> Black], \n         Background -> Lighter@color, FrameStyle -> None], Last@#],\n       Text[\n        Framed[First@#, FrameMargins -> margins, \n         BaseStyle -> Prepend[style, FontColor -> GrayLevel@.9], \n         Background -> Darker@color, FrameStyle -> Black], Last@#]\n       ]\n\n      ] & /@ Flatten[wordCoordinates, 1]\n   }, Axes -> False, ImageSize -> 500]\n\n\n", "differential equations - NDSolve Problem": "\nThis is a very frequently asked question, but I agree it might not be so easy to find out what is happening.  The solution is defining the functions as\nf[x_ ? NumericQ] := ...\n\nto prevent them from evaluating for non-numerical arguments\n", "image processing - Using ImageCapture to access a USB webcam in linux": "\nYes it is possible, but it is not natively supported. Therefore, the way through ImageCapture will not work here. Nevertheless, no one prevents you to use a library like opencv to access the webcam. With a MathLink wrapper you can write a routine to catch frames from the cam and transfer them as Image to Mathematica.\nWhen opencv is initialized and has opened your cam, the pure catching routine is in the simplest case very short:\nvoid catchFrame(void){\n  if(!frame){\n    MLPutSymbol(stdlink,\"$Failed\");\n    return;\n  }\n  long dims[3],size,mu;\n  int *bm;\n\n  dims[0]=frame->height;\n  dims[1]=frame->width;\n  dims[2]=frame->nChannels;\n  size=dims[0]*dims[1];\n  mu=size*dims[2];\n  bm=new int[mu];\n  for(long i=0; i<size; i++) {\n    bm[3*i]=(unsigned char)frame->imageData[3*i+2];\n    bm[3*i+1]=(unsigned char)frame->imageData[3*i+1];\n    bm[3*i+2]=(unsigned char)frame->imageData[3*i];\n   } \n  MLPutFunction(stdlink,\"Image\",2); \n  MLPutIntegerArray(stdlink,bm,dims,NULL,3);\n  MLPutString(stdlink,\"Byte\");\n\n  delete[] bm;\n  }\n\nI admit that this approach is not as simple as calling ImageCapture, but if you are willing to install opencv and cweb I could send you an implementation. It was once written by Jens-Peer Kuska and I only made it work for Mathematica 8.0 and its Image-framework.\nUpdate\nI made a pure C version (without CWeb) and added a detailed how-to-use comment. You can download the file from here and with a bit of luck you can use images from your webcam in a few minutes.\n", "graphics - Producing a bar chart with height and color determined by two distinct lists": "\nHere's one approach, where we compute the heights using the first part of the results from Tally, and the colors using the second part.  Then it's just a simple use of ChartStyle.\nlist = Sort@RandomInteger[{1, 10}, 20]\n\n(*\n==> {1, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 9, 10, 10}\n*)\n\n{height, color} = Transpose[Tally[list]]\n\n(*\n==> {{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, {1, 3, 1, 1, 2, 1, 1, 7, 1, 2}}\n*)\n\ncolor = ColorData[\"Rainbow\"] /@ Rescale[color];\n\nBarChart[height, ChartStyle -> color, BarSpacing -> 0, \n ChartBaseStyle -> EdgeForm[]]\n\n\n", "How to match a pattern with a pattern?": "\nUse Verbatim. It was explicitly designed as an escaping mechanism for patterns. In this particular case:\nCases[rules, \n  _?(MatchQ[First@#, \n       b | a | (Verbatim[Alternatives][elems___] /; MemberQ[{elems}, a | b])] &\n    )\n]\n\nwill do the trick.\n", "import - Difficulties with Importing PDFs in Mathematica": "\nIf it's really scanned images, then you could try this:\npages = Import[\"yourfile.pdf\", {\"PDF\", \"Images\"}]\n\nOtherwise, I'd suggest running the file through ghostscript or another distiller to clean up the potentially malformed PDF code first. The command would look like this:\ngs -dSAFER -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile=newfile.pdf badfile.pdf\n\nEdit\nSince you mentioned that you're on Mac OS X and also appear to be able to view the PDF file in Preview.app, there is an even simpler way: \nIf you're on Lion: Open the PDF in Preview, and export it as multipage TIFF. This can be done under the File > Export menu. The resulting file can be imported in Mathematica and yields a list of images.\nAnother possible approach that works for all OS X versions is to open the PDF in Preview and print it to a file. With that method, you could also select only the pages you really need by highlighting them in the Thumbnail view, and then choosing File > Print Selected Pages.... The PDF-printed file would hopefully have been processed to get rid of the errors. \n", "Fitting fractional complex data with NonlinearModelfit": "\nThis is, at least in principle, a duplicate of jVincent's answer and the one I gave here. The general approach has been suggested by various people over the years, although I first encountered it here courtesy of Daniel Lichtblau the first time I needed to fit several datasets simultaneously.\nI've been meaning to post this package for a while, ideally after having generalized it further, but given that generalization is somewhat complicated, and yet this remains a common question, I think on balance it's probably worthwhile to post the code as it stands. Despite certain limitations (listed below), it seems good enough for most applications that require fitting complex data.\nBeginPackage[\"TransformedFit`\"];\n\nClearAll[TransformedParameter];\nSetAttributes[TransformedParameter, HoldRest];\n\nUnprotect[TransformedFit]; ClearAll[TransformedFit];\n\nUnprotect[ComplexFit]; ClearAll[ComplexFit];\n\nBegin[\"`Private`\"];\n\n(* Transform numeric quantities rather than renaming them *)\nTransformedParameter[t_, num_?NumericQ] := t[num];\n\n(* Generate unique symbols for each transformed parameter -- this avoids difficulties\ncaused by overzealous common subexpression elimination when the models are compiled *)\nTransformedParameter[t_, p_] := TransformedParameter[t, p] =\n   With[{sym = Unique[\"TransformedParameter$\", Temporary]},\n    (* Unset memo when cleared to facilitate garbage collection *)\n    sym /: clear : (Clear | ClearAll | Remove)[___, sym, ___] :=\n     clear /; (TransformedParameter[t, p] =.; True);\n\n    (* Display as the parameter by itself if the transformation is Identity *)\n    sym /: MakeBoxes[sym, form_] :=\n     With[{boxes = MakeBoxes[p, form]},\n       InterpretationBox[boxes, sym]\n      ] /; t === Identity;\n\n    sym /: MakeBoxes[sym, form_] :=\n     With[{boxes = MakeBoxes[t[p], form]},\n      InterpretationBox[boxes, sym]\n     ];\n\n    sym\n   ];\n\nClearAll[$FitFunctions];\n$FitFunctions = If[$VersionNumber >= 7,\n   {FindFit, NonlinearModelFit},\n   {FindFit}\n  ];\n\nOptions[TransformedFit] = {\n   \"FitFunction\" -> First[$FitFunctions],\n   \"Transformation\" -> Identity,\n   \"ParameterTransformation\" -> Identity,\n   \"Hold\" -> False\n  };\n\nTransformedFit::cons = \n  \"The constraint(s), `1`, should be given in terms of the transformed parameters only.\";\n\nTransformedFit[\n    data_, {model_, cons_}, pars_, vars_,\n    opts___\n   ] /; Internal`DependsOnQ[cons, pars] :=\n  Message[TransformedFit::cons, cons];\n\n(* Deal with data given as ordinate values only *)\nTransformedFit[\n   data_?VectorQ, model_, pars_, vars_,\n   opts : OptionsPattern[{TransformedFit, Sequence @@ $FitFunctions}]\n  ] :=\n  TransformedFit[\n   Transpose[{Range@Length[data], data}], model, pars, vars,\n   opts\n  ];\n\nTransformedFit[\n   data_?MatrixQ, {model_, cons_} | {model_} | model_, pars_, vars_,\n   opts : OptionsPattern[{TransformedFit, Sequence @@ $FitFunctions}]\n  ] :=\n  With[{\n    fitFunction = If[MemberQ[$FitFunctions, #], #, First[$FitFunctions]] & @ OptionValue[\"FitFunction\"],\n    transformations = List@OptionValue[\"Transformation\"]~Flatten~1\n   },\n   Block[{\n     transformedData,\n     transformedParameters, unusedParameterMask, parameterRules,\n     transformedModel,\n     i\n    },\n    (* TRANSFORM DATA *)\n    With[{\n      abscissae = Take[data, All, {1, -2}],\n      ordinates = Take[data, All, {-1}]\n     },\n     transformedData = {\n         ConstantArray[Range@Length[transformations], {Length[abscissae], 1}]~Transpose~{2, 3, 1},\n         ConstantArray[abscissae, Length[transformations]],\n         Through@transformations[ordinates]\n        }~Flatten~{{2, 3}, {1, 4}};\n     ];\n\n    (* TRANSFORM PARAMETERS *)\n    transformedParameters = Outer[\n       TransformedParameter,\n       transformations, {pars}~Flatten~1\n      ] // Transpose;\n    With[{\n      (* Original and transformed parameters without initial guesses *)\n      originalParameterNames = Replace[pars, {p_, __?NumericQ} :> p, {1}],\n      transformedParameterNames = Replace[transformedParameters, {p_, __?NumericQ} :> p, {2}]\n     },\n     With[{\n        (* Representations of the original parameters in terms of their transformations *)\n        parameterRepresentations = OptionValue[\"ParameterTransformation\"] @@@ transformedParameterNames\n       },\n       unusedParameterMask = MapThread[\n         Composition[Thread, Unevaluated, FreeQ],\n         {parameterRepresentations, transformedParameterNames}\n        ];\n       Clear @@  Flatten@Pick[transformedParameterNames, unusedParameterMask];\n       parameterRules = Thread[originalParameterNames -> parameterRepresentations];\n      ];\n    ];\n\n    (* TRANSFORM MODEL *)\n    With[{\n      reparameterizedModel = model /. parameterRules,\n      KroneckerDelta = If[Equal[##], 1, 0] & (* compilable *)\n     },\n     transformedModel = Inner[\n        #1[reparameterizedModel] KroneckerDelta[i, #2] &,\n        transformations, Range@Length[transformations]\n       ];\n    ];\n\n    (* PERFORM FIT *)\n    If[TrueQ@OptionValue[\"Hold\"], Composition[Hold, fitFunction], fitFunction][\n     transformedData,\n     {transformedModel, cons},\n     Pick[transformedParameters, unusedParameterMask, False]~Flatten~1,\n     {i, vars}~Flatten~1,\n     FilterRules[{opts}, Options[fitFunction]]\n    ]\n   ]\n  ];\n\nProtect[TransformedFit];\n\nClearAll[coordinateSystemRules];\ncoordinateSystemRules[\"Cartesian\"] = Sequence[\n   \"Transformation\" -> {Re, Im},\n   \"ParameterTransformation\" -> (#1 + I #2 &)\n  ];\ncoordinateSystemRules[\"Polar\"] = Sequence[\n   \"Transformation\" -> {Abs, Arg},\n   \"ParameterTransformation\" -> (#1 Exp[I #2] &)\n  ];\ncoordinateSystemRules[\"Real\"] = Sequence[\n   \"Transformation\" -> {Re, Im},\n   \"ParameterTransformation\" -> (#1 &)\n  ];\ncoordinateSystemRules[\"Imaginary\"] = Sequence[\n   \"Transformation\" -> {Re, Im},\n   \"ParameterTransformation\" -> (I #2 &)\n  ];\n(* Default to Cartesian coordinates *)\ncoordinateSystemRules[_] = coordinateSystemRules[\"Cartesian\"];\n\nOptions[ComplexFit] = {\n   \"CoordinateSystem\" -> Automatic\n  };\n\nComplexFit[\n   data_, model_, pars_, vars_,\n   opts : OptionsPattern[{ComplexFit, TransformedFit, Sequence @@ $FitFunctions}]\n  ] :=\n  TransformedFit[\n   data, model, pars, vars,\n   coordinateSystemRules@OptionValue[\"CoordinateSystem\"],\n   FilterRules[{opts}, Except[\"CoordinateSystem\" | \"Transformation\" | \"ParameterTransformation\"]]\n  ];\n\nProtect[ComplexFit];\n\nEnd[];\n\nEndPackage[];\n\nPackage (.m) and notebook files are also available.\nThe primary limitations are:\n\nthe Weights option is not (directly) supported, because it isn't clear to me how one should transform the weights in general when splitting a complex-valued function into a multivalued real mapping\nthe returned FittedModel objects still contain a reference to an index, i, that labels the coordinates (e.g. real line/imaginary line, modulus/argument, or whatever applies to any other coordinate system one may choose), because the structure of these objects is undocumented and I didn't yet figure out how to split them up\nthe transformation is done quite rigidly and is not currently versatile enough to cater for all foreseeable situations\n\nAnyway, let's give it a try:\nComplexFit[\n  Table[{i, I + 3*i^2 I}, {i, 0, 10}],\n  a + b*x^2 I, {a, b}, x,\n  \"FitFunction\" -> NonlinearModelFit\n ][\"ParameterConfidenceIntervalTable\"]\n\n\nOr, in polar coordinates:\nComplexFit[\n  Table[{i, I + 3*i^2 I}, {i, 0, 10}],\n  a + b*x^2 I, {a, b}, x,\n  \"FitFunction\" -> NonlinearModelFit,\n  \"CoordinateSystem\" -> \"Polar\"\n ][\"ParameterConfidenceIntervalTable\"]\n\n\nAnd, just for fun, here's an example using FindFit instead of NonlinearModelFit, and where the parameters and the initial guesses of their values are explicitly complex:\nComplexFit[\n Table[{x, (17.381 + 53.249 I) x^(1.897 + 0.632 I)}, {x, -10, 10}],\n (a x^b), {{a, 20 + 50 I}, {b, 2 + 0.5 I}}, x\n]\n(* -> {Re[a] -> 17.381, Im[a] -> 53.249, Re[b] -> 1.897, Im[b] -> 0.632} *)\n\nThis is also useful for fitting real-valued data where the model may become erroneously complex-valued for certain values of the parameters. For example, from the other question:\nComplexFit[\n {{0.0, 100.0}, {0.02, 81.87}, {0.04, 67.03},\n  {0.06, 54.88}, {0.08, 44.93}, {0.10, 36.76}},\n a b^t, {a, b}, t,\n \"CoordinateSystem\" -> \"Real\"\n]\n(* -> {Re[a] -> 100.004, Re[b] -> 0.0000452493} *)\n\n", "plotting - Arrows on axes in Plot3D": "\nHere is a simple way to do this:\narrowAxes[arrowLength_] :=\n  Map[{Apply[RGBColor, #], Arrow[Tube[{{0, 0, 0}, #}]]} &, \n   arrowLength IdentityMatrix[3]]\n\nThis function draws three axes with arrows. To apply it:\nGraphics3D[{Sphere[], arrowAxes[3]}]\n\n\nThis doesn't have axis labels, though. \nTo add labels by leveraging the built-in axes, one compromise (to save the work of making all labels by hand) would be to do the following:\nGraphics3D[{Sphere[{1, 1, 1}], arrowAxes[3]}, Axes -> True, \n Boxed -> False, AxesOrigin -> {0, 0, 0}, AxesStyle -> Opacity[0], \n TicksStyle -> Opacity[1]]\n\n\nEdit\nIn my attempt at a labeled set of axes above, I deliberately set the axes to be invisible but left the ticks visible. You may find it more visually consistent to keep the default axes visible, together with the new 3D arrow-axes. For this, one could replace AxesStyle above with this: AxesStyle -> MapThread[RGBColor, IdentityMatrix[3]].\n", "output formatting - hat not big enough": "\nThis answer is just a quick hack. I think that to make true extensible character might not be something that an end-user can do... \nAnyway, redefine the formatting for OverHat using\nOverHat /: MakeBoxes[OverHat[a_], form_] := \n With[{s = First[Rasterize[a, \"RasterSize\"]], \n   ab = MakeBoxes[a]}, With[{sl = N[2 Log[2 s]]},\n   InterpretationBox[OverscriptBox[ab, \n     TagBox[GraphicsBox[LineBox[{{-s, 0}, {0, sl}, {s, 0}}], \n       ImageSize -> {s, Automatic}], \"LongOverHat\", \n      Selectable -> False]], OverHat[a]]]]\n\nThen, just type in the expression as per normal, e.g., \n,\nand then select the OverHat expression and reformat the boxes using the menu command Cell > Convert To > Standard From \n(which can also be done using the shortcut \nCtrlShiftN) to get \n. The FullForm of this expression is OverHat[abc].\nHere's an example showing how the modified OverHat scales for longer expressions\n\nThe MakeBoxes command also works with TraditionalForm (CtrlShiftT), but you might want to modify it to include an \nAdjustmentBox[..., BoxBaselineShift -> b] in order to get the vertical spacing looking right.\n", "kernel - Aborting evaluation when the memory exceeds a certain limit": "\nSince one may not always accurately predict when MemoryContrained is needed, I recommend setting up a watch-dog task.  Belisarius described how to do this here in answer to my question.  I will reproduce it below as answers that are merely links are discouraged.\n\n\nIn Mathematica 8 you could start a memory watchdog, something along\n  the lines of:\nmaxMemAllowed        = 1.3 1024^3; (*1.3 GB*);\nintervalBetweenTests = 1; (*seconds*)\niAmAliveSignal       = 0;\nDynamic[iAmAliveSignal]\nRunScheduledTask[\n       If[MemoryInUse[] > maxMemAllowed , Quit[], iAmAliveSignal++],      \n       intervalBetweenTests];\n\nRemember to run\nRemoveScheduledTask[ScheduledTasks[]];\n\nto disable it.\n\n", "evaluation - Making a symbol's new definitions be tried before all previously defined ones": "\nI will suggest a solution for DownValues - based definitions, but it may be generalized to other types of definitions as well. I will only consider a case of a single symbol, but again, the generalization is rather straightforward. You will also have to execute your code in a special dynamic environment. \nA first ingredient of my suggestion is a (slightly modified) symbol-cloning functionality described here:\nClear[GlobalProperties];\nGlobalProperties[] := \n {OwnValues, DownValues, SubValues, UpValues, \n    NValues, FormatValues, Options, DefaultValues, Attributes};\n\nClearAll[clone];\nAttributes[clone] = {HoldAll};\nclone[s_Symbol, new_Symbol] :=\n  With[{clone = new, sopts = Options[Unevaluated[s]]},\n    With[{setProp = (#[clone] = (#[s] /. HoldPattern[s] :> clone)) &},\n      Map[setProp, DeleteCases[GlobalProperties[], Options]];\n      If[sopts =!= {}, Options[clone] = (sopts /. HoldPattern[s] :> clone)];\n      HoldPattern[s] :> clone]]\n\nHere comes my suggested dynamic environment then:\nClearAll[withUserDefs];\nSetAttributes[withUserDefs, HoldAll];\nwithUserDefs[sym_Symbol, {defs__}, code_] :=\n  Module[{s, inSym},\n    clone[sym, s];\n    Block[{sym},\n     defs;\n     sym[args___] /; ! TrueQ[inSym] :=\n        Block[{sym, inSym = True},\n          clone[s, sym];\n          With[{result = sym[args]},\n             result /; result =!= Unevaluated[sym[args]]\n          ]\n        ];\n     code]];\n\nWhat is happening here: first, we clone the original symbol. Then, we Block it, and run the definitions which we want to override the previous ones. Then, we add a catch-all definition which uses the Villegas-Gayley trick, but also Block-s the symbol in question again, and inside the inner Block uses the clone to effectively \"unblock\" the symbol to its original defs by reverse-cloning it, and  run those. The extra trick to use With and a shared local variable result is needed to avoid infinite iteration in cases when neither user-defined nor previous rules apply.\nHere comes an example:\nClearAll[f];\nf[1] = 10;\nf[x_] := x^2;\nf[x_, y_] := x + y;\n\nAnd now:\nwithUserDefs[f, {f[x_] := x^4}, {f[1], f[2], f[1, 2], f[1, 2, 3]}]\n\n(* \n  ==> {1, 16, 3, f[1, 2, 3]}\n*)\n\nyou can see that in the first two cases, the modified definitions were used, in the third one the original definition was used, and the last one did not match any and evaluated to itself.\nOne can nest these constructs, and the inner one will override the outer ones then. For example:\nwithUserDefs[f, {f[x_] := x^4}, \n   withUserDefs[f, {f[1] := 100}, \n     {f[1], f[2], f[1, 2], f[1, 2, 3]}]]\n\n(* \n  ==> {100, 16, 3, f[1, 2, 3]}\n*)\n\nYou can ask why I wasn't just using the Villegas-Gayley trick by itself, which is much simpler. The answer is that there is no guarantee that the ordering of definitions will be right with it, even if we manually reorder them, and moreover, cases like f[1] = 10 are immune to all reorderings of DownValues and will always be at the top, so can not be dealt with at all, within a pure Villegas-Gayley approach - but can be successfully dealt with in this more complex one.\nThe suggested approach is as good as the symbol's cloning procedure is. For SubValues, UpValues etc, it should be modified. The full solution involving all possible global rules and multiple symbols will likely look more complex, but I just wanted to illustrate the idea in the simplest possible setting. Also, we probably can not count on such generalization to be fully robust.\n", "latex - Unable to convert $\\TeX$ input into mathematica": "\nEdit\nAn updated version of this answer is here. I forgot that there was some duplication when I posted the linked answer, but the material in that answer is more recent so I'll update that one and leave this post unchanged.\nEnd edit\nThe conversion from $\\LaTeX$ in general is rather quirky, but I don't see a failure of the kind you see. \nHowever, there is in fact something wrong: The $\\LaTeX$ syntax you're entering is completely valid and it should be interpreted as the square root of the product of two variables, x and y. However, Mathematica (my version is 8.0.4) incorrectly outputs a single variable xy instead of a product. \nSo there is really a bug in how products are interpreted. The work-around is to put thin spaces in your $\\LaTeX$ code explicitly, as in\nToExpression[\"\\\\sqrt{x\\\\,y}\",TeXForm]\n\nNow the question still is why your conversion failed. My only explanation for that would be that before executing the ToExpression, you might have had a global variable by the name xy defined in Mathematica, for which it turned out to be impossible to take the square root. You could test this by first typing Clear[xy,x,y] and then re-trying the conversion from $\\LaTeX$.\nEdit\nTo expand a little on the quirks of $\\LaTeX$-to-Mathematica conversion, here are some more points to watch out for:\n\nTo translate integrals properly, Mathematica expects the integration variable in the $\\LaTeX$ code to be preceded by \\\\, d. Only with the additional space will it recognize the d as the differential part of the integral.\nExpress derivatives using the \\\\partial symbol ($\\partial$):     ToExpression[\"\\\\frac{\\\\partial^2 f(x)}{\\\\partial x^2}\", TeXForm, Hold]\nIn the above code, the argument Hold prevents evaluation so you can copy the expression from the output cell if desired (you can later apply ReleaseHold to evaluate the expression)\nAll matrices and vectors must be written in list form using escaped curly brackets, as in \\\\{x,y,f (z)\\\\}. The conversion of array environments or commands such as \\pmatrix to Mathematica produces wrong formatting.\nTo group expressions, use only round parentheses, i.e., \\\\left( and \\\\right), not square [...] or curly {...} brackets. The latter are interpreted differently by Mathematica. \n\nI copied this list from this my web page where I also collected some notes on the reverse process of getting equations out of Mathematica.\nEdit 2\nA comment by RM below brings to mind another point that is related more to $\\LaTeX$: some novice authors write lazy expressions like $volume = length \\times area$ and wonder why the typeset equation has unnatural-looking character spacing inside the \"words\" used here as variables. The reason is that $\\TeX$ considers each single character in a sequence such as volume to be a single variable and applies the corresponding horizontal spacing rules to them. \nNot knowing this feature, you may think that Mathematica has every right to interpret x y and likewise xy as the name of a single variable \"xy\". However, that goes against the rules of the $\\TeX$ language and is therefore an incorrect translation. \n", "plotting - How to plot two sets of data on one ListLinePlot": "\nInstead of ListLinePlot[ list1, list2 ] use ListLinePlot[ {list1, list2} ].\n", "numerical integration - NDSolve does not give me the expected solution": "\nIf your friend used MATLAB's ode15s solver, then your equations are most likely stiff, and the default NDSolve options are unlikely to give you a numerically stable result unless your step sizes are insanely small. You'll need a stiff solver instead. \nFor examples on how to proceed in Mathematica, look at tutorial/NDSolveStiffnessTest. Specifically, explore the methods \"StiffnessSwitching\", \"StiffnessTest\" and \"NonStiffTest\". Since you haven't described your system, there is nothing more I can say at this point, but these hints should give provide a good starting point for you. \n", "compatibility - Internal \"Periodical\" functions in version 7": "\nYou can turn this then into a package, and change the lower-case to uppercase... Hope it works well enough for your goals. If not, we'll improve it in time\nAppendTo[$ContextPath, \"Internal`\"];\n\nClearAll[\"`private`*\"];\nSetAttributes[`private`count, HoldRest];\n`private`count[_, expr_, count_Symbol][id_, ___] /; \n  Block[{$scheduledTask = `private`getST[id]}, expr; ++count]/;False := Null\ne : `private`count[i_, _, count_Symbol][id_, endFun : _ : (Null &)] /;\n   count === i := (Remove[count]; RemovePeriodical[e]; endFun[])\n`private`count[___][___] := Null\n\n`private`getST[id_] /; \n  MemberQ[scheduledTasks[], scheduledTaskObject[id, ___]] := \n First@Cases[scheduledTasks[], scheduledTaskObject[id, ___]]\n`private`getST[_] := $Failed;\n\n`private`STQ[scheduledTaskObject[id_, expr_, time_, start_, _]] := \n Length[Cases[scheduledTasks[]/. HoldPattern@\\[Infinity] -> \\[Infinity], \n    scheduledTaskObject[id, expr, time, start, _]/. HoldPattern@\\[Infinity] -> \\[Infinity]]] >= 1\n`private`STQ[___] := False;\n\n`private`startScheduledTask[\n   st : scheduledTaskObject[id_, \n     expr_, {time_, count_}, (start_ /; start <= AbsoluteTime[]) | \n      Automatic, _]] := \n  Module[{counter = 0}, ClearAttributes[counter, Temporary];\n   AddPeriodical[`private`count[count, expr, counter][\n     id, `private`startStop[id, False] &], time]];\n\n`private`startScheduledTask[\n  st : scheduledTaskObject[id_, expr_, {time_, count_}, start_, _]] :=\n  start - AbsoluteTime[] /. \n  remaining_ :> \n   With[{pst := `private`startScheduledTask[\n       scheduledTaskObject[\n        \"\", `private`startScheduledTask[\n         scheduledTaskObject[id, expr, {time, count}, Automatic, \n          False]], {remaining, 1}, Automatic, \n        False]]}, `private`extraTasks[id] = Hold[pst]; pst]\n\nClearAll[createScheduledTask, startScheduledTask, \n  stopScheduledTask, $scheduledTask, removeScheduledTask, \n      scheduledTasks, scheduledTaskObject, runScheduledTask];\n    $scheduledTask::usage = \"\"; scheduledTaskObject::usage = \"\";\nSetAttributes[{createScheduledTask, runScheduledTask}, HoldFirst];\nSetAttributes[scheduledTaskObject, HoldAll];\nSetAttributes[{stopScheduledTask, removeScheduledTask}, Listable];\n\n\nscheduledTasks[] = {}; `private`idCounter = 0;\n`private`startStop[st : (sto : scheduledTaskObject)[__], \n   b : True | False] := st /. sto[rest__, _] :> sto[rest, b];\n`private`startStop[id_Integer, b : True | False] := \n  scheduledTasks[] = \n   scheduledTasks[] /. \n    e : scheduledTaskObject[id, rest__] :> `private`startStop[e, b];\n\ncreateScheduledTask[expr_, {time_, count_: 1}, \n   start_: Automatic] := ++`private`idCounter /. \n    c_ :> scheduledTaskObject[c, expr, {time, count}, start, \n      False] /. sto_ :> (AppendTo[scheduledTasks[], sto]; sto);\n\ncreateScheduledTask[expr_, time_: 1, rest___] := \n  createScheduledTask[expr, {time, \\[Infinity]}, rest];\n\nstartScheduledTask[\n  st : scheduledTaskObject[\n     id_, __]?`private`STQ] := (`private`startStop[id, \n   True]; `private`startScheduledTask[st]; Null /; False)\nstartScheduledTask[s_] := s;\n\nstopScheduledTask[\n  st : scheduledTaskObject[id_, \n     expr_, {time_, \n      count_}, __]?`private`STQ] := (Periodicals[] /. {HoldForm[\n      i : `private`count[sth__][id, __]] :> \n     Quiet@RemovePeriodical[i]}; `private`extraTasks[id] /. \n   Hold[`private`startScheduledTask[\n      scheduledTaskObject[_, e_, ___]]] :> Quiet@RemovePeriodical[e];\n  Quiet[`private`extraTasks[id] =.];\n  `private`startStop[id, False]; Null /; False)\n\nstopScheduledTask[st_] := st;\n\nrunScheduledTask[stuff___] := \n  startScheduledTask@createScheduledTask@stuff~`private`startStop~True;\n\nremoveScheduledTask[\n  st : scheduledTaskObject[\n     id_, __]?`private`STQ] := (stopScheduledTask[st]; \n  scheduledTasks[] = (DeleteCases[scheduledTasks[], \n     scheduledTaskObject[id, __]]); st)\nremoveScheduledTask[_] := $Failed;\n\nIn case you are interested to copy or as reference, here go the usage messages\nToExpression[#, InputForm, Function[name, name::usage, HoldAll]] & /@ \n Names[\"System`*Sche*\"]\n\nreturns, copied as plain text\n{CreateScheduledTask[expr] creates a task that will repeatedly evaluate expr once per second.\nCreateScheduledTask[expr,time] creates a task that will repeatedly evaluate expr every time seconds.\nCreateScheduledTask[expr,{time}] creates a task that will evaluate expr once after time seconds.\nCreateScheduledTask[expr,{time,count}] creates a task that will try evaluating expr once every time seconds up to count times total.\nCreateScheduledTask[expr,timespec,start] creates a task that will evaluate expr according to timespec starting at start time.,RemoveScheduledTask[obj] remove the obj from the list of currently set tasks.,ResetScheduledTask[obj] resets scheduled task object obj to the original parameter values.\nResetScheduledTask[obj,timespec]  resets scheduled task timing to timespec.\nResetScheduledTask[obj,timespec,offset] resets scheduled task time offset to offset.,RunScheduledTask[expr] schedules and starts a task that will repeatedly evaluate expr once per second.\nRunScheduledTask[expr,time] schedules and starts a task that will repeatedly evaluate expr every time seconds.\nRunScheduledTask[expr,{time}] schedules and starts a task that will evaluate expr once after time seconds.\nRunScheduledTask[expr,{time,count}] schedules and starts a task that will try evaluating expr once every time seconds up to count times.\nRunScheduledTask[expr,timespec,start] schedules a task that will automatically start at start time.,ScheduledTaskObject[id,expr,spec,...]  is a task object specifying future evaluation of expr according to spec.,ScheduledTasks[]  returns a list of ScheduledTaskObject expressions that represent current tasks.,StartScheduledTask[obj] starts the task represented by obj.,StopScheduledTask[obj] deactivates the task obj.,$ScheduledTask returns the current ScheduledTaskObject. }\n\n", "front end - Copy TraditionalForm output to TraditionalForm input while keeping formatting": "\nI'm not understanding, or I can't reproduce the behaviour of the pasting of the first part, please post a more concrete example. As to the 0.3333 issue, you could set the NumberMarks option of the input cells to False. Also, if you really meant that you wanted it copied as 0.3333 when your output had been 0.333333 you should also change PrintPrecision to 4\nTo change the options, a way would be to go to Format-Edit stylesheet, write Input in the box and press enter. Then, select the cell, go to Format->Options inspector. Check that \"Selection\" is set, search for the mentioned options and edit them\nAfter these changes, any machine precision number you type in an Input cell, once you append a \"`\" mark, will be displayed as a rounded number, without the \"`\", and with PrintPrecision digits. However, you won't be losing precision in your calculations\n", "programming - Programmatic formatting for Mathematica code": "\nUpdate November 3, 2013\nFinally, the formatter has been made much more robust by adding a custom function like MakeBoxes, names CodeFormatterMakeBoxes, to construct simplified box representation. This solves the main problem that the formatter does not currently support many boxes, since CodeFormatterMakeBoxes constructs the pure RowBox-based representation.\nAlso, added functions CodeFormatterPrint which prints definitions for a given function / symbol, and CodeFormatterSpelunk to make system spelunking easier.\nSome things to try:\nImport[\"https://raw.github.com/lshifr/CodeFormatter/master/CodeFormatter.m\"]\n\nand then\nCodeFormatterPrint[RunThrough]\n\nCodeFormatterSpelunk[RunThrough]\n\nBasically, the difference is only that CodeFormatterPrint does retain long (fully-qualified) symbol names, while CodeFormatterSpelunk does not. Some more details on spelunking in my answer here.\nUpdate 19th of June, 2013\nCode formatter has been extended to support spaces in place of tabs, variable - width tabs and an overall offset. \nThis made it possible finally to start using it for code formatting here on SE - check this out!\nAlso, several other improvements and several bugs fixed.\n\nShort answer\nYes.\nCode formatter\nWhile I will be most happy to see other answers to this question, and will hope that there will be better answers than this one, I am also glad to announce the alpha version of the Mathematica code formatter, which I was working on for some time.\nThe project\nThe code formatter lives here, and the specific file (package) can be downloaded using \nthis link. The code fomatter resides in a package CodeFormatter.m, and has currently two public functions: FullCodeFormat and FullCodeFormatCompact. Both take a piece of code converted to boxes, and return the box form of formatted code. The README file in the project contains the brief description of how to use them, and the  notebook which is included in the project contains many more examples.\nStealing from README, the typical way to use this is to define a helper function like this one:\nprn = CellPrint[Cell[BoxData[#], \"Input\"]] &\n\nand then, use it like:\nprn@FullCodeFormat@MakeBoxes@\n   Module[{a, b}, a = 1; Block[{c, d}, c = a + 1; d = b + 2]; b]\n\nScreenshots\nThese are some screenshots of code pieces processed by FullCodeFormat.\n\n\n\n\nFurther plans/development\nThere are a number of things I plan to add to the formatter and /or develop based on it, such as\n\nDevelop the palette to paste code to SE, based on the formatter (this will come out very soon)\nSupport more boxes\nRefactor the code to eliminate the code duplication and better separate the DSL layer\nAdd more ways to format code\n\nI will start accepting pull requests soon, perhaps after I do the main code refactoring I currently plan. Meanwhile, please do fork me on GitHub if you are interested in playing with this.\nComments, suggestions, bug reports\nAll welcome. For bug reports, I have not decided yet what would be the best place to put them, but the Issues section on GitHub project repository seems appropriate.\nA simplified bare-bones code formatting engine\nHere, I will try to explain my approach, and provide a minimal functioning code-formatting \"engine\", which is a simplified version of the one I referred to above. The motivation for this section (and in fact, for placing the entire post here rather than on meta for example), is to make the code of the formatter accessible, and explain it in simple terms. This would allow you to fork the project and modify the formatter easier to suit your needs, should you wish to do so.\nDesign problems and choices\nThe main idea here is that while parsed expression is a bit too high-level for the formatting purposes, plus tries to evaluate all the time, the box-level is a bit too low-level, and the formatter based on that has a danger of not being robust. \nTherefore, I take the box input, and create an intermediate inert Mathematica expression representation with preprocess and preformat (see below). The formatting procedure itself has two stages: the format proper - which only decides where to put new lines and tabs, and the tabification stage (tabify), which \"executes\" the tabification instructions given by format at the previous stage. \nThis architecture is because there is a certain impedance mismatch between the statement \"I want to move this block of several lines of code one or more tabs to the right\", and the actual way to achieve that with boxes (I suspect, this was one of the major obstacles for implementing code formatter - since I am sure, many people tried that). By separation of these two stages, it was possible to make this tabification abstraction reasonably robust. The final stage is post-formatting (postformat). It takes the result produced by format and tabify, and converts that back to boxes.\nBy using this 3-layer architecture, I am able to make high-level description of the actual formatting rules, in the definitions of format only, and the rest is taken care of by other layers. This makes the formatter both more robust (because, for example, the tabification engine is rather general and does not depend on specific formatting rules, including those I may wish to add later), and more easily extensible. In a sense, I implemented a very small DSL for code formatting. \nSettings and preprocessing\nNow, the code. First comes the only setting we will have here:\n$maxLineLength = 70;\n\nthis defines the maximal length of line of code, and is used by the formatter to decide which long lines need dissection. \nNext comes the pre-processing function, which serves to remove spaces and tabs possibly existing in the box expression:\nClearAll[preprocess];\npreprocess[boxes_] :=\n  boxes //.\n      {RowBox[{(\"\\t\" | \"\\n\") .., expr___}] :> expr} //.\n      {\n        s_String /; StringMatchQ[s, Whitespace] :> Sequence[],\n            RowBox[{r_RowBox}] :> r\n      };\n\nConverting boxes to intermediate inert representation\nNow, we will define the heads of our inert intermediate representation, to which we want to transform the original box expression:\nClearAll[$blocks, blockQ];\n$blocks = {\n   CompoundExpressionBlock, GeneralHeadBlock, GeneralBlock, \n   StatementBlock, NewlineBlock, FinalTabBlock, GeneralSplitHeadBlock,   \n   SuppressedCompoundExpressionBlock, CommaSeparatedGeneralBlock     \n};\n\nblockQ[block_Symbol] :=    MemberQ[$blocks, block];\n\nThe following function will translate the box expression into this intermediate language. It is very simplistic and misses many important cases - a more comprehensive one is in the code of the CodeFormatter` - but it illustrates the general structure. Note that is is recursive, moving from outside to inside.\nClearAll[preformat];\n\npreformat[RowBox[elems : {PatternSequence[_, \";\"] ..}]] :=\n  SuppressedCompoundExpressionBlock @@ Map[\n      Map[preformat, StatementBlock @@ DeleteCases[#, \";\"]] &,\n      Split[elems, # =!= \";\" &]];\n\npreformat[RowBox[elems : {PatternSequence[_, \";\"] .., _}]] :=\n  CompoundExpressionBlock @@ Map[\n      Map[preformat, StatementBlock @@ DeleteCases[#, \";\"]] &,\n      Split[elems, # =!= \";\" &]];\n\npreformat[RowBox[elems : {PatternSequence[_, \",\"] .., _}]] :=\n  CommaSeparatedGeneralBlock @@ \n    Map[preformat, DeleteCases[elems, \",\"]];\n\npreformat[RowBox[elems_List]] /; ! FreeQ[elems, \"\\n\" | \"\\t\", 1] :=\n  preformat[RowBox[DeleteCases[elems, \"\\n\" | \"\\t\"]]];\n\npreformat[RowBox[{head_, \"[\", elems___, \"]\"}]] :=\n  GeneralHeadBlock[preformat@head, \n    Sequence @@ Map[preformat, {elems}]];\n\npreformat[RowBox[elems_List]] :=\n  GeneralBlock @@ Map[preformat, elems];\n\npreformat[block_?blockQ[args_]] :=\n  block @@ Map[preformat, {args}];\n\npreformat[a_?AtomQ] := a;\n\npreformat[expr_] :=\n    Throw[{$Failed, expr}, preformat];\n\nYou can see that it treats only  few selected heads like CompoundExpression separately, plus has rules for general heads.\nFormatting\nNext will come two helper functions, used in formatting to determine whether or not a given line of code is too long and needs to be split. The first one, maxLen, determines the maximal length of the code line in an expression, accounting for the fact that it may already have been split into several lines.\nClear[maxLen];\nmaxLen[boxes : _RowBox ] :=\n  Max@Replace[\n      Split[Append[Cases[boxes, s_String, Infinity], \"\\n\"], # =!= \"\\n\" &],\n      {s___, (\"\\t\" | \" \") ..., \"\\n\"} :> \n        Total[{s} /. {\"\\t\" -> 4, ss_ :> StringLength[ss]}],\n      {1}];\n\nmaxLen[expr_] :=\n  With[ {boxes = postformat@expr},\n       maxLen[boxes] /; MatchQ[boxes, _RowBox ]\n   ];\n\nmaxLen[expr_] :=\n  Throw[{$Failed, expr}, maxLen];\n\nNote that maxLen uses not yet defined postformat, which is perhaps a bit stronger coupling between components than desirable, and is a design short-cut to be removed. The next one is a simple convenience function:\nClearAll[needSplitQ];\nneedSplitQ[expr_, currentTab_] :=\n  maxLen[expr] > $maxLineLength - currentTab;\n\nNow comes the main formatting function, format. All specific formatting rules are included here. It takes an intermediate inert expression as a first argument, and the current number of tabs inserted, as a second one. It is also essentially recursive, and processing an expression from outside to inside.\nClearAll[format];\nformat[expr_] :=  format[expr, 0];    \n\nformat[TabBlock[expr_], currentTab_] :=\n  TabBlock[format[expr, currentTab + 4]];\n\nformat[NewlineBlock[expr_, flag_], currentTab_] :=\n  NewlineBlock[format[expr, currentTab], flag];    \n\nformat[(ce : (CompoundExpressionBlock | \n    SuppressedCompoundExpressionBlock))[elems__], \n    currentTab_] :=\n  With[ {formatted = Map[format[#, currentTab] &, {elems}]},\n       (ce @@ Map[NewlineBlock[#, False] &, formatted]) /; \n         !FreeQ[formatted, NewlineBlock]\n  ];\n\nformat[StatementBlock[el_], currentTab_] :=\n    StatementBlock[format[el, currentTab]];\n\nformat[expr : GeneralHeadBlock[head_, elems___], currentTab_] :=\n  With[ {splitQ = needSplitQ[expr, currentTab]},\n       GeneralSplitHeadBlock[\n           format[head, currentTab],\n           Sequence @@ Map[\n               format[If[ splitQ,\n                             TabBlock@NewlineBlock[#, False],\n                             #\n                         ], \n                   currentTab] &,\n               {elems}]] /; splitQ\n   ];\n\n(* For a generic block, it is not obvious that we have to tab, so we don't*)\nformat[expr : (block_?blockQ[elems___]), currentTab_] :=\n  With[ {splitQ = needSplitQ[expr, currentTab]},\n       block @@ Map[\n           format[If[ splitQ,\n                         NewlineBlock[#, False],\n                         #\n                     ], currentTab] &,\n           {elems}]\n   ];\n\nformat[a_?AtomQ, _] := a;\n\nYou can see that format uses two new block types: NewlineBlock and TabBlock, and the former also accepts a flag which can be True or False. This flag, when being set to True, forces the formatter to create a new line, while when being set to False, tells the formatter to propagate the new line request deeper into the expression. The TabBlock directive also accepts a similar flag. The reason that the flags are needed in this approach is that it is not straightforward to implement the abstraction such as \"move this piece of code one tab to the right\" on the box level, for example because each new line in the boxes must be tabbed separately. \nIn any case, format does only part of the job, because it only instructs what must be done. It has a companion, tabify, which actually executes the instructions of format:\nClearAll[tabify];\ntabify[expr_] /; ! FreeQ[expr, TabBlock[_]] :=\n    tabify[expr //. TabBlock[sub_] :> TabBlock[sub, True]];\n\ntabify[(block_?blockQ /; ! MemberQ[{TabBlock, FinalTabBlock}, block])[\nelems___]] :=\n    block @@ Map[tabify, {elems}];\n\ntabify[TabBlock[FinalTabBlock[el_, flag_], tflag_]] :=\n  FinalTabBlock[tabify[TabBlock[el, tflag]], flag];\n\ntabify[TabBlock[NewlineBlock[el_, flag_], _]] :=\n  tabify[NewlineBlock[TabBlock[el, True], flag]];\n\ntabify[TabBlock[t_TabBlock, flag_]] :=\n  tabify[TabBlock[tabify[t], flag]];\n\ntabify[TabBlock[(block_?blockQ /; ! MemberQ[{TabBlock}, block])[ \n     elems___], flag_]] :=\n  FinalTabBlock[\n    block @@ Map[tabify@TabBlock[#, False] &, {elems}],\n    flag];\n\ntabify[TabBlock[a_?AtomQ, flag_]] :=\n  FinalTabBlock[a, flag];\n\ntabify[expr_] :=  expr;\n\nYou can see that it introduces another tab-related block, FinalTabBlock - which is a block that signifies the need to tab a particular line by one tab, and is inert in the sense that once TabBlock is converted to FinalTabBlock, it does not any more actively influence the work of tabify. \nPost-formatting\nThe final stage of the formatting procedure is to take the  expression  processed with format and tabify. We need one helper function which serves to prevent the addition of several new lines (\"gaps\" in the formatted code) , by determining whether or not the next line of code starts with a new line (if so, the NewlineBlock directive around it is ignored): \nClearAll[isNextNewline];\nisNextNewline[_NewlineBlock] := True;\n\nisNextNewline[block : (_?blockQ | TabBlock)[fst_, ___]] :=\n  isNextNewline[fst];\n\nisNextNewline[_] := False;\n\nHere is finally the code for the inverse converter from the inert intermediate representation to boxes, postformat:\nClearAll[postformat];\npostformat[GeneralBlock[elems__]] :=\n  RowBox[postformat /@ {elems}];\n\npostformat[CompoundExpressionBlock[elems__]] :=\n  RowBox[Riffle[postformat /@ {elems}, \";\"]];\n\npostformat[SuppressedCompoundExpressionBlock[elems__]] :=\n  RowBox[Append[Riffle[postformat /@ {elems}, \";\"], \";\"]];\n\npostformat[GeneralHeadBlock[head_, elems___]] :=\n  RowBox[{postformat@head, \"[\", \n      Sequence @@ Riffle[postformat /@ {elems}, \",\"], \"]\"}];\n\npostformat[GeneralSplitHeadBlock[head_, elems___]] :=\n  With[ {formattedElems = postformat /@ {elems}},\n       RowBox[{postformat@head, \"[\",\n           Sequence @@ Riffle[Most[formattedElems], \",\"],\n           Last[formattedElems], \"]\"}]\n   ];\n\npostformat[GeneralBlock[elems___]] :=\n  RowBox[Riffle[postformat /@ {elems}, \",\"]];\n\npostformat[StatementBlock[elem_]] :=\n  postformat[elem];\n\npostformat[NewlineBlock[elem_?isNextNewline, False]] :=\n  postformat@elem;\n\npostformat[CommaSeparatedGeneralBlock[elems__]] :=\n  RowBox[Riffle[postformat /@ {elems}, \",\"]];\n\npostformat[NewlineBlock[elem_, _]] :=\n  RowBox[{\"\\n\", postformat@elem}];\n\npostformat[FinalTabBlock[expr_, True]] :=\n  RowBox[{\"\\t\", postformat@expr}];\n\npostformat[FinalTabBlock[expr_, False]] :=\n  postformat@expr;\n\npostformat[a_?AtomQ] :=  a;\n\npostformat[arg_] :=\n  Throw[{$Failed, arg}, postformat];\n\nIt is also necessarily recursive, and the code should be pretty much self-documenting.\nThe final function\nThe function which brings it all together is very simple:\nClearAll[fullCodeFormat];\nfullCodeFormat[boxes_] :=\n  postformat@tabify@format@preformat@preprocess@boxes;\n\nExamples and limitations\nThis very simplified version of the formatter is quite limited. However, it can handle a few not so trivial examples. Here is a rather non-trivial one to try:\nprn@fullCodeFormat@MakeBoxes[\n   Compile[{{data, _Real, 2}}, \n     Module[{means = Table[0., {maxIndex}], num = Table[0, {maxIndex}], \n        ctr = 0, i = 0, index = 0, resultIndices = Table[0, {maxIndex}], \n          indexHash = Table[0, {maxIndex}]}, \n      Do[index = IntegerPart[data[[i, 2]]];\n       means[[index]] += data[[i, 1]];\n       num[[index]]++;\n       If[indexHash[[index]] == 0, indexHash[[index]] = 1;\n       resultIndices[[++ctr]] = index];, {i, Length[data]}];\n       resultIndices = Take[resultIndices, ctr];\n       Transpose[{resultIndices, \n       means[[resultIndices]] + num[[resultIndices]]}]],(*Module*)\n       CompilationTarget -> \"C\", RuntimeOptions -> \"Speed\"]]\n\nhere is a screenshot of what you should see as a result (prn is defined as prn = CellPrint[Cell[BoxData[#], \"Input\"]] &):\n\nBecause of the way the final function is written, it is very easy to inspect what is happening in the intermediate stages. For example, you can only apply\nformat@preformat@preprocess@boxes\n\nto see what format is doing.\nThis simplified formatter has a number of limitations, so don't expect it to work nicely on code involving e.g. function definitions through SetDelayed, some complex patterns, etc. The real code formatter in the CodeFormatter` package, while having the same core, has a number of additional rules to handle more cases.\n", "warning messages - Indeterminate expression. Where?": "\nSince you define f[m_,x_] by Sum[a[m,n,x],{n,0,Infinity}] so there are terms in the sum like 0^0 because :\na[0,n,1]=1/2^n ((-1)^n)/((2n)!) Sum[Binomial[0,l] (0-2l)^(2n),{l,0,0}] x^(2n)\n\nWhen there is a[0,n,1] you start the sum with Sum[Binomial[0,l] (0-2l)^(2n),{l,0,0}] and the first term in the definition of f[m_,x_] is with n==0.\nEdit\nTo prevent generating of messages one can define a[m,n,x] and f[m,x] this way : \na[m_Integer, n_Integer, x_] /; n > 0 := \n  1/2^n (-1)^n/((2 n)!) Sum[ Binomial[m, l] (m - 2l)^(2n), {l, 0, m}] x^(2 n)\na[m_Integer, 0, x_] := 1\nf[m_Integer, x_] := Sum[ a[ m, n, x], {n, 0, Infinity}]\n\n", "list manipulation - How can I multiply matrix and vector element wise like Numpy?": "\nThe problem is that Mathematica wants to match up $v$ with the rows of $C$. In order to get what you want, you can do:\nS=Transpose[Transpose[C]/v]\n\n", "list manipulation - Does Mathematica have advanced indexing?": "\nUsing a little Mathematica pattern matching, I think you can get similar performance as @Szabolcs's answer while having nice Matlab-style syntax:\nreplaceWhere[cond_, selectTrue_, selectFalse_] := \n   With[{evaluatedCondition = evaluateTensorCondition[cond]},\n        selectTrue*evaluatedCondition + selectFalse*(1 - evaluatedCondition)]\n\nreplaceWhere[cond_, selectTrue_] := replaceWhere[cond, selectTrue, 0]\n\nevaluateTensorCondition[a_ > b_] := UnitStep[a - b]    \n\nevaluateTensorCondition[a_ < b_] := UnitStep[b - a]\n\nevaluateTensorCondition[a_ && b_] := \n    evaluateTensorCondition[a]*evaluateTensorCondition[b]\n\nevaluateTensorCondition[a_ || b_] := \n    UnitStep[evaluateTensorCondition[a]+evaluateTensorCondition[b]-1]\n\n(implementing more comparison and logical operators should be straightforward)\nUsage:\nreplaceWhere[T > 15, L, 0]\n\nreturns a new list, where every index that is greater than 15 in T is set to 0 , the other elements are the same as L. And it should have similar performance as @Szabolcs's answer, because all the conditions are just transformed into vectorizable tensor operations. (I haven't timed it, though.) \nNote that this works for arbitrarily complex expressions, and the last two parameters can be tensors or scalars:\nreplaceWhere[(T > 5 && T < 15) || Sin[L]<Cos[T], L, L*2]\n\nIf you evaluate this expression symbolically:\nClear[T, L]\nreplaceWhere[(T > 5 && T < 15) || Sin[L] < Cos[T], L, 0]\n\nyou get one long tensor expression composed of UnitStep's\nOut = L UnitStep[-1 + UnitStep[15 - T] UnitStep[-5 + T] + UnitStep[Cos[T] - Sin[L]]]\n\nSo \"under the hood\" Mathematica will do the same operations as in @Szabolcs's answer. You just get a more readable syntax.\n\nIf you don't want to do all those fancy syntax manipulations, you can always use MapThread to combine higher dimensional arrays in any way you'd like. For your question, this would be:\nMapThread[If[#1 > 15, 0, #2] &, {T, L}, 2]\n\nThis takes the 2d-Tensors (last argument 2) T and L (second argument {T, L}), passes the corresponding elements in the two tensors to a function (first argument If[#1 > 15, 0, #2] &) and returns a new tensor containing the return value of that function. This is slower than @Szabolic's answer, but it is also a lot more flexible.\n", "function construction - Can SetDelayed (:=) be compiled?": "\nCompile can't handle SetDelayed. \nIn your specific case, you might be able to avoid the need for SetDelayed altogether through the use of Boole.\nkd[m_, n_] :=If[m == n, 1, 0] can be replaced by Boole[n==m]. (or as FJRA pointed out in comments, by KroneckerDelta.)\ncosfun[m_, n_] := \n If[m == n, 0, (1 - Cos[(m + n) \u03c0])/((m + n) \u03c0) + \n  ((Cos[(m - n) \u03c0] - 1)/((m - n) \u03c0))]\n\ncan be replaced by  \nBoole[m == n] (1 - Cos[(m + n) \u03c0])/((m +  n) \u03c0) + \n ((Cos[(m - n) \u03c0] - 1)/((m - n) \u03c0)) (-I A2 m Pi/L)\n\nGiving\neenew = Compile[{{\u03bc, _Real}, {NNN, _Integer}}, \n  Module[{NN = NNN}, (* do you even need this placeholder for the input? *)\n   mm = Table[Boole[m == n] (MM - B2 k k - B1 (m Pi/L)^2), {m, 1, NN}, {n, 1, NN}]; \n   kz =  Table[Boole[m != n] (1 -  Cos[(m + n) \u03c0])/((m + n) \u03c0) + \n     ((Cos[(m - n) \u03c0] - 1)/((m - n) \u03c0)) (-I A2 m Pi/L), \n     {m, 1, NN}, {n, 1, NN}]; \n   kxM =   Table[Boole[m == n] A1 k, {m, 1, NN}, {n, 1, NN}]; \n  \u03bcM = Table[Boole[m == n] \u03bc, {m, 1, NN}, {n, 1, NN}]; \n   HH =    ArrayFlatten[{{\u03bcM + mm, 0 mm, kz, kxM}, \n      {0 mm, \u03bcM + mm, kxM, -kz}, {kz, kxM, \u03bcM - mm,0 mm}, \n      {kxM, -kz, 0 mm, \u03bcM - mm}}]; \n  ees = Table[Eigenvalues[HH], {k, -.1, .1, .01}]]] \n\nWhat is k for in this last line? There is no way for the iterator to matter for HH.\nThis doesn't give the error involving SetDelayed anymore.\n", "numerical integration - NIntegrating within an Ellipsoid": "\nWhy not use elliptical coordinates? That's what they are there for. \nFor example, if your function is f[x_,y_], then you define the coordinate transformation \nx[u_, v_]:= Cos[v] Cosh[u];\ny[u_, v_]:= Sin[v] Sinh[u];\n\nThe Jacobian is Sin[v]^2 + Sinh[u]^2, so you simply do the integral like this:\nNIntegrate[\n f[x[u, v], y[u, v]] (Sin[v]^2 + Sinh[u]^2), {u, 0, 1}, {v, 0, 2 Pi}]\n\nThat's the basic idea. You can always rotate and scale your function arguments to fit within this particular ellipse which has axis lengths of Cosh[1] and Sinh[1], respectively. You can also adjust the integration limit in {u, 0, 1} to something other than 1 depending on the eccentricity of the ellipse. These steps are easy once you understand the coordinate system. \nYou can also do all this using the VectorAnalysis package, but I'd say that is overkill for this relatively simple problem.\nRescaling to a circle in 2D\nIn fact, you may also want to look into just rescaling your x and y coordinates to fit into a circle and use polar coordinates... (that also generalizes more easily to higher dimensions).\nThere isn't exactly one built-in function to do the rescaling, but you can probably find all you need by starting at this post. I'll just describe the logic:\nAssume you have already figured out the semimajor and -minor axes (vec1 and vec2) as well as the center (in a variable center) of the ellipse. Then you can figure out the rotation angle required to make vec1 the x-axis, leading to a rotation R. The scale transformation T that you need is given by the lengths of vec1 and vec2, resp. \nNow compose your function f[x,y] with these transformations. This transformation introduces a Jacobian given by the product Norm[vec] * Norm[vec2]. \nThe final step is to go to polar coordinates which introduces an additional factor r (the radial coordinate). \nPolar coordinates are probably best in this case, unless you plan on doing other manipulations with your function that go beyond integration.\nEdit\nTurns out it's almost more difficult to describe the transformations in words than it is to do it in Mathematica. So I'm adding the code now:\nrescaling = Composition[TranslationTransform[center], \n   RotationTransform[{{1, 0}, vec1}], \n   ScalingTransform[{Norm[vec1], Norm[vec2]}]]\n\nThis is now used in the integral of your function which I assume to be defined as \nf[{x_, y_}] := ...\n\n(note that the argument is a single list representing the point). With this, it only remains to write the integral\nintegrand = Composition[f, rescaling];\npolarIntegrand[r_?NumericQ, a_?NumericQ] := \n     integrand[{r Cos[a], r Sin[a]}] r;\nNIntegrate[\n  polarIntegrand[r,a], \n   {r, 0, 1}, {a, 0, 2 Pi}] Norm[vec1] Norm[vec2]\n\nHere, I've tweaked the integrand a little to make sure we don't get slowed down by Mathematica attempting to symbolically simplify it. The ?NumericQ rules that out. That should be all you need.\n", "list manipulation - Defining a string based sort function": "\nIf all the entries in your array are strings, then one way to sort it is to do something like this:\norder[str_String /; \n   StringMatchQ[str, \"T\" ~~ (DigitCharacter | \"p\") .. ~~ \"K\"]] := 1\norder[str_String /; \n   StringMatchQ[str, \"Vg\" ~~ DigitCharacter .. ~~ \"V\"]] := 2\norder[str_String /; StringMatchQ[str, \"Ch\" ~~ DigitCharacter ..]] := 3\norder[a_] := a\n\n#[[Ordering[order /@ #]]] & /@ list\n\nThis method uses the fact that numbers come before strings in an ordered list.\n", "linear algebra - Composition of functions": "\nThe function your looking for is Composition which does exactly what you would like it to do. For instance,\n{rot1, rot2} = MapThread[RotationTransform, {{theta1,theta1},{point1,point2}}]\ncomposed = Composition @@ %\n\n\nComposition[\n     RotationTransform[theta1, point1], \n     RotationTransform[theta1, point2]\n  ]\n\n\nwhich can then be used like rot1 and rot2 would, e.g. composed[ {x, y, z} ]. From some experiments, it seems that Composition will combine multiple TransformationFunction into a single TransformationFunction, e.g.\nComposition[ RotationTransform[ Pi/2 ], RotationTransform[ Pi/2] ] ]\n\nsimplifies to \nRotationTransform[ Pi ]\n\n\nHere is a specific example using the following rotations\nRotationTransform[Pi/2, {1, 0}]\nRotationTransform[Pi/2, {1, 1}]\ncomposed = Composition @@ {%, %%}\n\nwhich gives the output (it's in picture form as the output is displayed using boxes):\n\nNow, applying them one at a time to a triangle, using the following code\nFoldList[\n  {EdgeForm[Black], White, #2[#1]} &, \n   Polygon[{{1, 0}, {0, Sqrt[3]}, {-1, 0}}], \n  {# &, \n   GeometricTransformation[#, RotationTransform[Pi/2, {1, 0}]] &, \n   GeometricTransformation[#, RotationTransform[Pi/2, {1, 1}]] &}\n][[2 ;;]] //\nGraphicsRow[\n Graphics[#, Frame -> True, PlotRange -> {{-3, 3}, {-3, 3}}] & /@ # \n]&\n\ngives\n\nUsing the composition directly via\nGraphics[{\n   EdgeForm[Black], White, \n   GeometricTransformation[\n       Polygon[{{1, 0}, {0, Sqrt[3]}, {-1, 0}}], \n       composed]\n  }, Frame -> True, PlotRange -> {{-3, 3}, {-3, 3}}]\n\ngives the identical end result\n\nTwo things to note here. First, the functions are entered into Composition in reverse order of application, i.e. the first function to be applied is last, and the last function is first. Second, I made use of GeometricTransformation to apply the rotations to a Graphics primitive.\n", "packages - $InputFileName backwards compatibility": "\nYou can try\nSystem`Private`$InputFileName\n\nSeems to work on M7, not sure about M6.\n", "web access - Mathematica Import functions fails for data download from website": "\nThe user agent (requester_id) probably isn't the issue. Indeed, Mathematica does not appear as a standard browser to web servers (it identifies itself as Mathematica), but that usually isn't an issue for normal HTML pages. And indeed Squid can solve problems if your page is testing for a specific browser (see also an earlier question on user agents)\nFor pages that are partly generated by a Javascript script this is different, as Mathematica does not interpret Javascript. I don't think you can get this to work.\n", "performance tuning - Making a \"cached\" version of `Manipulate[]`?": "\nThe following code demonstrates a bit of caching. The initialization code is run only once, because the variable cached which is saved in the Manipulate remembers the cached state. So when you copy the Manipulate into an empty notebook and open this in a fresh session, the cached plots stored in the saved variable plot (stored because of the SaveDefinitions option) won't be calculated again. \nRemove the cached = True line and insert a Print[\"Init\"] before the Plot command to see that plot is recalculated when the notebook  containing the Manipulate is opened and viewed in a fresh session (without explicitly executing any code).\nDynamicModule[{cached, plot},\n Manipulate[\n  plot[[kx, ky]],\n  {kx, 1, 10, 1},\n  {ky, 1, 10, 1},\n  Initialization :> {\n    If[\\[Not] TrueQ[cached],\n     plot = \n      Table[Plot3D[\n        Sin[kx x] Cos[ky y], {x, 0, \\[Pi]}, {y, 0, \\[Pi]}], {kx, 10}, {ky, 10}];\n     cached = True\n     ]},\n  SaveDefinitions -> True,\n  SynchronousInitialization -> False\n  ]\n ]\n\n\n", "probability or statistics - Most efficient way to obtain samples from high-dimensional multivariate distributions?": "\nMultivariate distributions do not require any named variables. My hunch is that your confusion in this regard is due to the excessive use of {{1, \u03c1}, {\u03c1, 1}} in the documentation for MultivariateTDistribution. You might've missed the fact that in most cases, the value for \u03c1 is being substituted via a Table or a ParallelTable. \nYou can directly input your covariance matrix (and any additional parameters depending on the distribution) and call RandomVariate to draw from that. For your example:\n\u03a3 = With[{\u03c1 = 0.2}, SparseArray[{i_, i_} -> 1, {100, 100}, \u03c1]];\nx = RandomVariate[MultivariateTDistribution[\u03a3, 10], {100}];\n\nThis will generate 100 samples of multivariate T distributed random vectors, each of length 100.\n", "curated data - WordData for other languages": "\nThe current references for WordData can be seen online.\nIf you would like to suggest an addition, there is a link where you can suggest additional functionality.\n", "custom notation - How to use subscript in pattern names?": "\nYou can use Symbolize, from the Notation package following the tutorial as you did.\nThen, just take the precaution of writing the pattern with its head explicit, such as: Pattern[xr, _]\nThe problem is that Mathematica can't interpret the short notation for patterns (xr_ for example) if it has a box structure before the \"_\"\n", "performance tuning - Plot on command within DynamicModule?": "\nIf you want the user to have absolute control over updates...say, by having an explicit Update button, then you can do so by adding an independent variable to control the updating and changing your Dynamic so that it only tracks that variable. Here, I introduce a variable update, which is an integer. Its value and type don't matter...what matter is that the Dynamic only updates when that variable does:\nDynamicModule[{a = 0, b = 0, update = 0}, \n Column[{Slider[Dynamic[a]], Slider[Dynamic[b]], \n   Button[\"Update\", update++], \n   Dynamic[update; Plot[Sin[(a + 1) t + \\[Pi] b], {t, 0, 2 \\[Pi]}], \n    TrackedSymbols :> {update}]}]]\n\n", "front end - Detecting double click events": "\nYou can use a combination of MouseDown and MouseClickCount as in the following examples: \nexample 1: double-click increments the value of j:\nj = 1; EventHandler[Panel[Dynamic[j]], \n\"MouseDown\" :> If[CurrentValue[\"MouseClickCount\"] == 2, ++j]]\n\nexample 2: double-click toggles the text color:\nDynamicModule[{col = Green}, \n  EventHandler[\n    Style[\"text\", FontColor -> Dynamic[col]], \n   {\"MouseDown\" :> \n      If[CurrentValue[\"MouseClickCount\"] == 2, \n         (col = col /. {Red -> Green, Green -> Red})]}\n  ]]\n\n", "list manipulation - What's the most intelligent way to store the information of a selfmade graph?": "\nThis might be a suitable use case for UpValues. UpValues (/:) associate the definition with the inner symbol, rather than the outer function, and can be used as a kind of tag. So you can define your data:\na5 /: parents[a5] = {a1, a4};\na5 /: name[a5] = \"mila\";\na74 /: parents[a74] = {a2, a55, a71};\na74 /: name[a74] = \"bob\";\n\nThe other question is how you are going to store the original data to be loaded into the UpValues. In your question you suggested it would be some sort of text file. I assume it is the form\na4 \"alice\" a3 a2\na9 \"carol\" a6 a4\n\nso you can Import it into a normal Mathematica matrix.\nYou could then write a function to process the imported data. Notice the use of Repeated (..) in the Pattern (:). The With construct seemed to be necessary to avoid certain errors firing.\nmakeDef[d : {{_Symbol, _String, __Symbol}..}] := \nWith[{nn = First[#]},  \n (UpValues[nn] = {name[nn] -> #[[2]], \n   parents[nn] -> Drop[#, 2]})] & /@ d\n\nThe output from this looks strange but the UpValues are then correct.\nAnd then a simple function like this\nmakeFamilyGraph[p_List] := \n Graph[Flatten[Thread[parents[#] -> #] & /@ p], \n  VertexLabels -> (# -> name[#] & /@ p)]\n\nGives output like this:\nmakeFamilyGraph[{a4, a5, a9, a74}]\n\n\n", "programming - Importing Zip files": "\nThe documentation for the MIME type ZIP does not seem to say much about what you want to do, but luckily the first thing I tried worked! \nFirst, I saved your zip file onto my desktop. Then, I extracted the first level of file names (note that \"FileNames\" is the default option, so is not explicitly needed)\nIn[1]:= fn1 = Import[\"/home/simon/Desktop/RV120312.zip\", \"FileNames\"]\nOut[1]= {\"today_rv.zip\"}\n\nThen the second level of file names\nIn[2]:= fn2 = Import[\"/home/simon/Desktop/RV120312.zip\", {fn1[[1]], \"FileNames\"}]\nOut[2]= {\"TGENTRADES.M3\", \"CCONTRGRP.C2\", \"CCONTRTYP.C2\", \\\n    \"CCONTRACTS.C2\", \"CCONTRSTAT.C2\", \"CTHEORPRICES.C2\", \"CDELTAS.C2\", \\\n    \"CINTRASPR.C2\", \"CINTERSPR.C2\", \"CVALARRAYS.C2\", \"CYIELDCURVE.C2\", \\\n    \"CVOLATILITYSKEW.C2\", \"MCONTRACTS.M3\"}\n\nFinally, I extracted, for example, the third file in the inner archive\nIn[4]:= Import[\"/home/simon/Desktop/RV120312.zip\", {fn1[[1]], fn2[[3]]}]\nOut[4]= {{\"\\\"20120312\\\";\\\"C2\\\";\\\"20\\\";\\\"0100\\\";\\\"FuturoC IBEX MINI\\\";1;1\", \n  \"00;\\\"EUR\\\";\\\"1\\\";\\\"FFICSX\\\"\"}, {...}, ....}\n\nI think that this final Import defaulted to a CSV import, when you seem to want to separate elements by semicolons (\";\"), so you should use:\nIn[5]:= Import[\"/home/simon/Desktop/RV120312.zip\",{fn1[[1]], fn2[[3]], \"Table\"}, \n           \"FieldSeparators\"->\";\"] // Short[#,3]&\nOut[5]//Short= {{20120312, C2, 20, 100, FuturoC IBEX MINI, \n                 1, 1,00, EUR, 1, FFICSX}, <<916>>, \n                {20120312, C2, VI, 240, Contado VIVENDI, \n                 1, 1,00, EUR, 2, ESXXXX}}\n\n\nNote that you could, e.g., use a While loop to automate the digging down to the lowest level of the archive.\n", "performance tuning - Speeding up a slow indefinite integral": "\nIf you break it up as below it will be considerably faster. The idea is to use symbolic integration on the inner integral (Why? Because we can, and it makes this faster).\nIn[263]:= \ni1[n_, t_] = \n Integrate[\n  Exp[-((z^2 + (200*n - z)^2)/(4*t))] + \n   Exp[-((z^2 + (100 + 200*n - z)^2)/200)], {z, -50, 50}, \n  Assumptions -> {t > 0, -4 <= n <= 4}]\n\nOut[263]= (5*Sqrt[Pi]*(-Erf[10*n] + Erf[10*(1 + n)]))/\n  E^(25*(1 + 2*n)^2) + \n   (Sqrt[Pi/2]*Sqrt[t]*(Erf[(25*Sqrt[2]*(1 - 2*n))/Sqrt[t]] + \n           Erf[(25*Sqrt[2]*(1 + 2*n))/Sqrt[t]]))/E^((5000*n^2)/t)\n\nIn[264]:= i2[t_] = Sum[i1[n, t], {n, -4, 4}];\n\nIn[265]:= \npwd[y_] := (1/(4*Sqrt[Pi]))*\n  NIntegrate[Exp[-1/(4*t)]/t^(3/2)*i2[t], {t, 0, y}]\n\nThe tabulation for the interpolation should complete in something approximating reasonable time. Well, within several hours, in any case, if counting by hundreds is any indication.\nIn[272]:= Timing[tabulate = Table[{y, pwd[y]}, {y, 0, 100000, 100}];]\n\nOut[272]= {150.71, Null}\n\n", "curated data - Computing Many Slow I/O Operations": "\nAs Szabolcs mentions, the simplest way to do this is to start a new kernel and push this bulk of data acquisition to that kernel and let it run in the background. There are good examples in the documentation in tutorial/ConcurrencyManagingParallelProcesses.\nFor your specific case, here's an example following the above:\nLaunchKernels[1];\nj = ParallelSubmit[{#, FinancialData[#, \"DividendYield\"]} & /@ \n   Take[FinancialData[\"NYSE:*\"], 30]];\n\n\nParallel`Developer`QueueRun[]\nOut[3]= True\n\n\nYou can continue working as usual in your main kernel.\n", "polynomials - GroebnerBasis without specifying variables": "\nIf the (ordered) list of variables is not specified, GroebnerBasis will order the variables as it encounters them. I remark that, as this depends on implementation details, it can be version dependent.\nThe question (which I should have anticipated) was raised as to how one might get the \"variables\" that GroebnerBasis sees, and in the same order. It can be done with a non-System-context function GroebnerBasis`DistributedTermsList. It will both rewrite the polynomials in an internal format (as its name implies), and also give the variables in the order it is using them. One must specify CoefficientDomain -> Rationals in order to force it to create new variables rather than treat unspecified ones as part of the coefficient field (the default behavior).\nHere is a simple example.\npolys = {3*y*z - 5, 2*x^2 + y + z^3 - 1, x*y - 2};\nVariables[polys]    \nOut[1]= {x, y, z}\n\nGroebnerBasis`DistributedTermsList[polys, CoefficientDomain -> Rationals]\nOut[2]= {{{{{1, 1, 0}, 3}, {{0, 0, 0}, -5}}, {{{1, 0, 0}, 1}, {{0, 3, 0}, 1}, \n    {{0, 0, 2}, 2}, {{0, 0, 0}, -1}}, {{{1, 0, 1},1}, {{0, 0, 0}, -2}}}, {y, z, x}}\n\n", "Problm with Compil Function - Mathmatica Stack Exchang": "\nNot a proper answer, but I just want to comment that the procedure carried out by @rcollyer can be automated to a large extent. Here is a code for a simplistic common subexpression eliminator:\nClearAll[csub];\ncsub[expr_Hold, rules_List, limitCount_] :=\n  With[{newrule = \n     Replace[\n       If[# =!= {} && #[[-1, -1]] > 1, #[[-1, 1]], {}] &@\n         SortBy[Tally[\n           Cases[expr,          \n             x_ /; Depth[Unevaluated[x]] > 2 && \n               LeafCount[Unevaluated[x]] > limitCount :> Hold[x],\n             Infinity]],\n           Last],\n       Hold[x_] :> (HoldPattern[x] -> Unique[])]\n    },\n    csub[expr /. newrule, Append[rules, newrule], limitCount] /; \n        newrule =!= {}];\n\ncsub[Hold[expr_], rules_, _] :=\n Append[\n   Thread[\n     (rules /. (Verbatim[HoldPattern][x_] -> var_) :> Hold[var := x]), \n     Hold\n   ],\n   Unevaluated[expr]\n  ] /. Hold[defs_, exp_] :> Hold[LetL[defs, Hold[exp]]]\n\nwhere the LetL macro implements the sequential With construct, defined as\nClearAll[Let];\nSetAttributes[Let, HoldAll];\nLet /: (lhs_ := Let[vars_, expr_ /; cond_]) := \n   Let[vars, lhs := expr /; cond]\nLet[{}, expr_] := expr;\nLet[{head_}, expr_] := With[{head}, expr]\nLet[{head_, tail__}, expr_] := With[{head}, Let[{tail}, expr]]\n\nI discussed is more here. Using\nheld = Hold[If[your-expression]]\n\nsetting the threshold to say 10 (I played with this a bit), and executing\ncsub[held,{},10]\n\nwe get this:\nHold[\n  letL[{\n    $3 := #1[[2]] - #1[[1]], $4 := #1[[1, 2]] - #1[[2, 2]], \n    $5 := #1[[2, 1]] - #1[[1, 1]], $6 :=  Sqrt[$3[[1]]^2 + $3[[2]]^2], \n    $7 := (#1[[1, 3 ;; 4]].{$4, $5} {$4, $5})/\n       (Sqrt[$4^2 + $5^2] Sqrt[$4^2 + $5^2]), \n    $8 := #1[[2, 3 ;; 4]].$3[[{1, 2}]]\n    }, \n    Hold[\n       If[(list[[2]] - list[[1]])[[{1, 2}]] != {0, 0}, \n          (\n           Flatten[{\n             #1[[1, 1 ;; 2]] + $7 + ($8 $3[[{1, 2}]])/($6 $6), \n             $7 + (($8 $6) $3[[{1, 2}]])/$6\n           }] &) /@ {{list[[1]], list[[2]]}, {list[[2]],list[[1]]}}, \n         (Flatten[{#1[[{1, 2}]] + #1[[{3, 4}]], #1[[{3, 4}]]}] &) /@ list]\n       ]\n    ]\n  ]\n\nIf you now apply ReleaseHold to the above, you recover your code, wrapped in Hold. Note that while I tried automatic minimization of Leafcount for the above, it turns out to give smaller thresholds than what seems to be the easiest for us to read. The real metric here should include some penalty for long chains of dependencies, since they are hard for us humans to digest.\n", "performance tuning - Transferring a large amount of data in parallel calculations": "\nThere are two performance problems here. The first is relatively minor: MultinormalDistribution[\u03bc, \u03a3] is evaluated in each slave kernel, returned to the master kernel, and sent back to the slave kernels as part of the RandomVariate call. In your example, this is a packed array of about 80KB in size: not large, yet not small either, and this behaviour may become an issue in other contexts. This is easily solved by specifying Method -> \"CoarsestGrained\" as an option to ParallelTable. However, while certainly representing an improvement, this setting unfortunately has little impact on overall behaviour in the current case.\nThe second issue is both more subtle and more serious, and comes from the handling of aborted evaluations by the Parallel` package. The essence of it is that all results returned to the master kernel by the slaves are checked for aborted evaluations using MemberQ[res, $Aborted]. Here, res is a large matrix in the form of a packed array $\\approx$160MB in size, and the unpacking of this by MemberQ accounts for the poor performance and considerable memory consumption of this example. The peak memory consumption does not persist, however, since after the absence of $Aborted has been verified, the intermediate (unpacked) results are discarded.\nTo demonstrate more concretely the source of problem, we examine the file\nFileNameJoin[{$InstallationDirectory, \"AddOns\", \"Applications\", \"Parallel\", \"Combine.m\"}]\n\nand note that we can change the behaviour of this example using only the excerpt (which is complete with original comments, but repackaged to be a stand-alone modification of the relevant code, as well as slightly reformatted):\nBeginPackage[\"Parallel`Combine`\"];\nBegin[\"`Private`\"];\n\nNeeds[\"Parallel`Parallel`\"];\nNeeds[\"Parallel`Kernels`\"];\n\n(* Additional required contexts -- O. R. *)\nNeeds[\"Parallel`Protected`\"];\nNeeds[\"Parallel`Developer`\"];\n\nparallelIterateE[orig_, iter_, comb_, f_, expr_,\n                 it : {w1_}, others___, {meth_, dist_, ___}] :=\n With[{nk = $KernelCount, items = Internal`GetIteratorLength[it, orig]},\n  Module[{batches, batchsize, sizes, res},\n   If[ !IntegerQ[items] || items < 0, (* cannot do it if symbolic *)\n    Message[orig::nopar1, HoldForm[orig[expr, {w1}, others]]];\n    Return[iter[expr, {w1}, others]]\n   ];\n   (* handle Method option *)\n   grokMethodOption[orig, Evaluate[items], nk, batches, batchsize, meth];\n   sizes = makeSizes[items, nk, batches, batchsize];\n   (* send definitions *)\n   Parallel`Protected`AutoDistribute[{f, expr, others}, orig, dist];\n\n   parStart;\n   With[{\n     chunks = HoldComplete @@ sizes /.\n      u1_Integer :> f[iter[expr, {u1}, others]]\n    },       \n    res = If[\n     batches === 1,\n     ParallelDispatch[chunks],\n     ConcurrentEvaluate[chunks]\n    ];\n   ];\n   res = If[\n    (* Here lies the problem -- O. R. *)\n    MemberQ[res, $Aborted],\n    $Aborted,\n    comb @@ res\n   ]; (* remote abort received *)\n   parStop;\n\n   res\n  ]\n ]\n\nEnd[];\nEndPackage[];\n\n(I should stress that the above is only one example of this code pattern as used in Combine.m; it also appears in other places not relevant to this example.)\nModifying this, either by removing the MemberQ call, or simply by commenting out res, and then running it (after loading the Parallel` package) to modify the definitions made in Combine.m can be seen to restore the expected performance. \nUnfortunately, although one might think up a more performant (or at least non-unpacking) but semantically equivalent replacement, such as\nBlock[{$Aborted := Abort[]}, CheckAbort[res, $aborted]] === $aborted\n\nthis won't work since $Aborted is Locked. In any case, for obvious reasons, I hesitate to suggest modifying Combine.m in order to fix this problem, so attempting a workaround seems to be the best option here.\nEdit: the workaround\nAs promised in the edit comment I left when I deleted my initial (incorrect) attempt at a workaround, here is a potential (this time, hopefully correct) solution to the problem of MemberQ unpacking. It is different in spirit to @Szabolcs's approach, being based on a modification of the original MemberQ rather than a reimplementation, so I feel it is worth posting as well. However, the same caveat applies: modifying System` functions is something which should be attempted with great care and only as a last resort. This method is based on the replacement of any packed arrays that appear in the first argument of MemberQ with an opaque list when the second argument is a symbol. I think it's safe, but there may be a situation I've overlooked, so I still advise caution.\nwithModifiedMemberQ[expr_] :=\n Module[{doneQ, unmatchable},\n  Internal`InheritedBlock[{MemberQ},\n   Unprotect[MemberQ];\n   (* Can uncomment this if we want to print out the MemberQ calls:\n   mq:MemberQ[args___]/;(Print@HoldForm[mq];True):=mq;\n   *)\n   MemberQ[list_, patt_Symbol, args___] /; !TrueQ[doneQ] :=\n    Block[{doneQ = True},\n     MemberQ[\n      Unevaluated[list] /. _List?Developer`PackedArrayQ -> {unmatchable},\n      Unevaluated[patt],\n      args\n     ]\n    ];\n   Protect[MemberQ];\n   expr\n  ]\n ];\nSetAttributes[withModifiedMemberQ, HoldAllComplete];\n\nLet's test it. For this I've uncommented the definition that prints out the calls to MemberQ so that its operation will produce some debug output. (Note also that Range returns a packed array.)\nOn[\"Packing\"];\n\nMemberQ[Range[5], $Aborted]\n(* (message) Developer`FromPackedArray::unpack: Unpacking array in call to MemberQ.\n   False *)\n\nwithModifiedMemberQ@MemberQ[Range[5], $Aborted]\n(* (prints) MemberQ[{1, 2, 3, 4, 5}, $Aborted]\n   (prints) MemberQ[{unmatchable$1305}, $Aborted]\n   False *)\n\nwithModifiedMemberQ@MemberQ[Range[5], 1]\n(* (prints) MemberQ[{1, 2, 3, 4, 5}, 1]\n   (message) Developer`FromPackedArray::unpack: Unpacking array in call to MemberQ.\n   True *)\n\nSo it looks okay. Now let's comment out the debug output (otherwise the front end will probably lock up) and try it on the problematic ParallelTable call:\nOn[\"Packing\"];\n\nwithModifiedMemberQ@AbsoluteTiming[\n Join @@ ParallelTable[\n  RandomVariate[\n   MultinormalDistribution[\\[Mu], \\[CapitalSigma]], \n   200000\n  ], {2}\n ];\n]\n(* {2.8593750, Null} *)\n\nNo unpacking messages are printed, and the performance issue is fixed. (On my computer, the version using the unmodified MemberQ takes 5.6 seconds.)\n", "graphics - Graph stories, 3-d volumes": "\nWarning: It appears that in version 9 this tends to crash the kernel.  Beware and save your work before trying!\n\nHere's a starting point.  It needs a lot more polish.\nFirst, make a bottle:\n{p1, p2, p3, p4} = Table[{i, 0.5}, {i, 4}];\nif = Interpolation[{{0, 1/2}, p1, p2, p3, p4, {5, 1/2}}];\n\nColumn[{\n  LocatorPane[\n   Dynamic[{p1, p2, p3, \n     p4}, ({p1, p2, p3, p4} = #; \n      if = Interpolation[{{0, 1/2}, p1, p2, p3, p4, {5, 1/2}}]) &], \n   Dynamic@Plot[if[x], {x, 0, 5}, PlotRange -> {{0, 5}, {0, 1}}]],\n  Dynamic[\n   bottle = \n    RevolutionPlot3D[{if[x], x}, {x, 0, 5}, PlotStyle -> Opacity[0.5],\n      Mesh -> None]]\n  }]\n\n\nThen fill it and animate it:\nvolume = Derivative[-1]@FunctionInterpolation[if[x]^2, {x, 0, 5}]\n\nTable[Rasterize@\n   Show[bottle, \n    RevolutionPlot3D[{0.95 if[x], x}, {x, 0, \n      InverseFunction[volume][t]}, Mesh -> None, \n     PlotStyle -> Blue]], {t, 0.1, volume[5], 0.1}] // ListAnimate\n\n\n", "probability or statistics - RandomVariate with a Discrete Distribution": "\nThis is a multinomial distribution.  Obtain your bootstrap sample quickly as in this example:\nz = RandomReal[{0, 1}, 10];\nz = z / (Plus @@ z) (* Generate an example set of values for  z0^, ..., z8^, q *)\nf = MultinomialDistribution[2^28, z];\nTiming[RandomVariate[f, 1000];]\n\n(1.342 seconds).\n", "performance tuning - Update only one element in a dynamic grid?": "\nStudying various parts of the your code I found that having an array hold your images seems to be the main cause of delay for some reason not directly clear to me. Using normal variables (which can be done easily by putting the DynamicModule deeper in the hierarchy) the process gets much quicker:\nGrid[\n Table[\n  DynamicModule[\n   {g = Image[RandomReal[{0.5, 1}, {16, 16, 3}]]},\n   Button[\n    Dynamic[g],\n    g = Image[RandomReal[1, {16, 16}]],\n    ImageSize -> Full, Appearance -> None\n    ]\n   ], {i, 19}, {j, 19}\n  ], Spacings -> {0, 0}\n ]\n\n\nYou can still see the ugly white lines that are also in your original code (but not in your alternative). Have to find out how to remove these...\n", "equation solving - How to find regions that satisfy this inequality?": "\n[Please please please...post actual cut-and-pastable code.]\nHere is a method that is, unfortunately, impractical. But it sometimes gives results if you are patient.\nisEmpty[a_?NumericQ, b_?NumericQ] := Module[{finst},\n  finst = \n   FindInstance[(3*x + y Exp[x*y])*(x \\[Minus] a) + (6*y + \n         x*Exp[x*y])*(y \\[Minus] b) < 0, {x, y}];\n  If[ListQ[finst],\n   If[Length[finst] == 0, True, False]\n   , $Failed]\n  ]\n\nIn[306]:= isEmpty[1, 3]\n\nOut[306]= False\n\nHere is a start on a method that uses contpur plotting. One must settle for a finite range on {x,y} for this; I use -+10 for both.\nisEmpty2[a_?NumericQ, b_?NumericQ] := Module[{cplot},\n  cplot = \n   ContourPlot[(3*x + y Exp[x*y])*(x \\[Minus] a) + (6*y + \n         x*Exp[x*y])*(y \\[Minus] b) == 0, {x, -10, 10}, {y, -10, 10}, \n    ContourShading -> False, Frame -> None]\n  ]\n\nIt just gives a picture but i guess those better versed in Mathematica's Graphics might be able to extract at True/False therefrom. It would of course not be a guaranteed resutl, since plotting uses numeric approximation methods.\nIt gives a nice result for a=-4, b=-1.\n\n--- edit ---\nA comment asks about a specific set of inputs for {a,b}. Not one to duck such a test, I'll show a result with FindRoot. Here we find an {x,y} pair for which the expression of interest is negative (equal to -0.2), by setting y first to 0. I did this because the contour plot indicated there was a negative region in that general vicinity.\nIn[339]:= FindRoot[((3*x + y Exp[x*y])*(x - a) + (6*y + \n        x*Exp[x*y])*(y - b) /. {a -> -1.0643, b -> -.15, \n     y -> 0.}) == -.2, {x, .1}]\n\nOut[339]= {x -> -0.0634401}\n\n--- end edit ---\n", "scoping - Find variable name from DumpSave on a scoped variable": "\nYou can open the MX file in an ASCII editor. The variable name is there in plain text (interpolation$511 in my case). The rest is binary gibberish.\nSo given an MX file with a single variable with the $ suffix, the following expression can be used to access that variable directly:\ngetExpression[filename_] := Module[{a}, \n   ToExpression[(a = StringCases[Import[filename, \"Text\"], \n   WordCharacter ... ~~ \"$\" ~~ NumberString][[1]])];\n   << (filename);\n   ToExpression[a]\n  ]\n\nE.g.,\nresult = getExpression[\"interpolation.mx\"]\n  (* InterpolatingFunction[{{1,10}},<>] *)\n\nEvaluating the variable name before reading it with Get (or <<) seemingly overcomes the Temporary attribute discussed in Leonid`s answer. As a (perhaps unwanted) side-effect of the above expression, the original variable remains defined.\nThis approach could probably be extended to work with multiple variables and expressions in one MX file.\n", "plotting - How do I speed up Plot when the independent variable is in the Numerical expression": "\nYou are solving the eigenvalue problem for every point in the plot. If it is feasible to work out the analytical expression for the eigenvalues with kx as a symbol, then calculate that outside the plot and plot the solution.\nHH = H /. {\u03bc -> 1, \u0394 -> .3, L -> 11, ky -> 0};\neHH=Eigenvalues[HH]]];\nPlot[Re[Sort[eHH]], {kx, -2 \u03c0/11, 2 \u03c0/11}, PlotPoints -> 10]\n\nYou could also try\nPlot[Re[Sort[Evaluate@Eigenvalues[HH]]], {kx, -2 \u03c0/11, 2 \u03c0/11}, PlotPoints -> 10]\n\nBut seriously, if you only want ten plot points, precalculate the eigenvalues and then use ListPlot or ListLinePlot.\neHHlist= With[{HH = H /. {\u03bc -> 1, \u0394 -> .3, L -> 11, ky -> 0}}, \n Table[Re[Sort[Eigenvalues[HH]]], {kx, -2 \u03c0/11, 2 \u03c0/11, 2  \u03c0/55}]  ]\nListPlot[eHHlist]\n\n", "programming - Basic questions about running Mathematica": "\nHeike's code produces a graphics output. So if you run it inside a raw kernel (which is what the math command does on linux), it won't display any graphics. Instead you'll see something like --Graphics-- on your screen. To actually display the output, you'll need to load the JavaGraphics package as <<JavaGraphics` before the plot command (this needs to be done only once per session).\nJens has more on running Mathematica without a front-end. Brett Champion also notes the following:\n\nWhen using JavaGraphics`, graphics are rendered by a child front end and converted to a bitmap format. So most new features of graphics are supported. The exception is that if there are interactive aspects to the graphic (tooltips, mouse-overs, Dynamics), they will effectively be ignored. Visualization functions sometimes have problems since in order for them to work correctly, they have to handle Show and DisplayFunction just right. If you do run across problems with a visualization function when using JavaGraphics` , please file it as a bug. \n\nAs for the rest of the questions, I'll refer you to the official documentation that Sjoerd shared, as there is no need to duplicate information.\n", "numerics - Meaning of backtick in floating-point literal": "\nThe backtick is a short-hand to mark the precision of your output. If it is not followed by any number, it denotes machine precision. You can denote arbitrary precision by including a number, as for example, 0.3`20.\nBy default, these are not displayed in StandardForm, which is why you see them only when copying, at which point it gets converted to InputForm. You can show them with NumberMarks -> True. For example:\nSqrt[2] // N\n(* 1.4142135623730951 *)\n\nInputForm[Sqrt[2] // N, NumberMarks -> True]\n(* 1.4142135623730951` *)\n\n", "How to generally match, unify and merge patterns?": "\nIn my opinion, this is a very good and worthwhile question, but certainly not easy to answer. I don't have a full solution by any means, but as far as the comparison/matching part is concerned, the undocumented function Internal`ComparePatterns may be of substantial assistance. What follows is a short summary of what I know about this function, which exists in Mathematica 7 and 8, but not version 5.2. I would guess that it is new-in-6 and used in the implementation of OptionsPattern and related functions.\nInternal`ComparePatterns[p, q] (where p and q are patterns) operates somewhat like MatchQ, except that rather than simply True or False to signify agreement or disagreement, multiple (namely, five) possibilities exist to describe the relationship p has to q:\n\nIdentity\nTwo patterns are considered identical if they match verbatim up to, but not including, naming. This relation should obviously be transitive and commutative, and I haven't observed any counterexamples so far. An example could be:\nInternal`ComparePatterns[a_, b_]\n(* -> \"Identical\" *)\n\nIt is also aware of attributes that affect pattern matching. Here we attempt to mask the Orderless attribute of Plus (and thus possibly confuse Internal`ComparePatterns) by wrapping it in HoldComplete:\nInternal`ComparePatterns[\n HoldComplete[x_Real + y_Integer],\n HoldComplete[y_Integer + x_Real]\n]\n(* -> \"Identical\" *)\n\nPattern names are not completely ignored, however, and seem to be taken into account where appropriate:\nInternal`ComparePatterns[x_Real + y_Integer, x_Integer + y_Real]\n(* -> \"Incomparable\" *)\n\nEquivalence\nIf p has the same meaning as q but is not structurally identical, the patterns are considered equivalent:\nInternal`ComparePatterns[a | b, b | a] (* Alternatives is not Orderless *)\n(* -> \"Equivalent\" *)\n\nInternal`ComparePatterns[a : y_ + x_, b : (f : Plus)[x_, y_]]\n(* -> \"Equivalent\" *)\n\nHowever, determination of this relationship is not completely robust. Patterns that are sufficiently structurally different sometimes will not be considered equivalent even if they manifestly are:\nInternal`ComparePatterns[a : y_ + x_, b : (f : Plus | Plus)[x_, y_]]\n(* -> \"Specific\" *)\n\nHere are two more examples of patterns that are equivalent, but where the relationship is misstated. The second of these is particularly interesting:\nInternal`ComparePatterns[Repeated[_, Infinity], Repeated[_]]\n(* -> \"Specific\" *)\n\nInternal`ComparePatterns[Repeated[_, {1, Infinity}], Repeated[_, Infinity]]\n(* -> \"Identical\" *)\n\nSpecificity\nIn some circumstances, Internal`ComparePatterns is able to determine when one pattern is a special case of another:\nInternal`ComparePatterns[_h, _]\n(* -> \"Specific\" *)\n\nHowever, this situation is often misdiagnosed with equivalent patterns, which will instead be identified as special cases of each other:\nInternal`ComparePatterns[__, (_) ..]\n(* -> \"Specific\" *)\n\nInternal`ComparePatterns[(_) .., __]\n(* -> \"Specific\" *)\n\nDisjointness\nWhat is more reliably stated is when one pattern is exclusive of another, i.e. there are no expressions that could be matched by both:\nInternal`ComparePatterns[_a, _b]\n(* -> \"Disjoint\" *)\n\nIncomparability\nFinally, we have the situation whereby the patterns are either unrelated, or Internal`ComparePatterns simply does not know how to interpret their relationship:\nInternal`ComparePatterns[a | b, b | c]\n(* -> \"Incomparable\" *)\n\nNotably, it seems to be the case that Internal`ComparePatterns works entirely inside the pattern matcher, so that conditional patterns (which need to invoke the main evaluation loop), if not identical, are generally incomparable (by this mechanism):\nInternal`ComparePatterns[_ /; True, _ /; Sequence[True]]\n(* -> \"Incomparable\" *)\n\nInternal`ComparePatterns[_?(True &), _ /; True]\n(* -> \"Incomparable\" *)\n\n\nNow let's try it on the examples:\nInternal`ComparePatterns[a | b, b | a]           (* -> \"Equivalent\" -- correct *)\nInternal`ComparePatterns[a | b, c | b | a]       (* -> \"Specific\" -- correct *)\nInternal`ComparePatterns[a | b | c, b | a]       (* -> \"Incomparable\" -- correct *)\nInternal`ComparePatterns[a | b | (c : b), b | a] (* -> \"Incomparable\" -- incorrect, but: *)\nInternal`ComparePatterns[a | (c : b), b | a]     (* -> \"Equivalent\" -- correct *)\nInternal`ComparePatterns[{a ..}, {a ..}]         (* -> \"Identical\" -- correct *)\nInternal`ComparePatterns[{a ..}, {a ...}]        (* -> \"Specific\" -- correct *)\nInternal`ComparePatterns[{a ...}, {a ..}]        (* -> \"Incomparable\" -- correct *)\n\nSo, Internal`ComparePatterns fails only in one case, and its answer is still technically correct as it is the result of the inability of the function to see the relationship between these patterns (Internal`ComparePatterns[a | b | b, b | a] gives \"Specific\" rather than \"Equivalent\") and not a statement about the expressions they will match.\nI should finish by saying that I wasn't able to find any concrete examples of where Internal`ComparePatterns is actually used in Mathematica, which should give one pause considering its occasional mistakes. However, it may be that I didn't find it because I wasn't trying hard enough, rather than because it isn't used anywhere. Here is code for a hook that can be installed (using $Pre = withHookedComparePatterns) during normal usage. If you're lucky enough to stumble on a function that uses Internal`ComparePatterns, the call stack and the call itself will be printed out at that point, which will help to identify what its use case is, if any. Anyone finding any examples is welcome to edit this answer to include them below (marking as Community Wiki at the same time, if desired).\nClearAll[withHookedComparePatterns];\nSetAttributes[withHookedComparePatterns, HoldAll];\nBegin[\"System`Private`\"];\nwithHookedComparePatterns[expr_] :=\n  Internal`InheritedBlock[{Internal`ComparePatterns},\n   Unprotect[Internal`ComparePatterns];\n   cp : Internal`ComparePatterns[___] /;\n     StackInhibit[Print[{Stack[], HoldForm[cp]}]; True] := cp;\n   Protect[Internal`ComparePatterns];\n   StackBegin[expr]\n  ];\nEnd[];\n\n", "assumptions - simplify assuming a variable equals zero": "\nYou can use /. (ReplaceAll) : \n% /. a->0\n\nSimplify[%,a=0] produces an error ( this  expression a = 0 cannot be used as an assumption)  because it means just setting the value zero to the variable a, in another form Set[ a, 0], see Set.\nIn some cases, when there are more variables which depends on another ones you may need the repeated replacement for applying rules repeatedly until the expression no longer changes, then you would rather use ReplaceRepeated, (//.)  e.g. :\n% //. {a -> b + 1, b -> 2}\n\n", "plotting - plot function against composite variable": "\nHere's an approach that uses Rationalize to turn a real number into a rational number, and extracts the numerator and denominator to be used when evaluating f[x,y].\nf[x_, y_] := y^2/x^2 Exp[x/y] + 5 x/y\n\ng[xy_?NumericQ] := \n    With[{r = Rationalize[xy, 0]}, \n        f[Numerator[r], Denominator[r]]\n        ]\n\nPlot[g[xy], {xy, 0, 2}]\n\n\nA few notes:\n\nthe definition of g doesn't need to know what f is.\nI used Rationalize[x, 0] to make sure the result is rational, avoiding cases like  Rationalize[0.123423789] returning 0.123423789.\nI used _?NumericQ to make sure g is only defined for numbers, since Rationalize[x,0] will return x, which I want to avoid.\n\n", "assignment - MapThread gives different results from ToExpression when trying to assign variables from a list": "\nI believe it is because Set has attribute HoldFirst.  The FullForm of what you are attempting would look like...\nSet[ToExpression[data[[1,1]]],1]\n\nThe ToExpression doesn't get a chance to evaluate before trying to assign the value.  You can use Evaluate if you insist on doing it this way.\nEvaluate[ToExpression[data[[1, 1]]]] = data[[2, 1]]\n\n", "plotting - InterpolationOrder for ContourPlot": "\nThe most efficient way to carry out your task, which is to plot a contour map of a kernel density of your points, is by converting the points to raster format and using a Fast Fourier Transform to convolve them with a density kernel.  But that takes some work.  If you're willing to wait a few seconds, the whole procedure is (less efficiently) built into Mathematica's SmoothKernelDistribution function.\nHere is an example taken, with minor changes (to make it more interesting), directly from the help page:\n(* Create some data--around 10,000 points--for the illustration *)\ndata = Join @@ Table[RandomVariate[BinormalDistribution[m, {1/2, 1/2}, 0], 1500], \n        {m, RandomReal[{1, 9}, {7, 2}]}];\n\n(* Create a rough (D1) and smooth (D2) density for contouring *)\nD1 = SmoothKernelDistribution[data, 0.02]; (* Takes a few seconds *)\nD2 = SmoothKernelDistribution[data, 0.5];  (* Takes a few more seconds *)\n\n(* Plot the points and their densities *)\npoints = ListPlot[data, PlotRange -> {{0, 10}, {0, 10}}, AspectRatio -> 1];\nTableForm[{\n  Prepend[\n   Table[\n     ContourPlot[\n       Evaluate@PDF[D, {x, y}], {x, 0, 10}, {y, 0, 10}, \n       PlotRange -> All, \n       ColorFunction -> \"TemperatureMap\"], \n     {D, {D1, D2}}\n ], points]\n}]\n\n\n", "Creating a table/Matrix during a For loop": "\nTypically the best way to accumulate results from an arbitrary process is to use Sow and Reap.\nI picked four functions of i as an example.  Since there are four, I Partition at the end into subsets of four:\nReap[\n  For[i = 1, i < 10, i++, Sow[i]; Sow[i^2]; Sow[i!]; Sow[N@Log@i]];\n][[2, 1]] ~Partition~ 4\n\n\n{{1, 1, 1, 0.},\n {2, 4, 2, 0.693147},\n {3, 9, 6, 1.09861},\n {4, 16, 24, 1.38629},\n {5, 25, 120, 1.60944},\n {6, 36, 720, 1.79176},\n {7, 49, 5040, 1.94591},\n {8, 64, 40320, 2.07944},\n {9, 81, 362880, 2.19722}}\n\n\nIf you can formulate your code to do a single Sow for each row it will be cleaner:\nReap[\n  For[i = 1, i < 10, i++, Sow[{i, i^2, i!, N@Log@i}]];\n][[2, 1]]\n\n\nBrett Champion recommended that I show the two argument from of Sow, which groups results according to explicit tags.\n\nSow[e, tag]\n  specifies that e should be collected by the nearest enclosing Reap whose pattern matches tag.  \nSow[e, {tag1, tag2, ...}]\n  specifies that e should be collected once for each pattern that matches a tagi. \n\n(See this answer for a powerful use of the multiple tag form.)\nHere is an example using this in place of Partition in the case of separate Sow expressions per loop.\nReap[\n For[i = 1, i < 10, i++, Sow[i, i]; Sow[i^2, i]; Sow[i!, i]; Sow[N@Log@i, i]];\n][[2]]\n\n\nAlso, with a few exceptions it is better to avoid For in Mathematica and use constructs such as Table, Do, Array, Map, NestWhile, FixedPointList and others.  I chose to answer your direct question rather than to answer with what I think you should use instead.  If you are interested in alternative ways to write your program you should post a new question to that effect with an example For loop you wish to optimize.\n", "sorting - Sort data after specific ordering (ascending/descending) in multiple columns": "\n\nCaveat lector: Incorrect results are generated by this solution, e.g.,\nsortByColumn[{{\"a\", 1, 1}, {\"b\", 2, 3}, {\"a\", 3, 2}}, {1, 1, -1}]\nreturns \n{{\"a\", 1, 1}, {\"b\", 2, 3}, {\"a\", 3, 2}}\nwhen the correct result is obviously \n{{\"a\", 1, 1}, {\"a\", 3, 2}, {\"b\", 2, 3}}\nI've commented on the answer to bring it to the attention of the author, \n  however seeing as they've not been here in some time, I'm also putting this here: I think a highly upvoted and accepted answer needs to be correct. - ciao\n\nHere is my contribution, which has the following benefits over previous answers:\n\nIt sorts both numbers and non-numeric structures\nYou can sort any column (not just the first, followed by the second, etc)\nYou can sort in either direction (ascending / descending)\nOriginal order is kept: if you sort on the second column, the first entry will follow the order of the original list. See the example with {0,-1}\nEdit also allow specifying the priority of the columns. So given {-1,1} for the ordering, you can specify {1,2} to give the higher priority to the second column. \n\nThe code is as follows, including my usage code for my own comments. \nClear[sortByColumn]\nsortByColumn::usage = \n  \"Arguments: [Table, Direction, Priority]. Returns the list sorted \\\nby the directions for each column specified in `Direction`. For \\\nascending order, use `1`, and for descending order, use `-1`. For \\\nsorting more than one column, input `Direction` as a list. For \\\nexample, Direction={-1,1} will sort the first column in descending \\\norder followed by the second column in ascending order, ignoring any \\\nother column. To sort on the second column, use {0,1} for the syntax.\n\n  When sorting two or more columns, you can provide the `Priority` \\\nfor which column should be sorted first. For example, \\\n`sortByColumn[data,{-1,1},{1,2}]` would sort first in ascending order \\\non the second column (because it has a higher priority) and then in \\\ndescending order on the first column.\";\n\nsortByColumn[list_?MatrixQ, dir : _Integer | {__Integer}, priority_: {}] := \n Module[{l = Length@list[[1, All]], w, p, d},\n  w = Reverse@Range@l;\n  p = If[Length@priority > 0, PadRight[Flatten@{priority}, l], \n    p = Range@l];\n  w = w[[Ordering@p]];\n  d = PadRight[Flatten@{dir}, l];\n  Sort[list, NonNegative@Total[(w d MapThread[Order, {##}])] &]]\n\nFor example, using the data set provided by Mr. Wizard:\ndata={{\"a\", 1, 1}, {\"a\", 1, 5}, {\"a\", 1, 3}, \n      {\"c\", 2, 1}, {\"b\", 2, 2}, {\"b\", 2, 3}, \n      {\"c\", 3, 1}, {\"a\", 3, 2}, {\"a\", 3, 3}};\ndata[[All, 2]] = data[[All, 2]] /. {1 -> \"q\", 2 -> \"r\", 3 -> \"s\"};\n\nHere are the results of some trial runs. First the original:\n{a,q,1}\n{a,q,2}\n{a,q,3}\n{c,r,1}\n{b,r,2}\n{b,r,3}\n{c,s,1}\n{a,s,2}\n{a,s,3}\n\nThe result of sortByColumn[data,-1]. \n{c,r,1}\n{c,s,1}\n{b,r,2}\n{b,r,3}\n{a,q,1}\n{a,q,2}\n{a,q,3}\n{a,s,2}\n{a,s,3}\n\nResult of sortByColumn[data,{0,-1}]\n{c,s,1}\n{a,s,2}\n{a,s,3}\n{c,r,1}\n{b,r,2}\n{b,r,3}\n{a,q,1}\n{a,q,2}\n{a,q,3}\n\nAnd finally, the result the OP wanted, sortByColumn[data,{1,-1,1}]\n{a,s,2}\n{a,s,3}\n{a,q,1}\n{a,q,2}\n{a,q,3}\n{b,r,2}\n{b,r,3}\n{c,s,1}\n{c,r,1}\n\nAn example showing the use of the priority argument: sortByColumn[data, {-1, 1}, {1, 2}]\n{a,q,1}\n{a,q,5}\n{a,q,3}\n{c,r,1}\n{b,r,2}\n{b,r,3}\n{c,s,1}\n{a,s,2}\n{a,s,3}\n\n", "plotting - Why is my plot cut off?": "\nIf you fix the syntax errors in Plot and Export, and change the ordering of the two graphics in Show everything works fine. The source of problem you are having is: Show uses the options from the first graphics object, and automatic values of image padding for your g1 does not leave space for the frame labels of g2 to show. So, the following minor changes in your code should fix the problem.\n  g1 = Plot[x, {x, 0, 100}, AspectRatio -> 1] ;\n\n  g2 = ListContourPlot[data, FrameLabel -> {\"label1\", \"label2\"}, \n  PlotLabel -> \"title\", AspectRatio -> 1, \n  DataRange -> {{0, 100}, {0, 100}}] ;\n\n  g3 = Show[{g2, g1}]\n\n  Export[\"test.pdf\", g3, ImageResolution -> 600]\n\nproduces the correct pdf file that shows the frame labels.\nNotes:\n\nEverything looks great on the computer.\n\n\nNot quite... With Show[{g1,g2}] you get the following on the screen:\n\nwhere\n data = RandomReal[{0, 10}, {20, 2}];\n\nis used as data input for ListContourPlot. \nUsing Show[{g2,g1}] you get:\n\nFinally, although the resulting pdf file shows the plot and frame labels\n\nyou probably still want to play with various values for ImagePadding as Szabolcs suggests to adjust the spaces on the four sides of the graph.\n", "Dealing with numbers too large for machine precision in Graphics": "\nI wonder whether I have understood your question correctly because I know you'll be aware of Clip\ndata = \n Clip[#, {-$MaxMachineNumber, $MaxMachineNumber}] & /@ {0, Exp[1000.]}\n\n(*\n==> {0, 1.797693135*10^308}\n*)\n\nPrecision /@ data\n\n(*\n==> {\\[Infinity], MachinePrecision}\n*)\n\n\ndata = RandomReal[10, {10, 2}]~Join~{{0, Exp[1000.]}};\n\nGraphics[Point[data], PlotRange -> {0, 10}]\n\n\ndata = Map[Clip[#, {-$MaxMachineNumber, $MaxMachineNumber}] &, data, 2]\n\n(*\n==> {{1.712790207, 2.900090032}, {2.659619591, \n  7.829120544}, {1.961467042, 3.28800444}, {8.391594058, \n  6.895205615}, {7.272335729, 5.320941734}, {2.663140973, \n  0.988927991}, {3.408201238, 2.47708199}, {7.951584505, \n  7.102838229}, {6.826916007, 5.639933047}, {5.307337319, \n  1.629710693}, {0, 1.797693135*10^308}}\n*)\n\nGraphics[Point[data], PlotRange -> {0, 10}]\n\n\n", "How can I compare a dynamic variable with a literal in Mathematica?": "\nManipulate will work. This simple alarm will sound for 1 minute or shorter period if you hit reset:\nManipulate[If[Refresh[DateList[], UpdateInterval -> 1][[4 ;; 5]] == \n {hours, minutes} && oo, EmitSound[Sound[SoundNote[\"C\", 1]]]];\n Text@Style[DateString[], 20], {{hours, 0}, Range[25] - 1}, {{minutes, 0}, \n Range[61] - 1}, {{oo, True, \"alarm\"}, {True -> \"ON\", False -> \"OFF\"}}]\n\n\n", "numerical integration - Boosting the performance of expensive NIntegrate by feeding in a cheap approximation of the integrand": "\nWould it be a solution to evaluate $L$ at a set of points $x_i$ and morph $G$ with a function $G_m$ in such a way that $G_m[x]G[x]=L[x]$ for those points? That is, with $G_m[x]$ defined as the interpolated function through the set of points ${x_i,L[x_i]/G[x_i]}$. \nFor example, let your two functions be:\nl[x_] := PDF[GammaDistribution[5, 2], x]\ng[x_] := PDF[NormalDistribution[8, (3 E^4)/(16 Sqrt[2 \\[Pi]])], x]\n\nThey share the same maximum, and are somewhat similar but not closely:\nPlot[{l[x], g[x]}, {x, 1, 20}, Frame -> True, Axes -> False]\n\n\nThen with:\ngm = Interpolation[Table[l[x]/g[x], {x, 1, 21}]];\n\nthe plots are much more similar:\nPlot[{l[x], gm[x] g[x]}, {x, 1, 20}, Frame -> True, Axes -> False]\n\n \nNIntegrate[l[x], {x, 1, 20}]\n\n(*\n==> 0.9705751963\n*)\n\nNIntegrate[g[x], {x, 1, 20}]\n\n(*\n==> 0.9550846595\n*)\n\nNIntegrate[gm[x] g[x], {x, 1, 20}]\n\n(*\n==> 0.9703985212\n*)\n\nIn this case, the result of integrating the morphed 'el cheapo' function is within 0.02% of the value of the 'expensive' function. Of course, for this to work the functions should be sufficiently smooth and G should never get too close  to zero.\nThe set $x_i$ could be obtained with the EvaluationMonitor option in the integration of $G$:\n Last@ Reap[\n   NIntegrate[g[x], {x, 1, 20}, EvaluationMonitor :> Sow[x]]]\n\n    (*\n    ==> {{1.151189079, 1.891291464, 3.335416098, 5.384541554, 7.843511075, \n  10.5, 13.15648893, 15.61545845, 17.6645839, 19.10870854, \n  19.84881092, 1.07559454, 1.445645732, 2.167708049, 3.192270777, \n  4.421755537, 5.75, 7.078244463, 8.307729223, 9.332291951, \n  10.05435427, 10.42440546, 10.57559454, 10.94564573, 11.66770805, \n  12.69227078, 13.92175554, 15.25, 16.57824446, 17.80772922, \n  18.83229195, 19.55435427, 19.92440546}}\n    *)\n\nThis set is for one reason or another a meaningful set and could be used as anchorpoints for the interpolating function.\n\nActually, now that I come to think about it a bit more, this may not be so useful in many cases as the number of evaluations of the expensive function may not be drastically reduced. We need to evaluate the sample points and this set may be as large as the set NIntegrate might need.  So, this saves time only if we can reduce the number of points used in the interpolation function. But if we could halve that set this would save a factor $2^n$ for $n$-dimensional functions. \n", "list manipulation - n-fold symbolic integral in Mathematica": "\nUse Sequence to paste in the range in Integrate :\nRemove[intCube]\nintCube[n_, a_] := \nModule[{xvars, range, expression}, \n    xvars = Table[Symbol[\"x\" <> ToString[i]], {i, 1, n}];\n    range = Table[{xvars[[i]], 0, a}, {i, 1, n}];\n    (* range=Row[Riffle[range,\",\"]]; *)\n    Print[range];\n    expression = Product[xvars[[i]], {i, 1, n}]; Print[expression]; \n    Integrate[expression, Sequence @@ range]\n];\n\n{{x1,0,a},{x2,0,a}}\n\nx1 x2\n\na^4/4\n\n", "replacement - Fill out blanks with a upcoming number in a list?": "\nYou could do something like this\nlist = Append[RandomReal[5, 30] /. a_ /; a < 2 :> \"\", 1.]\n\n\n{3.82088, \"\", 2.17919, 2.38081, \"\", \"\", 4.54655, \"\", \"\", 3.97074, \"\",\n 3.72551, 4.75268, \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", 2.74955, \"\", \"\",\n 4.98933, 2.40911, 3.72805, \"\", 4.50331, 4.75458, 1.}\n\n\nReverse[FoldList[#2 /. {\"\" -> #1} &, Last[list], Reverse[Most[list]]]]\n\n\n{3.82088, 2.17919, 2.17919, 2.38081, 4.54655, 4.54655, 4.54655,\n 3.97074, 3.97074, 3.97074, 3.72551, 3.72551, 4.75268, 2.74955,\n 2.74955, 2.74955, 2.74955, 2.74955, 2.74955, 2.74955, 2.74955,\n 2.74955, 4.98933, 4.98933, 4.98933, 2.40911, 3.72805, 4.50331,\n 4.50331, 4.75458, 1.}\n\n\n", "plotting - Plot does not plot over the specified range": "\nI'm assuming you want to use the same PlotRange for cell (2,2) as for the other cells.\nYou can change the order: show Plot before ListPlot.  Note that Plot will now set the PlotRange; as I understand it, the first function called by Show controls the graphics settings (if there should be a conflict).\nShow[Plot[cumulativeGauss[x, fit2[[1]], fit2[[2]]], {x, 0, 30},  \n           PlotRange -> {{0, 30}, {0, 1}}],\n     ListPlot[data2]\n    ]\n\nThe following questions remain: \n\n\"Why isn't the full plot range displayed when ListPlot comes before Plot?\n\"Why can't you specify the PlotRange in Show as follows?\"\nShow[Plot[cumulativeGauss[x, fit2[[1]], fit2[[2]]], {x, 0, 30}],\n      ListPlot[data2], PlotRange -> {{0, 30}, {0, 1}}]\n According to the documentation, this latter approach should work  (but it does not):\n\n\nEither of these result in the following:\n\n\nEdit\nYou can display the data points beneath the model using. Note, however that the points will lie beneath the axes.\nPlot[cumulativeGauss[x, fit2[[1]], fit2[[2]]], {x, 0, 30},  \n     PlotRange -> {{0, 30}, {0, 1}},\n     PlotRangePadding -> {{.3, 3}, {0.1, 0}},\n     Prolog -> {Red, PointSize[Large], Point[data2]}]\n\n\n", "Crating Lists From Loops - Mathmatica Stack Exchang": "\nGenerally, the solution to this kind of problems is using Table:\nTable[Count[col7, i], {i, 100}]\n\nHowever, in this case I suggest Tally or BinCounts:\nTally[col7]\n\nBinCounts[col7, {0, 100, 1}]\n\nTally will not list elements that don't appear at all.\n", "plotting - Styling ticks in a plot": "\nThis works, but it does require some manual tweaking \nHistogram[data, BarOrigin -> Left, Axes -> False, \n Frame -> {{True, None}, {True, None}}, \n FrameTicks -> {{Transpose[{a, \n      Row[{#, Pane[\"\", {10, Automatic}]}] & /@ a, \n      Table[{-0.02, 0}, {i, Length[a]}]}], \n    None}, {Transpose[{b, \n      Pane[#, {Automatic, 20}, Alignment -> {Center, Bottom}] & /@ b, \n      Table[{-0.02, 0}, {i, b}]}], None}}]\n\n\n", "front end - Prevent text from wrapping in a notebook": "\n\nYou can also set option PageWidth -> Infinity for the Cell or Notebook, e.g.:\nSetOptions[EvaluationNotebook[], PageWidth -> Infinity]\n\n", "front end - Collapse a section of a huge function": "\nThe Mathematica Front End does not have this feature.  Wolfram Workbench does though.\nHowever, it is possible to collapse cell groups in notebooks by double clicking their brackets.  This is useful.\nFor navigating functions, the Ctrl+. key combination (extend selection) is extremely useful.\n", "graphics - Is there an option to plot the Z axis reversed (as shown in the figure)?": "\nMathematica graphics is interactive. Just drag & rotate the plot with mouse till you flip it up side down. You also can do this programmatically:\nPlot3D[Sin[x y]^2, {x, -2, 2}, {y, -2, 2}, ViewPoint -> {-1, -2.5, -1}, \nViewVertical -> {0, 0, -1}]\n\n\nHere is how I got these options - if you are curious. Produce Mathematica 3D graphics object and play with it by rotating it around. As soon as you like its orientation excute\nOptions[%]\n\nAnd get something like this:\nOut[2] = {Axes -> True, BoxRatios -> {1, 1, 0.4},  Method -> \n{\"RotationControl\" -> \"Globe\"}, PlotRange -> {{-2, 2}, {-2, 2}, {0., 1.}}, \nPlotRangePadding -> {Scaled[0.02], Scaled[0.02], Scaled[0.02]},  \nViewPoint -> {-1, -2.5, -1}, ViewVertical -> {0, 0, -1}}\n\nOptions ViewPoint and ViewVertical will be most important for your particular case. You can use them now in your code to avoid the need to adjust graphics interactively every time.\nNOTE (thanks to @Heike comment below):\nIn some cases if Options[%] does not work you may try this:\n\nwhich will produce the set of options I showed above.\n", "plotting - How can I make an X-Y scatter plot with histograms next to the X-Y axes?": "\nHere's my solution, which constructs the three components and uses Inset to combine them into a single graphic.  I've taken some care so that:\n\nthe coordinate systems should line up across the plots (check the gridlines)\nas many graphics and plotting options are respected without breaking the layout\nthe graphic can be reasonable resized\n\n\ncustomPlot[data_, o___] := \n Block[{xmin, xmax, ymin, ymax, x, y, mainplot, xhist, yhist, \n   opts = Flatten[{o}]},\n  {x, y} = Transpose[data];\n  xhist = HistogramList[x, 50];\n  yhist = HistogramList[y, 50];\n  {xmin, xmax} = Through[{Min, Max}[First[xhist]]];\n  {ymin, ymax} = Through[{Min, Max}[First[yhist]]];\n  mainplot = \n   ListPlot[data, Frame -> {{False, True}, {False, True}}, \n    Axes -> False, FrameTicks -> None, AspectRatio -> 1, \n    PlotRange -> {{xmin, xmax}, {ymin, ymax}}, \n    PlotRangePadding -> Scaled[0.02], ImagePadding -> {{None, 1}, {None, 1}},\n    FilterRules[opts, Options[ListPlot]], \n    FrameStyle -> GrayLevel[0.3], GridLines -> Automatic, \n    GridLinesStyle -> Directive[Gray, Dotted]];\n  xhist = \n   Histogram[x, {First[xhist]}, \n    Frame -> {{True, True}, {True, False}},\n    FrameTicks -> {{None, None}, {Automatic, None}}, Axes -> False, \n    AspectRatio -> 1/3, ImagePadding -> {{1, 1}, {None, All}},\n    FilterRules[opts, Options[Histogram]], \n    GridLines -> {Automatic, None}, FrameStyle -> GrayLevel[0.3], \n    GridLinesStyle -> Directive[Gray, Dotted]];\n  yhist = \n   Histogram[y, {First[yhist]}, \n    Frame -> {{True, False}, {True, True}}, Axes -> False, \n    FrameTicks -> {{Automatic, None}, {None, None}}, AspectRatio -> 3,\n    BarOrigin -> Left, ImagePadding -> {{All, None}, {1, 1}},\n    FilterRules[opts, Options[Histogram]], \n    GridLines -> {None, Automatic}, FrameStyle -> GrayLevel[0.3], \n    GridLinesStyle -> Directive[Gray, Dotted]];\n  Graphics[{{Opacity[0], Point[{{360, 360}, {-120, -120}}]},\n    Inset[mainplot, {0, 0}, {Left, Bottom}, {360, 360}],\n    Inset[xhist, {0, 0}, {Left, Top}, {360, Automatic}],\n    Inset[yhist, {0, 0}, {Right, Bottom}, {Automatic, 360}]},\n   PlotRange -> {{-120, 360}, {-120, 360}}, \n   FilterRules[opts, Options[Graphics]], \n   ImagePadding -> {{30, 1}, {30, 1}}]\n  ]\n\nNow to create some data and try it out:\nd = RandomVariate[BinormalDistribution[{0, 0}, {1, 2}, 0.4], 100];\n\ncustomPlot[d]\n\n\n\n\ncustomPlot[d, \n   PlotStyle -> Directive[PointSize[Large], Orange], \n   ChartStyle -> Orange, ChartElementFunction -> \"FadingRectangle\", \n   FrameStyle -> White, Background -> Black]\n\n\n\n\n", "import - Organizing similar datasets using Contexts or otherwise": "\nI think, using contexts here is a sensible suggestion, particularly because you want to use several variables. One possible alternative is to set up a struct-like data structure, where encapsulation mechanism is based on Module-generated persistent variables. There were many discussions related to emulation of structs in Mathematica, but, given the encapsulation aspect, I will refer you to this answer. Contexts do have an advantage that the symbols encapsulated with them can be easily serialized (e.g. with Save or DumpSave), but a disadvantage that it is not clear how to construct these long variable names automatically without using strings (should you wish to automate things).\nIn any case, the reason that your function does not work is because the parsing is done first, before any code executes, and all your symbols are already created in the current (most likely Global`) context, so these are used also inside Begin and End. While I don't see how you can avoid creation of such symbols  (except explicit use of Remove, or if you use your code in a string form), here is a work-around to create the symbols you need in a proper context:\nClearAll[contextWrap];\nSetAttributes[contextWrap, HoldFirst];\ncontextWrap[code_, context_String] :=\n   With[{boxed = MakeBoxes[code]},\n     Block[{$ContextPath},\n       BeginPackage[context];\n         Quiet@ReleaseHold@MakeExpression@boxed;\n       EndPackage[];\n     ]\n  ]; \n\nBasically, this converts the code into the boxed form, and delays its parsing until runtime. I used similar technique in this answer. Here is an example:\ncontextWrap[a = 1; b = 2; c = 3, \"MyContext`\"]\n\nMyContext`a\n\n(* \n   1\n*)\n\nThere is no shadowing here because the context MyContext` was not kept on the $ContextPath. So,  in your case, you'd need something like\ncontextWrap[\n   dataRaw=Import[cityName~~\".csv\"];\n   data=Differences[dataRaw];\n   dataMax=Max[dataRaw];,\n   ToLowerCase[cityName]~~\"`\"\n]\n\nIf you absolutely want to avoid the side effect of creation of new symbols in the current context, I can refer you to the hack based on $PreRead, which I posted in this MathGroup thread.\n", "plotting - Can I make a plot with gradient filling?": "\nHow about this?\nbankerPlot[data_] := ListLinePlot[\n  data,\n  AxesOrigin -> {0, 0},\n  Prolog -> Polygon[Join[data, Reverse[data.DiagonalMatrix[{1, 0}]]],\n    VertexColors -> Join[\n      Blend[{Black, Blue}, #] & /@ Normalize[data[[All, 2]], Max],\n      ConstantArray[Black, Length[data]]\n      ]\n    ],\n  PlotStyle -> White,\n  Background -> Black,\n  AxesStyle -> White\n  ]\n\nbankerData = Transpose[{Range[100], Accumulate[RandomReal[{-1, 1}, 100]] + 10}];\nbankerPlot[bankerData]\n\n\n", "equation solving - Backsubstituting solution into FindRoot": "\nYou can use FoldList or NestList to use the solution of a step as the starting value for the next step. Please check the documentation on these two functions for detailed examples of how they are used.  \n  FoldList[FindRoot[{#2 x == 1, y x == #2/2},{{x, #1[[1, 2]]}, {y, #1[[2, 2]]}}] &,\n  {x -> 0.5, y -> 0.5}, Range@10]\n\nIt gives:\n\n{{x -> 0.5, y -> 0.5}, {x -> 1., y -> 0.5}, {x -> 0.5, y -> 2.}, \n  {x -> 0.333333, y -> 4.5}, {x -> 0.25, y -> 8.}, {x -> 0.2, y -> 12.5}, \n  {x -> 0.166667, y -> 18.}, {x -> 0.142857, y -> 24.5}, \n  {x -> 0.125, y -> 32.}, {x -> 0.111111, y -> 40.5}, {x -> 0.1, y -> 50.}}\n\n\nNestList is a little more complicated:\n  NestList[\n  {#[[1]] + 1, FindRoot[{(#[[1]] + 1)  x == 1, y x == (#[[1]] + 1)/2}, \n  {{x, #[[2, 1, 2]]}, {y, #[[2, 2, 2]]}}]} &, \n  {0, {x -> 0.5, y -> 0.5}}, 10]\n\nwhich produces\n\n {{0, {x -> 0.5, y -> 0.5}}, {1, {x -> 1., y -> 0.5}}, {2, {x -> 0.5,y -> 2.}}, \n   {3, {x -> 0.333333, y -> 4.5}}, {4, {x -> 0.25, y -> 8.}}, \n   {5, {x -> 0.2, y -> 12.5}}, {6, {x -> 0.166667, y -> 18.}}, \n   {7, {x -> 0.142857, y -> 24.5}}, {8, {x -> 0.125, y -> 32.}}, \n   {9, {x -> 0.111111, y -> 40.5}}, {10, {x -> 0.1, y -> 50.}}}\n\n\nYou can get the second parts of the rows by adding the following code at the end:\n  NestList[...] // Last /@ # &\n\n", "graphics - How can the {x,y,z} points that fall on the outer boundary of a set of values be selected and smoothly surfaced?": "\nNot sure about the creation of a \"smooth\" surface. But from Mma help, you may create a convex hull in 3D by using TetGenConvexHull\nNeeds[\"TetGenLink`\"]\ndata3D = RandomReal[{0, 1}, {100, 3}];\nGraphics3D[Point[data3D]];\nsurface = TetGenConvexHull[data3D];\n(* TetGenConvexHull was changed sometime between 8.0.0 and 8.0.4.\n   Uncomment the following line only if you are using 8.0.4. *)\n(* surface = Last[surface] *)\nGraphics3D[GraphicsComplex[data3D, Polygon[surface]]]\n\n\nHTH ... I am not really sure ...\nTo get the points in the convex hull, you could use for example:\n  pointss = data3D[[Union@Flatten@surface]]\n\n", "front end - Make the selection become the button you click": "\nTry:\nButton[\"Select this cell\", SelectionMove[ButtonNotebook[], All, EvaluationCell]]\n\n", "front end - SubTitle and SubSubTitle do not group by default": "\nIn the course of researching this question, I discovered an answer.\nLooking at the Option Inspector -> Cell Options -> General Properties for each of the cells shown above, reveals the option: CellGroupingRules. Unfortunately, there is little in terms of documentation for this option.\nUpon inspection, CellGroupingRules has the value of {\"TitleGrouping\", 0}, {\"TitleGrouping\", 10}, and {\"TitleGrouping\", 20} for the three title cells, respectively, in order of appearance. The Section cells, down to the SubSubSection have CellGroupingRules = {\"SectionGrouping\", x} where x goes from 30 to 50 as you descend the hierarchy. So, obviously, the number indicates the level in the hierarchy. A Text cell (7th in the hierarchy) has CellGroupingRules = \"NormalGrouping\". \nChanging CellGroupingRules on SubSubTitle to {\"SectionGrouping\", 20} appears to do the trick. For whatever reason, \"TitleGrouping\" implies that sub-titles are not to be included in the grouping.\n", "Palette with editable InputField": "\nThe following code should fix the problem:\nCreatePalette[Pane[InputField[\"Enter a string\"]], WindowFloating -> False,\nWindowClickSelect -> True];\n\nBut as we figured out it is not!\nI read all available information about WindowClickSelect and WindowFloating options in Mathematica documentation. \nI didn't find any notices that we can't use the options simultaneously. \nI also didn't find any cautions that we can't use the options with Mathematica palettes.\nThus, such unexpected behavior is probably a bug in Mathematica.\nI advice to contact Wolfram support team regarding this bug.\n", "packages - Function to compute the probability of exactly one event occurring out of N independent events": "\nPr[independentProbabilities__] := \n Block[{x, len = Length[{independentProbabilities}]},\n  Probability[Sum[x[i], {i, len}] == 1, \n   Thread[x /@ Range[len] \\[Distributed] \n     BernoulliDistribution /@ {independentProbabilities}]]\n  ]\n\nSo\nIn[19]:= Pr[0.1, 0.22, 0.17, 0.28]\n\nOut[19]= 0.414007\n\nOr, doing the math\nPrV2[independentProbabilities__] := \n Total[Times @@@ ((1 - \n       ConstantArray[{independentProbabilities}, \n        Length[{independentProbabilities}]]) + \n     DiagonalMatrix[2 {independentProbabilities} - 1])]\n\n", "plotting - How to show values of points on surface plotted with ContourPlot3D": "\nThe location that the mouse is pointing to on a 3D surface can be found by starting with MousePosition[\"Graphics3DBoxIntercepts\"].  This will give you the two points where the line perpendicular to the screen at the mouse pointer intersects the three-dimensional bounding box.\nWe can calculate the intersection of this line with the surface to find a point.  Here is a simple implementation to track that point dynamically:\nfun defines the surface:\nfun[{x_, y_, z_}] := x^3 + y^2 - z^2\n\nLet's plot it:\nplot = ContourPlot3D[\n   fun[{x, y, z}] == 0, {x, -2, 2}, {y, -2, 2}, {z, -2, 2}]\n\nNow let's try to find the intersection of the mouse pointer with the surface using FindRoot.  There might be several intersections, so I specified the box intersection point closer to the viewer as a starting point for FindRoot (t == 0 in the code).  This does not guarantee that the closest (i.e. visible) point will be found, but it makes it more likely.\nShow[plot,\n Graphics3D[{\n   Red,\n   Dynamic@Quiet@Check[\n      Sphere[#, Scaled[0.01]]& @ Module[{p1, p2, t},\n        {p1, p2} = MousePosition[{\"Graphics3DBoxIntercepts\", Graphics3D}];\n        (p2 - p1) t + p1 /. FindRoot[fun[(p2 - p1) t + p1], {t, 0, 0, 1}]\n        ],\n      {}]}]\n ]\n\n\nNow that we have the point on the surface, you can do with it whatever you want (calculate another functions, etc.)  You can use EventHandler to just record clicks instead of tracking values dynamically.\n\nTo address your other question about how to get a number of points on the surface.  One way is to use FindInstance.\nFindInstance[\n fun[{x, y, z}] == 0 && Thread[-2 < And[x, y, z] < 2, And], {x, y, \n  z}, Reals, 10]\n\nThis will give you 10 points that are precisely on the surface (this uses exact calculations).  Let's show them:\nShow[plot, Graphics3D[{Red, Sphere[{x, y, z}, Scaled[0.01]] /. %}]]\n\nTo get the points generated by ContourPlot3D, extract them from the GraphicsComplex object is creates.  These coordinates will not be quite as precise as they are meant for visualization only.\nFirst@Cases[plot, GraphicsComplex[points_, ___] :> points, Infinity]\n\nLet's show those points:\nGraphics3D@Point[%]\n\n\n", "number theory - Do we really know the reliability of PrimeQ[n] (for $n>10^{16}$)?": "\nI and a number of others have proved that there are no BPSW-pseudoprimes below $2^{64}$. This builds on the work of Jan Feitsma around 2009. In particular this means that, barring programming errors, PrimeQ is correct for all values below $1.844\\cdot10^{19}.$\n", "variable definitions - Why can't I define vector v as having subscripted elements v_1, v_2, v_3...?": "\nYou could also use something like OverVector, since \nOverVector[v] = {Subscript[v,1],Subscript[v,2],Subscript[v,3]}\n\nisn't recursive, and so won't cause problems. \nThis takes a bit more effort to input\n\nType Ctrl+& and then Esc vec Esc to enter directly\n\nbut if you're interested in the typeset forms it might be worth it.\n", "plotting - ParametricPlot3D creates a blank graphic in this case": "\nYou are dividing by zero at a point where there is a singularity anyway.\nMathematica handles this in the 2D case:\nParametricPlot[{v Cosh[u/v], u}, {u, -1, 1}, {v, -1, 1}]\n\n\nYou can get the graphic you are looking for by breaking up the plot into pieces, avoiding the zone near $v=0$. ParametricPlot3D allows you to show multiple objects in the same plot pretty simply.\nParametricPlot3D[{{v Cosh[u/v], v Cosh[u/v], u},\n {-v Cosh[u/-v], -v Cosh[u/-v], u}}, {u, -1, 1}, {v, 0.1, 1}, \n Mesh -> None]\n\n\nAdapting b.gatessucks's suggestion of using Exclusions, I have found that you also need to specify PlotRange and PlotPoints to get a sensible graphic.\nParametricPlot3D[{v Cosh[u/v],  v Cosh[u/v], u}, {u, -1, 1}, {v, -1, 1},\n Mesh -> None, Exclusions -> {0, 0}, \n PlotRange -> {{-4, 4}, {-4, 4}, {-1, 1}}, PlotPoints -> 100]\n\n\n", "shortcut key for traverse command history in a Mathematica session in a terminal?": "\nI use the command line kernel quite often and use it in conjunction with rlwrap. This allows for history, command line completion, and command line editing. A convenient addition - all one would desire.\n", "import - Organizing similar datasets using DownValues instead of Contexts": "\nSince no other answer has been posted yet I'll give my opinion.\nUsing DownValues, which I believe is a hash table of sorts, is the normal and accepted way to store this kind of information in Mathematica, to the best of my knowledge.  I cannot think of any real disadvantages compared to direct symbol assignment.\nEither form (direct assignment or DownValues) may take up considerably more memory than storing the information in large array, packed or sparse if possible.  The nature of the data and how it is accessed best determine which method to use.\nThe other option you should be aware of is to use replacement rules.  When optimized using Dispatch this will be similar to DownValues in many ways, but it allows different usages and has strengths that can make it superior in some applications.\ndata = Dispatch @ {\"Madrid\" -> 7, \"Paris\" -> 2, \"Porto\" -> 4, \"Perth\" -> 1};\n\n{\"Madrid\", \"Paris\"} /. data\n\n\n{7, 2}\n\n\n\nBy the way you can write importCity like this:\nimportCity[cityName_String] :=\n  With[{raw = Import[cityName ~~ \".csv\"]},\n    dataRaw[cityName] = raw;\n    data[cityName]    = Differences @ raw;\n    dataMax[cityName] = Max @ raw;\n  ]\n\n", "cdf format - CDF and MediaWiki": "\nI am the author of the comp.soft-sys.math.mathematica message linked by Szabolcs, wherein I briefly mentioned a CDF extension for MediaWiki I have developed. In the few days since I sent that message, I have improved the extension so that meets MediaWiki's best practice guidelines for extensions, and added new features: it can show CDF files uploaded to a wiki in wiki pages using a simple syntax, it can optionally show CDF files from other servers, and you can configure it to show a 'download' link beneath each CDF so that users may view the file offline if they want.\nFull documentation for the extension, including installation instructions and examples, is given on the extension's page on mediawiki.org at http://www.mediawiki.org/wiki/Extension:WolframCDF but a brief summary of the page follows.\n[edit]Note that this extension will only work with MediaWiki 1.17 or later. Earlier versions of MediaWiki do not include the Resource Loader system this relies on.[/edit]\nTo install the extension, download a zip archive of the latest version, unpack it and place the wolfram_cdf directory in your mediawiki extensions directory. Add the following to your wiki's LocalSettings.php file:\nrequire_once(\"$IP/extensions/wolfram_cdf/CDF.php\");\nYou will also need to ensure that file uploads are enabled, and .cdf file extensions are allowed, to do this your LocalSettings.php will need to include code like:\n$wgEnableUploads  = true;\n$wgUseImageMagick = true;\n$wgFileExtensions = array( 'png', 'gif', 'jpg', 'jpeg', 'txt', 'cdf' );\nYou may also need to either ensure that your webserver serves up .cdf files with the mime type application/x-netcdf or, if that is not possible, you may need to modify your wiki's includes/mime.types to contain\ntext/plain txt cdf\notherwise uploading CDF files may fail. Once the extension is installed, you can show CDF files in wiki pages by following these steps:\n\nupload your CDF file to the wiki\nplace a <cdf width=\"width in pixels\" height=\"height in pixels\">filename</cdf> tag in the page where you want the CDF file to appear.\n\nFor example, if you upload a 500x600 pixel CDF file called \"MyDemonstration.cdf\" to the wiki, you can show it in a page using\nMyDemonstration.cdf\nMore configuration options and examples are provided on the MediaWiki.org page linked above.\n", "front end - Is it possible to insert an animated image into Mathematica notebook?": "\nThe credits go to belisarius and the Mathematica help (ref/format/GIF), but I thought the comment would be worth an answer.\nImport[\"ExampleData/cellularautomaton.gif\", \"Animation\"]\n\n\n\n\n", "plotting - subscripts in plot axis labels": "\nThere is a subtle problem if you use strings as axis labels. Look closely at a plot like this:\nPlot[f, {x, -1, 1}, AxesLabel -> {x, \"\\!\\(\\*SubscriptBox[\\(f\\), \\(i\\)]\\)(x)\"}]\n\nYou will see that the argument x in the function appears in a different font style than the argument on the horizontal axis. \nTo make sure that you get a consistent font style on both axes using the default styling for graphics, you should use the following:\nPlot[f, {x, -1, 1}, AxesLabel -> {x, HoldForm[Subscript[f, i][x]]}]\n\nOf course, to enter the Subscript expression in your label, you can still use the keyboard shortcuts that are mentioned by @Szabolcs.\nThe argument in HoldForm is your vertical label, typed in actual Mathematica syntax with square brackets for the function argument. I didn't surround the horizontal label in HoldForm, but you could do that for safety, in particular if your variable x has been assigned a value somewhere else in the Notebook.\n", "list manipulation - Partition a set into subsets of size $k$": "\nTry with\npartitions[list_, l_] := Join @@\n  Table[\n    {x, ##} & @@@ partitions[list ~Complement~ x, l],\n    {x, Subsets[list, {l}, Binomial[Length[list] - 1, l - 1]]}\n  ]\n\npartitions[list_, l_] /; Length[list] === l := {{list}}\n\nThe list must have a length multiple of l\n", "graphics - Extruding along a path": "\nIn Mathematica 7 or 8, you can just use Tube.  Please see the docs for many, many examples.\nExample:\nShow[ParametricPlot3D[{Cos[x], Sin[x], x/5}, {x, 0, 15}] /. \n  Line -> (Tube[#, 0.2] &), PlotRange -> All]\n\n\n", "plotting - How can I make a 2D line plot with a drop shadow under the line?": "\nThis solution creates copies of the original curve that use coordinates shifted by Offset to have the shadow behave the same regardless of the scale of the coordinates.  It uses multiple copies of the original, in varying thicknesses, opacities, and offsets.  It also uses JoinForm[\"Round\"] to avoid sharp corners in the shadow.\noffset[p_, o_] := Offset[o, #] & /@ p\n\noffsetPrims[prims_, o_] := \n prims /. {\n    GraphicsComplex[p_, r__] :> GraphicsComplex[offset[p, o], r], \n    Line[p_, r___] :> Line[offset[p, o], r]\n    }\n\nshadow[prims_] := \n   With[{bare = DeleteCases[prims, _Hue | _RGBColor, Infinity]}, \n      {Black, JoinForm[\"Round\"], \n         {AbsoluteThickness[5], Opacity[0.05], offsetPrims[bare, {3, -3}]}, \n         {AbsoluteThickness[4], Opacity[0.1], offsetPrims[bare, {2, -2}]},     \n         {AbsoluteThickness[3], Opacity[0.1], offsetPrims[bare, {1, -1}]}}\n      ]\n\nDropShadow[g_Graphics] := Graphics[{shadow[First[g]], First[g]}, Options[g]]\n\nDropShadow[\n   DateListPlot[\n      {FinancialData[\"GOOG\", \"Close\", {{2009, 5, 1}, {2010, 4, 30}}], \n       FinancialData[\"AAPL\", \"Close\", {{2009, 5, 1}, {2010, 4, 30}}]}, \n      Joined -> True]]\n\n\n\n\nThis could be extended to work with points and polygons as well.\n", "graphics - Forcing a graph not to resize": "\nAssuming that timecoeff is scaled between 0 and 1 you could do something like this (I just made something up for timecoeff and hamiltMol): \nClear[ighamiltMol, t]; t = 0;\ntimeCoeff[i_] := (1 + Sin[t + 2.5 i])/2\nhamiltMol = NestList[RotateRight, {0, 1, 0, 0, 0, 1}, 5];\n\nighamiltMol = \n Dynamic@AdjacencyGraph[hamiltMol,(*hamiltMol is a symmetric sparse/\n   adjacency matrix*)\n   EdgeShapeFunction -> (Line[#1] &),\n   VertexLabels -> Placed[\"Name\", Tooltip], \n   GraphStyle -> \"SpringEmbedding\", \n   VertexShapeFunction -> ({{Opacity[0], Disk[#1, #3]},\n       Disk[#1, #3 timeCoeff[#2] ]} &),\n   VertexSize -> \n    4/3];(*timeCoeff[] looks in a list of complex \\\nexponentials*)Animator[Dynamic[t], {0, 2 Pi}, .1]\nighamiltMol\n\n\nThis works by using a VertexShapeFunction which consists of two disks on top of each other, namely a transparent one with a fixed radius, and a solid one with a varying radius. The option VertexSize -> 4/3 makes sure that the maximum radius is equal to 2/3 time the mimimum length of all vertices.\n", "list manipulation - Elegant operations on matrix rows and columns": "\nI like to use Part even when I don't want to modify the original matrix.  This of course requires making a copy but it keeps syntax more consistent.\nadding column one to column three:\nm = Range@12 ~Partition~ 3;\nm // MatrixForm\n\n$\\left(\n\\begin{array}{ccc}\n 1 & 2 & 3 \\\\\n 4 & 5 & 6 \\\\\n 7 & 8 & 9 \\\\\n 10 & 11 & 12\n\\end{array}\n\\right)$\nm2 = m;\n\nm2[[All, 3]] += m2[[All, 1]];\n\nm2 // MatrixForm\n\n$\\left(\n\\begin{array}{ccc}\n 1 & 2 & 4 \\\\\n 4 & 5 & 10 \\\\\n 7 & 8 & 16 \\\\\n 10 & 11 & 22\n\\end{array}\n\\right)$\nWith an external vector:\nv = {-1, -2, -3, -4};\n\nm2 = m;\n\nm2[[All, 3]] += v;\n\nm2 // MatrixForm\n\n$\\left(\n\\begin{array}{ccc}\n 1 & 2 & 2 \\\\\n 4 & 5 & 4 \\\\\n 7 & 8 & 6 \\\\\n 10 & 11 & 8\n\\end{array}\n\\right)$\nswapping rows and columns:\nm2 = m;\n\nm2[[{1, 3}]] = m2[[{3, 1}]];\n\nm2 // MatrixForm\n\n$\\left(\n\\begin{array}{ccc}\n 7 & 8 & 9 \\\\\n 4 & 5 & 6 \\\\\n 1 & 2 & 3 \\\\\n 10 & 11 & 12\n\\end{array}\n\\right)$\nm2 = m;\n\nm2[[All, {1, 3}]] = m2[[All, {3, 1}]];\n\nm2 // MatrixForm\n\n$\\left(\n\\begin{array}{ccc}\n 3 & 2 & 1 \\\\\n 6 & 5 & 4 \\\\\n 9 & 8 & 7 \\\\\n 12 & 11 & 10\n\\end{array}\n\\right)$\n\nSimultaneous row-and-column operations\nPart is capable of working with rows and columns simultaneously(1).\nWe can operate on (or replace) a contiguous sub-array:\nm2 = m;\n\nm2[[3 ;;, 2 ;;]] /= 5;\n\nm2 // MatrixForm\n\n$\\left(\n\\begin{array}{ccc}\n 1 & 2 & 3 \\\\\n 4 & 5 & 6 \\\\\n 7 & \\frac{8}{5} & \\frac{9}{5} \\\\\n 10 & \\frac{11}{5} & \\frac{12}{5} \\\\\n\\end{array}\n\\right)$\nOr a disjoint specification:\nm2 = m;\n\nm2[[{1, 2, 4}, {1, 3}]] = 0;\n\nm2 // MatrixForm\n\n$\\left(\n\\begin{array}{ccc}\n 0 & 2 & 0 \\\\\n 0 & 5 & 0 \\\\\n 7 & 8 & 9 \\\\\n 0 & 11 & 0 \\\\\n\\end{array}\n\\right)$\nOr construct a new array from constituent parts in arbitrary order:\nmx = BoxMatrix[2] - 1;\n\nmx[[{1, 2, 5, 4}, {4, 5, 1}]] = m;\n\nmx // MatrixForm\n\n$\\left(\n\\begin{array}{ccccc}\n 3 & 0 & 0 & 1 & 2 \\\\\n 6 & 0 & 0 & 4 & 5 \\\\\n 0 & 0 & 0 & 0 & 0 \\\\\n 12 & 0 & 0 & 10 & 11 \\\\\n 9 & 0 & 0 & 7 & 8 \\\\\n\\end{array}\n\\right)$\n", "From a list to a list of rules": "\nAnother way:\nThread[var -> #] & /@ values\n\n", "performance tuning - Split a string at specific positions": "\nHere is a faster version of Istv\u00e1n's function:\nsplit[s_String] :=\n  StringReplace[s, {\n    StartOfString ~~ l : LetterCharacter .. :> l,\n    l : LetterCharacter .. ~~ EndOfString   :> l,\n    l : LetterCharacter .. :>\n          StringInsert[l, \" \", 1 + Quotient[StringLength@l, 2] ],\n    d : Repeated[DigitCharacter, {2, \u221e}] :>\n          StringJoin @ Riffle[Characters@d, \" \"]\n  }] // StringSplit\n\nTimings:\nstr = StringJoin @@ (RandomInteger[{0, 1}, {500000}] /. {0 -> \"0\", 1 -> \"x\"});\n\nFirst@AbsoluteTiming[istvan = splitIstvan@str;]\nFirst@AbsoluteTiming[mrwizard = split@str;]\nistvan === mrwizard\n\n\n0.7710441\n\n0.4260243\n\nTrue\n\n\n", "Copying an image from the clipboard, modifying it and returning it to the clipboard": "\nHere are two functions that'll do what you need.\nputClipboardImage[img_Image] := Module[{nb},\n  nb = CreateDocument[{}, Visible -> False, WindowSelected -> False];\n  NotebookWrite[nb, \n   Cell[BoxData@ToBoxes@Image[img, Magnification -> 1]]];\n  SelectionMove[nb, All, CellContents];\n  FrontEndTokenExecute[nb, \"CopySpecial\", \"MGF\"];\n  NotebookClose[nb]\n  ]\n\ngetClipboardImage[] := Module[{tag},\n  Catch[NotebookGet@ClipboardNotebook[] /. \n    r_RasterBox :> \n     Block[{}, \n      Throw[Image[First[r], \"Byte\", ColorSpace -> \"RGB\"], tag] /; \n       True];\n   $Failed, tag]\n  ]\n\nWarning: if the image is very small, this method will pad it with some wide pixels.  It is copying the cell contents, not the image itself.  If the image is small than the cell height, it'll get padded.\nCopying\nThe reason the image can't be pasted to every program when using CopyToClipboard is that it is placed onto the clipboard as a metafile (as well as a Mathematica expression), but not as a bitmap.\nMy function works by writing the image into a new hidden notebook, then invoking the Edit -> Copy As -> Bitmap command programmatically, to ensure that the image is placed on the clipboard as a bitmap.  This works on Windows, but on OS X it's probably necessary to change MGF to something else, as the same command is not available (try PDF).  On Linux this functionality is simply not available.\nPasting\nPasting works by accessing the special object ClipboardNotebook[] and reading its contents.  The unusual looking ReplaceAll - Throw - Catch construct is just a performance optimization to avoid unpacking the array representing the image data.\nI used the same techniques in the image uploader palette.\n", "functions - How to test if optional argument has been given?": "\nWhy not use something like\nf[first_, arg___] := {arg} === {\"ArgValue\"};\n\nFor general tests, you can compare {arg} to {}, to determine whether or not the arg is empty.\n", "front end - How to prevent the welcome screen from showing up after I close my last notebook? (Ubuntu 11.10, MMA 8.0.4.0)": "\nThe screen won't show when you use File | Quit, or you can use the shortcut Ctrl+Q.\nI actually wrote the Wolfram support about this issue, the response said that that window opening is the desired behavior and it's thought to be somewhat of a substitute of not having the \"main bar\" the Windows version has. In that sense, it is not intended that closing all notebooks also shuts down Mathematica (plus kernel). When I told him that it's a bug unless you can disable it, I was told he'll bring the idea up for development at some point. Oh well.\n", "manipulate - How to use button to evaluate a cell": "\nThe first button you don't have to create ;-) It's called the \"Enter\" button and it's already on your keyboard. Press it with the insertion cursor in the following block of code:\nd = Manipulate[Plot[Sin[k x], {x, 0, 2 \\[Pi]}], {k, 1, 10}];\ne = True;\n\nDynamic[If[e, d, \"\"]]\n\n\nThe second button is generated below. Pressing it toggles the Manipulate between an on and off state.\nButton[\"Manipulate On/Off\", e = Not[e]]\n\n\n", "export - How to do http POST in Mathematica?": "\nIn a post about automated image uploading Arnoud Buzing describes an undocumented and unsupported POST method. It looks like this:\n xml = Import[url, \"XML\", \"RequestMethod\" -> \"POST\", \n              \"RequestParameters\" -> {\"key\" -> key, \"image\" -> image}];\n\nNote: at the time of this answer I was using V8. Since the arrival of URLFetch in V9 I believe URLFetch is the preferred method.\n", "list manipulation - Why does MatrixForm affect calculations?": "\nMatrixForm is a wrapper that pretty-prints your matrices. When you do the following:\ncov = {{0.02, -0.01}, {-0.01, 0.04}} // MatrixForm\n\nyou're assigning the prettified matrix to cov (i.e., wrapped inside a MatrixForm). This is not accepted as an input by most functions (perhaps all) that take matrix arguments. What you should be doing to actually assign the raw matrix to cov, yet get a pretty print in the output, is the following:\n(cov = {{0.02, -0.01}, {-0.01, 0.04}}) // MatrixForm\n\nYou can also read more about why this happens due to the different precedences here in Leonid's book.\n\nYou can also avoid having to use MatrixForm every time by setting the default display for matrix outputs to be typeset accordingly. For this, you set the $PrePrint variable in your init.m file as:\n$PrePrint = Replace[# , mat_?MatrixQ :> MatrixForm[mat]] &\n\nYou can also find this in Szabolcs's mathematica tricks. To reset the value of $PrePrint, simply unset it with $PrePrint=.\n", "graphics - How to draw a gene regulatory state space diagram in Mathematica": "\nThis could be useful to get started:\nGraphics[\n GraphicsComplex[\n  Tuples[{0, 1}, {2}], {Thick, Blue, Arrowheads[.1],\n   Arrow[{{2, 1}, {3, 1}, {4, 2}, {4, 3}}, .1]}],\n Axes -> True, AxesOrigin -> -{0.5, 0.5}, \n AxesStyle -> Arrowheads[.05], GridLines -> {{.5, 1.5}, {.5, 1.5}}, \n PlotRange -> {{-.5, 1.5}, {-.5, 1.5}}, Ticks -> {{0, 1}, {0, 1}}, \n AxesLabel -> {\"b\", \"c\"}\n ]\n\n\n", "syntax - Error when using rule as a list index": "\nUsing Trace,\nTrace[x = Range[10]; { i, x[[i]] } /. i -> 5]\n\nwe will see that the error comes from Mathematica trying to evaluate\n{1,2,3,4,5,6,7,8,9,10}[[i]]\n\nAs you pointed out, the error message is harmless in this case.  If you want Mathematica to substitute first, you can use Hold and ReleaseHold:\nx = Range[10];\nReleaseHold[Hold[{i, x[[i]]}] /. i -> 5]\n\nwhich prevents the evaluation of {i, x[[i]]} until the Hold is released.  The output is the same, but now without the error message:\n\n{5,5}\n\n", "front end - Is there a way to have a Tooltip for non-editable raster graphics produced by MakeBoxes?": "\nMy colleague John Fultz suggested the following answer.\nf /: MakeBoxes[dat : f[args_], fmt_] := \n TagBox[ToBoxes[Rasterize@RandomImage[1, {100, 100}]], \n  InterpretTemplate[f[args] &], Editable -> False, Selectable -> True,\n   SelectWithContents -> True, Tooltip -> \"tooltip\"]\n\nAfter a bit of exploring I realized that I should have checked the Options for TagBox all along.\nOptions[TagBox]\n\n==> {AutoDelete -> False, BaseStyle -> {}, \n DefaultBaseStyle -> {}, DefaultTooltipStyle -> \"TooltipLabel\", \n DeleteWithContents -> True, DeletionWarning -> False, \n Editable -> Automatic, SelectWithContents -> False, \n Selectable -> Automatic, StripWrapperBoxes -> False, \n SyntaxForm -> Automatic, TagBoxNote -> None, Tooltip -> None, \n TooltipDelay -> 0., TooltipStyle -> {}}\n\nHopefully someone else finds this useful.\n", "list manipulation - Extracting values from nested rules in JSON data": "\nIt is possible to get rid of all but one ReplaceAll. First, you need to remember that ReplaceAll tests each Rule in order, so to deal with the missing \"badge_counts\" condition, you can simply add that to the list, as follows\n{\"display_name\", \"creation_date\", \"reputation\", \"reputation_change_week\",\n \"is_employee\", \"last_access_date\", \"user_type\", \n \"badge_counts\"} /. Flatten[{ record, \n   \"badge_counts\" -> {\"bronze\" -> 0, \"silver\" -> 0, \"gold\" -> 0} }]\n\nwhere record is one user record. Since, \"badge_counts\" -> {\"bronze\" -> 0, \"silver\" -> 0, \"gold\" -> 0} is listed after the one in the user info, it will only be used if there is no \"badge_counts\" in the user info.  To eliminate the \"badge rules\", I would remove them using ReplaceRepeated (//.) and one more replacement rule and a final Flatten:\n{\"display_name\", \"creation_date\", \"reputation\", \"reputation_change_week\",\n \"is_employee\", \"last_access_date\", \"user_type\", \n \"badge_counts\"} //. Flatten[{ record, \n   \"badge_counts\" -> {\"bronze\" -> 0, \"silver\" -> 0, \"gold\" -> 0},\n   Rule[_, a_]:> a}] // Flatten\n\nwhich returns for your info\n\n{\"Verbeia\", 1326833982, 3571, 605, False, 1331949804, \"registered\", 35, 0, 11}\n\nEdit: Originally, I used a slightly different approach instead of Rule[_, a_]:> a. I am reproducing it here, for the curious:\n{\"display_name\", \"creation_date\", \"reputation\", \"reputation_change_week\",\n \"is_employee\", \"last_access_date\", \"user_type\", \n \"badge_counts\"} /. Flatten[{ record, \n   \"badge_counts\" -> {\"bronze\" -> 0, \"silver\" -> 0, \"gold\" -> 0}}] // \nBlock[{Rule=#2&}, Flatten[#]]&\n\nwhich relies on the property of Block to temporarily override the behavior of Rule.\nEdit 2: Here's one more alternative which should reduce it to a single pass, unlike ReplaceRepeated. This method, also, eliminates the need for the final Flatten\nClear[killRules]\nkillRules[a : {_Rule ..}] := Sequence @@ a[[All, 2]]\n\n{\"display_name\", \"creation_date\", \"reputation\", \"reputation_change_week\",\n \"is_employee\", \"last_access_date\", \"user_type\", \n killRules[\"badge_counts\"]} /. Flatten[{ record, \n   \"badge_counts\" -> {\"bronze\" -> 0, \"silver\" -> 0, \"gold\" -> 0}}]\n\n", "Operate on several lists to create one list": "\nThe general way to do this is using MapThread.  Using your norm example,\nMapThread[Norm[{##}]&, {listX, listY, listZ}]\n\nThis particular example has easier solutions though:\nSqrt[ listX^2 + listY^2 + listZ^2 ]\n\n", "cdf format - Can CDF file embedded in a web page receive external parameters?": "\nYou cannot import data to a web embedded CDF:\nhttp://www.wolfram.com/player-pro/how-player-pro-compares.html\n...that is to say in principle you can't. However if you read this thread:\nDeploying Mathematica Content Online\nyou will note that @Jens demonstrated that it was possible to import data from a URL. However after investigating this I was told by Wolfram that this was a bug that will be closed in future builds so you cannot rely on this.\n", "Mathematica: finding min/max in list": "\nWell, you could extract the y values and then calculate their minimum.\nrand = RandomInteger[{0, 9}, {10, 3}]\n\n\n{{6, 5, 2}, {3, 8, 3}, {0, 4, 0}, {3, 7, 5}, {4, 2, 7}, {6, 4, 5}, {3, 3, 3}, {7, 9, 7}, {4, 5, 5}, {4, 2, 5}}\n\n\nMin[ rand[[All, 2]] ] (* 1 = x, 2 = y, 3 = z *)\nMax[ rand[[All, 2]] ]\n\n\n2\n9\n\n\nAnother approach is of course sorting the list by user-defined rules and then picking the first/last element. For example, the following sorts the list according to ascending y values, and then extracts the min/max from that.\nsorted = Sort[rand, #1[[2]] < #2[[2]] &]\nsorted[[1, 2]] (* Minimal y *)\nsorted[[-1, 2]] (* Maximal y *)\n\n\n2\n9\n\n\nNote that this actually sorts the whole list, which is far less effective computationally. Normally, min/max functions don't sort, they just search.\n", "front end - Pasting TemplateBox with a Dynamic argument": "\nPause[3]; NotebookWrite[InputNotebook[], \n TemplateBox[{Dynamic}, \"Print\", \n DisplayFunction :> OpenerBox[(# &)]]]\n\nHad to make name a valid function name.\n", "numerics - Wrong computation with N": "\nThis will fix the problem:\nPartition[\n  Table[{n, N[f[n + 1]/Product[f[k], {k, 1, n}], 10]}, {n, 1, 20}],\n        2] // Grid\n\nwith output:\n\nThe fix I added is precision 10 specification to the function N[... , 10]. If you read Documentation for N in section \"More Information\" you find:\n\"N[expr] gives a machine-precision number, so long as its magnitude is between $MinMachineNumber and $MaxMachineNumber.\" \nEvaluating this:\nIn[1]:= $MaxMachineNumber\nOut[1]= 1.79769*10^308\n\ntells us that when your Table reaches n=9 you hit the greater than $MaxMachineNumber case:\nIn[2]:= N[f[9 + 1]]\nOut[2]= 2.463534156527763*10^348 + 0. I\n\nnote 348 > 308 exponent. So now you should explicitly specify the precision you want, like I did with N[... , 10] for example.\nAlso, to clarify the nature of repeating 4.5826..., I played a bit with Mathematica to come up with a \"conjecture\":\n$$\\frac{2\\cos\\left(2^n \\cos^{-1}\\frac52\\right)}{\\prod_{k=1}^n 2\\cos\\left(2^{k-1} \\cos^{-1}\\frac52\\right)}=\\sqrt{21}\\coth\\left(2^n \\cosh^{-1}\\frac52\\right)$$\nSo because Coth saturates quickly at 1 we have our limit for large arguments\nIn[3]:= N@Sqrt[21]\nOut[3]= 4.58258\n\nyet the numbers in your Table should of course decrease very slowly in \"not printed\" after-decimal-point part due to decreasing Coth function. And this is why the 1st number is 4.6:\nIn[4]:= TrigExpand[Sqrt[21] Coth[2 ArcCosh[5/2]]]\nOut[4]= 23/5\n\n", "keyboard - Ctrl+= opens the alpha input instead of below-script": "\nThe keyboard shortcut for underscripts has now been changed to ctr-4 (ctr-$). So, to enter your Sum[expr, {n, 1, 10}], you should type\nescsumesc\nctr-$n=1ctr-%10\nctr-spaceexpr\nAnother option is to type the overscript ctr-& first and then use the ctr-% shortcut to move to the underscript position.\nNot all of the tutorials have been updated (and if you feel like it, you can submit a bug report to WRI about the oversight that you noticed). That said, the main documentation page on Typing Underscripts does use the correct shortcut (as does the Underscript page).\nBy the way, I also still find myself pressing ctr-= for underscript and getting frustrated. But I don't think that I'd go as far as to claim that the Wolfram|Alpha interface is completely useless...\n", "formatting - Delete a style type from stylesheet": "\nI probably haven't understood your problem, but since you're not going into Mr.Wizard's question I have to go by what I read. So here it goes.\nHere we have a MMA notebook (left) and a style file (right):\n\nDeleting a style from the style file (just selecting the cell bracket and hitting the delete key):\n\nAnd finally deleting the last style, we're back at the default style:\n\n", "differential equations - How can you compute It\u014d Integrals with Mathematica?": "\nWhile I cannot answer your question I would like to point at Computational Financial Mathematics using MATHEMATICA\u00ae: Optimal Trading in Stocks and Options, which should answer it.\nFrom the index:\n\n", "programming - Using a list of tuples in a pure function": "\nIt is good practice to check the precedence of code that is not behaving as you expect.\n\nOne of the easiest ways to do this is to use Ctrl+. to expand the selection outward from the cursor while respecting Mathematica precedence.\nConverting the expression to StandardForm (Ctrl+Shift+N) will often reveal something about the way Mathematica is parsing your code.\nExplicitly parenthesize the code using group, supplied below.\nWrapping the code with HoldForm[FullForm[ . . . ]] (or appending // FullForm // HoldForm)  is a robust but harder to read way to check exactly what Mathematica makes of your code.\nIn this case syntax highlighting should also tell you that something may be wrong, but the highlighting is not entirely reliable.  (It may show errors on some correct code.)\nAs a last resort if other methods fail e.g. because your code has syntax errors you can use UndocumentedTestFEParserPacket to see how the Front End is parsing it.  Example:\n\nInfix form of PutAppend ( >>> ) does not work with variable\n\n\nIn the image below I have converted to StandardForm and also used Ctrl+. to expand the selection.  You can see that Mathematica is parsing your Function as (0. &) and that the Map operation is being done before the Set operation.\n\nA function to explicitly parenthesize code:\nSetAttributes[group, HoldFirst]\n\ngroup[expr_] := \n  Replace[\n    Unevaluated[expr], \n    x : _[___] :>\n      RawBoxes @ RowBox[{\"(\", ToBoxes @ Unevaluated @ x, \")\"}],\n    {0, -1}\n  ];\n\nApplied to your case:\ngroup[\n  value[#[[1]], #[[2]]] = 0. & /@ tuples\n]\n\n\n((value[((#1)[[1]]), ((#1)[[2]])]) = ((0. &) /@ tuples))\n\n\n\nThis may be easier to read than the FullForm as it tends to expand code less.\nThe output of group is valid input which may be used as-is or modified.\n\n", "differential equations - What method does NDSolve use for solving PDEs?": "\nUpdate: The answer below is for Mathematica 9 or earlier.  Since version 10, Finite Element Methods are included:\n\nhttps://reference.wolfram.com/language/FEMDocumentation/tutorial/FiniteElementOverview.html\n\n\nThe methods NDSolve uses are documented in detail here:\n\nAdvanced Numerical Differential Equation Solving in Mathematica\n\nThis section says that PDEs are solved using the \"method of lines\", and explains which kinds of problems this method can deal with.  There's also a detailed example of how the method works.\n\nThe numerical method of lines is a technique for solving partial\n  differential equations by discretizing in all but one dimension, and\n  then integrating the semi-discrete problem as a system of ODEs or\n  DAEs.\n...\nIt is necessary that the PDE problem be well posed as an initial value\n  (Cauchy) problem in at least one dimension, since the ODE and DAE\n  integrators used are initial value problem solvers. This rules out\n  purely elliptic equations such as Laplace's equation, but leaves a\n  large class of evolution equations that can be solved quite\n  efficiently.\n\n", "numerics - Funny behaviour when plotting a polynomial of high degree and large coefficients": "\nIf you Rationalize your real numbers you will be able to use Mathematica's arbitrary precision engine:\npoly2 = Rationalize[poly[z], 0];\n\nPlot[poly2, {z, 0, 1}, WorkingPrecision -> 50]\n\n\n\nArbitrary and machine precision\nMathematica has two kinds of numeric calculations: machine precision, and arbitrary precision.  Machine precision is fast but is limited to 53 binary (\u224816 decimal) digits(1)(2) and may lose precision during a calculation.  Mathematica also does not track the precision of a result.\nNumbers entered as 1.234 or 1234` are taken to be machine precision.\nArbitrary precision is slower, but Mathematica will track the precision of calculations, often using more calculations as necessary to preserve precision, and print the precision of the result.\nExact values such as 1234 and 1/2 can be used in arbitrary precision calculations.  Numbers can also be entered with e.g. 1.234`20 specifying 20 digits of precision, and these will automatically use arbitrary precision if all other values are either exact or arbitrary.\nPrecision can be checked with the function Precision:\nPrecision /@ {1.234, 1234`, 1.234`20, 7}\n\n\n{MachinePrecision, MachinePrecision, 20., \u221e }\n\n\nPrecision can only be preserved if all values in a calculation have at least that precision.  Also, arbitrary precision arithmetic may be used with numbers having a precision less than MachinePrecision -- Mathematica will show the true precision of the result.\nPrecision[1.234 + 7]\n\nPrecision[1.234`20 + 1.234`12]\n\n\nMachinePrecision\n\n12.301\n\n\nPrecision can be set with SetPrecision.  It is probably better to use this rather than Rationalize to put numbers into a form that the arbitrary precision engine will use, because the latter will be manufacturing false precision.\nApplying this to your problem:\npoly3 = SetPrecision[poly[z], 15];\n\nPlot[Evaluate[poly3], {z, 0, 1}, WorkingPrecision -> 50]\n\n\nDuring evaluation of In[91]:= Plot::precw: The precision of the\n  argument function <<>> is less than WorkingPrecision (50.`). >>\n\nThis is an important warning because it lets you know that your results may not be valid.\nSee this tutorial for more information about precision.  Take time to understand the difference between Mathematica's meanings of Accuracy and Precision.\n\nRecommended reading, a more recent answer from Szabolcs regarding arbitrary precision:\n\nVery different results from evaluating same expression with different precisions\n\n\nInterval\nMichael's answer shows the folly of simply doing a Rationalize as I did at the start of this answer.  Since questions like this come up often it would be good to have a general solution that is easily applied.  I propose this rule using his formula:\nmachineToInterval = \n  c_Real?MachineNumberQ :> \n    Interval[ {1 - 2^-54, 1 + 2^-54} SetPrecision[c, \u221e] ];\n\nThis converts any machine numbers into explicit Interval form.\nTo extract an ordered pair of values from a numeric Interval we merely need First.\npoly3 = poly[z] /. machineToInterval;\n\nPlot[{First @ poly3, poly[z]}, {z, 0, 1}\n , WorkingPrecision -> 50\n , PlotStyle -> {{Thick, Red}, ColorData[97][1]}\n]\n\n\n", "plotting - RegionPlot3D contour problem": "\nSolution using Show needs to rearrange the order of ranges in ContourPlot3D, e.g. : \nShow[RegionPlot3D[(s - 3 q*s + q > 0 && p == 0) ||\n                     (s - 3 q*s + q <= 0 && p == 1), \n                  {q, 0, 1}, {s, 0, 1}, {p, 0, 1}, AxesLabel -> Automatic], \n     ContourPlot3D[s - 3 q*s + q == 0, {q, 0, 1}, {s, 0, 1}, {p, 0, 1}]]\n\n\nEdit\nHere is another solution without Show, using only Plot3D and HeavisideTheta function :\nPlot3D[ HeavisideTheta[-s + 3 q*s - q], {q, 0, 1}, {s, 0, 1}, \n        Exclusions -> None, PlotPoints -> 100, PerformanceGoal -> \"Quality\", \n        ColorFunction -> Function[{x, y, z}, RGBColor[x, y, 1]], \n        MeshFunctions -> {#1 &, #2 &, #3 &}, BoxRatios -> {1, 1, 2/3}]\n\n\n", "performance tuning - Efficient conditional division": "\nTo stay with your example:\nn = 12; p = 4;\nIf[\n   #2 == 0, n= #1;\n   Print[\"A division took place!\"]\n   ] & @@ QuotientRemainder[n, p]\n\n\nA division took place!\n\n", "manipulate - What changes in Dynamic have occurred from Mathematica 7 to Mathematica 8 that might induce incompatibilities?": "\nThe following does something similar to OP's parametric manipulate function. It works without issue in version 8.0.4:\n    animFunc[Dynamic[freq1_], Dynamic[freq2_]] := Manipulate[\n    ParametricPlot[{a1 Sin[freq1 (x + p1)], \n    a2 Cos[freq2 (x + p2)]}, {x, 0, 20 Pi}, PlotRange -> 1, \n    PerformanceGoal -> \"Quality\"],\n    {{a1, 1}, 0, 1, Animator, AnimationRunning -> False}, {p1, 0, 2 Pi,\n    Animator, AnimationRunning -> False}, {{a2, 1}, 0, 1, Animator, \n    AnimationRunning -> False}, {p2, 0, 2 Pi, Animator, \n    AnimationRunning -> False}, ControlPlacement -> Top];\n\nUsage example:\n    Column[{Slider[Dynamic[y1], {1, 4, .1}], \n    Slider[Dynamic[y2], {1, 4, .1}], animFunc[Dynamic@y1, Dynamic@y2]}]\n\nScreenshots with two different settings:\n\n", "output formatting - Constructing a list that includes a leading zero (01,02,03 ... 55, 56, etc.)": "\nI always use IntegerString for this (I also number my files in a similar way):\nIn[1]:= IntegerString[#, 10, 2] & /@ Range[87]\n\nOut[1]= {\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \\\n\"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \\\n\"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \\\n\"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \\\n\"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \\\n\"55\", \"56\", \"57\", \"58\", \"59\", \"60\", \"61\", \"62\", \"63\", \"64\", \"65\", \\\n\"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \\\n\"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\"}\n\nI think this is the most convenient solution, as it's built-in and doesn't require any additional effort to get it working.\n", "formatting - CDF and personalized style": "\nI encountered no problems here. My system: Mathematica 8.0.4 WIN7. My workflow:\n1) File > New > Notebook\n2) Format > Edit Stylesheet... I applied new styles to Title, Subtitle and Section.\n3) Enter your content in Mathematica notebook.\n4) File > Deploy > Standalone... This will produce a CDF file with inherited styles.\nHere is the snapshot of CDF file I created opened in Wolfram CDF Player - as you can see all styles are preserved:\n\n", "Using patterns in pure functions": "\nYou could write something like this:\n# /. x_Integer :> x (x - 1) & /@ {1, 2, 3}\n\n\n{0, 2, 6}\n\n", "extract values from replacement list": "\nI also think that what you are already using is the best way, but here is another one to toss into the mix:\nSolve[x + y == 3 && x - y == 6, {x, y}][[1]] /. Rule -> (#2 &)\n\n\n{9/2, -(3/2)}\n\n\n", "plotting - Ad hoc graphics primitives-like objects": "\nThe result of Plot3D and related functions is something of the form Graphics3D[primitives, options], so to extract the graphics primitives you can simply take the first part of the plot. These can then be manipulated similar to Sphere[] in your example, e.g.\nplot = Plot3D[Exp[-(x^2 + y^2)], {x, -2, 2}, {y, -2, 2}][[1]];\n\nGraphicsRow[\n Table[Graphics3D[\n   Rotate[Scale[{GrayLevel[.7], plot}, {1, 1.5, 1}, {0, 0, 0}], \n    i Degree, {0, 0, 1}], PlotRange -> {{-2, 2}, {-2, 2}, {-2, 2}}, \n   AspectRatio -> 1, Background -> Black, Boxed -> False, \n   ViewPoint -> Front, SphericalRegion -> True, \n   Lighting -> {{\"Directional\", White, \n      ImageScaled[{0, 0, 1}]}}], {i, {0, 45, 90}}]]\n\n\n", "plotting - Saner alternative to ContourPlot fill": "\nI actually like your own solution as a way to generalize the RegionPlot approach, and the answer by @tkott! \nEdit with improved version of RegionPlot trick\nSince @tkott's solution was still rough around the edges, I hacked together a version of it that should be able to emulate all the features of ContourPlot - i.e., be usable as a drop-in replacement with the same syntax and options. Here it is:\ncontourRegionPlot[f_, rx_, ry_, opts : OptionsPattern[]] := \n Module[{cont, contourOptions, frameOptions, colList, levelList, lab, \n   gr, pOpt, allLines, contourstyle, regionPlotOptions, \n   contourStyleList},\n  contourstyle = \n   ContourStyle /. {opts} /. \n     None -> Opacity[0] /. {ContourStyle -> Automatic};\n  contourOptions = \n   Join[FilterRules[{opts}, \n     FilterRules[Options[ContourPlot], \n      Except[{Prolog, Epilog, Background, ContourShading, \n        ContourLabels, ContourStyle, RegionFunction}]]], {Background -> None, \n     ContourShading -> True, ContourLabels -> Automatic, \n     ContourStyle -> contourstyle}];\n  regionPlotOptions = \n   Join[FilterRules[{opts}, \n     FilterRules[Options[RegionPlot], \n      Except[{Prolog, Epilog, Background,RegionFunction}]]], {Background -> None, \n     PlotStyle -> None}];\n  cont = Normal@\n    ContourPlot[f, rx, ry, Evaluate@Apply[Sequence, contourOptions]];\n  colList = \n   Reverse@Cases[\n     cont, {EdgeForm[___], ___, \n       r_?(MemberQ[{RGBColor, Hue, CMYKColor, GrayLevel}, \n           Head[#]] &), ___} :> r, Infinity];\n  {contourStyleList, levelList} = \n   Transpose@\n    Cases[cont, Tooltip[{gr_, __}, lab_] -> {gr, lab}, Infinity];\n  frameOptions = FilterRules[{opts}, Options[Graphics]];\n  allLines = \n   Flatten@Prepend[\n     Table[RegionPlot[Evaluate[f < levelList[[i]]], rx, ry, \n       Evaluate@Apply[Sequence, regionPlotOptions]], {i, \n       Length[levelList]}], \n     RegionPlot[f > levelList[[-1]], rx, ry, \n      Evaluate@Apply[Sequence, regionPlotOptions]]];\n  pOpt = allLines[[1, 2]];\n  Show[Graphics[\n    MapThread[{EdgeForm[#1], FaceForm@Directive[Opacity[1], #2], \n       FilledCurve[\n        List /@ Cases[Normal[#3], _Line, Infinity]]} &, {Append[\n       contourStyleList, Opacity[0]], colList, allLines}], pOpt], \n   frameOptions]]\n\nEdit 3\nI streamlined some inefficient code, and made the ContourStyle option work. The function  is clearly slower than my rasterized approach. But it comes close to the old version-5 behavior. \nEdit 4\nIn the above code, one can now also use Epilog, and it is allowed to specify ContourStyle as a list with separate directives for each contour.\nThat's probably all I'll do with this method, since there are sufficiently many alternatives that could be used if the above doesn't do what you want. I personally still prefer the continuous gradients of DensityPlot and contourDensityPlot (see below). Meanwhile there is also @Szabolcs' answer, which is seen in his example to accept the RegionFunction argument. Instead of implementing this option, I chose to ignore it in the above solution (it does work in the contourDensityPlot solution below).  \nHere is another example:\ncontourRegionPlot[Sin[x^2 + y^2]/(x^2 + y^2), {x, -2, 2}, {y, -2, 2}, \n ContourStyle -> Black, ColorFunction -> Hue]\n\n\nIf you leave out the styling, you'll get the version-8 default styles.\nAlternative image-based approach\nI don't know if my solution (based on rasterization, not your proposal) is saner, but it offers some additional possibilities. In case you haven't already tried it, you may want to look at my answer on stackOverflow. The post links to a page whose parent page has several different functions that all use rasterized images for the shading. In this case, the relevant one would be rasterContourPlot. Since it uses images, one can apply opacity or potentially other image effects to the output.\nBut as I said, your approach of stacking different image levels seems very sane to me. \nEdit\nAmong the rasterized solutions I list above, the first one I did was the one listed below. My rationale for it was: if I am going to try and fix the shading problem for ContourPlot, why not add a feature that I was looking for anyway: \nWhile contour lines are good, I also like to have the color fill to have a smooth gradient representing the function more faithfully. With the uniform ContourShading of ContourPlot, it seems to me that you're sometimes losing too much information about the function. Of course if I just want smooth color gradients, I could use DensityPlot instead. But wanted both, gradients and contours. That's originally why I decided it was time to write my own replacement for ContourPlot, listed here:\ncontourDensityPlot[f_, rx_, ry_, \n  opts : OptionsPattern[]] :=\n (* Created by Jens U.N\u00f6ckel for Mathematica 8,revised 12/2011*)\n Module[{img, cont, p, plotRangeRule, densityOptions, contourOptions, \n   frameOptions, rangeCoords}, \n  densityOptions = \n   Join[FilterRules[{opts}, \n     FilterRules[Options[DensityPlot], \n      Except[{Prolog, Epilog, FrameTicks, PlotLabel, ImagePadding, \n        GridLines, Mesh, AspectRatio, PlotRangePadding, Frame, \n        Axes}]]], {PlotRangePadding -> None, ImagePadding -> None, \n     Frame -> None, Axes -> None}];\n  p = DensityPlot[f, rx, ry, Evaluate@Apply[Sequence, densityOptions]];\n  plotRangeRule = FilterRules[Quiet@AbsoluteOptions[p], PlotRange];\n  contourOptions = \n   Join[FilterRules[{opts}, \n     FilterRules[Options[ContourPlot], \n      Except[{Prolog, Epilog, FrameTicks, Background, ContourShading, \n        Frame, Axes}]]], {Frame -> None, Axes -> None, \n     ContourShading -> False}];\n  (* //The density plot img and contour plot cont are created here:*)\n  img = Rasterize[p];\n  cont = If[\n    MemberQ[{0, \n      None}, (Contours /. FilterRules[{opts}, Contours])], {}, \n    ContourPlot[f, rx, ry, \n     Evaluate@Apply[Sequence, contourOptions]]];\n  (* //Before showing the plots,\n  set the PlotRange for the frame which will be drawn separately:*)\n  frameOptions = \n   Join[FilterRules[{opts}, \n     FilterRules[Options[Graphics], \n      Except[{PlotRangeClipping, PlotRange}]]], {plotRangeRule, \n     Frame -> True, PlotRangeClipping -> True}];\n  rangeCoords = Transpose[PlotRange /. plotRangeRule];\n  (* //To align the image img with the contour plot,enclose img in a//\n  bounding box rectangle of the same dimensions as cont,\n  //and then combine with cont using Show:*)\n  Show[Graphics[{Inset[\n      Show[SetAlphaChannel[img, \n        \"ShadingOpacity\" /. {opts} /. {\"ShadingOpacity\" -> 1}], \n       AspectRatio -> Full], rangeCoords[[1]], {0, 0}, \n      rangeCoords[[2]] - rangeCoords[[1]]]}, \n    PlotRangePadding -> None], cont, \n   Evaluate@Apply[Sequence, frameOptions]]]\n\nWith your example, it produces the following output. To get this result, using the rasterized image of the DensityPlot was the only \"sane\" alternative.\ncontourDensityPlot[Cos[x] + Cos[y], {x, 0, 4 Pi}, {y, 0, 4 Pi}]\n\n\nI should add a note about the options: you can feed this function with the options for ContourPlot and DensityPlot.  You can completely suppress the ContourPlot output by giving the option Contours -> None.\nI also added an option \"ShadingOpacity\" that can be used to make the shaded background transparent. The shading is fully opaque for \"ShadingOpacity\" -> 1 and fully transparent for \"ShadingOpacity\" -> 0. This option is useful if you want to combine the plot with a Prolog, or if you have added Gridlines -> Automatic which usually will be hidden behind the density plot shading.\nEdit 2\nAs mentioned in the comment to the question, I also tried polygone (a command-line tool you have to run in Terminal), and got mixed results with EPS exported from Mathematica version 8.\n", "charts - Retrieving PlotRange from BarChart": "\nExtracting the PlotRange from a BarChart is not as straightforward as it should be. If no PlotRange is specified in creating the chart, then Options will return PlotRange -> All and AbsoluteOptions will return PlotRange -> {{0., 1.}, {0., 1.}\nbc = BarChart[{1, 2, 3, 4}];\n\nOptions[bc, PlotRange]\n(* {PlotRange -> All} *)\n\nAbsoluteOptions[bc, PlotRange]\n(* {PlotRange -> {{0., 1.}, {0., 1.}}} *)\n\nThe incorrect result from AbsoluteOptions appears to be related to the presence of dynamic objects in the graphics expression (i.e. the bars with their mouseover effects) . I don't know why this causes AbsoluteOptions to go wrong, but a workaround is to replace the dynamic bars with straighforward rectangles, allowing AbsoluteOptions to extract the correct PlotRange. Thus, a replacement for AbsoluteOptions for BarCharts is:\nbarChartOptions[chart_, opts___] := \n AbsoluteOptions[chart /. \n  Tooltip[StatusArea[RawBoxes[DynamicBox[{_, RectangleBox[data__]}]], _], _] :> \n    Rectangle[data], opts]\n\nbarChartOptions[bc, PlotRange]\n(* {PlotRange -> {{0.545455, 4.45455}, {0., 4.}}} *)\n\n", "How to remove repeated permutations?": "\nDid I understand correctly?\nSubsets[Range[1, 16], {2}]\n\nEDIT: If you want to use Permutations, you could use\nDeleteDuplicates[Permutations[Range[16], {2}], Sort[#1] == Sort[#2] &]\n\nwhich deletes all \"duplicates\", where \"duplicate\" is defined by the equality of the two lists when sorted (ie, {2,3} is \"equal\" to {3,2} for purposes of this comparison).\nEDIT: The meaning of #1 and #2 may be demonstrated by this example:\nf={#1,#2}&\n\nand then f[a,b] evaluates to {a,b}. That is, you are defining a pure function which takes two arguments, returning a list containing the two arguments, and assigning it to f. This could also be useful.\nIn the DeleteDuplicates example above, I am using as a test function (see second usage example in the documentation and also this example) that considers two lists equal if they are the same after sorting; thus, {3,4} is equal to {4,3}, since when sorted they both become {3,4}.\nSee also this.\n", "packages - How safe is Encode?": "\nThe documentation of Encode states:\n\nNo function is provided in Mathematica to convert encoded files back\n  to their original form.\n\nimplying that an average user should not be able to view your proprietary code.\nIf you look at the example on the Encode doc page you see that Get is used to read back the Encoded Collatz package and Collatz works as intended. If you now type: \nDefinition[Collatz]\n\nyou get\nCollatz[1]:={1}\n\nCollatz[Collatz`Private`n_Integer]:=\n    Prepend[Collatz[3 \n        Collatz`Private`n+1],Collatz`Private`n]/;OddQ[Collatz`Private`n]&&\n           Collatz`Private`n>0\n\nCollatz[Collatz`Private`n_Integer]:=\n    Prepend[Collatz[Collatz`Private`n/2],Collatz`Private`n]\n      /;EvenQ[Collatz`Private`n]&&Collatz`Private`n>0\n\nSo, some or all of your code becomes visible.\nOf course, you can use TagSet to prevent this:\nCollatz /: Definition[Collatz] := \"\"\n\nbut I'd think there will be ways to get around that and other measures.\nSo, it doesn't seem that Encode is sufficient to keep your code proprietary. It might be a good way to prevent third parties from viewing your code during transport, though. In a quick search I couldn't find the type of encryption, so there's not much to say about its actual safety. \nIf you want to deploy your code in encoded form, your clients might have to use Mathematica Player Pro (or MMA itself) as I don't think the CDF-player reads encoded documents (it doesn't import and export documents at all, see the CDFplayer FAQ). There may be Digital Rights Management in future versions according to the same FAQ:\n\nCan I put copy protection on my CDFs? \nAt the moment, we do not have\n  Digital Rights Management (DRM) for CDF, but we are working on making\n  it available. Contact us for more details when DRM support becomes\n  available.\n\n\nUpdate:\nThere was a discussion about DRM in the LinkedIn group Mathematica. Perhaps you could contact the guy who seemed to have a solution?\n", "matrix - Obtain approximate Hessian using FindMinimum": "\nUnfortunately, this requires a lot more devious trickery than I would have preferred. As noted in the documentation at tutorial/UnconstrainedOptimizationQuasiNewtonMethods, the Hessian is not formed directly in the BFGS method, so we have to recover it from the Cholesky factors. However, all of this is done inside the kernel where we cannot access it using ordinary methods, and the only way I can see to obtain these factors is to hook calls to the BLAS function *TRSV (called as LinearAlgebra`BLAS`TRSV in Mathematica) and extract its arguments directly. Needless to say, this is hardly likely to be particularly robust, but it hopefully it will work well enough for your needs.\nLet us define:\napproximateHessianList[f_, vars_, start_] :=\n  With[{fmarg2 = Thread[{vars, start}]},\n   Module[{steps, lowerTriangles, upperTriangles},\n    Internal`InheritedBlock[{LinearAlgebra`BLAS`TRSV},\n     Unprotect[LinearAlgebra`BLAS`TRSV];\n     trsv : LinearAlgebra`BLAS`TRSV[uplo_, trans_, diag_, a_, x_] /; (\n       Switch[\n        trans,\n        \"N\", Sow[LowerTriangularize[a], \"LowerTriangle\"],\n        \"T\", Sow[UpperTriangularize[a], \"UpperTriangle\"]\n       ]; True\n      ) := trsv;\n     Protect[LinearAlgebra`BLAS`TRSV];\n     {steps, lowerTriangles, upperTriangles} =\n      Reap[\n       FindMinimum[\n        f, fmarg2,\n        Method -> {\"QuasiNewton\", \"StepMemory\" -> Infinity},\n        StepMonitor :> Sow[vars, \"Step\"]\n       ], {\"Step\", \"LowerTriangle\", \"UpperTriangle\"}\n      ][[2, {1, 2, 3}, 1]];\n     Transpose[{steps, MapThread[Dot, {lowerTriangles, upperTriangles}]}]\n    ]\n   ]\n  ];\nSetAttributes[approximateHessianList, HoldAll];\n\nWe may now write:\napproximateHessianList[Cos[x^2 - 3 y] + Sin[x^2 + y^2], {x, y}, {1, 1}]\n\nwhich gives a list of steps in the BFGS optimization along with the approximate Hessians evaluated at those points. For the sake of brevity (and because it is obviously the most accurate), let us take only the last of these:\n\n{{1.37638, 1.67868}, {{15.1553, 0.986982}, {0.986982, 20.2017}}}\n\n\nwhich we may compare to the exact Hessian evaluated at this point:\nD[Cos[x^2 - 3 y] + Sin[x^2 + y^2], {{x, y}, 2}] /. {\n  x -> 1.376384972443001`, y -> 1.6786760817546214`\n }\n\n\n{{15.1555, 0.983708}, {0.983708, 20.2718}}\n\n\nClearly, it is not a bad approximation.\nNow, some caveats. Since the logic of the code inside the kernel is completely opaque, I am not sure whether this business with the upper and lower triangles is really necessary, since the argument a of LinearAlgebra`BLAS`TRSV appears to be the same for successive calls, firstly with trans == \"N\" and then with trans == \"T\". However, this represents at most an inefficiency. A more serious problem is that I am not sure whether the first Hessian obtained using this method corresponds to the initial point, $(x,y)=(1,1)$ , or the point at the end of the first step, which here is $(x,y)=(0.811216, 1.68144)$ . While this does not really matter if the approximation has converged, it does influence the interpretation of the earlier approximations substantially, so hopefully someone with access to the kernel code will be able to clarify this aspect of FindMinimum`QuasiNewton's behaviour.\n", "Quality of random numbrs - Mathmatica Stack Exchang": "\nI finally found some time to investigate this. I think it warrants a detailed response. In places I will repeat what others have pointed out, but I wanted something that ties together the various threads as best I can discern them.\nI'm not certain what is meant by the Rule 30 RNG having \"an extremely small effective size\". Possibly it refers to taking bits only from the middle column? That is in fact what it does, or at least did the last time I looked at the implementation code. That is relatively less speed efficient than other RNGs but does give pseudorandom sequences of high quality. More on that in a bit.\nI see the claim: \"ExtendedCA: What is this? Apparently hasn't been tested.\" The documentation states\n\nThe cellular automaton used by \"ExtendedCA\" produces an extremely high level of randomness. It is so high that even using every single cell in output will give a stream of bits that passes many randomness tests, in spite of the obvious correlation between one cell and five previous ones.\n\nI will give a bit more detail on this matter. In house testing has shown ExtendedCA passing all Diehard and BigCrush tests. One test has a p-value around .993, with all others in the range .01-.99. Moreover some correlation testing has been done that is outside of the tests in TestU01 (the Crush suite).\nThe Rule 30 generator is almost as good as this in terms of the Big Crush suite. I want to address specifically the following comment: \"Rule30CA: Low quality (Meier & Staffelbach 1991, Sipper & Tomassini 1996)\"\nI have not yet managed to locate a copy of that first article. I did find some explanation of it in a more recent paper by Lacharme, Martin, and Sole (see refs below). I gather the issue is strictly of cryptographic usage, where (un)predictability is more important than (pseudo)randomness. They indicate that it may be possible to reconstruct part of the initial configuration given the stream of middle column bits. While this is out of my area, I will concede that this might be problematic for that type of use. That said, let me also remark that the initial configuration part reconstructed is from the left half set of columns. If one has a look at the Rule 30 output from a very specific one bit initial cell, as seen in the \"Structure and properties\" section in Rule 30's Wikipedia article, one will observe considerably more regularity on the left side than the right. This leads me to suspect that knowing the leftmost initial bits will not be of general help in full reconstruction of the middle column. But again, I'm no expert on this.\nPseudorandomness is an entirely different matter. As I mentioned above, Rule 30 actually tests quite well in this regard. So let me take up the matters under discussion in Sipper & Tomassini (1996). It is important to understand what exactly is their claim. They tested using not just the center column, but all columns, of the various RNGs. Used in this way, Rule 30 is indeed quite bad. That's why it does not get used in this way. I note that the authors point out that this is the actual use (first paragraph of section 2). They also state quite clearly (section 4):\n\nThe relatively low results obtained by the rule 30 CA may be due to the fact that we considered N random sequences generated in parallel, rather than the single one considered by Wolfram.\n\nThe point, I think, was not that they were claiming Rule 30 generator is bad when properly used, but rather that they were able to find ones that operate more efficiently in terms of how many bits can be used per iteration.\nAs mentioned in another response and comments thereto, they then (section 5) state  (emphasis mine):\n\nIt seems safe to say at this point that our co-evolved generators are at least as good as the best available CA randomizers.\n\nHere is the point. They tested against the suite by Knuth which, at the time of that writing, was \"best practice\". The Marsaglia Diehard test suite showed up also in 1996 so it may be no surprise they were not aware of it. The l'Ecuyer Crush tests were not around for several more years. Later analysis, as indicated in the paper by Seredynski, Bouvry, and Zumaya (linked to by a comment to this query, see below for another link), indicates that a related evolved CA-based generator, by Tomassini and Perrenoud (see below for ref), does not fare terribly well on Diehard. While I do not know if this is also the case for the Sipper and Tomassini RNG, I will speculate that the Sipper/Tomassini generator would be no better, and perhaps worse, since (going by dates of publication) it was very likely developed a few years earlier. The upshot is that the Rule 30 and ExtendedCA RNGs are, by the standards of current testing, quite sound. Some of the others that showed up in the earlier literature apparently fall short.\nSome other pseudorandom remarks.\n\n(From comments)\n\n[T]he ExtendedCA generator is just a simplified version of CA30 so is likely to suffer from the same problems.\"\n\nIt may have similar problems but it is not a simplified version of Rule 30. It uses a neighborhood of five noncontiguous cells (this is indicated in the first paragraph describing it from the documention I referenced above).\n\nReading about the evolution methods used to construct nonuniform CA-based RNGs leads me to think they should not of necessity work well. That is to say, they might, but one has to be lucky. Here is my reasoning. First, as best I can tell, they select based on an entropy condition that will be satisfied even better by a low discrepancy sequence generator. Such sequences have excellent qualities e.g. for quasi-Monte-Carlo integration. But they are quite far from random. Second is that the winners of each \"round\" (in the sense of evolutionary methods) are heavily dependent on what I'll call \"the kindness of neighbors\". So there is no compelling reason to believe that a local rule that seemingly works well will continue to do so if its neighbors change. This is a general problem with evolutionary methods that have such linkage between genes or their equivalent units. Such methods do in practice still often give good results, due to the effect of co-evolution amongst neighbors. But still...\n\n(From comments):\n\nNow remember that Rule 30 was introduced for the purpose of crypto, so this is a reasonable avenue to check.\n\nI cannot myself give an accurate accounting of the historical origins of Rule 30 applications. For what it is worth, here is what Stephen Wolfram writes in his 2002 NKS tome.\n\n\"I originally studied rule 30 in the context of basic science, but I soon realized that it could serve as the basis for practical random sequence generation and cryptography, and I analyzed this extensively in 1985. (Most but not all of the results from my original paper are included in this book, together with various new results.) In 1985 and soon thereafter a number of people (notably Richard and Carl Feynman) tried to cryptanalyze rule 30, but without success. From the beginning, computations of spacetime entropies for rule 30 (see page 960) gave indications that for strong cryptography one should not sample all cells in a column, and in 1991 Willi Meier and Othmar Staffelbach described essentially the explicit cryptanalysis approach shown on page 601. Rule 30 has been widely used for random sequence generation, but for a variety of reasons I have not in the past much emphasized its applications in cryptography.\"\n\n\n\nI hope this is of some use for understanding the qualities of the CA-based RNGs in Mathematica.\n\nHere are some references.\n\nSeredynski, Bouvry, and Zumaya paper \"Cellular automata computations and secret key cryptography\" (Parallel Computing, 2004).\n\nTomassini and Perrenoud paper \"Cryptography with cellular automata\" (Applied Soft Computing, 2001).\n\nLacharme, Martin, and Sole paper \"Pseudo-random sequences, Boolean functions and cellular automata\" (Proceedings of Boolean Functions: Cryptography and Applications, BFCA 2008); also here.\n\n\n", "evaluation - Subtle difference in conditional rules placement": "\nThis isn't a runtime issue, so you won't find the answer by tracing f[foo] and family.\nIt's a definition thing. If you look at the downvalues you'll see that in f as well as in h the Unevaluated got stripped off when running the SetDelayed\nLet's look at the fullform of your definitions\nf:\nSetDelayed[\n f[Condition[Pattern[x, Blank[]], \n   SameQ[Head[Unevaluated[x]], Symbol]]],\n Unevaluated[x]]\n\nSo, Mathematica sees this code. \nFirst it evaluates SetDelayed, it is inert.\nIt checks its attributes: HoldAll, SequenceHold.\nNow it strips off the Unevaluated of its arguments... (!!)\nEvaluates the expression as a whole, and stores the definition (the Unevaluated is gone already)\ng:\nSetDelayed[\n g[Pattern[x, Blank[]]],\n Condition[Unevaluated[x], SameQ[Head[Unevaluated[x]], Symbol]]]\n\nNow, in this case, no argument has head Unevaluated so it survives :)\nh:\nSetDelayed[\n Condition[h[Pattern[x, Blank[]]], \n  SameQ[Head[Unevaluated[x]], Symbol]], Unevaluated[x]]\n\nSame as f, goodbye Unevaluated\n", "Impossible to bypass evaluation on returned values?": "\nWell, it seems that you just hit the fundamental problem of this approach: any global definition is attached to some symbol. In cases of DownValues, SubValues and perhaps UpValues, this does not harm your approach. But for OwnValues (meaning symbols which have direct values, i.e. variables), it does. You pretty much made this observation yourself. You have to decide which semantics you wish for your function. From what I can tell, you probably do wish to wrap them in some Hold-like wrapper.\nHowever, I would take a different road. I would use Block dynamically, to make a dynamic environment where these symbols are Block-ed, and work in that dynamic environment for whatever code transformations (quoting, etc) you may wish to perform. Yet another approach is to temporarily hide certain symbols with some dummy symbols (assuming that your goal is to make some portions of your code inert and available as data) - I described a very simple version of it here. I actually did write a quoting library based on a combination of these two approaches, for some code-generation purposes, and this worked out quite well for me.\n", "list manipulation - Equating matrices (or higher order tensors) element-wise": "\nWhat about flattening first?\nThread[Flatten /@ (A==B)]\n\n", "probability or statistics - Cluster analysis returns questionable results": "\nClustering is  a relatively unstable process. Points which exist near to cluster boundaries may have small Euclidean, or other, distances between them, but be on different sides of the local boundary. So, in and of themselves, point separation distance metrics may be misleading.\nIf clusters in the data overlap to any degree, a common case, then there is almost certain that some unavoidable mislabelling of cluster membership will occur in the region of overlap.\nThe exact specifics of how this mislabelling came about will depend on the distance metric used  and the  distribution and dimensionality of the original data.\nProjecting the data down into a low dimensional space (1D,2d,3D) using PrincipleComponents[], or other similar dimensional reduction transform ... MDS etc, will allow you to plot the clusters and visualise some elements of their specific configurations. This may, or may not, be useful in deciding if the clustering you have is sensible.\n", "How to know if a number is the square of a rational?": "\nThe only trick I can see is a trivial one: if $x$ is the square of a rational, it is also a rational. That's because of the  $x = (a/b)^2 = a^2/b^2$.\nSo, I'd write a function testing the rationality, which returns either True, False, or Null (if rationality cannot be established):\nisRational[x_] := If[Simplify[x \u2208 Rationals], True, False, Null]\n\nwhich works like this:\nIn[30]:= isRational /@ {1/3, \u03c0, EulerGamma}\nOut[30]= {True, False, Null}\n\nAnd then simply use it by first checking if the number itself is known to be rational:\nisSqrRational[x_] := If[isRational[x], isRational[Sqrt[x]], False, isRational[Sqrt[x]]]\n\nwhich gives:\nIn[33]:= isSqrRational /@ {1/3, 1/4, \u03c0, EulerGamma}\nOut[33]= {False, True, False, Null}\n\n", "functions - Cannot evaluate differential in Mathematica": "\n$P[y]$ is defined to be $\\partial_yF[y]$. If you now call $P[2]$ for example, this is translated to $\\partial_2F[2]$, which of course does not make any sense.\nOne way to get around this behavior is not taking the derivative with respect to y, but with respect to the first argument instead. The following example assigns f[y] to be the derivative of g[y]:\ng[y_] := y^2\nf[y_] := Derivative[1][g][y]\nf[x]\n\n\n2 x\n\n\nInstead of Derivative[1][g][y] you could also have used the shorthand notation g'[y]. Read the explicit long version I used as an operator applied to multiple things: Derivative[1] takes a function and calculates its first derivative with respect to the first argument. Derivative[1][g] is that derivative (as a pure function), and Derivative[1][g][y] is that pure function applied to a value y.\nThe script above has one problem however: Every time you call f[x], it re-calculates the derivative, which can take some time if your function is more complicated and you need a lot of data points. If you use functions instead of patterns (i.e. no :=) you can also get around this problem:\ng = #^2 &\nf = g'\nf[x]\n\n\n#1^2 &\n2 #1 &\n2 x\n\n\n", "Saving in $\\LaTX$ - Mathmatica Stack Exchang": "\nThe way you do this - by saving the whole notebook with un-formatted In/Out cells - will get you a file with non-traditional working Mathematica notation. For example you will get  square brackets for functions instead of round ones and capitalized functions names. If your goal is just to get a nicely formatted formula in $\\TeX$ form, you could use this (for your 1st equation):\nIn[1]:= f = First[y /. DSolve[y'[x] + x y'[x]^2 == 1, y, x]];\n        TeXForm[f[x]]\n\nOut[1]//TeXForm=\nc_1+\\frac{1}{2} \\left(-2 \\sqrt{4 x+1}-2 \\log \\left(1-\\sqrt{4 x+1}\\right)\\right)\n\nIf you paste the output in the body of your $\\TeX$ file between $$ you'll get a nice formula:\n\nIf you would like to save the whole document you need to apply some formatting to it, depending on what you exactly need. For example turning an output cell into text cell will result in wrapping the formulas in \\( ... \\) , which is an equivalent of $...$ in $\\LaTeX$.\n", "graphs and networks - Simple algorithm to find cycles in edge list": "\nEdited to account for @Szabolcs comment\nA index-disordered edge list (a bit different from yours):\nel = {{3, 2}, {1, 3}, {2, 5}, {5, 8}, {4, 7}, {7, 6}, {6, 4}, {8, 1}}\n\nLet's visualize with labels \ngr = Graph[el, VertexLabels -> \"Name\", PlotRangePadding -> .2]\n\n\nThis will pick up the cycles but reorder them (as @Szabolcs reflects in the comment)\nIn[1]:= ConnectedComponents[gr]\n\nOut[1]= {{1, 2, 3, 5, 8}, {4, 6, 7}}\n\nWe see this ordering is wrong because there is no edge between vertices 1 and 2. This more elaborate line will work:\nIn[2]:= Map[First, (FindHamiltonianCycle /@ (Subgraph[gr, #] & /@ \n         ConnectedComponents[gr])), {3}]\n\nOut[2]= {{{1, 3, 2, 5, 8}}, {{4, 6, 7}}}\n\nFindEulerianCycle would work too.\nI wonder how it scales if you check this on your ~1000 vertex case.\n", "front end - Close subgroup of cells and keep them closed": "\nAdapting this answer, please try this:\nautoFoldOutput[] := (If[$FrontEnd =!= $Failed, \n   SelectionMove[EvaluationNotebook[], All, EvaluationCell];\n   FrontEndTokenExecute[\"SelectionCloseUnselectedCells\"]])\n\nAnd then in a new cell:\n2 + 2\nautoFoldOutput[]\n\n", "Can Mathematica do symbolic linear algebra?": "\nFor the posted example, TensorReduce does the trick:\nTensorReduce[\n  Transpose[Transpose[A].Transpose[B]], \n  Assumptions -> {A \u2208 Matrices[{m, n}], B \u2208 Matrices[{k, m}]}\n]\n\n\nB.A\n\n\n", "plotting - How to save plots in grayscale": "\nOne way would be to use ColorConvert to convert the RGB or Hue values to gray scale. Here's an example:\nPlot[{Sin[x], Cos[x], Exp[-x^2], Sinc[\u03c0 x]}, {x, 0, \u03c0}] /. \n  x : _RGBColor | _Hue | _CMYKColor :> ColorConvert[x, \"Grayscale\"]\n\n\n\nFor 2D plots that accept a ColorFunction, you can simply use GrayLevel to get the plot in grayscale as:\nDensityPlot[\n  Sin[x ^2 + y^2], {x, 0, 3}, {y, 0, 3},\n  ColorFunction -> GrayLevel,\n  PlotPoints -> 100\n]\n\n\n\n\nTypically, these grayscale plots are useful when submitting to journals that charge exorbitant prices just to print in colour. However, just a note of caution that discerning different shades of gray is not easy. For the most effect, it is recommended (at least in the journals I publish in), that you also change the line type for your different curves (and not more than 4 curves/plot). You should also choose the colours (or colourscale, for 2D surface plots) wisely so that they convert well to grayscale. For example:\n\n\n", "graphics - Consistent Plot Styles across multiple MMA files and data sets": "\nFor an example of plot option customization that I am still rather proud of please see:\nHow to change the default ColorData used in Mathematica's Plot?\nFor general customization I think you already outlined some good options.  I personally favor the custom function method for maximum control.  Another, perhaps cleaner method that I crudely copy from Leonid works well if you can pool options for all plot types in one list ($myoptions):\nUpdate: changed withOptions to use the \"injector pattern\" so as not to disrupt functions if withOptions is used indiscriminately (withOptions[ 1 + 1 ]). \n$myoptions = {Filling -> {1 -> {{2}, {Red, Purple}}}};\n\nSetAttributes[withOptions, HoldFirst]\n\nwithOptions[head_Symbol[body__]] :=\n  FilterRules[$myoptions, Options[head]] /. {opts___} :> head[body, opts]\n\nwithOptions @ Plot[{Sin @ Log @ x, Cos[3 x]}, {x, 0, Pi}]\n\n\n\nHere I posted another method in answer to specifying plot ranges, but the method is very general and can be used for any options or parameters.  It works by creating an UpValue assignment for the symbol given that applies to any head.  This could of course be further restricted to apply to only one head or a list of heads.  One could also include FilterRules as shown in the code above, depending on the effect desired.  For example:\nSetAttributes[setOpts, HoldAllComplete]\n\nQuiet[\n setOpts[s_Symbol, pat_: _, spec__?OptionQ] :=\n  s /: (h : pat)[pre__, s, post___] :=\n   FilterRules[{spec}, Options[h]] /. {opts___} :> h[pre, opts, post],\n Optional::\"opdef\"\n]\n\nNow a single option as used above is assigned to op1:\nsetOpts[op1, Filling -> {1 -> {{2}, {Red, Purple}}}]\n\nAnd used in Plot:\n Plot[{Sin @ Log @ x, Cos[3 x]}, {x, 0, Pi}, op1]\n\n\nAlternatively the options can be restricted to a particular head or head pattern.  Here a different set of options, also named op1, is defined only for ParametricPlot:\nsetOpts[op1, ParametricPlot, Frame -> True, PlotStyle -> Thick, Axes -> None, \n MeshShading -> {Red, Blue}, Mesh -> 15]\n\nParametricPlot[{{2 Cos[t], 2 Sin[t]}, {2 Cos[t], Sin[t]}}, {t, 0, 2 Pi}, op1]\n\n\nUsing op1 in Plot will still produce the result shown earlier.\nYou could also use Alternatives in the pattern, e.g: Plot | ListPlot | Histogram or more complication patterns with conditions, etc.\n", "Make a ragged list rectangular by trimming instead of padding": "\nYou are looking for Take. To then make the array rectangular, I would do something like this\nTake[ragged, All, Min[Length /@ ragged] ]\n\n", "calculus and analysis - Integral not simplifying": "\nMathematica obviously cannot decide the sign of l^2*ArcCos[x/l] - x*Sqrt[l^2 - x^2]. The rest of your code is fine. For example, just replace the first function by \nFunction[x, \n If[x < l, (NN*Pi*\u03b1*b^2*(l^2 ArcCos[x/l]))/(a^2*\u03b2), 0]] \n\n(in other words, just get rid of -x*Sqrt[l^2 - x^2]) and everything will work as expected. \n", "functions - Block attributes of Equal": "\nyou are good! Based on your comments, I crafted this:\nBlock[{Equal, H = Developer`ToPackedArray},\n SetAttributes[Equal, Listable];\n Equal[x_H, y_H] := \n  Equal[Developer`FromPackedArray[x], Developer`FromPackedArray[x]];\n a == b]\n\nwhich works in both cases.\nUpdate\nMr.Wizard said \" I expected symbols localized with Block to behave generically.\" Although the above works, as mentioned in the comments, there is an observable difference between Equal and other user defined symbols in the rewrite/eval loop in regards to Listable and automatic unpacking of packed arrays. I played with different definitions and couldn't find why this happens.\nClear[f, g, h, z1, z2];\nClearAttributes[{z1, z2}, {Listable}];\nf[a_, b_] := Block[{Equal, H = Developer`ToPackedArray},\n   SetAttributes[Equal, Listable];\n   Equal[x_H, y_H] := \n    Equal[Developer`FromPackedArray[x], \n     Developer`FromPackedArray[x]];\n   Print[ a == b  // FullForm];\n   a == b];\ng[a_, b_] := Block[{Equal, H = Developer`ToPackedArray},\n   SetAttributes[Equal, Listable];\n   Print[ a == b  // FullForm];\n   a == b];\nh[a_, b_] := Block[{Equal = z1, H = Developer`ToPackedArray},\n    SetAttributes[z1, Listable];\n    Print[ a == b  // FullForm];\n    a == b] /. z1 -> Equal;\ni[a_, b_] := Block[{Equal = z2, H = Developer`ToPackedArray},\n    SetAttributes[Equal, Listable];\n    Print[ a == b  // FullForm];\n    a == b] /. z2 -> Equal;\n\nThen I did\n{a , b } = {{1, 2}, {1, 3}};\n{c , d} = Developer`ToPackedArray /@ {a, b};\n\nwhich produces,\n\nIn[211]:= f[a, b]\nList[Equal[1,1],Equal[2,3]]\nOut[211]= {True, False}\nIn[212]:= f[a, c]\nList[Equal[1,1],Equal[2,2]]\nOut[212]= {True, True}\nIn[213]:= g[a, b]\nList[Equal[1,1],Equal[2,3]]\nOut[213]= {True, False}\nIn[214]:= g[a, c]\nEqual[List[1,2],List[1,2]]\nOut[214]= True\nIn[215]:= h[a, b]\nList[z1[1,1],z1[2,3]]\nOut[215]= {True, False}\nIn[216]:= h[a, c]\nList[z1[1,1],z1[2,2]]\nOut[216]= {True, True}\nIn[217]:= i[a, b]\nz2[List[1,2],List[1,3]]\nOut[217]= False\nIn[218]:= i[a, c]\nz2[List[1,2],List[1,2]]\nOut[218]= True\n\nSo one can see that there is a difference between g[a,c] and h[a,c]: in g Equal does not unpack, whereas in h the user-defined z1 does. I think all the other behaviours can be explained from the evaluation (rewrite) steps as explained in the Mathematica documentation.\nAnyway, just wanted to comment finally that although Mr Wizard's is a fair claim. There are a number of areas where other than pure symbolic/rewrite manipulation is occurring, and that simply Block is not probably considering. For example -hope not to trivial for you-, Block[{Equal}, ToExpression[\"?Equal\"]] still prints the Equal documentation, instead of a reference to an undefined symbol. So, like in this case, maybe Equal (and other built-ins) have special behaviour which Block is not touching.\nSorry, I will leave it as answer, but now probably I should say it is not...\nUpdate 2\nActually, just checked that Block leaves ::usage untouched! So, if you do\nf::usage = \"Symbol f\";\n\nthen\n\nInformation[f]\nSymbol f\n\nAnd if you do Block still you get the same\n\nBlock[{f}, Information[f]]\nSymbol f\n\nso Block and Information are not working together, even for user-defined symbols! \nLast update\nAs noticed by some, symbols like Plus have special behaviour too. So this\nBlock[{Plus}, Print[Trace[Plus[1, 2]]]]; (* 1 *)\nBlock[{Global`Plus}, Print[Trace[Plus[1, 2]]]]; (* 2 *)\nBlock[{Global`Plus}, Print[Trace[Global`Plus[1, 2]]]]; (* 3 *)\n\nproduces\n\n{1+2,3}\n{1+2,3}\n{}\n\nwhich demonstrates that Plus retains the built-in behaviour in 1 and 2, being really overridden only with a syntax like 3, which is not convenient. By the way, 2 generates a warning. \nBottom, line, to answer Mr.Wizard's request -I believe this answer was suggested in the comments- it seems the only generic way to override a built-in is to provide your own user defined symbol instead. If one wants to redefine, say Plus, IMHO it is not a burden as whatever definition one wants to introduce can be done with the user-defined symbol and still one has the convenience of the syntactic sugar. To wit\nBlock[{Plus = plus}, plus[0, _] := 0; Print[Trace[0 + 2]]]; \nwhich produces\n\n{{Plus,plus},plus[0,2],0}\n\nSo, I will leave it like this.\n", "sound - Random data gnrator - Mathmatica Stack Exchang": "\nEdit: this answer is now structured in two sections. The first deals about creating a candidate RNG from audio data. The second demonstrates some testing I performed on this RNG.\n\nCreating the RNG\nOkay, I'll got at it another way then. I recorded 10 seconds of ambient noise on my MacBook Pro internal speakers. I was possibly in the worst conditions for this: my quiet flat, at night. The generated wav file was then imported into Mathematica. At least for my own combination of hardware, this doesn't look too good:\ndata = Import[\"test.wav\", \"Data\"];\nLength[data]\nListPlot[data[[1]]]\nHistogram[data[[1]], PlotRange -> {{-0.0004, 0.0004}, Automatic}]\n\nThe data array has two components of length 520192 (it's 48\u00a0kHz audio, so it's indeed raw data). But, they take only a handful of possible values:\n\nThat being said, maybe some randomness can be extracted if the signal oscillate between these values in some random manner. If that's the case, I expect each value will only bring very little entropy to the result, but collectively you can still get something out. And indeed, the Fourier transform is:\nListPlot[Abs@Fourier[data[[1]]]]\n\n\nwhich shows some promising behaviour. We take the mantissa, which is still very far from being uniformly distributed:\nHistogram[(MantissaExponent[#][[1]] &) /@ Abs@Fourier[data[[1]]]]\n\n\nand we can further refine by keeping only least-significant bits:\nHistogram[(BitAnd[Floor[MantissaExponent[#][[1]]*2^32], 2^8 - 1] &) /@ Abs@Fourier[data[[1]]]]\n\n\nEach integer in this list is between 0 and 255 (inclusive), so it's a 8-bit integer. They look nicely equidistributed, which of course is the lowest possible criterion for any kind of random generator. They should be further tested for randomness.\nAlternatively, we can make it into a RNG that creates floating-point numbers between 0 and 1. The following is my \u201cfinal state\u201d code:\ndata = Import[\"test.wav\", \"Data\"][[1]];\nPrint[\"Raw data length (one channel): \", Length[data]];\nrandombytes = \n  BitAnd[Floor[MantissaExponent[#][[1]]*2^32], 2^8 - 1] & /@ \n   Abs@Fourier@data;\nPrint[\"Number of random bytes: \", Length[randombytes]];\nrandomint32s = \n  Table[randombytes[[i]] + randombytes[[i + 1]]*2^8 + \n    randombytes[[i + 2]]*2^16 + randombytes[[i + 3]]*2^24,\n   {i, 1, Length[randombytes], 4}];\nrandomfloats = N[#/2^32] & /@ randomint32s;\nn = Length[randomfloats];\nPrint[\"Number of random reals: \", n];\n\n\nTesting this RNG\nI'm not an expert, so I performed so basic randomness tests following the guidelines in John D. Cook\u2019s \u201cTesting a Random Number Generator\u201d chapter in Beautiful Testing. It's not DIEHARD, or DIEHARDER, but it's a start!\nThe approach I followed is to compare the properties of our RNG to those of streams of Mathematica\u2019s default RNG (with the same size). I thus generate 100 vectors of reference random numbers:\nreferences = Table[Table[RandomReal[], {i, n}], {j, 100}];\n\nThen, I compare their properties. For example, I compare the average of randomfloats to the distribution of averages of same-sized vectors returned by RandomReal. For our RNG to be decent, our average must fit somewhere in the distribution of averages from RandomReal, which I test by calculating the later\u2019s standard deviation:\nw = Mean[randomfloats]\nt = Mean /@ references; Print[Min@t, \" \", Mean@t, \" \", Max@t, \" \", StandardDeviation@t];\nPrint[\"DeltaMean over deviation: \", (w - Mean@t)/StandardDeviation@t];\n\nwhich outputs:\n\n0.499767\n0.498 0.500117 0.502256 0.00081088\nDeltaMean over deviation: -0.432063\n\n\nso our result is at $-0.43\\sigma$, and we can be happy about it! I did the same thing for the min ($-0.25\\sigma$), max ($0.22\\sigma$), and variance (slightly larger at $1.4\\sigma$, but still no cause for concern). I skipped the book's bucket test, because we already established that using histograms.\nThen, the Kolmogorov-Smirnov test:\nQuiet@KolmogorovSmirnovTest[randomfloats, UniformDistribution[{0, 1}], \"TestConclusion\"]\n\n\nThe null hypothesis that the data is distributed according to the UniformDistribution[{0,1}] is not rejected at the 5. percent level based on the Kolmogorov-Smirnov test.\n\nHere I'd be tempted to say: victory!\n\nObviously, if you've read until here, either you like what I write (and I'd appreciate an upvote) or you are an expert, in which case I welcome comments on my empirical investigation. Thanks!\n", "linear algebra - ordering of functional eigenvalues": "\nMy strong hunch is that when the eigenvalues cannot be treated as numbers, the eigenvalues are always ordered according to \"Sort\". Thus, they are sorted in MMA's \"canonical\" order, some of which is described in this question: https://mathematica.stackexchange.com/a/2730/360. \nFor your specific example:\nIn[48]:= Sort[{Log[x], Log[2 x], Log[3 x]}]\n\nOut[48]= {Log[x], Log[2 x], Log[3 x]}\n\nIn[49]:= Sort@Eigenvalues[{{Exp[x], Exp[x]}, {Exp[x], Exp[x/2]}}] == \n Eigenvalues[{{Exp[x], Exp[x]}, {Exp[x], Exp[x/2]}}]\n\nOut[49]= True\n\nFor mixed eigenvalues, the numeric ones are listed first:\nIn[63]:= m = ({{1000, 0, 1}, {1, Log[3 x], 0}, {0, 0, Log[2 x]}});\nEigenvalues[m]\n\nOut[64]= {1000, Log[2 x], Log[3 x]}\n\n", "calculus and analysis - Checking if first derivative is zero at a given point": "\nYou have three variables, so the \"first derivative\" is a little ambiguous.  You can take a derivative with respect to one of these and feed the solution in directly, e.g.\nD[V[a, h, tau], a] /. {a -> 8.47344, h -> 1.67718, tau -> 12.9438}\n\n(Spoiler: none of them are zero)\nWhen you take the total derivative Dt[V[a, h, t], a, h, tau], it gives you a result in terms of the relationship between the variables, such as Dt[a,h] or Dt[h,tau].  You have to specify what these are from you original problem.  Substituting in numbers directly gives nonsensical expression such as Dt[8.47344, 1.67718].  You can't take the derivative of a number with respect to a number.\nYou could also ask Mathematica when one of the first derivatives is zero:\nSolve[D[V[a, h, tau], a] == 0]\n\n", "How do I treat elements in a list as variables inside a module?": "\nYou should have included the error messages. There are several problems with this code. First, you can only assign to parts of an expression, if it is stored in some symbol. This is because expressions are immutable in Mathematica. I discuss this here. In your case, you pass the list itself. So, the first step would be to use pass-by-reference semantics (emulated by Hold - attributes) and write\nSetAttributes[testscan, HoldAll];\ntestscan[listin_] := \n  Module[{zz}, \n     Do[\n       listin[[1]] = zz; Print[{zz, listin[[1]]}], \n       {zz, 1, 2, 1}\n     ]\n  ]\n\nand then use it as\nlst = {a, 1, 3, 1};\ntestscan[lst]\n\nwhich gives the desired outcome, bacause now the input list is stored in a variable which is passed unevaluated (as a reference, more or less). \nIt is important to note however, that the a in lst was not modified, but rather replaced by new values, so that now \n?lst\n\nGlobal`lst\nlst={2,1,3,1}\n\nIf you really want to modify a, I recommend reading this answer.\n", "plotting - Changing the plot variable inside Plot": "\nPlot has attribute HoldAll (you can check with Attributes[Plot]), which makes it not recognize the two separate curves and \"sees\" it as one. Use Evaluate to overcome this.\nPlot[Evaluate[vec /. x -> y], {y, -2, 2}, PlotStyle -> {Blue, Red}]\n\n", "calculus and analysis - simplifying $\\frac{\\log x^a}{a} = \\log x$": "\nIn your particular examples, PowerExpand[Log[x^a]/a] evaluates to Log[x], and PowerExpand[1/a*Log[(x + Log[x]*Cos[x])^a]] also works.\nEDIT: To be clear, and as commented upon by Andrzej, PowerExpand may give wrong answers. See the documentation, in particular this.\nEDIT2: Does something like (1/a*Log[(3*Exp[-1/x]*Sqrt[1 - Exp[1/x]])^a]) //. \n Log[Times[x_, y_]] -> Log[x] + Log[y] do what you want? (this it pattern-matching, a Andrzej suggested in reply to your comment).\n", "plotting - Non-linear inequalities": "\nUnless I made a typo (please next time provide the equations also in MMA code) your problem is rather strange.\nThe a5 is clearly just a point, a4 is false, and a3 reduces to a line. Only a2 and a1 are areas as the following shows:\na1 = b^2 + 9*c^2 - 3*c < 0\na2 = Reduce[{(Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c <= 0 && \n           (-Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c <= 0}]\na3 = Reduce[{(Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c <= 0 &&\n           (-Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c == 12}]\na4 = Reduce[{(-Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c <= 0 &&\n           (Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c == 12}]\na5 = Reduce[{(Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c == 12 &&\n           (-Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c == 12}] \nbb = {3*c > 2*b - 1 && 3*c > -(2*b) - 1 && 1 > 3*c}\n\n(*\n==> b^2 - 3 c + 9 c^2 < 0\n\n==> (0 < c < 1/15 && \n   Sqrt[3 c - 9 c^2] <= b <= 1/4 (1 + 9 c)) || (b == 2/5 && c == 1/15)\n\n==> -(1/4) < b <= 0 && c == 1/9 (-1 - 4 b)\n\n==> False\n\n==> c == 1/15 && b == -(2/5)\n\n==> {3 c > -1 + 2 b && 3 c > -1 - 2 b && 1 > 3 c}\n*)\n\nRegionPlot[{a1, a2, a3, a4, a5, bb}, {b, -1, 1}, {c, -1, 1}, PlotPoints -> 100]\n\n\n", "plotting - Using a function name instead of its definition in AxesLabel": "\nWhat you are looking for can be achieved by wrapping the labels in HoldForm, or if you prefer, HoldForm@InputForm. For example, here is a plot that combines both labeling issues you mentioned:\nf = x^2;\nPlot[f, {x, -2, 2}, AxesLabel -> {x, HoldForm[InputForm[E = f]]}]\n\nThe two issues you mention are indeed separate: \n\nTo get f instead of $x^2$ you should use HoldForm, but that still allows the display of TraditionalForm shorthand forms for built-in symbols such as E (which is Euler's constant but is pretty-printed as $\\mathbb e$). \nTo prevent the replacement of E by $\\mathbb e$, InputForm can be used. \n\nAs you noticed, using strings in labels (though sometimes perfectly fine) has undesirable effects on the font and requires more \"finger-painting\" with styles. The HoldForm approach is easier to use and the code is easier to read when labels get complicated.\nSee also this related question.\nTo expand on this topic:\nSometimes you need more complicated labels that require \"two-dimensional\" typesetting, as in $\\psi = \\frac{1}{2}\\int f(x) \\mathbb{d}x$, see this image:\n\nEdit: how to get formatting into labels in general\nFor output like the above, the essential ingredient is that the expression should be wrapped in a FormBox. Strings aren't made for two-dimensional display, but Mathematica has a way of sneaking FormBoxes into strings: see the documentation.\nTherefore, you can get a two-dimensional formula into a plot label either using HoldForm or a string. Using HoldForm, I got the formatting in the image by doing the following:\n\nCreate the formula in a TraditionalForm environment. This could e.g. be in a Text cell by starting an equation with Ctrl-( and ending with Ctrl-).\nCopy this formula from within that math inset. \nLay out your plot by typing something like Plot[f, {x, -2, 2}, AxesLabel -> {x, HoldForm[    ]}]\nIn the blank space that I have left inside the HoldForm[    ], paste the copied equation.\nYou will be asked if you want to wrap the TraditionalForm expression in a FormBox, and the answer is yes.\nProvided that the pasted expression obeys Mathematica syntax, you should now be able to evaluate the plot cell and get the output shown above.\n\nNow in some cases you want to label a graph with a two-dimensional formula that doesn't obey Mathematica syntax, and in that case you would replace step 4. above by this:\nPlot[f, {x, -2, 2}, AxesLabel -> {x,\"\"}\n\nInstead of HoldForm, I now left an empty string \"\" in the label. Now proceed as above with step 4, for example using an equation like\n-(\\[HBar]^2/(2m))\\[PartialD]^2 \\[Psi]\n\nentered in a math inset (in a text cell as in step 1). If you tried this with HoldForm, it would give a syntax error because the \\[PartialD] is being used in a mathematically acceptable but syntactically incorrect way.\nEdit 2: the fastest way\nThe way I described copying and pasting of TraditionalForm into strings was based on my habits, but it's actually not the fastest. I should adjust my habits to the following: In the code for your plot, type a single string placeholder letter for your label, such as \"y\". Using the mouse, highlight the y in your string and go to the menu item Cell > Convert To > TraditionalForm (or use the keyboard shortcut). This creates the all-important FormBox. Since this box is invisible, you now have to use the arrow keys or mouse to get inside this FormBox, right next to to the placeholder y. From here, you can start typing any arbitrary formula which will then be typeset as TraditionalForm in the plot label.\nSo in conclusion, HoldForm is a very direct way of getting valid Mathematica expressions into labels without expanding them, and strings should be used in combination with the FormBox wrapper method above to typeset arbitrarily complicated labels.\n", "numerical integration - What is NDSolve`FEM`*?": "\nVersion 8 does not have a built-in finite element method. If you want to use the finite element method, you may want to look at the following packages:\n\nACEFem\nIMTEK Mathematica Supplement (IMS) and here and here \n\nTo the question: NDSolve`FEM` is an internal context to NDSolve that currently does not do anything much. It's only use is as a container in the unstructured interpolation.\nHope this helps.\n", "bugs - How to fix broken InterpolatingFunction?": "\nThis is a bug in version 8 and has been fixed in the development version. For now, you have to export the data and reconstruct the interpolation once you have read in the data. What follows is way to recover your data. You should not use this on a day to day basis. The idea is to recover your data and store the data and then reconstruct the interpolation.\ncoords = intNew[[3, 1, 1]];\nvals = Partition[intNew[[4]], 1];\ndata = Join[coords, vals, 2];\nInterpolation[data, InterpolationOrder -> 1]\n\nUpdate:\nHere is a slightly better fix. For large data the re-computation of the underlying mesh can be expensive. In this case, (and only in this case), you can use the following to avoid the expensive mesh creation.\nmesh = intNew[[3, 1]];\nvals = intNew[[4]];\niff = NDSolve`FEM`ElementInterpolation[{mesh}, vals]\n\nHope this helps.\n", "front end - Why are some function names red?": "\nThe red colouring indicates shadowing \u2014 i.e., when a symbol originally in a particular context, is exposed to the current context path, thereby clashing with another symbol of the same name in a different context, also on the context path. \nExample of shadowing:\nHere is a short example that demonstrates this. Try it out in a fresh kernel (call Quit[] before you try it).\n(* Define f in the test` context *)\nBegin[\"test`\"]\n    f[x_] := x^2\nEnd[]\n\n(* Define f in the Global` context *)\nf[y_] := y^3\n\nSo far, all's well and you see the symbols coloured the way you're used to. Now expose test`f by adding it to the context path with:\n$ContextPath = Prepend[$ContextPath, \"test`\"]\n\nYou'll now notice that both the f turned red to indicate that it is being shadowed by a different definition.\n\nFor more information on this, you can read about shadowing in the documentation and also this article by David Wagner in the Mathematica journal.\nWhich definition is used in case of a conflict?\nThe definition that is used first, in the case of shadowing, is the one belonging to the context that appears first in $ContextPath. This is the same behaviour as in your unix shells, where directories in the $PATH variable are searched in the order they appear.\nIn the above example, I used Prepend, which would've placed test` first in the list. So the definition of f will be test`f and you can easily test this:\nf[x]\nOut[1]= x^2\n\nNow quit your kernel and do the same, except now you place the new context at the end. You can see that the definition used is that of Global`f. \n$ContextPath = Append[$ContextPath, \"test`\"]\nf[x]\nOut[2]= x^3\n\nIncidentally, it is also possible to trigger this shadowing warning (red colour) even if there isn't a real conflict. This can occur if the same context appears at different positions in $ContextPath. To test this, in a clean kernel, define test`f as before, and Append and Prepend it to $ContextPath.  \nChanging the colour of the warning\nTo change the colour from red to your favourite, go to Preferences > Appearance > Syntax Coloring > Errors and Warnings and change the colour in the very last option:\n\nTo do it programmatically, evaluate:\nSetOptions[$FrontEndSession, AutoStyleOptions -> {\"SymbolShadowingStyle\" -> \n    {FontColor -> Orange}}]\n\nReplace Orange with the color of your choice and $FrontEndSession with $FrontEnd if you want the change to persist across future sessions (it essentially writes it to the FE's init.m). See this answer for more on the various style tokens and what they control.\n", "front end - Why are some functions available without having to load their parent package?": "\nIf you look at their Contexts, you'll see that all of them are in the System` context and not the GraphUtilities` context.\nContext /@ {GraphDistanceMatrix, CharacteristicPolynomial, AdjacencyMatrix}\nOut[1]= {\"System`\", \"System`\", \"System`\"}\n\nSome packages are preloaded when the kernel starts \u2014 System` is one of them, whereas GraphUtilities` is not. You can see all packages that are pre-loaded with $Packages\n$Packages\nOut[2]= {\"ResourceLocator`\", \"DocumentationSearch`\", \"GetFEKernelInit`\",\n    \"JLink`\", \"PacletManager`\", \"WebServices`\", \"System`\", \"Global`\"}\n\n", "plotting - Labeling points of a list in plot": "\nBubbleChart with a custom function for the tooltip content:\n labelingfunc[v : {x_, y_, w_}, i_, ___] := \n Placed[Grid[{{\"point \", i}, {\"coordinates\", {x, y}}}, Frame -> All, \n Alignment -> Left], Tooltip];\n BubbleChart[(Append[#, 1] & /@ coord), \n ChartLabels -> Placed[Style[#, \"Subsection\"] & /@ Range[Length@coord], Center],\n BubbleSizes -> {0.1, 0.1}, LabelingFunction -> labelingfunc]\n\n\n", "symbolic - Extract real part of a complex expression better than Re does": "\nRemoving the imaginary portion of an expression is done by doing\nComplexExpand[Re[expression]].\n\nUsing just Re alone will not work as Re does no evaluation on symbols with unknown complex parts.\nNow as stated in the problem and the comments above this particular problem requires a fair amount of assumptions. The simplest way to add local assumptions is to use Assuming. But this will not work, so we must instead make use of Simplify. For example:\nSimplify[ComplexExpand[Re[expression]], a > 0]\n\nwhere a is a symbol used in expression and is a real number greater than zero.\n", "symbolic - Validating simplifications analytically": "\nYou are assuming that\n$$\r\n\\sqrt{\\frac{a}{b}} = \\frac{\\sqrt{a}}{\\sqrt{b}}\r\n$$\nThis is not generally true.  Take for example $a=1$ and $b=-1$ for which this identity does not hold.\nYou need to give additional assumptions to Simplify, in this case that $b>0$.\nSimplify[Sqrt[a/b] == Sqrt[a]/Sqrt[b], b > 0]\n\n(* ==> True *)\n\n", "variable sized lists and using lists as variables": "\nI would start by creating a function that returns a value based on your equation, i.e. the solution of your example $x^2+y^2+z^2=1$:\nfindSolutions[y_, z_] := Module[{x},\n    x /. Solve[x^2 + y^2 + z^2 == 1, x]\n]\n\nThe output looks like this:\nfindSolutions[1, 2]\n\n\n{-2 I, 2 I}\n\n\nNext, set up the table of $(y,z)$ values you want to feed that function, for example by generating random numbers or by using some formula:\nsampleData = Table[{y, z}, {y, -2, 2, 1/2}, {z, -1, 1, 1/3}];\nsampleData = Flatten[sampleData, 1]\n\n\n{{-2, -1}, {-2, -2/3}, {-2, -1/3}, ...}\n\n\nThe second line is necessary since Table creates an additional nested layer for each variable it cycles through, so that the data initiall looks like {{{ ... }}}. The Flatten gets rid of this (here) unnecessary layer.\nAlright, let's apply our function to the data,\nfindSolutions @@@ sampleData\n\n\n{{-2 I, 2 I}, {-((I Sqrt[31])/3), (I Sqrt[31])/3}, ...}\n\n\nfindSolutions @@@ sampleData applies findSolutions to every sublist of sampleData, the result is a list of all results of the function based on the data provided. You can now do additional stuff with that, for exmple use Union (will sort the list as well) or DeleteDuplicates (won't do that) to get rid of double entries; you may also want to flatten the result, since findSolutions returns tuples of all possible solutions for a given $(y,z)$, etc. For example // Flatten // Union yields\n\n{-1, 0, -I/3, I/3,  ...}\n\n\n", "graphics - Change the color of a Locator in a Manipulate": "\nAs far as I know, you can't change the colour of the default locator directly, but you could use the specification for the default locator to create a coloured version of the default locator. These specifications can be found in the file MiscExpressions.tr located in $InstallationDirectory\\SystemFiles/FrontEnd/TextResources. It turns out that the locator is specified as \nGraphicsBox[\n InsetBox[GraphicsBox[{col, {AbsoluteThickness[1], \n     Antialiasing -> False, \n     LineBox[{{{0, -10}, {0, -2}}, {{0, 2}, {0, 10}}, {{-10, 0}, {-2, \n         0}}, {{2, 0}, {10, 0}}}], Antialiasing -> True, \n     CircleBox[{-0.5, 0.5}, 5]}, {AbsoluteThickness[3], Opacity[0.3], \n     CircleBox[{-0.5, 0.5}, 3]}}, ImageSize -> 17, \n   PlotRange -> {{-8, 8}, {-8, 8}}], {0, 0}, Center]]\n\nSo using this you could create a coloured locator by doing something like\nloc[col_] := Rasterize[\n  ToExpression@\n   GraphicsBox[{col, {AbsoluteThickness[1], Antialiasing -> False, \n      LineBox[{{{0, -10}, {0, -2}}, {{0, 2}, {0, 10}}, {{-10, 0}, {-2,\n           0}}, {{2, 0}, {10, 0}}}], Antialiasing -> True, \n      CircleBox[{-0.5, 0.5}, 5]}, {AbsoluteThickness[3], Opacity[0.3],\n       CircleBox[{-0.5, 0.5}, 3]}}, ImageSize -> 17, \n    PlotRange -> {{-8, 8}, {-8, 8}}],\n  Background -> None]\n\nGraphics[{Disk[], Locator[{0, 0}, loc[Darker[Green]]]}]\n\n\n", "programming - Handling failed FindRoot calls": "\nYou can use Check to return an alternate result and use Quiet to avoid the messages that you are expecting anyway.  Here's an example:\nQuiet[Table[Check[x /. FindRoot[x^2 - c, {x, 1}],\n  \"NaN\", {FindRoot::lstol, FindRoot::jsing}], {c, -5, 5}],\n  {FindRoot::lstol, FindRoot::jsing}]\n\n(* Out: \n  {\"NaN\", \"NaN\", \"NaN\", \"NaN\", \"NaN\", 7.45058*10^-9, \n   1., 1.41421, 1.73205, 2., 2.23607}\n*)\n\nOne important note is to make sure that the Check is inside the Quiet, and not the other way around.  If Quiet is inside Check the message will be \"quieted\" before it is seen by Check and so you won't get \"NaN\".\n", "Manipulate Evaluation Order Problem": "\nI can't help you with why your code doesn't work, but this seems to work. In this solution n is reset to either 1 or 2 when Parity is changed before Print is called. \nManipulate[Manipulate[\n  If[Not[Parity[n]], n = Mod[n + 1, 2, 1]];\n  Print[{Parity, n}];\n  {Parity, n},\n  {n, Select[Range[1, 10, 1], Parity]}], {Parity, {OddQ, EvenQ}}]\n\n", "programming - Path queries for tree-structured data": "\nThis is not really a full answer, but it may be a start. If you want something like a path specification with wildcards, spans and such, then you are actually very close to general pattern matching, and you might want such functionality anyway, so why not just start out with this? Replace and Replace All just extract components of this structure type, so they aren't ideal for doing the path queries. \nLets define a test structure:\ndata = {\n  row1 -> {key1 -> 1, key2 -> value2}, \n  row2 -> {key1 -> 2, key2 -> value4}, \n  row2 -> {key1 -> 3, key2 -> value4}\n};\n\nThen to take the element identified by the symbolname row1, we do:\n Cases[data, HoldPattern[row1 -> _],1]\n\nTo do a wildcard search we do\n Cases[data, HoldPattern[_ -> _],1]\n\nTo do a range search, we need to carry out a check on the matches and only take those in range, so we take:\n Cases[data, HoldPattern[_ -> a_] /; (key1 /. a) < 3]\n\nSimilarly you can carry out arbitrary checks on the elements of the pattern you are looking for, and do arbitrary depth searches and other nice things. And if you need to manipulate the data structure, you can simply use positions to get the point to edit. \neditAt = First@Position[data, HoldPattern[_ -> a_] /; ((key1 /. a) == 2), 1]\ndata[[Sequence @@ editAt]] = {key1 -> 22, key2 -> value4}\n\n", "graphics - Composition: how to make a day and night world map?": "\nLet me first name your maps correctly (you switched night and day maps):\nnight= Import[\"http://eoimages.gsfc.nasa.gov/images/imagerecords/55000/55167/earth_lights_lrg.jpg\"];\nday= Import[\"http://eoimages.gsfc.nasa.gov/images/imagerecords/57000/57752/land_shallow_topo_2048.tif\"];\n\nThe images have different sizes:\nImageDimensions[day]\n\n(*\n==> {2048, 1024}\n*)\n\nImageDimensions[night]\n\n(*\n==> {2400, 1200}\n*)\n\nso, I rescale the night image. Artefacts (if any) will probably be less visible there.\nnight = ImageResize[night, ImageDimensions[day]];\n\nNow, for the calculation of the mask we don't need to use external sources. AstronomicalData will do:\nmask =\n Rasterize[\n  RegionPlot[\n   AstronomicalData[\"Sun\", {\"Altitude\", {2012, 6, 21}, {lat, long}}] <\n     0, {long, -180, 180}, {lat, -90, 90}, Frame -> None, \n   PlotRange -> Full, PlotStyle -> Black, PlotRangePadding -> 0, \n   AspectRatio -> (#2/#1 & @@ ImageDimensions[day])],\n  ImageSize -> ImageDimensions[day]\n  ]\n\n\nThen, stealing the ImageCompose idea from Yu-Sung:\npl=ImageCompose[night, SetAlphaChannel[day, mask]]\n\n\nBorrowing and adapting some code from the Texture doc page:\nShow[\n Graphics3D[{White, Tube[{{0, 0, -1.4}, {0, 0, 1.4}}, .04]}],\n SphericalPlot3D[1 , {u, 0, Pi}, {v, 0, 2 Pi}, Mesh -> None, \n  TextureCoordinateFunction -> ({#5, 1 - #4} &), \n  PlotStyle -> Texture[Show[pl, ImageSize -> 1000]], \n  Lighting -> \"Neutral\", Axes -> False, RotationAction -> \"Clip\"], \n Lighting -> \"Neutral\", Boxed -> False, \n Method -> {\"ShrinkWrap\" -> True}\n]\n\n\n", "functions - What is so special about Prime?": "\nActually, I believe the issue reduced to that of implementing PrimePi[]. It is easy to implement Prime[] using PrimePi[] and FindRoot[] \u2014 in fact this is done on page 134 of Bressoud and Wagon, \"A Course in Computational Number Theory\". So all you need is to have a fast implementation of PrimePi[].\nThe first efficient way was found by Legendre in 1808. The modern approach of Lagarias, Miller and Odlyzko (1985)  gives PrimePi[] for $10^{20}$, which is larger than the Mathematica implementation. All this is discussed in detail in the Bressound and Wagon book. Curiously they include a Mathematica package that implements the Lagarias, Miller and Odlyzko method, but it appears that (somewhat surprisingly) it has not been included in the Mathematica kernel.\n\n\nJ. C. Lagarias, V. S. Miller, and A. M. Odlyzko, Computing $\\pi(x)$*: The Meissel-Lehmer method*, Math. Comp. 44 (1985), 537\u2013560. MR 86h:11111\n\n", "front end - Avoiding an unresponsive user interface in OS X": "\nThe main part of this question has been answered at \nHow to abort on any message generated?\nHowever, in my mind there remains a very live issue: why should the front end ever crash at all? Its primary job is as a user interface. As such, there is no excuse for it to crash, ever.\nBy contrast, when I use a terminal program to connect with, say, a Linux console interface, one of my concerns is never that the terminal program itself would crash. Why should it?\nYet the Mathematica front end crashes or hangs several times a day during my work. I use the following sequence of ways to get out of an impending crash:\n\nIf one responds quickly, the hangup can usually be stopped with the menu command \"Interrupt Evaluation\". \nIf that doesn't work, pressing Cmd+. might halt the computation.\nIf Cmd+. fails, sometimes it is possible to use the menu command \"Quit Kernel\".\nIf I can't quit the kernel, sometimes I can quit Mathematica entirely by using the \"Force Quit\" command from the Dock.\nIf \"Force Quit\" also fails, then I have to go into Activity Monitor and terminate the Mathematica process at the level of the operating system.\n\nOnly the last method is certain to work.\nThis sort of distracting search for the proper panic button is often necessary several times per day when I am working intensively with relatively large objects, such as an image of more than ten megapixels.\nI find it very surprising that this glaring problem was not fixed a long time ago.\n", "graphics - Height-dependent filling color in 3D Data Plots": "\nIf nobody comes with a much cleverer solution, this might be a way to achieve what you're looking for. However, first your data have to be reshaped.\nnewtable = {{1, 2, 1}, {3, 1, 3}, {4, 3, 4}};\nBarChart3D[newtable, ChartLayout -> \"Grid\", \n    ViewPoint -> {3.33, -8.26, 5.36}, ColorFunction -> \"DarkRainbow\", \n    Method -> {\"Canvas\" -> None}]\n\n\nWith some additional options:\nBarChart3D[newtable, ChartLayout -> \"Grid\", ChartElementFunction -> \"Cube\",\n    ViewPoint -> {3.33, -8.26, 5.36}, ColorFunction -> \"DarkRainbow\",\n    Method -> {\"Canvas\" -> None}, BarSpacing -> {None, None}]\n\n\n", "plotting - Easy Way to Create Trellis Plots in Mathematica": "\nPerhaps this is what you are doing, but just in case:\nt = Table[{RandomChoice[{\"Reg1\", \"Reg2\", \"Reg3\"}], \n    RandomReal[{10, 20}], RandomReal[{50, 70}]}, {i, 1, 10}];\nsel[x_] := Select[t, #[[1]] == \"Reg\" <> ToString[x] &];\nplt[x_] := ListLinePlot[#] &@(sel[x][[All, 2 ;; 3]]);\n\npltR = Flatten[Options[plt[#], PlotRange] & /@ Range[3] /. \n              HoldPattern[PlotRange -> x_] -> x, 1];\npltRR = {{Min@pltR[[All, 1, 1]],  Max@pltR[[All, 1, 2]]}, \n         {Min@pltR[[All, 2, 1]],  Max@pltR[[All, 2, 2]]}};\n\nGraphicsGrid[{ListLinePlot[#, PlotRange -> pltRR] &@ (sel[#][[All, 2 ;; 3]]) & \n             /@ Range[3]}, Dividers -> All]\n\n\n", "list manipulation - MapThread on a nested Map": "\nI am not exactly sure what you are looking for so, here are two ideas:\nMapThread[\n f[#1, #2] &, {Map[Map[(# + 1/Min[#]) &, #] &, #] & /@ list1, list2}]\n\nor\nMapThread[\n Function[{x, y}, Map[Map[(# + 1/Min[y]) &, #] &, x]], {list1, list2}]\n\nHope this helps.\n", "Calling a function an unspecified number of times": "\nSomething like :\nsample[ranges_] := Table[Evaluate[ranges[[All, 1]]], Evaluate[Sequence @@ ranges]]\n\nused like :\nsample[{{x, 0, 3, 1}, {y, -2, 2, 1}}]\n\n", "graphics - How to make an inkblot?": "\nA bit of image processing:\nTable[\n  Blur[\n    Dilation[\n     Graphics[\n      Table[\n        Rotate[\n           Disk[RandomReal[{-10, 10}, {2}], {RandomReal[{1, 5}],RandomReal[{1, 5}]}],\n           RandomReal[{0, 3.14}]\n          ], \n         {40}\n       ]\n     ], \n     DiskMatrix[20]\n   ], 20\n  ]// Binarize, \n  {3}, {3}\n] // Grid\n\n\nLots of parameters to play with...\nNow these are bitmaps and if vector graphics are required (the question seems to imply that) we can adapt a bit of Vitaly's code from here:\nimg = Thinning@EdgeDetect@p;\npoints = N@Position[ImageData[img], 1];\npts = FindCurvePath[points] /. c_Integer :> points[[c]];\nGraphics[{EdgeForm[Directive[Dashed, Thick, Red]],FilledCurve@({Line@#} & /@ pts)}]\n\n \nwith p our blob bitmap. (The contour is dashed to better show that we're dealing with vector graphics here).\n", "Edge problems in a directed graph": "\nSolution based on graphics primitives\nYou might consider using this approach:\nh = Graphics[Line[{{0, 1/2}, {0, -1/2}}]];\nGraphics[{\n    {Thick, Arrow[{{.1, 0}, {.9, 0}}]},\n    {Red, Thick, Arrow[{{.5, 0}, {.5, -.5}, {2, -.5}, {2, -.1}}]},\n    Arrowheads[{{Automatic, Automatic, h}}],\n    {Red, Thick, Arrow[{{1.1, 0}, {1.9, 0}}]},\n    Style[{Text[\"X\", {0, 0}], Text[\"Y\", {1, 0}], Text[\"Z\", {2, 0}]},\n    FontFamily -> \"Helvetica\", FontSize -> 20]\n}]\n\nthat produces this:\n\nFor the curved lines you can play with:\nGraphics[{Arrow[BezierCurve[{{0, 0}, {1, 1}, {2, -1}}]]}]\n\nSolution based on Graph\nThis solution is a bit more convoluted than the previous, but with some tweaking it works.\nh = Graphics[Line[{{0, 1/2}, {0, -1/2}}]];\nvlabel[lbl_] := Graphics[Text[Style[lbl, FontFamily -> \"Helvetica\", FontSize -> 20],\n    Background -> White]];\nverts = {\"X\", \"Y\", \"Z\"};\nedges = {\"X\" -> \"Y\", \"Y\" -> \"Z\", \"X\" -> \"Z\"};\nvcoords = {{0, 0}, {1, 0}, {2, 0}};\neshapef = {\"X\" \\[DirectedEdge] \"Y\" ->\n    ({Thick, Black, Arrow[{{0.1, 0}, {.9, 0}}]} &),\n    \"Y\" \\[DirectedEdge] \"Z\" ->\n    ({Thick, Red, Arrowheads[{{Automatic, Automatic, h}}],\n    Arrow[{{1.1, 0}, {1.9, 0}}]} &), \"X\" \\[DirectedEdge] \"Z\" ->\n    ({Thick, Red, Arrow[{{0.5, 0}, {0.5, -.5}, {2, -.5}, {2, -.1}}]} &)};\nGraph[{\"X\", \"Y\", \"Z\"}, edges,EdgeShapeFunction -> eshapef,\n    VertexCoordinates -> vcoords,\n    VertexLabels -> Table[i -> Placed[i, Center, vlabel], {i, verts}]]\n\n\n", "numerical integration - Publishing results obtained in Mathematica": "\nThis question is somewhat subjective, but here's my take on it:\nThe reason the precise methods are mentioned in papers is to make results reproducible.  One has to draw a line when it comes to describing methods.  Will you mention what method you used to add or multiply numbers on a computer?  What if the numbers are huge and you used FFT-accelerated convolution for arithmetic?  It all comes down to how essential the method was in obtaining your results.\nIf the method is really not essential to your results (solving differential equations on a computer can be considered rather trivial these days), then I don't believe it is necessary to mention the method.  If someone wants to reproduce your results, they can just implement any trivial method, or more likely use some package like Mathematica (or any other) that has it built-in.  If you feel like, you can say \"the PDEs were solved numerically using Mathematica 8\".\nIf a trivial method won't work (e.g. you have stiff equations), you may need to mention the method.  In this case it's likely that you also need to select a method manually and tune its parameters.  The available method are described in some detail here.  Again, you can just say that you used Mathematica and mention the method it uses for PDEs (the method of lines) and the exact settings you chose (e.g. an implicit Runge Kutta scheme).\nIf your equations are such that the method is absolutely essential to the results, then you likely have implemented the method yourself, and this question wouldn't come up.\nTo sum up: There's nothing wrong with saying that you used Mathematica, and there's nothing wrong with not mentioning the exact method for as long as this is not essential to getting the results.  People could reproduce your results using a naive application of MATLAB or SciPy as well.\nExample: I've used a Delaunay triangulation in my work.  I didn't mention how I got it, nor do I think it is necessary.  (In fact I don't even know how the triangulation algorithm works.) It is just a detail that would distract.  Similarly, the subject of your research might be the system described using the PDE, and you don't need to know any advanced PDEs solving methods to obtain your results.\n", "Formatting a fraction as a mixed number": "\nHere is a definition for mixedForm that works for all cases, i.e. proper and improper fractions and integers.\nClear[mixedForm]\nmixedForm[Rational[x_, y_]] := \n    If[Abs@x > y, HoldForm[#1 + #2/y], x/y] & @@ (Sign@x QuotientRemainder[Abs@x, y])\nmixedForm[x_Integer] := x\n\nSome examples:\nmixedForm /@ {2, 4/5, 10/3, -3/4, -5/2}\nOut[1]= {2, 4/5, 3 + 1/3, -3/4, -2 - 1/2}\n\nCompare with Eli's, which produces 0s if the number is an integer or a proper fraction\nImproperForm /@ {2, 4/5, 10/3, -3/4, -5/2}\nOut[2]= {2 + 0, 0 + 4/5, 3 + 1/3, -1 + 1/4, -3 + 1/2}\n\n", "equation solving - Solve Lagrange multipliers optimization problem": "\nThe short answer is that this is not a correct formulation of a Lagrange multiplier problem in the first place. In the question, derivatives are being taken with respect to the multipliers $\\lambda1$ and $\\lambda2$. That's simply wrong. These multipliers are there to enforce the fact that the gradients of the objective function and constraint conditions are linearly dependent. But they aren't themselves variables in the gradient. \n", "How to get string representation (like repr in Python)": "\nJust use ToString\nToString[\"a\\nb\", InputForm] // InputForm\n\n\n\"\\\"a\\\\nb\\\"\"\n\n\nAdding // InputForm is not strictly necessary.  It will influence only the printing of the output, not its structure.  By default, Mathematica does not show quotes around strings in the output, and it expands escaped characters (such as \\n) to their meaning (an actual newline in this case).  InputForm will change this behaviour and will cause Mathematica to show quotes and escaped characters.\n", "complex - presenting a real number as real instead of imaginary": "\nThat results only holds if you assume that d > c. I.e.\nSimplify[(I a)/Sqrt[c - d], Assumptions -> d > c]\n\n", "numerical integration - How to set the NDSolve method to LSODA": "\nIf you load the package using Needs as shown in the Tutorial and then evaluate $NDSolveProblems you will list a list of names of all the problems included in the package. \nI think I can now also answer the first part of the question. The method has to be called as\nNDSolve`LSODA\n\nrather than LSODA (for some reason it is in the NDSolve` context, which suggests that it is not intended for \"ordinary users\"). To see its options, just evaluate\n?NDSolve`LSODA\n\nThe whole issue of these \"hidden contexts\" in Mathematica could be the topic of an interesting discussion ;-)\n", "evaluation - Old values are not freed/garbage collected when you re-evaluate an assignment": "\nYou need to set\n$HistoryLength = 0\n\n(or other small value) at the beginning of the session to prevent Out from remembering previous outputs.  One non-obvious thing about Out is that if we do\nIn[1]:= a=1;\n\nthen Out[1] will still be set to 1 despite the semicolon at the end of the input!\nThere's also the CleanSlate` package which has a ClearInOut function that clears old inputs and outputs.\n", "evaluation - How to properly DumpSave & Get Global`s symbols inside packages while not touching Global context?": "\nTo show how this is possible:\n\nSimply put: I want to use DumpSave & Get the way I use Export &\n  Import, but with efficiency and flexibility benefits.\n\nYou can simply use Import and Export.  They do support the same format that DumpSave uses, and they give you the same performance.  But they don't save symbol names.\nExport[\"data.mx\", data, \"MX\"]\n\ndata = Import[\"data.mx\"]\n\nMX files are not portable between architectures though, so you may consider using Compressed strings, as described here.  This is several times slower, but it's still quite fast compared to any other alternative and it's portable.  \nIf you ever need to save InterpolatingFunctions, please be aware of this problem.\n", "assignment - Setting parts of a list": "\n(a[[#]] = {1, 2, 3}) & /@ Range[4, 6];\n\nYou get:\nIn[1]:= a\n\nOut[1]= {1, 2, 3, {1, 2, 3}, {1, 2, 3}, {1, 2, 3}, 7, 8, 9, 10}\n\nA convenient thing to remember is that if your elements are not sequential it is still easy to set up: \n(a[[#]] = {1, 2, 3}) & /@ {1, 3, 10};\n\nIn[2]:= a\n\nOut[2]= {{1, 2, 3}, 2, {1, 2, 3}, 4, 5, 6, 7, 8, 9, {1, 2, 3}}\n\n", "import - Fetching data from HTML source": "\nI recommend that you import as an XMLObject, which represents structured XML data in a Mathematica-based format.  \ninfo = Import[\n   \"http://area51.stackexchange.com/proposals/4470/martial-arts\", \n   \"XMLObject\"];\n\nYou can access the parts of xml using Mathematica patterns, like so:\nlabels = Cases[info, XMLElement[\n  \"div\", {\"class\" -> \"site-health-label\"}, label_] :> \n  First[label], Infinity];\nvalues = Cases[info, XMLElement[\n  \"div\", {\"class\" -> \"site-health-value\"}, value_] :> \n   First[value], Infinity];\nGrid[{labels, values}, Dividers -> All]\n\n\n", "evaluation - Arguments to If[] are not evaluated": "\nYou can evaluate\n?? If\n\nto see that its attributes are\nAttributes[If]={HoldRest,Protected}\n\nHoldRest tells you that the first argument always gets evaluated while the rest  (2nd, 3rd, and 4th) are unevaluated. In practice you can't make any assumptions about the rest because it's not possible to tell how a function evaluated held arguments internally.\n\nThat said, if you think about it, it's clear that If must evaluate the first argument, so see if it's True or False.  It is also highly desirable not to evaluate the rest of its arguments.  How would you expect the following to work?\nIf[a > 0,  b += 1]\n\nOf course it must only add 1 to b if a > 0, and not otherwise!  As you can see, it is a must for any code with side effects not to evaluate automatically.  Even if we don't have non-functional constructs, we may have something like\nIf[a > 0, f[a], f[-a]]\n\nfor a function f that would give an error for negative arguments.  Finally, if this function f is expensive to evaluate, an If without HoldRest would evaluate it twice, while using the result from only one evaluation---this is wasteful.\nI think this should make it clear why it is highly desirable for If to have HoldRest (and also why it is not necessary for it to have HoldAll)\n", "Morphing Graphics, color and location": "\nTry a simple way. Typical key frame animation is done by nothing more than n-degree interpolation (and n is usually 1), and they look quite reasonable.\nHere is how I would tackle (it is generic version, so individual points have its own colors).\n\nDefine \"start\" and \"final\" positions:\nstartPos = RandomReal[{-2, 2}, {4000, 2}];\n\nnormalRDN[\u03bc_, \u03c3_, No_] := RandomVariate[\n  NormalDistribution[\u03bc, \u03c3], No];\n\n(* Tuples does the neat trick to create corner points *)\nfinalPos = Join @@ Table[((normalRDN[#, .5, 1000] & /@ c)\\[Transpose]),\n   {c, Tuples[{-1, 1}, 2]}];\n\nDefine \"start\" and \"final\" colors as a list of triples:\nstartCol = Table[0.5, {4000}, {3}];\n\nfinalCol = Join[Table[{1., .5, .5}, {1000}], Table[{.4, .4, 1.}, {1000}],\n   Table[{0., 1., 0.}, {1000}], Table[{1., 1., 0.}, {1000}]];\n(* Numericize them to make sure that the end results are all nicely packed. *)\n\nDefine \"duration\" functions: a function from time to [0, 1]\nlocationDuration[t_] := Piecewise[{{0, t < 2},\n   {0.5 t - 1, 2 <= t < 4}, {1, True}}]\n\ncolorDuration[t_] := Piecewise[{{0, t < 0}, {0.5 t, 0 <= t < 2}, {1, True}}]\n\nThey are just piecewise linear functions, but you can find your own (such as CDF--much smooth) or try random perturbation.\nDefine \"easing\" function: Interpolating from start to end values with duration\neasing[t_, f_, sPos_, fPos_] := (1 - f[t]) sPos + f[t] fPos;\n\nAgain, it can be more sophisticated, but usually linear is OK.\nPut them together: The key here is usage of VextexColors; very effective way to change colors.\nManipulate[\n   Graphics[Point[easing[t, locationDuration, startPos, finalPos], \n   VertexColors -> easing[t, colorDuration, startCol, finalCol]], \n   PlotRange -> 2, Background -> Black], {t, -0.5, 4.5, Animator, \nAnimationRepetitions -> 1}]\n\n\nHere is the result (tiny).\n\nForget to mention that when you are using VertexColors, it doesn't get antialiased by default unlike other 2D graphics (true for Polygon too). It may result in square points, not circular points. You may want to turn on the hardware AA in Preference->Appearance->Graphics. One way to avoid (if your graphics hardware does not support AA) is to use color directive separately for each color group.\nThanks!\n", "wolfram alpha queries - Roughly how many times per day may WolframAlpha[] be used?": "\nPerhaps this helps:\n\nThe WolframAlpha function is limited to 1,000 API calls per day  for\n  professional Premier Service subscribers (500 API calls per  day for\n  student and classroom Premier Service subscribers), and  100 API calls\n  per day for all other users, unless an API upgrade is  purchased.\n\n", "performance tuning - Parallelization of distinct array write access from subkernels": "\nFirstly, I want to point out not only that Fourier works for arbitrary n-dimensional arrays (as already mentioned by whuber), but also that it's already very efficiently parallelized using threading (via the Intel MKL). Therefore, attempts to parallelize it further are futile unless you intend to distribute the workload over a cluster--and then, even using algorithms that require no synchronization, the cost of communication must be considered and carefully minimized. As Amdahl's law makes clear, the performance one may gain through parallelization is very strongly constrained by the remaining serial portion of the workload, and communication is inherently difficult to parallelize within the \"scatter/gather\" paradigm offered by the Parallel` package. It is possible to implement MPI-style message passing on top of MathLink, but even then, Mathematica and MathLink are not ideal for the purpose, and you will definitely need a cluster with a high-performance interconnect such as InfiniBand in order to make this reasonably scalable.\nAll this being said, there's no reason not to at least try to implement a row-column decomposition to see what can be done with it. Taking your MFFTs to start with, and assuming that the input array will always have quite a high aspect ratio as in your question, we can get much better performance by doing the column-wise transforms \"by hand\" with a tensor dot product rather than calling Fourier once for each column. This is because the overhead of the function call is significant, and for small $N$ there's not that much to be gained from an $O(N M \\text{log} N)$ algorithm versus one that works in $O(N^2 M)$ time (although this still implies $\\approx$ 3 times as many operations for $N = 4$, so it helps that the dot product is efficient and well parallelized). Let's write:\nDFTMatrix[n_] := 1/Sqrt[n] Table[Exp[(2 Pi I (r - 1) (s - 1))/n], {r, 1, n}, {s, 1, n}];\n\nMFFTs2[data_?ArrayQ] /; ArrayDepth[data] > 1 :=\n Block[{local = data, len = Length[data], i},\n  Do[local[[i, All]] = Fourier[local[[i, All]]], {i, 1, len}];\n  Developer`ToPackedArray@DFTMatrix@N[len].local\n ];\n\nMFFTs2[data_] := Fourier[data]; (* fallthrough for 1-d arrays *)\n\nwhich is a lot faster (and still works for arrays of arbitrary dimensionality). For an array with $(N, M) = (4, 2^{20})$ , the AbsoluteTiming of MFFTs2 is 0.52 seconds versus 12.16 seconds for MFFTs, and (this surprised me!) MFFTs2 is even faster than Fourier for arrays of certain non-power-of-2 dimensions such as $4 \\times (2^{20}+1)$ , where AbsoluteTimings are 0.78 seconds for MFFTs2 and 1.45 seconds for Fourier. Here I've kept your Do construct because it doesn't unpack, unlike the simpler Fourier /@ local, which unpacks down to level 1 (although isn't significantly slower as a result). It's worth remembering, though, that both approaches still copy their input (i.e., the FFT is not performed in-place).\nNow, thinking about parallelizing it, the main consideration is avoiding unpacking since there's really no way to avoid the communication cost of sending each of the sub-arrays at level 1 to the subkernels. As a result, performance will always be poor, even on a cluster; parallel FFTs are ordinarily used when the data do not need to be sent in their entirety as they have already been distributed, and it is then desired to form the distributed FFT. In any case, doing the best we can, we need both withModifiedMemberQ from this answer, and to avoid the distribution of the whole of the array when only the parts at level 1 are actually required by each subkernel. Writing that down, we get:\nMFFTp2[data_?ArrayQ] /; ArrayDepth[data] > 1 :=\n Block[{local = data, i},\n  local = withModifiedMemberQ@ParallelTable[\n   Fourier[i], {i, local},\n   DistributedContexts -> None\n  ];\n  Developer`ToPackedArray@DFTMatrix@N@Length[data].local\n ];\n\nMFFTp2[data_] := Fourier[data];\n\nwhich, for an array of $(N, M) = (4, 2^{21} + 1)$ , gives an AbsoluteTiming of 4.59 seconds (of which 0.81 seconds is spent on communication), versus Fourier's AbsoluteTiming of 3.04 seconds. So, at least communication costs aren't totally overwhelming, and perhaps on a cluster with a fast interconnect it might outperform Fourier for certain (large) inputs. However, performance is still mediocre at best, which conforms to our generally low expectations for this kind of approach.\n", "topology - Plotting the open ball for the post office metric space": "\nI'll just post because I don't think Eli Lansey\u2019s answer uses the right definition for post office metric. I like the other name of the post office metric better: British rail metric. It assumes that, when going from point A to point B, the fastest path is to go via London (i.e., the origin), unless of course you're already at your destination!\nSo, we consider a fixed point $\\mathbf{p}$, the ball $B_r(\\mathbf{p})$ is the set of points $\\mathbf{q}$ that satisfy:\n$$\\|\\mathbf{p}\\|^2 + \\|\\mathbf{q}\\|^2 < r^2$$\nthat is, if we have $\\mathbf{q}=(x,y)$, the ball $B_r(\\mathbf{p})$ is the union of the $\\{\\mathbf{p}\\}$ and all points satisfying:\n$$x^2 + y^2 < r^2 - \\|\\mathbf{p}\\|^2$$\nThe latter is the ball of radius $r' = \\sqrt{r^2 - \\|\\mathbf{p}\\|^2}$ around the origin for the Euclidean distance in the plane, which we might note $B_{r'}^{\\text{E}}(\\mathbf{O})$. To summarize:\n\nif $r < \\|\\mathbf{p}\\|$, $B_r(\\mathbf{p}) = \\{\\mathbf{p}\\}$\notherwise, $B_r(\\mathbf{p}) = \\{\\mathbf{p}\\} \\cup B_{r'}^{\\text{E}}(\\mathbf{O})$ with $r' = \\sqrt{r^2 - \\|\\mathbf{p}\\|^2}$\n\n\nOkay, this being Mathematica.SE, I figure I could give code to draw the above, in addition to doing the maths. So, this draws the ball (point $\\mathbf p$, which is part of the ball, is drawn as a little filled square so it's visible):\nball[p_, r_] := Show[\n  RegionPlot[\n   x^2 + y^2 + p[[1]]^2 + p[[2]]^2 < r^2, {x, -5, 5}, {y, -5, 5}, \n   PerformanceGoal -> \"Quality\"],\n  Graphics[{Blue, Point[p]}]\n  ]\n\nand this is an animation of a ball of radius 3 as its center $\\mathbf p$ moves from $(0,0)$ to $(0,4)$:\n\n", "Conditional Gathering of lists": "\nYou need Split:\nSplit[list, Greater]\n\nSplitBy doesn't work here because the specified function is applied to each element separately before doing a normal Split.  What you want is a pair-wise comparison with a custom comparator, which is what Split does.\n\nLooking at this again you may want GreaterEqual to group identical elements in the same list:\nSplit[{2, 1, 1, 7, 5, 5, 5, 6, 0}, GreaterEqual]\n\n\n{{2, 1, 1}, {7, 5, 5, 5}, {6, 0}}\n\n\nFor fun I tried to do this operation without Split.  Since I was having fun I used Do rather than Module to localize symbols i and x.\nsplit = Last @ Reap @ Do[If[n > x, i++]; Sow[x = n, i], {i, 1}, {x, 1}, {n, #}] &;\n\nsplit @ {2, 1, 1, 7, 5, 5, 5, 6, 0}\n\n\n{{2, 1, 1}, {7, 5, 5, 5}, {6, 0}}\n\n\n", "evaluation - How do I write a ValueQ function that only returns True if there exists an OwnValue?": "\nLeonid and I had a very productive chat with the end result of Leonid asking me to go ahead and post the answer. If others have a better answer to this narrowly phrased question please do not let my submission deter you!\nEssentially the problem with these \"safe\" ValueQ questions is one of interpretation. What does it mean when we ask if a symbol has a value? \n\nMathematica says a symbol has a value if it has any of the following: OwnValues, UpValues, DownValues, NValues, SubValues or FormatValues. This makes sense in the context of MMA being essentially a glorified pattern matcher.\nFolks that come from a non MMA background with prior programming experience will say that a symbol only has a value if it has some OwnValues. This mirrors the behavior of nearly every non MMA programming language in existence. \n\nIn order for MMA to implement #1 above, MMA chooses to do some evaluation in order to determine if any of the Up/Down/N/Sub/Format values actually contain a meaningful value. This is the heart of the problem. If the user expects behavior #2, that can be had with a very simple function that requires no evaluation at all.\nSetAttributes[ownValueQ,HoldAll];\nownValueQ[s_Symbol] := ValueQ[s]; \nownValueQ[_]        := False\n\nThe above includes no evaluation as the implementation of ValueQ when handling OwnValues on a symbol is: \nHoldComplete[sym]=!=(HoldComplete[sym]/.OwnValues[sym])\n\n", "import - Importing from Excl - Mathmatica Stack Exchang": "\nWith syntax errors fixed:\n  Import[\" appropriate path /Desktop/stproj.xls\", \"xls\", \"Data\", 1]\n\nshould import the file.\nRegarding population counts you are getting, the = sign at the beginning of an input cell invokes Wolfram Alpha query which allows free-form input (hence you get no syntax error warnings). Interestingly, Wolfram Alpha interprets the query somehow and returns:\n\nIf you click the red + button on the top right to get the full results, you see why W|A returns with this result: \n\n", "programming - Reading from STDIN, or: how to pipe data into Mathematica": "\nStandard input\nTry using the Input and or InputString commands to read from the standard input. For example a program that does\nPrint[InputString[]];\n\nwhen run on the commandline with \n$>  echo \"Hello\" | mathematicaScript\nHello\n\nOf course this also works from the standard Mathematica workbook.\nFrom Invoked program\nUse Import with a \"!\" before the shell command. For example:\nImport[\"!help\", \"string\"]\n\nYou may use any valid format that the Import function supports.\n", "equation solving - Solve[ ] with Method -> Reduce gives a different result than Reduce[ ]": "\nSolve by default works with generic parameters, even if you use the option Method -> Reduce. To get the special parameter value m = 2 you need to set MaxExtraConditions to All:\nSolve[Sqrt[x + Sqrt[x]] - Sqrt[x - Sqrt[x]] == m Sqrt[x/(x + Sqrt[x])], x, Reals, \n    Method -> Reduce, MaxExtraConditions -> All]\nOut[1]= {{x -> ConditionalExpression[(4 - 8 m + 8 m^2 - 4 m^3 + m^4)/(4 - 8 m + 4 m^2),\n    1 < m <= 2]}}\n\n", "geography - Google Map in Notebooks?": "\nAll we need to create an interactive Google Map in the notebook is access to the individual tiles - and there is a relatively simple naming scheme for those tiles.  The most basic form of a tile URL looks like: http://mt0.google.com/vt/x=xi&y=yi&z=i, where $0\\leq xi,yi < 2^i$. For example, at zoom level z=0, there is one tile representing the whole earth:\nhttp://mt0.google.com/vt/x=0&y=0&z=0\n\nAt zoom level 1, there are 4 tiles that cover most of the earth:\n\nWith a little understanding of the Mercator projection, it's not hard to translate from lat/lng values to tile indices:\n{alng,blng} = First[{a,b} /. Solve[\n  {a*(-180)+b==0,a(180)+b==1},{a,b}]];\nlngToIndex[lng_, zoom_] := Floor[(alng*lng+blng)2^zoom];\nmercator[lat_] = Log[Abs[Sec[lat*Degree]+Tan[lat*Degree]]];\n{alat,blat} = First[{a,b} /. Solve[{a*mercator[85.0511287798066]+b==0,\n  a*mercator[-85.0511287798066]+b==1},{a,b}]];\nlatToIndex[lat_, zoom_] := Floor[(alat*mercator[lat]+blat)2^zoom];\nindicesToTileURL[x_Integer, y_Integer, zoom_Integer] := \n  \"http://mt0.google.com/vt/x=\" <> ToString[x] <> \"&y=\" <> \n    ToString[y] <> \"&z=\" <> ToString[zoom]\n\nNow, suppose I'd like to compute the URL of a tile in my neighborhood.\n{lat0,lng0} = CityData[\"Asheville\", \"Coordinates\"];\nx0=lngToIndex[lng0,10];\ny0=latToIndex[lat0,10];\nindicesToTileURL[x0,y0,10]\n\n\"http://mt0.google.com/vt/x=277&y=403&z=10\"\n\nWe can put this all together to set up an interactive zoomer.\nManipulate[\n  With[{x0=lngToIndex[lng0,zoom],y0=latToIndex[lat0,zoom]},\n    Grid[{\n      {Import[indicesToTileURL[x0-1,y0-1,zoom]],\n       Import[indicesToTileURL[x0,y0-1,zoom]],\n       Import[indicesToTileURL[x0+1,y0-1,zoom]]},\n       {Import[indicesToTileURL[x0-1,y0,zoom]],\n       Import[indicesToTileURL[x0,y0,zoom]],\n       Import[indicesToTileURL[x0+1,y0,zoom]]},\n      {Import[indicesToTileURL[x0-1,y0+1,zoom]],\n       Import[indicesToTileURL[x0,y0+1,zoom]],\n       Import[indicesToTileURL[x0+1,y0+1,zoom]]}\n    }, Spacings -> {0,0}]\n  ],{{zoom,13},Range[2,18]}]\n\n\nThis is really just proof of concept at this point.  There's quite a lot more that could be done.  You could use an EventHandler to allow dragging and panning and add other controls as well.  You'd need some error handling to deal with scrolling out of range.  You could also interface other map servers.\nAlso, I checked the terms of use of the Google Maps API available here:\nhttp://www.google.com/intl/en_us/help/terms_maps.html \nI don't see anything that violates their terms of use but, then, I'm not a lawyer.\n", "plotting - Using the same frame ticks for two different histograms": "\nPerhaps:\nSetOptions[Histogram, BarOrigin -> Left, \n  Frame -> {{True, None}, {True, None}}, FrameTicks -> Automatic];\n\ndata1 = Table[BesselJ[1, x], {x, 0, 500}];\ndata2 = Table[BesselJ[1, x], {x, 0, 100}];\nGraphicsGrid[{{\n   histo1 = Histogram[data1],\n   histo2 = Histogram[data2],\n   Show[\n    Histogram[data2, ChartElements -> None], \n    Histogram[data1, {HistogramList[data2][[1]]}]]}}]\n\n\nEdit\nuse just \nShow[Histogram[data2, ChartElements -> None], Histogram[data1]]\n\nif you don't want to reuse the same bins:\n\n", "plotting - Formatting legend text font": "\nTry using Style in the option values for PlotLegend->{...}. For example:\n  Plot[{Sin[x], Cos[x]}, {x, 0, 2 Pi}, \n  PlotLegend -> {Style[\"sine\", Red, Bold, 18], \"cosine\"},  \n  LegendLabel -> None]\n\ngives:\n\n", "plotting - Number format of axes in a plot": "\nOne can also define a KMB number format using NumberForm and its options as follows:\n g[a_] := Switch[a, \"3\", \"K\", \"6\", \"M\", \"9\", \"B\", \"12\", \"T\", _, \"\"]; \n kmbtForm[num_?NumericQ, digits_?IntegerQ] := \n StringReplace[#, \".\" ~~ x : (\"K\" | \"M\" | \"B\" | \"T\") -> x] &@\n ToString@\n NumberForm[N@#1, #2, \n  ExponentFunction -> (If[0 >= #, 0, 3 Quotient[#, 3]] &), \n  NumberFormat -> (StringJoin[#1, g[#3]] &)] & @@ {num, digits}\n\nUsage examples:\n  {kmbtForm[#, 3], kmbtForm[#, 4]} & \n   /@ {-1234, 12.34, 12345.67, 123456.7, 1234567., 123456789.123, 1234567891.} // Grid\n\ngives\n\nFor plot ticks, using a variation of Faysal's tick function with this formatting function \n tickfunc[xmin_, xmax_] := \n Function[tickNumber, {tickNumber, kmbtForm[tickNumber, 3]}] /@ \n FindDivisions[{xmin, xmax}, 10];\n\nin\n Plot[1000 x^3, {x, -10, 10}, Ticks -> {Automatic, tickfunc}]\n\ngives\n \n", "graphics - Adding a circle to an already existing drawing": "\nYou need a large enough PlotRange, or\ncirc11 = Show[circ, Graphics[Circle[{0, 0}, 40]], PlotRange -> All]\n\nEdit: are you referring to Heike's code? If so, you could simply replace her plot[t] function \nby something like:\nplot[t_] := \n Show[Graphics[{Circle[{0, 0}, 40], \n    Translate[Rotate[{circ[[1]], Point[{0, 0}]}, om2 t], centre[t]]}],\n   If[Abs[t] <= $MachineEpsilon, {}, \n   ParametricPlot[centre[s], {s, 0, t}, PlotStyle -> {Black}]], \n  PlotRange -> {{-2 radius, 2 radius}, {-2 radius, 2 radius}}, \n  Axes -> True]\n\nand the outer circle will be visible and not fixed.\n", "string manipulation - Splitting words into specific fragments": "\nHere is a hybrid recursive/StringReplaceList method.  It builds a tree representing all possible splits.\nNow with a massive speed improvement thanks to Rojo's brilliance.\nUpdated element list per bobthechemist.\nelements =\n  Array[ElementData[#, \"Symbol\"] &, 118] /.\n    {\"Uup\" -> \"Mc\", \"Uus\" -> \"Ts\", \"Uuo\" -> \"Og\"} //\n    ToLowerCase;\n\nf1[\"\"] = Sequence[];\n\nf1[s_String] := \n  Block[{f1}, \n    StringReplaceList[s, \n      StartOfString ~~ a : elements ~~ b___ ~~ EndOfString :> a ~~ f1@b\n  ]]\n\nTesting:\nf1 @ \"titanic\"\n\n\n{\"ti\" ~~ {\"ta\" ~~ {\"n\" ~~ {\"i\" ~~ {\"c\"}}, \"ni\" ~~ {\"c\"}}}}\n\n\nf1 @ \"archbishop\"\n\n\n{\"ar\" ~~ {\"c\" ~~ {\"h\" ~~ {\"b\" ~~ {\"i\" ~~ {\"s\" ~~ {\"h\" ~~ {\"o\" ~~ {\"p\"}}, \n     \"ho\" ~~ {\"p\"}}}}, \"bi\" ~~ {\"s\" ~~ {\"h\" ~~ {\"o\" ~~ {\"p\"}}, \"ho\" ~~ {\"p\"}}}}}}}\n\n\n\nResponding to comments below and whuber's post, an extension that generates string lists:\nf2[s_String] := { f1[s] } //. x_ ~~ y_ :> Thread[x ~~ \".\" ~~ y] // Flatten\n\nf2 @ \"titanic\"\n\nf2 @ \"archbishop\"\n\n\n{\"ti.ta.n.i.c\", \"ti.ta.ni.c\"}\n\n{\"ar.c.h.b.i.s.h.o.p\", \"ar.c.h.b.i.s.ho.p\", \"ar.c.h.bi.s.h.o.p\", \"ar.c.h.bi.s.ho.p\"}\n\n\n\nIncidentally:\nf2 @ \"inconspicuousness\"\n\n\nin.c.o.n.s.p.i.c.u.o.u.s.n.es.s\nin.c.o.n.s.p.i.c.u.o.u.s.ne.s.s\nin.c.o.n.s.p.i.c.u.o.u.sn.es.s\nin.c.o.n.s.p.i.cu.o.u.s.n.es.s\nin.c.o.n.s.p.i.cu.o.u.s.ne.s.s\nin.c.o.n.s.p.i.cu.o.u.sn.es.s\nin.co.n.s.p.i.c.u.o.u.s.n.es.s\nin.co.n.s.p.i.c.u.o.u.s.ne.s.s\nin.co.n.s.p.i.c.u.o.u.sn.es.s\nin.co.n.s.p.i.cu.o.u.s.n.es.s\nin.co.n.s.p.i.cu.o.u.s.ne.s.s\nin.co.n.s.p.i.cu.o.u.sn.es.s\ni.n.c.o.n.s.p.i.c.u.o.u.s.n.es.s\ni.n.c.o.n.s.p.i.c.u.o.u.s.ne.s.s\ni.n.c.o.n.s.p.i.c.u.o.u.sn.es.s\ni.n.c.o.n.s.p.i.cu.o.u.s.n.es.s\ni.n.c.o.n.s.p.i.cu.o.u.s.ne.s.s\ni.n.c.o.n.s.p.i.cu.o.u.sn.es.s\ni.n.co.n.s.p.i.c.u.o.u.s.n.es.s\ni.n.co.n.s.p.i.c.u.o.u.s.ne.s.s\ni.n.co.n.s.p.i.c.u.o.u.sn.es.s\ni.n.co.n.s.p.i.cu.o.u.s.n.es.s\ni.n.co.n.s.p.i.cu.o.u.s.ne.s.s\ni.n.co.n.s.p.i.cu.o.u.sn.es.s\n\n\n", "list manipulation - How to \"ignore\" an element of Map or MapIndexed": "\nThis specific behaviour can be achieved using\nIf[condition, something, Unevaluated@Sequence[]]& /@ list\n\nThe key is Sequence[].  Unevaluated prevents it from disappearing from inside the If.\nAlternatively you can use Cases (or many other solutions shown in other answers and comments---some of these solutions may be better suited for the problem but Sequence[] has its place too).\nCases[list, element_ /; condition :> something]\n\n", "Plotting Complex Quantity Functions": "\nThe way you could use ContourPlot here, assuming your variable f is complex (f == x + I y) :\neqn[x_, y_] := (25 Pi ( x + I y) I)/(1 + 10 Pi ( x + I y) I)\n\n{ContourPlot[Re@eqn[x, y], {x, -1, 1}, {y, -1, 1}, PlotPoints -> 50], \n ContourPlot[Im@eqn[x, y], {x, -1, 1}, {y, -1, 1}, \n PlotRange -> {-0.5, 0.5}, PlotPoints -> 50]}\n\n\nThese are respectively real and imaginary parts of the function eqn. \nLet's plot the absolute value of eqn :\nPlot3D[ Abs[ eqn[x, y]], {x, -1, 1}, {y, -1, 1}, PlotPoints -> 40]\n\n\nAnd we complement with the plot of real and imaginary parts of eqn in the real domain :\neqnR[x_] := (25 Pi x I)/(1 + 10 Pi x I)\nPlot[{ Tooltip@Re@eqnR[x], Tooltip@Im@eqnR[x]}, {x, -0.25, 0.25}, \n      PlotStyle -> Thick, PlotRange -> All]\n\n\n", "programming - How do I generate the upper triangular indices from a list?": "\nThe solution is straightforward: Subsets, specifically\nSubsets[{1,2,3}, {2}]\n\ngives\n\n{{1, 2}, {1, 3}, {2, 3}}\n\n\nTo generate the lower indices, just Reverse them\nReverse /@ Subsets[{1,2,3}, {2}]\n\nwhich gives\n\n{{2, 1}, {3, 1}, {3, 2}}\n\n\n", "replacement - Replacing composite variables by a single variable": "\nYou can't use replacements that way, because Mathematica does not do replacements on expressions the way they appear to you. To see what I mean, take a look at the FullForm of your expression:\nx/(y*z) // FullForm\nOut[1]= Times[x,Power[y,-1],Power[z,-1]]\n\nWhereas, the replacement that you're using is Times[y, z]. \nIn general, it is not a good idea to use approaches that exploit the structure of expressions to do mathematical replacements. You might think you have nailed the replacement down, but it will break for a slightly different equation or terms.\nTo do this in a fail safe manner, you can use Simplify as:\nSimplify[x/(y z), w == y z]\nOut[2]= x/w\n\nFor more complicated examples, you might have to use Eliminate. From the documentation:\nEliminate[{f == x^5 + y^5, a == x + y, b == x y}, {x, y}]\nOut[3] = f == a^5 - 5 a^3 b + 5 a b^2\n\nAlso read the tutorial on eliminating variables.\n", "symbolic - What is a type in Wolfram Mathematica programming language?": "\nThe nearest Mathematica has to \"types\" are Heads of expressions that are Atoms. For example:\nThrough[{AtomQ, Head}[2]]\n\n{True, Integer}\n\nThrough[{AtomQ, Head}[2 + I]]\n\n{True, Complex}\n\nThrough[{AtomQ, Head}[\"cat\"]]\n\n{True, String}\n\nand so on...\nThere are also somewhat different \"types\" in the context of Compile.\n", "gpu - Why does CUDAQ (from CUDALink) download data from Wolfram servers?": "\nIt installs CUDA Resources, as indicated in the manual page. The resources are platform and driver specific and can also be downloaded manually from here.\n", "programming - Does every Symbol in Mathematica induce a monad?": "\nMathematica provides a perfect way to define monad by setting UpValues and DownValues of some symbol. Please, find specifications for monads Maybe and State below.\n\nMonad Maybe:\nDownValues[Just] = {Just[(a: Just[x_])] :> Just[x]};\nUpValues[Just] = \n    {(expr: (op: Except[Just | List | Trace | UpValues | DownValues])[\n       a___, Just[b_], c___]) /;  \n       !MatchQ[\n           Unevaluated[expr],\n           HoldPattern[If[__, __, Just[x_]] | If[__, Just[x_], __]]\n       ] :> Just[op[a, b, c]]};\n\nRule from DownValues[Just] stands for monad Maybe multiplication law. That is removing of head duplicates. Rule from UpValues[Just] stands for bind operation of monad Maybe. One need to use special pre-condition for this pattern because Mathematica uses some wrapping code to convert evaluating/reducing expression in standard form by low-level call MakeBoxes. For example, let's see this wrapping code:\nHold[\n If[False, 3,\n  With[{OutputSizeLimit`Dump`boxes$ =\n     Block[{$RecursionLimit = Typeset`$RecursionLimit},\n      MakeBoxes[Just[3], StandardForm]\n      ]\n    },\n   OutputSizeLimit`Dump`loadSizeCountRules[]; \n   If[TrueQ[BoxForm`SizeCount[OutputSizeLimit`Dump`boxes$, 1048576]], \n    OutputSizeLimit`Dump`boxes$,\n    OutputSizeLimit`Dump`encapsulateOutput[\n     Just[3],\n     $Line,\n     $SessionID,\n     5\n     ]\n    ]\n   ],\n  Just[3]\n  ]\n ]\n\nThat's why rule from UpValues[Just] has special pre-condition for being inside of condition expression. Now one can use symbol Just as a head for computations with exceptions:\nUpValues[Nothing] = {_[___, Nothing, ___] :> Nothing};\nJust[Just[123]]\n(*\n ==> Just[123]\n*)\n\nJust[123] + Just[34] - (Just[1223]/Just[12321])*Just[N[Sqrt[123]]]\n(*\n ==> Just[155.899]\n*)\n\nThanks to @celtschk for great comments of this point.\nMonad State:\nreturn[x_] := State[s \\[Function] {x, s}];\nbind[m_State, f_] := State[r \\[Function] (f[#[[1]]][#[[2]]] & @ Part[m, 1][r])];\nrunState[s_, State[f_]] := f[s];\n\nFor monad State I didn't use UpValues and DownValues just for similarity with Haskell notation. Now, one can define some sequential computation as State value with complex state logics as a monadic computation by using return and bind operations. Please, see an example:\ncomputation =\n  Fold[bind, return[1], \n   Join[{a \\[Function] s \\[Function] {a, a + s}, \n     b \\[Function] s \\[Function] {b, s + b/(3 s)}, \n     c \\[Function] s \\[Function] {c, s + (s^2 + c)}},\n    Array[x \\[Function] a \\[Function] s \\[Function] {a, s}, 300]\n    ]\n   ];  \n\nTo get more effective computation one can use runState operation:\nFold[#2[#1[[1]]][#1[[2]]] &, runState[23, return[1]], \n    Join[{a \\[Function] s \\[Function] {a, a + s}, \n          b \\[Function] s \\[Function] {b, s + b/(3 s)}, \n          c \\[Function] s \\[Function] {c, s + (s^2 + c)}},\n         Array[x \\[Function] a \\[Function] s \\[Function] {a, s}, 3000]\n  ]\n ]\n (*\n  ==> {1, 3119113/5184}\n *)\n\n\nConclusion: \n\nIdeas of rule-based programming and using Head as type identifier allow user to express any(?) programming concept in Mathematica. For example, as it has just been shown, monads State and Maybe from Haskell;\nUsing of UpValues and DownValues for assigning rules to symbols and using of generalized operations (such as bind is) allow user to put expressions in different monadic environments.\n\n", "plotting - SIGSEGV error with 3D Plots": "\nThe Mathematica Knowledge Base has an article on this issue.\nIt\u00b4s caused by an error with open source graphics drivers. The mesa solution works by bypassing your graphics card and so will make things run a bit more slowly.\n", "list manipulation - Why can't NumberQ be used as the head of a pattern?": "\nThe syntax _foo indicates that you're looking for a pattern with the head foo. NumberQ is not a Head, but a test returning a boolean True or False depending on whether the expression is a number or not. So you'd have to use it with PatternTest as _?NumberQ. For your example, the following should work:\nCases[list, _?NumberQ]\n\nIf you wanted to stick with DeleteCases, then you'll have to negate the test using either of the three constructs below:\nDeleteCases[list, _?(Composition[Not, NumberQ])]\nDeleteCases[list, _?(! NumberQ[#] &)]\nDeleteCases[list, Except[_?NumberQ]]\n\nBeware that ? has a very high precedence and binds very tightly and hence the parentheses are necessary in the first two constructs. See this question for more info.\n", "numerical integration - NDSolve, Schr\u00f6dinger equation, and decaying solution": "\nnoeckel\u2019s answer on StackOverflow is spot on. This is not a Mathematica issue, this is a mathematical issue. Namely, Mathematica is giving you the correct solution to the system of differential equation and boundary conditions given. The conditions given (and in particular the derivative imposed at the origin) are incompatible with the expected decay. Bear in mind that, at $r \\geq 5$, your wavefunction will have two components of the form $\\exp(\\alpha r)$ and $\\exp(-\\alpha r)$. For each set of boundary conditions, you get a different linear combination of these two, and the only conditions that make sense are those for which the diverging term is zero.\n", "list manipulation - What is a Mathematica packed array?": "\nI will answer a couple of your questions only.\nSpace efficiency\nPacked arrays are significantly more space efficient. Example: Let's create an unpacked array, check its size, then do the same after packing it:\nf = Developer`FromPackedArray[RandomReal[{-1, 1}, 10000]];\nByteCount[f]\nByteCount[Developer`ToPackedArray[f]]\n\n(*\n320040\n80168\n*)\n\nTime efficiency\nThe difference seems to be how they are stored; packed arrays can only contain objects of the same type, so mma does not need to keep track of the type of each element. This can also speed up operations with them. Define\nClearAll[timeIt];\nSetAttributes[timeIt, HoldAll]\ntimeIt[expr_] := Module[{t = Timing[expr;][[1]], tries = 1},\n    While[t < 1.,\n    tries *= 2;\n    t = AbsoluteTiming[Do[expr, {tries}];][[1]];\n    ];\n    Return[t/tries]]\n\nthen\nClearAll[f, fpacked];\nf = Developer`FromPackedArray[RandomReal[{-1, 1}, 500000]];\nfpacked = Developer`ToPackedArray[RandomReal[{-1, 1}, 500000]];\n\nfpacked.fpacked // timeIt\nf.f // timeIt\n\nSin[fpacked] // timeIt\nSin[f] // timeIt\n\n(*\n0.0001610173\n0.01167263\n0.00487482\n0.01420070\n*)\n\nUnpacking\nTo be warned of arrays being unpacked, you can do SetSystemOptions[PackedArrayOptions->UnpackMessage->True] or, in versions after 7, On[\"Packing\"] (thanks to OleksandrR for pointing this out). The you see that eg Select unpacks: try Select[fpacked, 3] and a message is produced. Also assigning a value of different type to a packed array unpacks it: try fpacked[[2]] = 4 to see this.\nThis unpacking explains mysterious slowdowns in mma code most of the time for me.\nAddressing\nIt appears that it is twice as slow to address a single element in a packed vs an unpacked array:\nClearAll[f, fpacked];\nf = Developer`FromPackedArray[RandomReal[{-1, 1}, 500000]];\nfpacked = Developer`ToPackedArray[RandomReal[{-1, 1}, 500000]];\n\nfpacked[[763]] // timeIt\nf[[763]] // timeIt\n(*\n4.249656*10^-7\n2.347070*10^-7\n*)\n\nAppendTo is not faster:\nAppendTo[fpacked, 5.] // timeIt\nAppendTo[f, 5.] // timeIt\n(*\n0.00592841\n0.00584807\n*)\n\nI don't know if there are other kinds of addressing-like operations that are faster for packed arrays (I doubt it but could be wrong).\nAside\nIn the Developer` context there are these names involving Packed:\nSelect[\n Names[\"Developer`*\"],\n Not@StringFreeQ[#, ___ ~~ \"Packed\" ~~ ___] &\n ]\n(*\n{\"Developer`FromPackedArray\", \"Developer`PackedArrayForm\", \n\"Developer`PackedArrayQ\", \"Developer`ToPackedArray\"}\n*)\n\nDeveloper`PackedArrayForm does this:\nClearAll[f, fpacked];\nf = Developer`FromPackedArray[RandomInteger[{-1, 1}, 5]];\nfpacked = Developer`ToPackedArray[RandomInteger[{-1, 1}, 5]];\n\nDeveloper`PackedArrayForm[f]\nDeveloper`PackedArrayForm[fpacked]\n(*\n{-1, -1, -1, -1, -1}\n\"PackedArray\"[Integer, <5>]\n*)\n\nSo, you could set $Post = Developer`PackedArrayForm and then packed arrays would be displayed in a special way. I am not sure if this has any other sideeffects (this has been suggested in this great answer by ruebenko).\n", "syntax - NMinimize with defined function call getting error NMinimize::nnum": "\nThe symbol f is the name of the function, and calling f with the proper argument structure (i.e. 1 argument, like x) replaces it with the function value (the definition on the right hand side). Since f is not called with an argument in your example in NMinimize, it is not replaced by the right hand side, thus a symbol is left which cannot be minimized.\nIf you define f as a function of y and not x, or even as a pure function:\nf = #^4 - 3 #^2 - # &;\n\nit is still not enough, as NMinimize then is replaced as:\nNMinimize[f, x] --> NMinimize[#^4 - 3 #^2 - # &, x]\n\nwhere # and x are not bound, as x now you can see that x does not appear at all in the function. On the other hand, this works:\nNMinimize[foo^4 - 3 foo^2 - foo, foo]\n\n\n{-3.51391, {foo -> 1.30084}}\n\nAlso note, that if you define your function in the standard way like this:\nf[x_] := x^4 - 3 x^2 - x;\n\nthen calling f on its own returns the symbol f itself, as f does not have any OwnValue (only DownValues), therefore NMinimize[f, x] does not make sense:\nf\n\n\nf\n\n{OwnValues[f], DownValues[f]}\n\n\n{{}, {HoldPattern[f[x_]] :> x^4 - 3 x^2 - x}}\n\n", "graphs and networks - NumberOfSpanningTrees command not working correctly": "\nThe Combinatorica package is now considered obsolete and not compatible with Mathematica's built-in Graph theory functionality. The function CycleGraph, which you are using, is a built-in function and is not understood by the Combinatorica package. You have to replace CycleGraph[i] simply by Cycle[i], which is the corresponding object in Combinatorica. You can confirm this that by looking at (for example) CycleGraph[5] and ShowGraph[Cycle[5]]:\nGraphicsRow[{CycleGraph[5] , ShowGraph[Cycle[5]]}]\n\n\nActually, the Combinatorica package still has a lot of functionality that has nothing equivalent in the Kernel (and it is not clear if this will ever change completely). On the other hand it is essentially undocumented (unless you buy the book by Skiena and Pemmaraju) and the quality of Mathematica programming is not great (there are also bugs that never seem to get fixed). \n", "Calling Correct Function for Plotting DiracDelta": "\nTo create the plot you could replace any occurrence of DiracDelta[a] with something like 10000 UnitStep[1/10000 - a^2]], so for example to plot\nf[x_] := DiracDelta[x - 2] + DiracDelta[x + 2]\n\nyou could do something like\nPlot[Evaluate[f[x] /. DiracDelta[a_] :> 10000 UnitStep[1/10000 - a^2]], \n  {x, -4, 4}, Exclusions -> None, PlotPoints -> 800]\n\n\nNote that for Mathematica to see the discontinuities you need to increase the number of plot points. The number of points needed will depend on the plot range, so you might have to tweak that. \n", "calculus and analysis - Does $x>0$ imply that $x\\in\\mathbb{R}$?": "\nThe most direct way to test this is probably the following:\n$Assumptions = x > 0;\nElement[x, Reals] // Simplify\n(* Out[1]= True *)\n\n$Assumptions = True;\nElement[x, Reals] // Simplify\n(* Out[4]= x \u2208 Reals *)\n\nSo $x>0$ seems to imply that $x$ is real.\n", "front end - How to replace the style of the inline cell in a StyleSheet": "\nUsing the Option Inspector:\nIn the Format menu choose Option Inspector, select Cell Options > New Cell Defaults and edit the value of the option DefaultNewInlineCellStyle. \nIn the screenshot below, I changed the value of this option from {} to \"Subsection\" using the drop-down menu.\nThe first two cells on the left notebook show the inline cell styles before and after changing the value of the option  in the Option Inspector.\n\nUsing SetOptions:\nTo change the for the new inline cells for the active notebook, use\n SetOptions[EvaluationNotebook[], DefaultNewInlineCellStyle -> \"Section\"]\n\nExample cell containing an inline cell: \n\nFor the style change to apply to all new inline cells in the current front-end session, use\n SetOptions[$FrontEndSession, DefaultNewInlineCellStyle -> \"Section\"]\n\nIf you want to have the changes to persist across sessions, use\n SetOptions[$FrontEnd, DefaultNewInlineCellStyle -> \"Section\"]\n\nFinally, to reset any of the changes, use\n SetOptions[xxx, DefaultNewInlineCellStyle -> Inherited]\n\nwhere xxx is EvaluationNotebook[], or $FrontEndSession or $FrontEnd.\nSetting your own custom styles:\n SetOptions[EvaluationNotebook[], \n DefaultNewInlineCellStyle -> {FontFamily -> \"SketchFlowPrint\", FontSize -> 24}]\n\n\n", "plotting - Using PlotLegends with Show messes up the graphics": "\nWhen Show is used the legends use ShowLegend. Here is a demo:\ndepth4 = Range[20]^3;\nplot = ListLogLogPlot[Sort[depth4], PlotRange -> {{1, 50000},\n     {1, 50000}}, Joined -> True, PlotStyle -> {Purple},\n   BaseStyle -> {FontSize -> 14}];\nline = LogLogPlot[11024 x^(-0.94232), {x, 1, 100000},\n   PlotStyle -> {Orange, Dashed, Thick}];\nline2 = LogLogPlot[31862 x^(-1.07076), {x, 1, 100000},\n   PlotStyle -> {Green, Dotted, Thick}];\n\nNeeds[\"PlotLegends`\"]\nShowLegend[Show[plot, line, line2, ImageSize -> 500],\n {{{Graphics[{Purple, Line[{{0, 0}, {2, 0}}]}], \"   depth4\"},\n   {Graphics[{Orange, Dashed, Line[{{0, 0}, {2, 0}}]}], \"   line\"},\n   {Graphics[{Green, Dashed, Line[{{0, 0}, {2, 0}}]}], \"   line2\"}},\n  LegendPosition -> {0.7, 0.2}, LegendSize -> {0.45, 0.4},\n  LegendShadow -> False}]\n\n\n", "How to set a rule in pattern matching to change a string from one form to another": "\nIt is not quite clear what you are aiming to do, but perhaps this would work:\nStringReplace[\"r1abc=CxxC(00)r2xyz\",\n R1__ ~~ \"=C\" ~~ x___ ~~ \"C(00)\" | \"C(0)\" ~~ R2__ :> \n  R1 <> \"C(O)\" <> x <> \"C\" <> R2]\n\n\nr1abcC(O)xxCr2xyz\n\n", "output formatting - How one can programmatically transform a text into Gothic, DoubleStruck, or something similar?": "\nEdit: \nQuoting from Heike\u00b4s comment: \"The font families used for Greek, script, gothic, and double struck symbols are respectively \"Mathematica1\", \"Mathematica5\", \"Mathematica6\", and \"Mathematica7\" \"\nWith this knowledge, just use Styletogether with the FontFamily option:\nStyle[\"Doth this help?\", FontFamily -> \"Mathematica6\", \n      FontSize -> 100]\n\n\nNow for my first version, which seems like prime obfuscation. The one benefit is that characters that are not in the special fonts do not get replaced. So I\u00b4ll leave this for purely educational purposes:\ntext = \"Hello world!\";\n\ngothic = StringReplace[\n   text, {x_?UpperCaseQ :> \n     ToString @ ToExpression[\"\\\\[GothicCapital\" <> x <> \"]\"],\n          x_?LowerCaseQ :> \n     ToString @ ToExpression[\"\\\\[Gothic\" <> ToUpperCase[x] <> \"]\"]}];\n\nStyle[gothic, 30]\n\n\n\n\nYou can get the right prefixes for this solution by looking at the FullForm of your favorite special character (here: Gothic or GothicCapital).\n", "options - Extract values for ViewMatrix from a Graphics3D": "\nThe documentation is wrong. It should have been fixed, but AbsoluteOptions does not work with ViewMatrix (on all platforms). M- introduced interactive 3D graphics since V6, and after that getting values through AbsoluteOptions (which is an old function) becomes very tricky since the Kernel (who evaluates the option) cannot fully know what is happening on FrontEnd side. To compare, before V6, the Kernel was solely responsible for rendering 3D scene (Postscript!), and of course it could tell every matrix value.\nInstead, you can try to use 5 values that can define the matrix using Dynamic:\nViewPoint, ViewAngle, ViewVertical, ViewCenter, and ViewRange.\n\nFor instance, the following example takes those 5 values from one graphics, and use it for another:\nDynamicModule[\n {point = {1.3, -2.4, 2}, angle = N[35 Degree], vertical = {0, 0, 1}, \n  center = Automatic},\n Grid[{{\n    Framed[\n     Graphics3D[{\n       (* Objects *)\n       EdgeForm[], Specularity[White, 20],\n       FaceForm[Red], Sphere[{-0.2, -0.1, -0.3}, .2],\n       FaceForm[Blue], Cylinder[{{0., 0.3, -.5}, {0., 0.3, 0.}}, .1],\n       FaceForm[Green], Cone[{{0.2, 0., -0.5}, {0.2, 0., -0.1}}, .2]\n       },\n      Boxed -> True, Lighting -> \"Neutral\",\n      ImageSize -> 300, RotationAction -> \"Clip\",\n\n      (* View control *)\n      ViewPoint -> Dynamic[point],\n      ViewAngle -> Dynamic[angle],\n      ViewVertical -> Dynamic[vertical],\n      ViewCenter -> Dynamic[center]\n      ],\n     FrameStyle -> LightGray],\n\n    (* The second object *)\n    Framed[\n     Plot3D[Sin[x y], {x, 0, 3}, {y, 0, 3},\n      ImageSize -> 300, Axes -> False,\n      (* View control *)\n      ViewPoint -> Dynamic[point],\n      ViewAngle -> Dynamic[angle],\n      ViewVertical -> Dynamic[vertical],\n      ViewCenter -> Dynamic[center]\n      ],\n     FrameStyle -> LightGray]\n    }}]\n ]\n\nExamples:\n \nand\n\nThis free course explains about the values in vary detail (with some cool demos--OK. shameless self-promotion :) ):\nWolfram Training: Visualization: Advanced 3D Graphics\nAlso, in essence, you can reconstruct the view matrix and projection matrix out of those values, but I need to take a look at an old textbook to make sure that I am not saying something wrong :)\n", "programming - Is there a convenient way to copy/paste text-interspersed SE code snippets into Mathematica?": "\nCode extractor using the StackExchange API\nThe following code uses the 2.0 version of the SE API and has also been cleaned up a bit (place it in your kernel's init.m or your custom functions package if you'd like to be able to use it anytime).\nThe function takes a single string argument, which is the URL obtained from the share link under a question/answer.\nExample\n\n\nimportCode[url_String] := With[\n  {\n   filterCode = StringCases[#, (\"<pre><code>\" ~~ (\"\\n\" ...) ~~ x__ ~~ (\"\\n\" ...) ~~ \"</code></pre>\") /; \n        StringFreeQ[x, \"<pre><code>\" | \"</code></pre>\"] :> x] &, \n   convertEntities = StringReplace[#, {\"&gt;\" -> \">\", \"&lt;\" -> \"<\", \"&amp;\" -> \"&\", \"&quot;\" -> \"\\\"\"}] &, \n   makeCodeCell = Scan[CellPrint@Cell[Defer@#, \"Input\", CellTags -> \"Ignore\"] &, Flatten@{#}] &,\n   postInfo = Import[ToString@StringForm[\n        \"http://api.stackexchange.com/2.1/posts/`1`?site=`2`&filter=!9hnGsretg\", #3, #1] & @@ \n        {First@StringCases[#, Shortest[s__] ~~ \".\" ~~ ___ :> s], #2, #3} & @@ \n        StringSplit[StringDrop[url, 7], \"/\"][[;; 3]], \"JSON\"]\n   },\n  OptionValue[\"items\" /. postInfo, \"body\"] // filterCode // convertEntities // makeCodeCell]\n\nNOTE: I don't do any rigorous error checking or check to see if you're entering a valid Stack Exchange URL or if the question/answer is deleted (deleted posts cannot be accessed via the API), etc. So if you get any errors, it might be worthwhile to check if there's something wrong on the site.\nAlso, SE API limits you to 300 calls/day/IP, if I remember correctly. That's quite a lot of calls for any reasonable person and ideally, you shouldn't cross that. Nevertheless, a possibility of being throttled is something to keep in mind if you also happen to be playing with the API for other purposes such as site statistics, etc.\n", "symbolic - Why does Assuming[x > 0, TrueQ[x > 0]] return False?": "\nBecause the assumption system is not called during the standard evaluation sequence, it is only called when Simplify, FullSimplify, Sum, Integrate etc... are used.\nThus, x>0 remains unevaluated:\nAssuming[x > 0, x > 0] \n(*\n==> x > 0\n*)\n\nand TrueQ then returns False:\nAssuming[x > 0, TrueQ[x > 0]]\n(*\n==> False\n*)\n\nIf, however, you run Simplify before TrueQ, you get the expected result\nAssuming[x > 0, TrueQ[Simplify[x > 0]]]    \n(*\n==> True\n*)\n\n\nAs an aside, there is some \"hidden\" functionality in the Assumptions` context that lets you perform various checks and calculations within the assumption system. Run ?Assumptions`* to see what's available. You code, in particular, could be written as\nAssuming[x > 0, Assumptions`APositive[x - 0]]\n(*\n==> True\n*)\n\n", "How to set row height in Grid?": "\nThe Pane construct is quite flexible. I cannot imagine not using it with table for fluid sizes control and features. Here are your data:\ndata={{\"000000000\\n111111111\\n222222222\",\"000000000\"},{\"000000000\",\"000000000\"}}\n\nThis will fix the cell size and cut off the content if it won't fit:\nGrid[Map[Pane[#, ImageSize -> {80, 30}] &, data, {2}], Frame -> All]\n\n\nThis will fix the cell size and shrink the content if it won't fit\nGrid[Map[Pane[#, ImageSize -> {80, 30}, ImageSizeAction -> \n\"ShrinkToFit\"] &, data, {2}], Frame -> All]\n\n\nUse Scrollbars to view the content that did not fit\ndata2 = 200! {{1, 1}, {1, 1}};\nGrid[Map[Pane[#, ImageSize -> {200, 100}, Scrollbars -> \n{False, True}] &, data2, {2}], Frame -> All]\n\n\nForbid line-breaks to use horizontal scrolling only for small row height (updated after @Yu-Sung comment):\ndata2 = 200! {{1, 1}, {1, 1}};\nGrid[Map[Pane[#, ImageSize -> {150, 30}, Scrollbars -> {True, False}] &, \ndata2, {2}], Frame -> All, BaseStyle -> {LineBreakWithin -> False}]\n\n\n", "import - How to load thumbnail, not image?": "\n\nIn Mathematica 8, few image files are supported natively--meaning, without calling external MathLink executables, which results in much faster speed (order of magnitude) and great efficiency in memory usage. Currently only TIFF and JPEG work that way. PNG was close but it was cut-off. What I am saying is that you will see much speed up in the future for PNG reading/writing.\nNow, I hate to say this, but with M8, there is not much thing to do to improve the speed of PNG (unless you are willing to venture and call libpng directly using LibraryLink. Probably out of bound for most users...).\nAgain, current Import does not support thumbnail read from image files (maybe we should). I am not sure PNG has its own embedded thumbnail (I think it has... sure for JPEG). So it is no go either...\nThe Windows system uses Thumbs.db to store \"pregenerated\" thumbnails. But again, M- can't utilize these files except in system dialog boxes (like SystemDialogInput[\"FileOpen\"]). It is in fact quite tricky to handle this DB so I don't think that the support will happen at all.\nIf you expect your code to access folders frequently, it won't be bad idea to maintain its own thumbnail database using Thumbnail function (which is quite fast). Possibly some hidden folder with miniaturized images for future use, or some specialized DB file (a notebook or DumpSave). But, yes, it is quite involving... I have to say.\n\nSorry, no good answer.\n", "curated data - How to save ChemicalData queries so that they are available immediately on notebook load?": "\nYou can \"preload\" all the data to your computer so that it doesn't have to look it up each time. An added advantage is that it'll also be available when you're offline. This is covered in this support article on wolfram.com. In your case, you would do:\nChemicalData[All,\"Preload\"]\nRebuildPacletData[]\n\nand you should be all set. Note that it will take a while to download all the data from their servers.\n", "FindInstance with a Diophantine equation seems to go on forever": "\nIt does not seem surprising that a search space 2000 times larger results in a substantially longer computation time.\nHere is a much more direct way to find a solution:\nSqrt @ IntegerPartitions[2012^2, {5}, Range[2012]^2, 1]\n\n\n{{2011, 63, 7, 2, 1}}\n\n\n", "linear algebra - Entering block matrices for an arbitrary matrix size": "\nWe can construct this matrix directly as a SparseArray. This allows some classes of numerical matrices to be stored as packed arrays while being combined with symbolic or exact vectors (or vice versa), so there can be storage and run-time efficiency reasons for using a SparseArray, in addition to the obvious benefit of direct construction. On the other hand, the function needed to construct a sparse block matrix is undocumented.\nDefine:\nf[A_?MatrixQ, t_?VectorQ] /; Length[A] == Length[t] := \n SparseArray`SparseBlockMatrix[{\n  {1, 1} -> A, {1, 2} -> Transpose[{t}], {2, 2} -> {{1}}\n }, Dimensions[A] + 1];\n\nNow:\nf[IdentityMatrix[5], Array[a, 5]]\n\ngives (as a sparse array; if you want exactly this output you must first use Normal):\n\n", "plotting - How to add a vertical line to a plot": "\nAn easy way to add a vertical line is by using Epilog.\nHere is an example:\nf[x_] := (x^2 z)/((x^2 - y^2)^2 + 4 q^2 x^2) /. {y -> \u03c0/15, z -> 1, q -> \u03c0/600}\nQuiet[maxy = FindMaxValue[f[x], x]*1.1]\nlineStyle = {Thick, Red, Dashed};\nline1 = Line[{{\u03c0/15 + 1/50, 0}, {\u03c0/15 + 1/50, maxy}}];\nline2 = Line[{{\u03c0/15 - 1/50, 0}, {\u03c0/15 - 1/50, maxy}}];\nPlot[{f[x], f[\u03c0/15], f[\u03c0/15]/Sqrt[2]}, {x, \u03c0/15 - 1/20, \u03c0/15 + 1/20},\n    PlotStyle -> {Automatic, Directive[lineStyle], Directive[lineStyle]},\n    Epilog -> {Directive[lineStyle], line1, line2}]\n\n\nCaveat\nWhile adding lines as Epilog (or Prolog) objects works most cases, the method can easily fail when automated, for example by automatically finding the minimum and maximum of the dataset. See the following examples where the red vertical line is missing at $x=5$:\ndata1 = Table[0, {10}];\ndata2 = {1., 1., 1.1*^18, 1., 6., 1.2, 1., 1., 1., 148341.};\n\nRow@{\n  ListPlot[data1, Epilog -> {Red, Line@{{5, Min@data1}, {5, Max@data1}}}],\n  ListPlot[data2, Epilog -> {Red, Line@{{5, Min@data2}, {5, Max@data2}}}]\n  }\n\n\nIn the left case, Min and Max of data turned out to be the same, thus the vertical line has no height. For the second case, Mathematica fails to draw the line due to automatically selected PlotRange (selecting PlotRange -> All helps). Furthermore, if the plot is part of a dynamical setup, and the vertical plot range is manipulated, the line endpoints must be updated accordingly, requiring extra attention.\nSolution\nThough all of these cases can be handled of course, a more convenient and easier option would be to use GridLines:\nPlot[{f[x]}, {x, \u03c0/15 - 1/20, \u03c0/15 + 1/20},\n    GridLines -> {{\u03c0/15 + 1/50, \u03c0/15 - 1/50}, {f[\u03c0/15], f[\u03c0/15]/Sqrt[2]}}, PlotRange -> All]\n\n\nAnd for the extreme datasets:\nRow@{\n  ListPlot[data1, GridLines -> {{{5, Red}}, None}],\n  ListPlot[data2, GridLines -> {{{5, Red}}, None}]\n  }\n\n\n", "plotting - Interactively extract points from a plot (ListPlot or SmoothDensityHistogram)": "\nThis is basically the same as what b.gatessucks is doing. The main addition is that I've put all the locators in one list. To add vertices to the polygon you just click somewhere on the graph. I've also added a reset button and a button that prints the indices of the points inside the polygon which makes it easier to copy.\npoints = RandomSample[\n   Transpose[{Flatten[{RandomReal[{0, 5}, 20], RandomReal[{4, 4.5}, 10]}], \n     Flatten[{RandomReal[1, 20], RandomReal[{1.5, 2}, 10]}]}], 30];\n\nwinding[poly_, pt_] := Round[(Total @ Mod[(# - RotateRight[#]) &@\n  (ArcTan @@ (pt - #) & /@ poly), 2 Pi, -Pi]/2/Pi)]\n\nDynamicModule[{pl, pos},\n pl = SmoothDensityHistogram[points, ColorFunction -> \"TemperatureMap\"];\n Manipulate[\n  pos = Pick[Range[Length[points]], Unitize[winding[poly, #] & /@ points], 1];\n  Show[pl, \n   Epilog -> {{Darker[Green], PointSize[Medium], Point[points[[pos]]]},\n     {Black, Point[Complement[points, points[[pos]]]]},\n     {EdgeForm[{Red, Dashed}], FaceForm[], Polygon[poly]}}],\n\n  {{poly, {}}, Locator, LocatorAutoCreate -> All},\n  Row[{Button[\"Copy Points\", Print[pos]], Button[\"Reset\", poly = {}; pos = {}]}]]]\n\n\n", "calculus and analysis - Bug in Integrate for Mathematica": "\nI think it is indeed a bug specific to version 8 of Mathematica. \nThe same integrals in version 7 give the correct result. \nCompare this issue with this answer. \nIn the both cases one works with assumptions which make Integrate behaving improperly.\nEdit 1\nIt seems that definite integrals are calculated correctly and if we subtract the limits of integration in the way that the boolean formula is slightly neutralized, then the result is correct, e.g. :\nIntegrate[ regFunc[x, y]*((4 x + 3 y) (3 x + 2 y))^4, {x, -10, 10}, {y, -10, 10}] // N\n\nIntegrate[ regFunc[x, y]*(12 x^2 + 17 x*y + 6 y^2)^4, {x, -10, 10}, {y, -10, 10}] // N\n\n\n7836.43\n7836.43\n\n\nRegionPlot[ {-5 < 4 x + 3 y && 4 x + 3 y < 5 && -2 < 3 x + 2 y && 3 x + 2 y < 2, \n             -10 < x < 10 && -10 < y < 10 },\n            {x, -25, 25}, {y, -25, 25}, PlotPoints -> 150, MaxRecursion -> 4]\n\n\nIt should be emphasized that Integrate doesn't work either when we use insted of Boole for example UnitStep :\nregFuncUS[x_, y_] := UnitStep[ 5 + 4 x + 3 y, 5 - 4 x - 3 y, 2 + 3 x + 2 y, 2 - 3 x - 2 y]\n\nEdit 2\nIn Mathematica 9 this bug has been fixed :\nIntegrate[ regFunc[x,y] (( 4 x + 3 y )( 3 x + 2 y ))^4,{x, -100, 100},{y, -100, 100}] //N\nIntegrate[ regFunc[x,y] ( 12x^2 + 17 x y + 6 y^2 )^4,{x, -100, 100},{y, -100, 100}] //N\n\n\n16000.\n16000.\n\n\n", "Manipulate not working inside DialogInput": "\nTry\nDialogInput[{Manipulate[Dynamic[x], {{x, 2}, {1, 2, 3}}, \n   LocalizeVariables -> False], Button[\"OK\", DialogReturn[x]]}]\n\nI'm not sure why Dynamic is required.\nLocalizeVariables -> False allows the value of x to be returned (outside of the scope of the Manipulate.  LocalizedVariables was shown to be necessary for a Manipulate embedded in DialogInput. See here.\n", "keyboard - Emacs key bind on Mathematica Linux": "\nI was never able to find a completely satisfying solution, but the following is what I use. The shortcuts for the Mathematica GUI are defined in [MathematicaDir]/SystemFiles/FrontEnd/TextResources/X/KeyEventTranslations.tr. You can also add your own shortcuts there, as long as the functionality you require already exists. (Actually you can also write your own functions and assign shortcuts there.) Of course the shortcuts need to be unique to work correctly, including the ones assigned to menu items, which normally have a Alt-... binding under Linux. These can be edited in the MenuSetup.tr file in the same directory. So you always have to make sure that there is no overlap between these two files. Just as an example, these are the custom shortcuts I defined:\n(* My emacs shortcuts *)\nItem[KeyEvent[\"I\", Modifiers -> {Command}], \"ScrollPageUp\"],\nItem[KeyEvent[\"K\", Modifiers -> {Command}], \"ScrollPageDown\"],\nItem[KeyEvent[\"d\", Modifiers -> {Command}], \"DeleteNext\"],\nItem[KeyEvent[\"D\", Modifiers -> {Command}], \"DeleteNextWord\"],\nItem[KeyEvent[\"i\", Modifiers -> {Command}], \"MovePreviousLine\"],\nItem[KeyEvent[\"k\", Modifiers -> {Command}], \"MoveNextLine\"],\nItem[KeyEvent[\"j\", Modifiers -> {Command}], \"MovePrevious\"],\nItem[KeyEvent[\"l\", Modifiers -> {Command}], \"MoveNext\"],\nItem[KeyEvent[\"o\", Modifiers -> {Command}], \"MoveNextWord\"],\nItem[KeyEvent[\"u\", Modifiers -> {Command}], \"MovePreviousWord\"],\nItem[KeyEvent[\"L\", Modifiers -> {Command}], \"MoveLineEnd\"],\nItem[KeyEvent[\"J\", Modifiers -> {Command}], \"MoveLineBeginning\"],\nItem[KeyEvent[\"O\", Modifiers -> {Command}], \"MoveNextCell\"],\nItem[KeyEvent[\"U\", Modifiers -> {Command}], \"MovePreviousCell\"]\n\n", "character encoding - Unicode-aware string functions?": "\nSee if this helps:\nNeeds[\"JLink`\"];\nClearAll[toUpperCase];\ntoUpperCase[s_String] :=\n    JavaBlock[JavaNew[\"java.lang.String\", s]@toUpperCase[]];\n\n", "calculus and analysis - Trying to prove that $x\\sin(\\frac{\\pi}{x})\\ge\\pi \\cos(\\frac{\\pi}{x})$ for $x\\ge 1$": "\nThe proof of the original statement that $f(x)\\equiv x\\sin\\frac{\\pi}{x}$ is a monotonically increasing function of $x$ for $x>1$ can be done as follows: \nFirst, we show that the second derivative $f''(x)$ of the function is negative:\nSimplify[D[x Sin[\u03c0/x], x, x] < 0, Assumptions -> x > 1]\n\n\nTrue\n\nThis means that the first derivative $f'(x)$ is a monotonically decreasing function of $x$ for $x>1$. \nNow we show that the derivative of the function approaches zero as $x\\to\\infty$:\nLimit[D[x Sin[\u03c0/x], x], x -> \u221e]\n\n\n0\n\nSince the derivative has been shown to be decreasing and to have a limit of zero for $x\\to\\infty$, it follows that $f'(x) > 0$ for $x>1$. This proves the desired statement about $f(x)$.\nEdit\nTo take the other route proposed in the edited version of the question, you could do the following:\nResolve[ForAll[{x}, x > 1 && Tan[\u03c0/x] >= \u03c0/x, f'[x] >= 0], Reals]\n\n\nTrue\n\nEdit 2\nIn the Resolve statement above, ForAll has three arguments: the variable {x}, a condition, and the statement to be proved. In words, this says the following: for all $x$ that satisfy the condition $x>1$ and $\\tan(\\pi/x)\\ge \\pi/x$, it holds that $f'(x)\\ge0$. Of course, the condition can actually be simplified because the tangent inequality as stated here only holds for $x>2$. \nTo make the condition fully consistent with the desired interval $x>1$, we simply have to replace $x$ by $2 x$ in the tangent inequality. This leaves the inequality unaffected but extends its range of validity to $x>1$. Therefore, we get the following statement that can be fed to Mathematica:\nResolve[ForAll[x, x > 1 && Tan[\u03c0/(2 x)] >= \u03c0/x/2, f'[x] >= 0], Reals]\n\n\nTrue\n\n", "index - Sequentially numbering a nested list": "\nI am pretty sure that it is not the best solution but how about this?\nnumbering[x_] := Block[{n = 0}, Replace[x, y_ :> {++n, y}, {-1}]]\n\nSome example outputs:\nIn[1]:= numbering[{a, b, {c, d}, e, {f, {g, h}}}]\n\nOut[1]= {{1, a}, {2, b}, {{3, c}, {4, d}}, {5, e}, {{6, f}, {{7, g}, {8, h}}}}\n\nIn[2]:= numbering[Nest[{#, #} &, x, 3]]\n\nOut[2]= {{{{1, x}, {2, x}}, {{3, x}, {4, x}}}, {{{5, x},\n    {6, x}}, {{7, x}, {8, x}}}}\n\nAbout the level spec {-1} (per reference):\n\nLevel -1 consists of numbers, symbols, and other objects that do not have subparts.\n\nSounds exactly like what you want.\n", "gui construction - Adjusting placement of control objects in a row within a panel": "\nYou want to use Grid.\nCode\nPanel[\n Grid[\n  {\n    (* The 1st row *)\n    {\n      Row[{\"Board size: \", InputField[Dynamic[max], Number, FieldSize -> 3]}], \n      Button[\"Clear Board\", ImageSize -> All]\n    },\n    (* The 2nd row *)\n    {\n      Graphics[Circle[], ImageSize -> 300], SpanFromLeft\n    }\n  }, Alignment -> {{Left, Right}, Baseline}]\n]\n\nResult\n\n\n\nFew things\n\nSpanFromLeft is used so that the first column of the second row would occupy the second column too.\nGrid[{\n  {\"A\", \"B\"},\n  {\"C\", SpanFromLeft}\n }, Frame -> All, BaseStyle -> {FontSize -> 36}]\n\n\n\n\nButton's default ImageSize is Full, which makes it stretched so that it would fill all cell. So I changed it to All which makes its width just enough for the text.\n\nButton[..., ImageSize->Full] (or the default)\n\n\n\nButton[..., ImageSize->All]\n\n\nAlignment can be specified in {horizontal, vertical} order. Within each, you can specify them for each row / column by giving a list (in this case, Left for the first column, Right for the second column).\n\nGrid has a very rich syntax. The reference is always a good source.\n", "Mathmatica Prcision - Mathmatica Stack Exchang": "\nNIntegrate[f[x], {x, 0, 2*Pi}, WorkingPrecision -> 15, PrecisionGoal -> 10]\n\n\n 7.95492652101285\n\n\n", "performance tuning - Loop optimization": "\nYour best bet is to remove the procedural programming Do, While and Append Statements, building lists with Append is not quick. Then embrace a functional programming approach on which Mathematica thrives. Making use of constructs like Transpose, Part, Nest, Map, Table and Fold. These are generally much faster and lead to eventually to less buggy code.\nIf machine precision numbers are enough you can look at using Compile.\nThere are many approaches, but you could try something along these lines:-\nThere is no need to initialise Particle in Mathematica.\nYou can eliminate the Do loop and  its 80,000 thousand calls to RandomVariate\nby just two calls.\ndimensions=2; numParticles=20000;\nXYs = \nTranspose[{RandomVariate[NormalDistribution[0, Sqrt[EmitX]], {numParticles,dimensions}],\n    RandomVariate[NormalDistribution[0, Sqrt[EmitY]], {numParticles,dimensions}]}];\n\nThis gives you a list of pairs of Xs and Ys of length numParticles.\nYou could then write a set of functions to compute coordS, coordsX, coordsY, say C[], cX[], cY[].\nThen combine Table and NestWhile.\nThe basic form for NestWhile is \nNestWhile[function, initial state, terminating condition]\n\nThe terminating condition is checked, 'function' is is applied to 'initial state' producing a result.\nThe result is held in a variable known as #. # may have several components. These components are accessed by the part notation, #[[1]], #[[2]] and so on.\nThe terminating condition is then checked and if true, result is then given to function to evaluate.\nThis produces a new result ... and so on. It's basically recursion.\nThe trick is to make the 'initial condition' have the same structure as the result of applying 'function'. Function may actually be a compound list of results gained by using several functions. And sometimes you need to 'pad' an element of the list, as it can be used to hold the parameters for the nest.\nIn your case perhaps something to compute the {coordX, coordY, coordS, XY }.\nThe shape of the code would look something like this\nres =   \nTable[\n NestWhile[{C[],cX[#[[1,1],#[[3,2]]],Cy[#[[2]]]}&,\n {p[[1]],p[[2]],{PhiS + Pi, BucketHeightP}},\n Abs[#[[3,1]]] >= (PhiS + Pi) ||  Abs[#[[3,2]]] >= d[#[[3,1]]] &], \n{p,XYs}]\n\nAssuming PhiS  BucketHeightP do not change between iterations.\nThis is just a roughed out solution and probably skips over some details and could definitely be improved but should help you towards a faster implementation and give you a flavour of the functional approach.\nI hope you can see that the form of the solution is essentially a Table command with a NestWhileand 3 auxiliary functions. You could even insert the initial creation of the variable XYs into Table command, but that would have just reduced comprehension in this case.\nThis is typical of what functional programming brings to the party. Very concise programs with a high level of abstraction. \nOne way of looking at it is that you start with your initial data and then apply some functional transforms to arrive at your final data. This avoids a lot of the bugs introduced by procedural programs that have lots of state information held in global variables. State information that often gets inadvertently corrupted.\nApologies, but this isn't debugged code, but a template solution - so there might be a few niggles to iron out before it flies.\nFurther performance tuning tips can be found at:\ntuning\n", "documentation - Listing the functions defined in a package": "\nPossibly this way:  \n<< PrimalityProving`\n\n?PrimalityProving`*\n\nor alternatively (see the copy&paste issue in the comments)\n?\"PrimalityProving`*\"\n\n\n\n\nSee also the help under ref/Information, subsection \"Generalizations & Extensions\". In some cases you have to provide a string argument:\nInformation[\"*Values\"]\n\n\n\n\n", "reference request - Strategies for simplifying complicated expressions": "\nI don't know why you would expect Mathematica to understand that this is a real expression when you have I, (-1)^(1/4) and (-1)^(3/4) at various places in the expression.\n(-1)^(1/4) // N\n(* Out[1]= 0.707107 + 0.707107 I *)\n\n(-1)^(3/4) // N\n(* Out[2]= -0.707107 + 0.707107 I *)\n\nIn this particular instance, the denominator is pretty obviously real.\nSimplify[Sign@Denominator[finalnew], \n  Assumptions -> {ka > 0, kd > 0, L > 0, \u03c9 > 0, d > 0}]\n\n(*\nOut[3]= Sign[(ka^4 \u03c9^2 + d^2 (kd^2 + \u03c9^2)^2 - 4 d ka^2 \u03c9 (kd^2 - kd \u03c9 + \u03c9^2)) \n    Cos[ Sqrt[2] L Sqrt[\u03c9/d]] - (ka^4 \u03c9^2 + d^2 (kd^2 + \u03c9^2)^2 + 4 d ka^2 \u03c9 (kd^2 + kd \u03c9 + \u03c9^2)) \n    Cosh[Sqrt[2] L Sqrt[\u03c9/d]] - 2 Sqrt[2] ka ((d^(3/2) (kd - \u03c9) \u03c9^(5/2) - \n        kd^2 (d \u03c9)^(3/2) + kd^3 Sqrt[d^3 \u03c9] - ka^2 kd Sqrt[d \u03c9^3] + ka^2 Sqrt[d \u03c9^5]) \n    Sin[Sqrt[2] L Sqrt[\u03c9/d]] + (kd^2 (d \u03c9)^(3/2) + kd^3 Sqrt[d^3 \u03c9] + ka^2 kd Sqrt[d \u03c9^3] + \n        ka^2 Sqrt[d \u03c9^5] + d^(3/2) \u03c9^(5/2) (kd + \u03c9)) \n    Sinh[ Sqrt[2] L Sqrt[\u03c9/d]])\n]\n*)\n\nSimplify[Im@Denominator[finalnew], Assumptions -> {ka > 0, kd > 0, L > 0, \u03c9 > 0, d > 0, u > 0}]\n(* Out[4]= 0 *)\n\nSo concentrate on refining the numerator. The equivalent\nSimplify[Im@Numerator[finalnew], \n Assumptions -> {ka > 0, kd > 0, L > 0, \u03c9 > 0, d > 0, u > 0}]\n\ndoes not simplify to zero. For example:\nExpand@Im@Numerator[finalnew] /. {ka -> 1, kd -> 1, L -> 1, \u03c9 -> 1, d -> 1, u -> 1}\n\n(*\nOut[5]= 6 Im[(-24 - 168 I) Cos[(-1)^(1/4)] - (24 - 168 I) Cosh[(-1)^(1/4)] - \n    (78 - 102 I) (-1)^(1/4) Sin[(-1)^(1/4)] + (42 + 24 I) (-1)^(3/4) Sin[(-1)^(1/4)] +\n    (108 + 144 I) (-1)^(1/4) Sinh[(-1)^(1/4)] + 6 (-1)^(3/4) Sinh[(-1)^(3/4)]]\n*)\n\nYou can confirm the numerator is also real for specific values of the parameters:\nFullSimplify@ Im[Numerator[finalnew] /. {ka -> 1, kd -> 1, L -> 1, \u03c9 -> 1,  d -> 1, u -> 1}] \n(* result is zero *)\n\nBut this takes an inordinate amount of time and the result is a long complex expression.\nFullSimplify[Im[Numerator[finalnew]], Assumptions -> {ka > 0, kd > 0, L > 0, \u03c9 > 0, d > 0, u > 0}]\n\nAs for general strategies, FullSimplify with as many variables in the Assumptions option is a good bet in most cases, as is separately simplifying numerators and denominators. I don't know if there are best-practice strategies, though. I would expect it would depend on the kind of expression, for example, whether it is a polynomial or contains trigonometric expressions.\n", "formatting - How to edit the text coming together with the numeration of pages in pdf produced out of a notebook?": "\nYou can do that in the \u201cHeaders and footers\u201d dialog:\n\nor right in the notebook with PageHeaders.\n", "graphics - How to reduce the memory necessary for the image?": "\nTry to use something like the following depending on the rasterization resolution you are seeking.\nExport[\"fig1A.pdf\", fig1A, \"AllowRasterization\" -> True,\nImageSize -> 350, ImageResolution -> 600]\n\nThis issue was previously discussed here and I am referring to the solution by Heike. Searching the site before posting a new question is the right thing to do. \n", "programming - Modifying a List in a function in place": "\nYou basically need a pass-by-reference semantics, which in Mathematica can be emulated with Hold-attributes. Add a HoldFirst attribute to your function:\nSetAttributes[func,HoldFirst]\n\nand you should be fine. Without it, list evaluates to its value before the assignment is attempted, and since expressions in Mathematica are immutable, you get an error.\nTo address your question in comments, the one-liner you asked for can be this:\nfunc = Function[{list,column}, \n         list[[All, column]] = Map[#*2 &, list[[All, column]]],\n         HoldFirst\n       ]\n\nNote however that, since this is a pure function, you can not do argument checks as elegantly as you can with patterns, and you can not overload your functions on different arguments as elegantly.\nNote also that, while yet another way to do this is to keep your function as it is but rather wrap the first argument in Unevaluated in every function call, I would strongly advise against that. The reason is that it makes the function itself not self-contained, because it has to assume that the user will always remember to use Unevaluated (which it shouldn't), and there is no way to test whether or not the user actually did use it. \n", "plotting - How do I get rid of the overlap of gridlines and tick mark labels?": "\nSetting PlotRangePadding to zero is probably the easiest option, but as an alternative you could draw the grid lines by hand using ProLog:\nticks = {Range[0, 2 Pi, Pi/6], Range[0, 1.5, .125]};\nPlot[1/Root[-3 - 8 #1 Tan[a/2] - \n     3 Tan[a/2]^2 + #1^4 (1 + Tan[a/2]^2) + #1^2 (-9 + \n        3 Tan[a/2]^2) &, 2], {a, 0, 2 Pi}, AxesOrigin -> {0, 0},\n Ticks -> ticks,\n Prolog -> \n  Style[{Gray, Dashed, \n    Line[{{#, 0}, {#, 1.4}}] & /@ Rest[ticks[[1]]], \n    Line[{{0, #}, {2 Pi + .2, #}}] & /@ Rest[ticks[[2]]]}, \n   Antialiasing -> False]]\n\n\n", "syntax - Convert operator to string": "\nThis seems to work\nconvert[str_] := Module[{stream, output},\n  stream = StringToStream[\"\\\"\\\\[\" <> ToString[str] <> \"]\\\"\"];\n  output = Read[stream];\n  Close[stream];\n  output]\n\nconvert /@ {Equilibrium, LongRightArrow, LeftVector, Equal} // InputForm\n\n\nEdit\nYou could also do something like this:\nconvert[str_] := ToExpression[\"\\\"\\\\[\" <> ToString[str] <> \"]\\\"\"]\n\nconvert /@ {Equilibrium, LongRightArrow, LeftVector, Equal} // InputForm\n\n", "syntax - Setting the DifferenceOrder Option": "\nThis is not an answer, but it is really too long for a comment.\nI don't know if IDA is the same as BDF, I would have to look closer. However, as you wish to have explicit control over the order of the method and that is not available, it is likely that you can extract what order it does use out of the InterpolationFunction returned.\nIf you set InterpolationOrder -> All on NDSolve, it's supposed to use the underlying method's order as the interpolation order. Experimenting with \nInterpolation[..., InterpolationOrder -> ...]\n\nreveals you may be able to extract the order of interpolation used. For instance, \nInterpolation[..., InterpolationOrder -> 2][[2]]\n\ngives something like \n\n{4, 7, 0, {11}, {3}, 0, 0, 0, 0, Automatic}\n\n\nThe fifth term, {3} in this case, is always one more than the order. Using that technique on\nsol = NDSolve[ {y''[t] + y'[t] + y[t] == 0, y'[0] == y[0] == 1}, \n               y, \n               {t, 0, 2 \\[Pi]}, \n               Method -> {\"BDF\"}, \n               InterpolationOrder -> All\n      ]\n\nvia sol[[1, 1, 2, 2]] gives\n\n{4, 17, 5, {119}, {4}, {InterpolatingFunction[{{0., 6.28319}}, \"<>\"]}, \n   0, 0, 0, Automatic}\n\n\nwhich implies that it uses a 3$^\\text{rd}$ order method.\n\nEdit:\nAs I intimated, the above method seems workable, but if the format of InterpolatingFunction changes, it will fail. However, there is a package specifically designed to extract this type of information from an InterpolatingFunction: DifferentialEquations`InterpolatingFunctionAnatomy`.  Using sol from above,\nNeeds[\"DifferentialEquations`InterpolatingFunctionAnatomy`\"];\nInterpolatingFunctionInterpolationOrder @ sol[[1, 1, 2]]\n\n\n{3}\n\n\nwhich confirms what the other method came up with.\nEdit 2:\nIn addition to the package, above, some opaque objects like SparseArray and InterpolatingFunction can have their properties queried. Thanks to Oleksandr, for InterpolatingFunction these are {\"Domain\", \"Coordinates\", \"DerivativeOrder\", \"InterpolationOrder\", \"Grid\", \"ValuesOnGrid\"}. So, then you can determine the order used, via\nsol[[1, 1, 2]][\"InterpolationOrder\"]\n\n", "parallelization - Export to file from ParallelDo loop": "\nAlthough I'd generally suggest using ParallelTable instead, I can imagine a scenario where you would like to use ParallelDo with a function that is really lengthy and could potentially hang or crash. Then you would want to save the results of each successful parallel computation to avoid losing it in case of a  crash.\nBut to do that, it's safest to create a separate file for each result, because we don't usually have control over the order and timing with which ParallelDo produces results. \nSince the loop can always be parameterized by integer indices, we can use these indices to label the individual result files, too. Then these files can later be combined into a single file when all the results have been written out:\nParallelDo[\n Export[\"out-\" <> \n   ToString@NumberForm[i, 2, NumberPadding -> {\"0\", \" \"}] <> \"-\" <> \n   ToString@NumberForm[j, 2, NumberPadding -> {\"0\", \" \"}], \n  ToString[Row[{i, \",\", j, \",\", integral1[i, j]}]] <> \"\\n\", \n  \"Text\"], {i, 10}, {j, 1, 10}]\n\nHere, I used NumberForm with 2 digits and leading 0 as padding, to produce file names in which the integers i and j appear with constant length. You would have to change the 2 to something larger if the integers range over more digits. \nI've inserted a ToString before the integral1 function because I don't know what that function is. \nWhen the loop is done, you'll have files ranging from out-001-001 to out-010-010. Under Unix, these can be combined easily by issuing the command cat out* > results which creates a file called results where you have everything in the desired format.\n", "options - What does MaxStepFraction do?": "\nThe documentation is fairly clear on this:\n\nMaxStepFraction is an option to functions like NDSolve that specifies the maximum fraction of the total range to cover in a single step.\n\nIn simpler terms, you can think of MaxStepFraction as the inverse of the number of intervals in the total range, whereas MaxStepSize is the length of an interval. The following graphic should make the difference clear:\n\nSo in other words, setting MaxStepFraction = 1/10 and setting MaxStepSize = L/10 will give you the same result. The documentation linked above also has an example that demonstrates this:\n", "formatting - NIntegrate is resetting my variables and not giving me a result?": "\nSome of the symbols you're using depend on the VectorAnalysis package.  So, be sure to execute the following from a fresh kernel.\nNeeds[\"VectorAnalysis`\"]\n\nAlso, be sure to define your hSol function for only numeric values.\nhSol[x_?NumericQ,y_?NumericQ,t_?NumericQ] := ...\n\n", "graphics - Using Texture to color countries according to their timezones": "\nThe main problem here is that you need to include a VertexTextureCoordinates (VTC) in the Polygon for a texture to be applied. However, the rest of the problem is not as simple as it seems. Here's the output of my approach. Below it, I discuss texturing several polygons belonging to the same country, according to their timezone. You can also skip that and jump straight to the code block.\n\nHandling textures for several polygons\nCountryData[country, \"Polygon\"] will give you a list of polygons that depict the main boundaries, but is not necessarily contiguous. This differs from country to country \u2014 for example, Alaska is not included for the USA, but Tasmania is for Australia. Since they're sorted by area (at least, that's how it seems to me), you could simply pick the first to get the largest land mass, but it looks weird in cases such as New Zealand, Canada, Indonesia, etc.\nHowever, the polygons returned are in the form Polygon[{poly1, poly2, ...}] and you cannot provide VTC for all of them at once. So you'll need to split the polygons and supply the VTC for each. If we na\u00efvely follow the documentation and try something like the following (zoneTexture is defined later, but is not necessary to understand), you get:\nWith[{country = \"Australia\"},\n    p = CountryData[country, \"FullPolygon\"];\n    c = CountryData[country, \"FullCoordinates\"];\n    z = zoneTexture@CountryData[country, \"TimeZones\"];\n];\n\nGraphics[{EdgeForm[Black], Texture[z], (Polygon[p[[1, #]], \n    VertexTextureCoordinates -> Transpose[Rescale /@ Transpose[c[[#]]]]] & /@ Range[Length[c]])\n}]\n\n\nDoesn't seem so bad, except when you look closely, you'll notice that Tasmania also has the same texture as the mainland \u2014 i.e., not coloured per its time zone. Now this can be easily fixed. You just need to get the extents of the country's boundaries and rescale the VTC to range from 0 to 1 within those extents.\nCode\nThe following code will generate the image above. Note that I use the image available in ColorData using the \"Image\" option, and index it directly to obtain the texture. This avoids having to convert it to an Image, which can slow it down. Texture rasterizes objects anyway, so nothing is lost here. I also resize it so that it covers some cases where you observe white gaps.\nBegin[\"ZoneMap`\"];\n    image = ImageResize[ColorData[\"Rainbow\", \"Image\"], 1000];\n    zoneTexture[zones_] := If[Length[zones] == 1, #, ImageRotate[#]] &[\n        ImageTake[image, All, Clip[Floor[1000 {#1 + 12, #2 + 12}/24], {1, 1000}]] & @@ \n        Through[{Min, Max}[zones]]\n    ];\n\n    CountryGraphics[country_] := Module[{\n        coordinates = CountryData[country, \"Coordinates\"],\n        polygons = CountryData[country, \"Polygon\"],\n        zones = CountryData[country, \"TimeZones\"],\n        minmaxlat, minmaxlong},\n\n        {minmaxlat, minmaxlong} = {Min@#, Max@#} & /@ Transpose[coordinates~Flatten~1];\n        Graphics[{EdgeForm[Black], Texture[zoneTexture[zones]],\n            (Polygon[polygons[[1, #]], VertexTextureCoordinates -> \n            Transpose[{Rescale[#1], Rescale[#2, minmaxlong]} & @@\n            Transpose[coordinates[[#]]]]] & /@ Range[Length[coordinates]])\n        }]\n   ];\nEnd[];\n\nZoneMap`CountryGraphics /@ CountryData[\"Countries\"] // Show\n\nNow this works fairly well and you should be able to replace zoneTexture with whatever you'd like.\nExtending to \"FullPolygon\" for the countries\nThis can also be extended to cover the full boundaries of a country, i.e., including unincorporated territories by choosing \"FullPolygon and \"FullCoordinates\" in the respective calls. However, it fails for 2 countries (to my knowledge): USA and Russia. The reason it fails is because there is no equivalent \"FullTimeZones\" that will return the full extent of the time zones. Hence, the rescaling stretches the time zone map for the primary regions all the way across the entire extent. For example, in the case of USA, Guam, which is near Australia, forces the texture to stretch from there onwards. It is worse in the case of Russia, because the far east tip of the mainland lies in the Western hemisphere, resulting in:\n\nOne would also expect a similar scaling problem for the UK, but Britain still has the same colour since there is only one time zone. In this case, the territories are also coloured as GMT, but they're tiny anyway. Since there are only two cases that stand out visually, they can be handled individually, which is left to the reader.\n", "Transpos unvn lists - Mathmatica Stack Exchang": "\nYes, but it is not trivial to comprehend. You would have to use the second argument of Flatten to implement a generalized transpose of uneven lists. For example:\n(* Uneven list *)\nlist = Range ~Array~ 5\nOut[1]= {{1}, {1, 2}, {1, 2, 3}, {1, 2, 3, 4}, {1, 2, 3, 4, 5}}\n\n(* Transpose the list *)\nlist ~Flatten~ {2}\nOut[2]= {{1, 1, 1, 1, 1}, {2, 2, 2, 2}, {3, 3, 3}, {4, 4}, {5}}\n\nFor more information on how the second argument of Flatten works and what it can do, see this answer by Leonid.\n", "plotting - How to make a 3D globe?": "\nThis answer was originally posted in 2012 and based on version 8 of Mathematica.  Since then, a number of changes have made it possible to generate the globe in much less code. Specifically:\n\nCountryData[_,\"SchematicPolygon\"] now returns polygons of sufficient resolution to make a nice globe. Thus, we don't need to apply polyline simplification to FullPolygons.\nTriangulation is now built in.\n\nThus, we can now generate the globe as follows:\ncountryComplex[country_] := Module[\n  {boundaryPts, mesh, g, triPts, tris, pts3D, linePts, lines, linePts3D},\n  boundaryPts = Map[Reverse, \n        CountryData[country, \"SchematicCoordinates\"], \n    {2}];\n  mesh = TriangulateMesh[Polygon[boundaryPts]];\n  g = Show[mesh];\n  {triPts, tris} = {g[[1, 1]], g[[1, 2, 2, 1, 1, 1]]};\n  pts3D = Map[\n        Normalize[First[\n            GeoPositionXYZ[GeoPosition[Reverse[#]]]\n        ]] &, triPts];\n  g = Show[RegionBoundary[mesh]];\n  {linePts, lines} = {g[[1, 1]], g[[1, 2, 2, 1, 1, 1]]};\n  linePts3D = Map[\n        Normalize[First[\n            GeoPositionXYZ[GeoPosition[Reverse[#]]]\n        ]] &, linePts];\n  {GraphicsComplex[pts3D, \n        {EdgeForm[], ColorData[\"DarkTerrain\"][Random[]], Polygon[tris]}, \n        VertexNormals -> pts3D],\n   GraphicsComplex[linePts3D, {Thick, Line[lines]}]}\n];\n\nSeedRandom[1];\ncomplexes = countryComplex /@ Prepend[CountryData[All], \"Antarctica\"];\npic = Graphics3D[{{ColorData[\"Aquamarine\"][3], \n  Sphere[{0, 0, 0}, 0.99]}, complexes}, \n  Lighting -> \"Neutral\", Boxed -> False]\n\n\n\nOrginal 2012 Answer\nI'm posting this as a second answer, as it's really a completely different approach.  It's also been substantially expanded as of April 25, 2012.  While this still doesn't specifically address the question of adding a region, it does plot the countries separately.  Of course, each country could be viewed as a region in itself.\nOur objective is to make a good, genuine 3D globe.  We prefer not to use a texturized parametric plot, for then we we'll have distortion at the poles and no access to the graphics primitives making the image.  \nIt's quite easy to project data given as (lat,lng) pairs onto a sphere using GeoPosition and related functions (or even just the standard parametrization of a sphere).  However, the SchematicPolygon returned by CountryData are of insufficient resolution to generate a truly nice image while the FullPolygons are so detailed that the resulting 3D object is clunky to interact with.  Furthermore, non-convex 3D polygons tend to render poorly in Mathematica with the fill leaking out.\nOur solution is two-fold.  First, we simplify the FullPolygons to a manageable but still detailed level.  Second, we triangulate the resulting polygons before projecting onto the sphere.  Note that we use a third party program called triangle for the triangulation.  Once installed, however, the procedure can be carried out entirely within Mathematica using the Run command.\nPolyline simplification\nHere are the Schematic and Full Polygons returned by CountryData for Britain, known for it's complicated coastline.  Note that the FullPolygon consists of nearly 4000 total points, while the SchematicPolygon has only 26.\npts[0] = Map[Reverse, \n  CountryData[\"UnitedKingdom\", \"SchematicCoordinates\"], {2}];\npts[1] = Map[Reverse, \n  CountryData[\"UnitedKingdom\", \"FullCoordinates\"], {2}];\nTotal /@ Map[Length, {pts[0], pts[1]}, {2}]\n\n{26, 3924}\nIn order to plot a nice image that is easy to interact with, we've really got to reduce the number of points in the FullPolygon.  A standard algorithm for reducing points while maintaining the integrity of the line is the Douglas-Peucker algorithm.  Here is an implementation in Mathematica:\ndist[q : {x_, y_}, {p1 : {x1_, y1_}, p2 : {x2_, y2_}}] := With[\n   {u = (q - p1).(p2 - p1)/(p2 - p1).(p2 - p1)},\n   Which[\n    u <= 0, Norm[q - p1],\n    u >= 1, Norm[q - p2],\n    True, Norm[q - (p1 + u (p2 - p1))]\n    ]\n   ];\ntestSeg[seg[points_List], tol_] := Module[{dists, max, pos},\n    dists = dist[#, {points[[1]], points[[-1]]}] & /@ \n      points[[Range[2, Length[points] - 1]]];\n    max = Max[dists];\n    If[max > tol,\n     pos = Position[dists, max][[1, 1]] + 1;\n     {seg[points[[Range[1, pos]]]], \n      seg[points[[Range[pos, Length[points]]]]]},\n     seg[points, done]]] /; Length[points] > 2;\ntestSeg[seg[points_List], tol_] := seg[points, done];\ntestSeg[seg[points_List, done], tol_] := seg[points, done];\ndpSimp[points_, tol_] := \n  Append[First /@ First /@ Flatten[{seg[points]} //. \n       s_seg :> testSeg[s, tol]], Last[points]];\n\nLet's illustrate with the coast of Britain.  The second parameter is a tolerance; a smaller tolerance yields a better approximation but uses more points.  The implementation doesn't like the first and last points to be the same, hence we use Most.  Finally, we can toss out parts that yield just two points after simplification, since they will be very small.\npts[2] = Select[dpSimp[Most[#],0.1]& /@ pts[1], Length[#]>2&];\nTotal[Length /@ pts[2]]\n\n341\nThe result has only 341 total points.  Let's look at the mainland.\nRow[Table[Labeled[Graphics[{EdgeForm[Black],White,\n  Polygon[First[pts[i]]]}, ImageSize -> 200],\n  Length[First[pts[i]]]],{i,0,2}]]\n\n\nOur simplified polygon uses only 158 points for mainland Britain to yield an approximation that should look good on a globe.\nTriangulation\nTriangulation is an extremely important topic in computational geometry and still a topic in current research.  Our topic here illustrates it's importance in computer graphics; it is also very important in the numerical solution of PDEs.  It is surprisingly hard to do well in full generality.  (Consider, for example, that our simplified polygons are not guaranteed to be simple, i.e. they may and probably do self-intersect.)  Unfortunately, Mathematica doesn't have a built in triangulation procedure as of V8.  Rather than start from scratch, I've written a little interface to the freely available program called triangle:\nhttp://www.cs.cmu.edu/~quake/triangle.html\nInstalling triangle on a unix based system, like Mac OS X, was easy enough for me - though, it does require some facility with C compilation.  I don't know about Windows.  Once you've got it set up to run from the command line, we can access it easily enough through Mathematica's Run command by reading and writing triangle files.  Let's illustrate with the boundary of Britain again.\nTriangle represents polygons using poly files.  The following code writes a sequence of points to a stream in poly file format.\ntoPolyFile[strm_, pts : {{_, _} ..}] := Module[{},\n   WriteString[strm, ToString[Length[pts]] <> \" 2 0 0\\n\"];\n   MapIndexed[\n    WriteString[strm, \n      ToString[First[#2]] <> \" \" <>\n       ToString[First[#]] <> \" \" <>\n        ToString[Last[#]] <> \"\\n\"] &, pts];\n   WriteString[strm, ToString[Length[pts]] <> \" 0\\n\"];\n   Do[WriteString[strm, \n     ToString[i] <> \" \" <> ToString[Mod[i - 1, Length[pts], 1]] <> \n      \" \" <> ToString[i] <> \"\\n\"],\n    {i, 1, Length[pts]}];\n   WriteString[strm, \"0\"]\n   ];\n\nFor example, we can write poly files for the british coast approximations as follows.\nDo[\n  strm = OpenWrite[\"BritishCoast\"<>ToString[i]<>\".poly\"];\n  toPolyFile[strm,First[pts[i]]];\n  Close[strm],\n{i,0,2}]\n\nWe'll triangulate using the following command.\n$triangleCmd = \"/Users/mmcclure/Documents/triangle/triangle -pq \";\n\nHere's the actual triangulation step.\nDo[\n  Run[$triangleCmd<>\"BritishCoast\"<>ToString[i]<>\".poly\"],\n{i,0,2}]\n\nThis produces new poly files as well as node and ele files.  These can be read back in and translated to GraphicsComplexs.\ntriangleFilesToComplex[fileName_String, itNumber_:1] := \n  Module[{pts, triangles, edges, data},\n   data = Import[fileName <> \".\" <> ToString[itNumber] <> \".node\",  \"Table\"];\n   pts = #[[{2, 3}]] & /@ data[[2 ;; -2]];\n   data = Import[fileName <> \".\" <> ToString[itNumber] <> \".ele\", \"Table\"];\n   triangles = Rest /@ data[[2 ;; -2]];\n   data = Import[fileName <> \".\" <> ToString[itNumber] <> \".poly\", \"Table\"];\n   edges = #[[{2, 3}]] & /@ data[[3 ;; -3]];\n   GraphicsComplex[pts, {\n     {White, EdgeForm[{Black,Thin}], Polygon[triangles]},\n     {Thick, Black, Line[edges]}}]]\n\nHere's the result.\nGraphicsRow[Table[\n  Graphics[triangleFilesToComplex[\"BritishCoast\"<>ToString[i]]],\n{i,0,2}], ImageSize -> 600]\n\n\nThe Globe\nOK, let's put this all together to generate the globe.  The procedure will generate a huge number of files, so let's set up a directory in which to store them.  (Unix specific)\nSetDirectory[NotebookDirectory[]];\nIf[FileNames[\"CountryPolys\"] === {},\n  Run[\"mkdir CountryPolys\"],\n  Run[\"rm CountryPolys/*.poly CountryPolys/*.node CountryPolys/*.ele\"]\n];\n\nThe next command is analogous to the toPolyFile command above, but accepts a country name as a string, generates poly files for all the large enough sub-parts, and triangulates them.\n$triangleCmd = \"/Users/mmcclure/Documents/triangle/triangle -pq \";\ntriangulateCountryPoly[country_String] := \n  Module[{multiPoly, strm, fileName, len, fp},\n   fp = CountryData[country, \"FullCoordinates\"];\n   multiPoly = Select[dpSimp[Most[#], 0.2] & /@ fp, Length[#] > 2 &];\n   len = Length[multiPoly];\n   Do[\n    fileName = \"CountryPolys/\" <> country <> ToString[i] <> \".poly\";\n    strm = OpenWrite[fileName];\n    toPolyFile[strm, multiPoly[[i]]];\n    Close[strm];\n    Run[$triangleCmd <> fileName], \n    {i, 1, len}];\n   ];\n\nNext, we need a command to read in a triangulated country (consisting of potentially many polygons) and store the result in a GraphicsComplex.\ntoComplex3D[country_String] := \n  Module[{len, pts, pts3D, ptCnts, triangles, edges, data},\n   Catch[\n    len = \n     Length[FileNames[\n       \"CountryPolys/\" <> country ~~ NumberString ~~ \".1.poly\"]];\n    pts = Table[\n      data = \n       Check[Import[\n         \"CountryPolys/\" <> country <> ToString[i] <> \".1.node\", \n         \"Table\"], Throw[country]];\n      #[[{2, 3}]] & /@ data[[2 ;; -2]], {i, 1, len}];\n    ptCnts = Prepend[Accumulate[Length /@ pts], 0];\n    pts = Flatten[pts, 1];\n    triangles = Flatten[Table[\n       data = \n        Check[Import[\n          \"CountryPolys/\" <> country <> ToString[i] <> \".1.ele\", \n          \"Table\"], Throw[country]];\n       ptCnts[[i]] + Rest /@ data[[2 ;; -2]], {i, 1, len}], 1];\n    edges = Flatten[Table[\n       data = \n        Check[Import[\n          \"CountryPolys/\" <> country <> ToString[i] <> \".1.poly\", \n          \"Table\"], Throw[country]];\n       ptCnts[[i]] + (#[[{2, 3}]] & /@ data[[3 ;; -3]]), {i, 1, len}],\n       1];\n    pts3D = \n     Map[Normalize[First[GeoPositionXYZ[GeoPosition[Reverse[#]]]]] &, \n      pts];\n    GraphicsComplex[pts3D,\n     {{EdgeForm[], ColorData[\"DarkTerrain\"][Random[]], \n       Polygon[triangles]},\n      {Line[edges]}}, VertexNormals -> pts3D]\n    ]\n];\n\nOK, let's do it.\ncountries = Prepend[CountryData[All], \"Antarctica\"];\ntriangulateCountryPoly /@ countries; // AbsoluteTiming\n\n{77.350341, Null}\nSeedRandom[1];\ncomplexes = toComplex3D /@ countries; // AbsoluteTiming\n\n{94.657840, Null}\nglobe = Graphics3D[{\n  {ColorData[\"Aquamarine\"][3], Sphere[{0, 0, 0}, 0.99]}, complexes},\n  Lighting -> \"Neutral\", Boxed -> False]\n\n\n", "syntax - Orthonormalization of non-hermitian matrix eigenvectors": "\nThe way I am interpreting this question, it has nothing to do with the vectors in question being eigenvectors of any particular matrix. If this interpretation is wrong, the question needs to be clarified. \nThe next point is that orthogonality requires an actual scalar product, and for a complex vector space this rules out the Dot product because Dot[{I,0},{I,0}] == -1 which is obviously not positive.\nTherefore, the only way that it could make sense to speak of orthogonalization with respect to the Dot product for complex vectors is that you might wish for some reason to apply the orthogonalization algorithm (e.g., Gram-Schmidt) to a set of vectors with complex entries. \nDoing this is completely legitimate, but it will not lead to vectors that are orthogonal with respect to the Dot product because the Dot product is not a scalar product. It just doesn't make sense to use the term \"orthogonality\" in this case.\nHere is a function that performs the algorithm as described:\northoDotize[vecs_] := Module[{s, a, e, ortho},\n  s = Array[a, Dimensions[vecs]];\n  ortho = Orthogonalize[s];\n  ortho /. Thread[Flatten[s] -> Flatten[vecs]]\n  ]\n\nThis function has the property that its output satisfies the expected Euclidean orthogonality relations when the vectors in the list vecs are real. If they are not real, then the dot product after \"pseudo-orthogonalization\" can have imaginary parts:\nmat = {{0. + 1.002 I, -1}, {-1, -I}};\nevecs = N[Eigenvectors[mat]];\novecs = orthoDotize[evecs]\n\n\n{{0.722734 + 0. I, -2.69948*10^-16 + 0.691127 I}, {3.67452*10^-15 + \n     0.691127 I, 0.722734 - 3.56028*10^-15 I}}\n\nChop[ovecs[[1]].ovecs[[2]]]\n\n\n0. + 0.999001 I\n\nEdit: a possible cause of confusion\nHowever, as I mentioned in my comment to the question (March 28), it could also be that there is a mathematical misunderstanding of a different kind here: equating orthogonality with biorthogonality. \nAs explained on this MathWorld page, we can define left and right eigenvectors of the matrix mat, which in this case are transposes of each other because mat is symmetric. To get these (generally different) sets of eigenvectors, you can do \neR = Eigenvectors[mat];\neL = Transpose[Eigenvectors[Transpose[mat]]];\n\nThe last line follows from \n$\\begin{eqnarray*}\\vec{x}_{L}^{\\top}M & = & \\lambda \\vec{x}_{L}^{\\top}\\\\\\Leftrightarrow\\,\\,\\,M^{\\top}\\vec{x}_{L} & = & \\lambda \\vec{x}_{L}\\end{eqnarray*}$\nThen the following holds:\neL.eR // Chop\n\n\n$\\begin{pmatrix}0.0446879 & 0\\\\0 & 0.0446879\\end{pmatrix}$\n\nThe appearance of the diagonal matrix here means that the rows of the matrix eL (the left eigenvectors) are orthogonal to the columns of eR (the right eigenvectors) in the sense of the matrix product. This is automatically true, and there is no need to do any further orthogonalization. \nEdit 2\nIn case it needs further clarification: for any symmetric matrix mat we have that Transpose[eR] == eL. This implies that Transpose[eR].eR is diagonal (see above) and therefore eR[[1]].eR[[2]] == 0. That's why there is no need for any further orthogonalization in the example given in the question. \nEdit 3\nIf mat is not symmetric, then its (right) eigenvectors are not orthogonal in the dot multiplication sense. Forming any kind of linear combination of those eigenvectors with the intention of orthogonalizing them will lead to new vectors which in general are no longer eigenvectors (unless the vectors in question share the same eigenvalue). So the orthogonalization idea is either trivial (for symmetric matrices) or violates the eigenvector property (for general non-symmetric matrices with non-degenerate spectrum).\n", "programming - Abort not aborting": "\nThis question has been asked before on stack overflow. However we will summerize some of the answers given there on our new Mathematica site.\nWrap In Compound Expression\nOne suggestion by Michael Pilat, given there was to wrap your lines in CompoundExpression, e.g.\n(\n   Print@Range[5];\n   Abort[];\n   Print@Range[5];\n)\n\n\nDuring evaluation of In[39]:= {1,2,3,4,5}\n$Aborted\n\n\nIf you mind the formatting of parenthesis, you could explicitly use the FullForm of CompoundExpression like this:\nCompoundExpression[\n   Print@Range[5],\n   Abort[],\n   Print@Range[5],\n]\n\nUse of $PreRead\nSuggested by Alexey Popkov:\nIn[1]:= $new$PreRead = False;\nAbortAllPendingInputs := \n  AbortProtect[If[! $new$PreRead, $new$PreRead = True;\n    $TimeOfAbort = SessionTime[];\n    last$PreRead = ToString[Definition[$PreRead], InputForm];\n    ClearAll[$PreRead];\n    $PreRead := If[TrueQ[SessionTime[] - $TimeOfAbort < 1], \"\",\n       $new$PreRead = False;\n       ClearAll[$PreRead];\n       If[last$PreRead === \"Null\", #, \n        ToExpression[last$PreRead]; $PreRead@#]\n       ] &;]];\n\nIn[3]:= f := CheckAbort[Pause[10], AbortAllPendingInputs; Abort[]]\n\nIn[4]:= While[True, f]\nWhile[True, f]\nWhile[True, f]\n\n\nOut[4]= $Aborted\n\nNote that this solution will need to be modified if you use $PreRead for anything else.\nUse of CellEvaluationFunction\nCellEvaluationFunction gets the BoxData expression, before it is even split. Just assigning something like CellEvaluationFunction:>ToExpression seems to do the trick.\nYou can set it as an Input cell style, or as a notebook option, or front end session option, or however you like\nSetOptions[$FrontEndSession, CellEvaluationFunction :> ToExpression]\n\nHowever, you lose the multiple outputs in those new lines when you don't use ;. This can probably be solved but I don't know very well how CellEvalutionFunction works, and how can it receive a box structure, default to Identity but expect to return an expression. Edit should you come up with any improvements\n", "list manipulation - Issues with a Counter that is tallying term appearances": "\nIf I am following your code, I think the problem is that you are collecting expressions such as bigramHash[\"ottawa\", \"citizen\"] which will evaluate differently depending on the DownValue associated with bigramHash.  Therefore, these expression will evaluate to whatever the final DownValue of bigramHash[\"ottawa\", \"citizen\"] is, if present.\nHere is a simplified example of the problem:\nfilelist = {\n   {{\"a\", 1}, {\"b\", 2}},\n   {{\"cat\", 5}, {\"dog\", 3}},\n   {{\"a\", 4}, {\"b\", 6}}\n };\n\nReap[Do[\n   Clear[bigramHash];\n   (bigramHash[#] = #2) & @@@ file;\n   count = bigramHash[\"a\"];\n   Print[count];\n   Sow[count],\n   {file, filelist}\n]][[2, 1]]\n\n\nDuring evaluation of In[26]:= 1\n\nDuring evaluation of In[26]:= bigramHash[a]\n\nDuring evaluation of In[26]:= 4\n\n{1, 4, 4}\n\n\nOne simple fix is to define a default DownValue e.g. bigramHash[___] = 0:\nReap[Do[\n   Clear[bigramHash];\n   bigramHash[___] = 0;\n   (bigramHash[#] = #2) & @@@ file;\n   count = bigramHash[\"a\"];\n   Print[count];\n   Sow[count],\n   {file, filelist}\n]][[2, 1]]\n\n\nDuring evaluation of In[36]:= 1\n\nDuring evaluation of In[36]:= 0\n\nDuring evaluation of In[36]:= 4\n\n{1, 0, 4}\n\n\n", "plotting - When using GraphPlot with an adjacency matrix, how can I make Mathematica draw exactly one self loop for any non-zero weight?": "\nA simple hack of a way to obtain the behaviour that you want is to negate the adjacency matrix. Now, don't ask me what that means or represents, but it works!\n\nModifying the example from the accepted answer in the question that CHM shared to include multiple self loops:\n\nYou can see that the second one displays the behaviour you want. \n", "graphics - Can 2D and 3D plots be combined so that the 2D plot is the bottom surface of the 3D plot boundary?": "\nThe following is probably what you want.\nMake3d[plot_, height_, opacity_] := \n  Module[{newplot},\n    newplot = First@Graphics[plot]; \n    newplot = N@newplot /. {x_?AtomQ, y_?AtomQ} :> {x, y, height};\n    newplot /. GraphicsComplex[xx__] :> {Opacity[opacity], GraphicsComplex[xx]}\n  ]\n\nShow[{Graphics3D[Make3d[twoDptsPlot, -1, .75]], threeDPtsPlot,surfacePlot}, Axes -> True]\n\nwhich gives\n\nThis function can takes any 2D plot and place it on a 3D box with a specified height. I got this trick in the web few years back but now cant remember the reference. Hope this helps you.\n", "import - How to extract sample values from an imported WAV file?": "\nYou want this:\ndata = Import[\"test.wav\", \"Data\"]\n\nThis imports the raw data of sample values. For example, on a test file of approximately 10 seconds, stereo at 48000\u00a0Hz, data is an array of size 2 \u00d7 520192 (from which I can deduce that my recording was actually 10.84 seconds). \nSee the documentation for WAV format import/export, as well as this answer on a related question for some more details.\n\nGoing at it differently, if you already have imported your file as a Sound object (as in your example), you can still recover the sample data. Inside your Sound object is a SampledSoundList:\nIn[25]:= Head@First@B\nOut[25]= SampledSoundList\n\nThis in turn contains the raw data:\nIn[26]:= Length@B[[1, 1]]\nOut[26]= 2\n\nIn[27]:= Table[Length@B[[1, 1, i]], {i, 1, 2}]\nOut[27]= {520192, 520192}\n\n", "parallelization - Are built-in Mathematica functions already parallelized?": "\nNatively multi-threaded functions\nA lot of functions are internally multi-threaded (image processing, numerical functions, etc.). For instance:\nIn[1]:= a = Image[RandomInteger[{0, 255}, {10000, 10000}], \"Byte\"];\n\nIn[2]:= SystemOptions[\"ParallelOptions\"]\n\nOut[2]= {\"ParallelOptions\" -> {\"AbortPause\" -> 2., \"BusyWait\" -> 0.01,\n    \"MathLinkTimeout\" -> 15., \"ParallelThreadNumber\" -> 4, \n   \"RecoveryMode\" -> \"ReQueue\", \"RelaunchFailedKernels\" -> False}}\n\nIn[3]:= ImageResize[a, {3723, 3231}, \n   Resampling -> \"Lanczos\"]; // AbsoluteTiming\n\nOut[3]= {1.2428834, Null}\n\nIn[4]:= SetSystemOptions[\n \"ParallelOptions\" -> {\"ParallelThreadNumber\" -> 1}]\n\nOut[4]= \"ParallelOptions\" -> {\"AbortPause\" -> 2., \"BusyWait\" -> 0.01, \n  \"MathLinkTimeout\" -> 15., \"ParallelThreadNumber\" -> 1, \n  \"RecoveryMode\" -> \"ReQueue\", \"RelaunchFailedKernels\" -> False}\n\nIn[5]:= ImageResize[a, {3723, 3231}, \n   Resampling -> \"Lanczos\"]; // AbsoluteTiming\n\nOut[5]= {2.7461943, Null}\n\nFunctions calling optimized libraries\nMathematica surely gets benefit from multi-threaded libraries (such as MKL) too:\nIn[1]:= a = RandomReal[{1, 2}, {5000, 5000}];\n\nIn[2]:= b = RandomReal[1, {5000}];\n\nIn[3]:= SystemOptions[\"MKLThreads\"]\n\nOut[3]= {\"MKLThreads\" -> 4}\n\nIn[4]:= LinearSolve[a, b]; // AbsoluteTiming\n\nOut[4]= {4.9585104, Null}\n\nIn[5]:= SetSystemOptions[\"MKLThreads\" -> 1]\n\nOut[5]= \"MKLThreads\" -> 1\n\nIn[6]:= LinearSolve[a, b]; // AbsoluteTiming\n\nOut[6]= {8.5545926, Null}\n\nAlthough, the same function may not get multi-threaded depending on the type of input.\nCompiled function\nCompiledFunctions and any other functions that automatically use Compile can be multi-threaded too, using Parallelization option to Compile.\nCaution\n\nMeasuring timing with AbsoluteTiming for multi-threaded functions could be inaccurate sometimes.\nThe performance gain is usually not direct proportion to the number of threads. It depends on a lot of different factors.\nIncreasing number of threads (by using SetSystemOptions ) more than what your CPU support (either physical or logical cores) is not a good idea.\n\n", "graphics - How do I draw a DensityPlot in polar coordinates?": "\nUse the two-argument form ArcTan[x, y] instead of ArcTan[y/x]:\n\nArcTan[x,y] gives the arc tangent of y/x, taking into account which quadrant the point $(x,y)$ is in. \n\nIt just works:\n\n", "graphics - Memory Leak in Frontend": "\nThis is a simpler example that shows the behavior (in Win-x86-64, M8.0.4):    \nDo[Rasterize[Graphics[Table[RGBColor @@ RandomReal[1, {3}], {1000}]]], {1000}]\n\nApparently, the memory gets allocated for each RGBColor with unique value, but is never freed. The same goes to other color directives.\n", "graphics3d - Facegrids at ticks": "\nThis can be found on the 'More Information' section of the FaceGrid doc page though it may not be very easy to grasp. Here's an example:\nPlot3D[Sin[R bn/10], {R, 2, 100}, {bn, 1, 5}, \n AxesStyle -> Thickness[0.005], \n Ticks -> {{2, 10, 20, 30, 50, 100}, {1, 2, 3, 4, 5}, {0.5, 1.0, 1.5, 2.0, 2.5}},\n Boxed -> False, \n Mesh -> {{0, 2, 5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100}, \n          {1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5}}, \n PerformanceGoal -> \"Quality\", \n FaceGrids -> \n   {{{0, -1, 0}, {{2, 10, 20, 30, 50, 100}, {0.5, 1.0, 1.5, 2.0, 2.5}}}, \n    {{1,  0, 0}, {{1, 2, 3, 4, 5}, {0.5, 1.0, 1.5, 2.0, 2.5}}}, \n    {{0, 0,  1}, {{2, 10, 20, 30, 50, 100}, {1, 2, 3, 4, 5}}}\n   }\n]\n\n\nBasically what Facegrid specifies here is which faces to draw and what lines to draw\nin each face. For each face, we need one list. An identification of the grid we are talking about is the first element of each face grid specification. This specification can be thought of the unit vector pointing straight to the grid you want to indicate, so {1,0,0} would be the $+x$ face grid, and {0,-1,0} would be the $-y$ grid.  The next element of the grid specification list is a specification of the grid lines, a list with tick values for each of the remaining coordinates. So, if the $+x$ grid is being specified this list contains a specification for the $y$ and $z$ ticks.\n", "numerical integration - Controlling the time step in NDSolve?": "\nTo get a fixed step size with the BDF method you can lower the AccuracyGoal and PrecisionGoal to increase the adaptive step sizes and then use MaxStepSize to limit the step size to any value you want.\nGet an example stiff system from the documentation:\nNeeds[\"DifferentialEquations`NDSolveProblems`\"];\nNeeds[\"DifferentialEquations`NDSolveUtilities`\"];\nsystem = GetNDSolveProblem[\"VanderPol\"];\n\nSolve with the BDF method:\nsols = NDSolve[system, {T, 0, 10}, Method -> \"BDF\"];\nPlot[Evaluate[sols[[1, All, 2]]], {T, 0, 10.}, Frame -> True]\n\n\nPlot the step sizes:\nStepDataPlot[sols] /. AbsolutePointSize[_] -> PointSize[Small]\n\n\nSolve again with low precision and accuracy goals and small MaxStepSize:\nsols = NDSolve[system, {T, 0, 10}, Method -> \"BDF\", \n  PrecisionGoal -> 0, AccuracyGoal -> 0, MaxStepSize -> 1. 10^-5\n];\nPlot[Evaluate[sols[[1, All, 2]]], {T, 0, 10.}, Frame -> True]\n\n\nNow we have a fixed step size:\nStepDataPlot[sols] /. AbsolutePointSize[_] -> PointSize[Small]\n\n\nWe can increase the step size, but the result starts to diverge from the true solution:\nsols2 = NDSolve[system, {T, 0, 10}, Method -> \"BDF\", \n   PrecisionGoal -> 0, AccuracyGoal -> 0, MaxStepSize -> 1. 10^-4\n];\nPlot[Evaluate[Flatten[{sols, sols2}][[All, 2]]], {T, 0, 10.}, Frame -> True]\n\n\nWe still have a fixed step size, though:\nStepDataPlot[sols2] /. AbsolutePointSize[_] -> PointSize[Small]\n\n\n", "kernel - Does Mathematica on Mac OS use virtualization for certain functions?": "\nYes, the Mathematica application on Mac OS contains a few external binaries, which are mostly used for importing and exporting. These files have suffix .exe:\n$ find \"/Applications/Mathematica 8.app\" -name '*.exe'|wc -l\n49\nBut even though .exe is a prefix common for Windows executables, it doesn\u2019t mean that it can\u2019t be used for other things. In fact, Mac OS (like Linux and other Unixes) doesn\u2019t care much how files are named, and while it is typically to name binary files on these systems without suffix at all, a .exe suffix doesn\u2019t hurt. Moreover, you can actually check that these files are Mac OS binary:\n$ file \"/Applications/Mathematica 8.app/SystemFiles/Converters/Binaries/MacOSX-x86-64/GIF.exe\"\n/Applications/Mathematica 8.app/SystemFiles/Converters/Binaries/MacOSX-x86-64/GIF.exe: Mach-O 64-bit executable x86_64\n\nthe key point being this last part of the string: Mach-O 64-bit executable x86_64. There is thus no need to assume that Mathematica uses virtualization on Mac OS (and I'd be very surprised, to say the least, if it did).\n", "conditional - How to avoid returning a Null if there is no \"else\" condition in an If construct": "\nIt depends what you consider nothing, but you could try something like this\nIf[a, b, Unevaluated[Sequence[]]]\n\nfor example \n3 + If[False, 1, Unevaluated[Sequence[]]]\n\nreturns 3. Wrapping an argument of a function in Unevaluated is effectively the same as temporarily setting the attribute Hold for that argument meaning that the argument isn't evaluated until after it's inserted in the definition of that function.\nBy the way, in your definition of QuickSort you're calling Cases[x, j_ /; j < pivot] six times. It's probably more efficient to assign Cases[x, j_ /; j < pivot] to a dummy variable and use that instead.\n", "cdf format - CDF plug-in and animation controls": "\nI don't think you are supposed to be able to use an input field. The Create a Computable Document HowTo says:\n\nAll interactive content must be generated with the Manipulate command\n  and may only use mouse-driven elements, such as Slider, Locator,\n  Checkbox, PopupMenu, etc.\n\nCouldn't you build numerical selectors like below?\nDynamicModule[{h = 0, s = 0, t = 0},\n Manipulate[\n  Grid[\n   {\n    {Button[\"+\", h++; If[h > 9, h = 0]], \n     Button[\"+\", t++; If[t > 9, t = 0]], \n     Button[\"+\", s++; If[s > 9, s = 0]]}, \n    {h, t, s}, \n    {Button[\"-\", h--; If[h < 0, h = 9]], \n     Button[\"-\", t--; If[t < 0, t = 9]], \n     Button[\"-\", s--; If[s < 0, s = 9]]}\n    }\n   ]\n  ]\n ]\n\n\n", "What are the differences between the \u201cHome Edition\u201d and the regular Mathematica?": "\nFrom the FAQ:\n\nQ: How is Mathematica Home Edition different from the professional version of Mathematica?\nMathematica Home Edition includes all of the functionality found in the professional version. The difference is that Mathematica Home Edition is only authorized for use on personally owned computers for non-professional and non-academic purposes.\n\n", "testing and verification - How can I run MUnit TestSuites outside WorkBench?": "\nHave a look at this post. There is a short explanation how to do it. I use this quite often and it works very well for me.\n", "programming - Repeatedly randomly redrawing part of a random sample that matches a certain criterion": "\nThis is wasteful but, if I understand the problem correctly, it does the trick with minimal code using ReplaceRepeated.\nn = 10000;\nlimitValue = 0.5;\nRandomReal[{0, 1}, n] //. x_ /; x < limitValue :> x + RandomReal[{0, 1}]\n\nI was actually surprised at the speed of it.\nEdit:\nPer request in the comments. To keep track of the number of additions we can modify things slightly with Reap and Sow.\nn = 10000;\nlimitValue = 0.5;\n{res, count} = \n  Reap[Transpose[{RandomReal[{0, 1}, n], Range[n]}] //. {x_, i_} /; \n      x < limitValue :> (Sow[i]; {x + RandomReal[{0, 1}], i})];\n\nNow res[[All,1]] contains the values you want and Tally[count[[1]]] contains a list of pairs {i,k} where i is the index and k is the number of additions.\n", "manipulate - How to generate a real-time stream of data?": "\nYou could use RunScheduledTask or its relatives for this. For example, to append a random integer to catch once every two seconds you could do something like \ncatch = {};\ntask = RunScheduledTask[AppendTo[catch, RandomInteger[10]], 2];\n\nYou could also use CreateScheduledTask which is similar to RunScheduledTask except that the task won't be started automatically after it's been created. You'll have to use StartScheduledTask to start it manually.\nTo start and stop the scheduled task you can use StartScheduledTask[task] and StopScheduledTask[task], respectively, and RemoveScheduledTask[task] will remove the scheduled task once you're done with it.\nAdditional information about these functions is available in the Documentation Center.\n", "graphics - Filling a polygon with a pattern of insets": "\nFinally, with version 12.1 come  the directives HatchFilling and PatternFilling which make the task much easier:\nGraphics[{HatchFilling[\"Diagonal\"], EdgeForm[Black], \n    Polygon[{{0, 0}, {1, 0}, {1, 1}, {0.5, 1.5}, {0, 1}}]}]\n\n\nimg = ExampleData[{\"TestImage\", \"Mandrill\"}];\n\nGraphics[{PatternFilling[img, ImageScaled[1.5]], EdgeForm[Black], \n    Polygon[{{0, 0}, {1, 0}, {1, 1}, {0.5, 1.5}, {0, 1}}] }]\n\n\nGraphics[{PatternFilling[#], EdgeForm[Black], \n   Polygon[{{0, 0}, {1, 0}, {1, 1}, {0.5, 1.5}, {0, 1}}] }, ImageSize -> 100] & /@ \n  {\"Checkerboard\", \"Chevron\", \"ChevronLine\", \"Circle\", \"Diamond\", \"DiamondBox\", \n   \"DiamondPlate\", \"DiamondPoint\", \"Grain\", \"Grid\", \"GridPoint\", \n   \"Halftone\", \"HalftoneGrid\", \"Herringbone\", \"Hexagon\", \n   \"Octagon\", \"Plaid\", \"Weave\", \"XGrid\", \"XGridPoint\"}  // Multicolumn[#, 5] &\n\n\n", "How to mark an imag? - Mathmatica Stack Exchang": "\nThis is a simple way:\nShow[\n    Plot[Sin[x], {x, 0, 2 \\[Pi]}],\n    Graphics[{PointSize[Large], Red, Point[{3 \\[Pi]/2, -1}],\n    Black, Text[\"Minimum\", {3 \\[Pi]/2, -.8}]}]]\n\n\nEdit\nIf you have an image created with Colorize you can apply the same method. In the example below img is the image you obtain by taking the first example given in the Help under Colorize.\nShow[\n   img,\n   Graphics[{PointSize[Large], Red, Point[{20, 100}],\n   White, Text[\"California\", {30, 90}]}]]\n\n\n", "plotting - ListLogLinearPlot logarithmic axis tickmarks": "\nYou can create some custom ticks that work the way you want. There might be a better way than Superscript, but I couldn't work out how to get ScientificForm or NumberForm to just show the exponent rather than 1 x 10^4 etc.\nmyTicks = Table[{10^i, Superscript[10, i]}, {i, -20, 15}]\n\nNotice I've changed the way the a variable enters into the Manipulate, as it will give you more chance to explore some of the lower-exponent values.\nManipulate[\n ListLogLinearPlot[{Table[{10^a s[T], T}, {T, 0, 1000}], \n   Table[{10^a t[T], T}, {T, 0, 1000}]}, GridLines -> None, \n  Ticks -> {myTicks, Automatic}, PlotStyle -> {Thickness[0.005]}, \n  Joined -> True, PlotRange -> Automatic], {a, -8, 8}]\n\n\n", "numerics - Annoying display truncation of numerical results": "\nMaybe this :\nNumberForm[#, 10] &@ {123.189094`, 123.189263`}\n\n\n{123.189094, 123.189263 }\n\n\n?\nEdit\nConsider also this utility of NumberForm[ x, {m, k}] giving m real digits of x with  k digits to the right of the decimal point, e.g. \nNumberForm[#, {10, 7}] &@ { 197.9898987322333, 201.73205080756887 }\n\n\n{ 197.9898987, 201.7320508 }\n\n\n", "cdf format - How to embed \"Share content\" button into a CDF?": "\nFor short textual content, you can always use SystemOpen on a crafted URL. For example, the code below works in CDF and allows you to embed content in a tweet (sorry, I don't know the facebook API, so I went with this instead!):\nhexEncode[s_String] := \n  StringJoin@Riffle[IntegerString[ToCharacterCode[s, \"UTF-8\"], 16, 2], \"%\", {1, -2, 2}];\nsendTweet[text_, expr_] := \n  SystemOpen[\"http://twitter.com/home?status=\" <> hexEncode@ToString@expr];\nButton[\"Share\", sendTweet[\"Check this out! \", data]]\n\n", "plotting - How to change the axes' origin and direction?": "\n1: Reversing the image in a 2D plot (ArrayPlot or MatrixPlot)\nSimply use DataReversed -> True. This has the effect of flipping the image along the horizontal axis. For example:\nfunc[x_, y_] := Sinc[y ^2 + x^3];\ndata = Table[func[x,y], {x, -\u03c0, \u03c0, 0.1}, {y, -\u03c0, \u03c0, 0.1}];\nArrayPlot[data, DataReversed -> #] & /@ {True, False} // GraphicsRow\n\n\n2: Changing the origin in a 1D plot (ListPlot or Plot)\nUse AxesOrigin -> {x, y} to change the origin to where ever you like. For example:\nPlot[Sin[x], {x, 0, 2 Pi}, AxesOrigin -> {0.5, 0.5}]\n\n\n3: Changing the direction of the y-axis (or x-axis) in a 1D plot\nFlipping the y-axis in a 1D plot is a bit more involved and is a very common approach in displaying depth plots. You can implement this in Mathematica by negating your input to ListPlot and assigning custom ticks with a function. Here's an example:\nx = Sin /@ Range[0, 2 \u03c0, 0.1];\nListPlot[-x, Ticks -> {Automatic, Function[{xmin, xmax}, \n    Table[{i, -i, {0.02, 0}}, {i, N@FindDivisions[{xmin, xmax}, 10]}]]}]\n\n\n", "evaluation - Changes in Handling of Real Zeros": "\nOnly precise zero coefficients are eliminated.  Use Chop:\n3. in + 4. in - 7. in + 5. lb // Chop\n\n\n5. lb\n\n\n\nLeonid admonished me for posting a method overloading Times.  I didn't honestly expect anyone to use that and I think I made that pretty clear in the original post.  \nNevertheless, here is a safer method that only affects uses of specified units:\nunits = {in, lb};\n\n(# /: 0. # := 0 #) & /@ units;\n\n3. in + 4. in - 7. in + 5. lb\n\n\n5. lb\n\n\n", "Function Interpolation with Automatic / Algorithmic Values Mesh": "\nAs far as I know, there is no built-in function to do this. However, what you can do is a heavy abuse of Part to extract the points from a Plot object:\ng = Plot[Sin[x], {x, 0, 2 Pi}]\n\n\n\n\nThe InputForm, i.e. how Mathematica sees this picture internally, looks like like this:\n\nGraphics[{{{}, {}, {Hue[0.67, 0.6, 0.6], Line[{{1.2*^-7, 1.2*^-7}, [long list of points]} ... (options etc)\n\n\nYou can now extract these points by using Part, i.e. [[ ]]:\npoints = g[[1, 1, 3, 2, 1]]\n\n\n{{0., 0.}, {0.01, 0.01}, {0.02, 0.02}, {0.03, 0.03}, {0.06, 0.06}, ...\n\n\nThis can now be used for a ListPlot to visualize the points extracted:\nListPlot[points]\n\n\n\n\nThe density of points and the recursion can be set usual when plotting, i.e. PlotPoints and MaxRecursion.\nRemarks:\n\nI've rounded the values above heavily so it doesn't blow up the answer. Usually the numbers are much more precise.\nBear in mind that this does extractions from Plot that are not supposed to be done. For this reason, you should be especially careful setting plotting parameters and things like these, as I could imagine that some of them may change the structure of the Graphics object you're extracting the data from.\n\n", "graphics - Autorotating 3D plots": "\nNote that ViewPoint is given in specially scaled coordinates which depend on amongst things the size of the bounding box. To get better control over the positioning of the camera you could use ViewVector instead, which is given in terms of the coordinates of the plot. You could for example do something like this:\nrotateMeHarder1[g_, vertical_, viewpoint0_, center_List: {0, 0, 0}, \n  nframes_Integer: 15, opts : OptionsPattern[]] := Module[{grlist},\n  grlist = \n   Table[Show[g, ViewVertical -> vertical, \n     ViewVector -> {RotationMatrix[2 Pi/nframes i, \n          vertical].(viewpoint0 - center) + center, center},\n     SphericalRegion -> True, opts], {i, 0, nframes - 1}]]\n\nwhere g is the Graphics3D object, vertical is the vertical axis, viewpoint0 is the starting position of the camera, center is the center of the graph, nframes is the number of frames, and opts are additional options of the graph. \nUsage\nTo create an animation of the plot p in the original question rotating around the axis anchored at {10, 0, 0} and direction {0, 1, 0}, and initial camera position {30, 30, 30} you could do something like\np = SphericalPlot3D[10 + 5*Re@ SphericalHarmonicY[3, -3, \u03b8, \u03d5], \n  \u03b8, \u03d5, Boxed -> False, Axes -> True, \n  AxesOrigin -> {0, 0, 0}, AxesStyle -> {{Thick, Red}, {Thick, Green}, {Thick, Blue}}, \n  Ticks -> None, PlotStyle -> Opacity[0.7]];\n\ngrlist = rotateMeHarder1[p, {0, 1, 0}, {30, 30, 30}, {10, 0, 0}, 20, \n  ViewAngle -> 50 Degree]\n\nListAnimate[grlist]\n\nNote that I'm using ViewAngle to adjust the size of the graphics relative to the viewing area. By increasing the ViewAngle you effectively zoom out and vice versa. Another option to change the relative size of the graphics would be to change the distance of the initial camera position to the axes of rotation. \nYou can use Export to create an animated .gif or other type of movie, e.g.\nExport[\"movie.gif\", grlist];\n\n\nThis solution requires some manual tuning especially in choosing the initial view vector and the view angle. You could for example use Manipulate to experiment with values for these parameters. \n", "streams - How do I re-direct FilePrint's output?": "\nI can only give a partial answer. Your problem arises because FilePrint doesn't use $Output (stdout). It uses the stderr stream, so you can't capture what it writes by using Block and assigning to $Output. Unfortunately, I don't think any system variable is bound to stderr. Perhaps I'm wrong. In that case, I hope a more knowable person will be able to complete this answer.\nIn case anyone is interested, here is how I discovered that FilePrint was using stderr.\ntext = \"fee fi fo fum\";\noutput = With[{str = OpenWrite[]},\n  Block[{$Output = str},\n    Print[text]];\n  Close[str]];\nFilePrint[Print[Streams[]]; output]\n\n{OutputStream[stdout,1],OutputStream[stderr,2]}\n\n\"fee fi fo fum\"\n\n", "plotting - Color linear interpolation of ParametricPlot3D": "\nThere are a few things wrong with your code. First of all, the ranges for the parameters are in the wrong format. They should be of the form {u, umin, umax} etc. If you want to control the step size you could use PlotPoints and MaxRecursion.\nSecondly, as celtschk pointed out, the arguments in a pure function should be combined in a list. If you check the documentation of ColorFunction, you'll see that for ParametricPlot3D, the arguments provided to the ColorFunction are in this case the three spacial coordinates $x, y, z$ and the two parameters $u, v$ in that order. Therefore you could define your ColorFunction for example as\nFunction[{x, y, z, u, v}, Blend[{Red, Green, Blue}, {(x/5)^2, (y/2)^2, (z/2)^2}]\n\nYou would also need to set ColorFunctionScaling -> False. With these settings, the ellipsoid then becomes something like\nParametricPlot3D[{5 Cos[u] Cos[v], 2 Cos[v] Sin[u], 2 Sin[v]}, {u, 0, \n  2 Pi}, {v, -Pi/2, Pi/2}, Axes -> False, Boxed -> False, Mesh -> None,\n PlotPoints -> 40,\n ColorFunctionScaling -> False, \n ColorFunction -> Function[{x, y, z, u, v}, Blend[{Red, Green, Blue}, \n   {(x/5)^2, (y/2)^2, (z/2)^2}]]]\n\n\n", "dynamic - Way to find color at a point in a Graphics?": "\nThis method uses Intersection to test the colours, which should be faster than looping through the list of sample points.\nI.e. with sample image, a:\na = Graphics[{Yellow, Rectangle[{0, 0}, {300, 185}], \n    Inset[Graphics[{Blue, Rectangle[{0, 0}, {20, 10}]}],\n     {100, 140}, {0, 0}, {20, 10}]},\n   PlotRange -> {{0, 300}, {0, 185}}, ImageSize -> 300];\n\nsamplepoints = {{101, 141}, {117, 141}, {117, 148}};\ntestcolours = {{255, 255, 0}, {255, 255, 255}, {0, 0, 0}};\n\nb = Rasterize[a];\npointcolors = Part[b, 1, 1, #2, #1] & @@@ samplepoints;\nvalid = Intersection[testcolours, pointcolors] == {}\n\n\nTrue\n\nThe test does not find yellow, white or black at coordinates (101, 141), (117, 141) or (117, 148) and so sets valid True.\nNote\nI opted not to use ImageValue as I found its results unpredictable, e.g.\nnewsamplepoints = {{1, 1}, {101, 141}, {117, 141}, {117, 148}, {300, 185}};\n\nb = Rasterize[a];\npointcolors = Part[b, 1, 1, #2, #1] & @@@ newsamplepoints;\nGraphics[{RGBColor @@ #, Disk[]}, ImageSize -> 20] & /@ pointcolors\n\n\npointcolors = ImageValue[a, newsamplepoints];\nGraphics[{RGBColor @@ #, Disk[]}, ImageSize -> 20] & /@ pointcolors\n\n\nThere are only colours yellow and blue in the sample graphic.\nThe rasterizing method does seem to be a little slower though.  You could use either.\nmoresamplepoints = \n  Transpose[RandomInteger[{1, #}, 10000] & /@ {300, 185}];\n\nTiming[(b = Rasterize[a];\n  pointcolors = \n   Part[b, 1, 1, #2, #1] & @@@ moresamplepoints;)]\n\n\n{0.078, Null}\n\nTiming[pointcolors = ImageValue[a, moresamplepoints];]\n\n\n{0.031, Null}\n\n", "computational geometry - How to determine the convex hull of some text?": "\nAn alternative approach that does not require the ComputationalGeometry package: You can use a combination of ClusteringComponents and ComponentMeasurements as follows:\nDefine\n  chVertices[txtimg_] := \n  Insert[#, First@#, -1] &@\n  ComponentMeasurements[ClusteringComponents[Binarize@txtimg, 2], \n  \"ConvexVertices\"][[2, 2]]\n\nExample data:\n  textimg1 = Image[Graphics[\n  Text[Style[\"'., ab cgixyz,...\", Green, FontFamily -> \"Times\", FontSize -> 72]]], \n  ImageSize -> {600, 100}];\n  textimg2 = Image[Graphics[{EdgeForm[], Brown, \n  ImportString[ExportString[\n  Style[\".t e q s t,\", Italic, FontFamily -> \"Times\", FontSize -> 36], \n  \"PDF\"], \"PDF\", \"TextMode\" -> \"Outlines\"][[1, 1]]}], ImageSize -> {600, 100}];\n  textimg3 = Image[Graphics[\n  Text[Style[\"Get Convex Hull points.\", Orange, 56]]], \n  ImageSize -> {600, 100}];\n\nInput pictures:\n\nResults:  \n Row[Show[#, Graphics@{Red, Thick, Line[chVertices[#]]}] & \n /@ {textimg1, textimg2, textimg3}]\n\n\n", "recursively solve equation and saving the values": "\nYou get\n  {0.0351204, 0.06995, 0.104221, 0.137709, 0.170237, 0.201687, 0.231988, 0.26111, 0.289058, 0.315857, 0.34155, 0.366188, 0.389828, 0.412529, 0.434347}\n\nusing any of the methods below:\n   Last /@ sols\n\nor\n   sols[[All,2]]\n\nor\n  sols /. (a_ == b_) -> b\n\nAll give a list of solutions with T== removed.\nUpdate: an alternative approach to get a list of solutions for T is to Map Reduce[...] on the list t:\n  solutionlist = Map[Reduce[f == #, T, Reals][[2]] &, t] \n\n", "list manipulation - Handling vector comparisons in \"Piecewise\" function": "\nI'm not in front of a computer now, but I think you should be able to set your function to Listable and use it as-is:\nSetAttributes[myfunc, Listable]\n\n", "calculus and analysis - Notation of partial derivative": "\nFor a start, f[x,y]^(0,1) isn't the same as f^(0,1)[x,y].\nBut the real reason is that these expressions are very different in meaning, as revealed by their FullForm:\nD[f[x, y], y] // FullForm\n\n\nDerivative[0,1][f][x,y]\n\n\nversus (and I had to use a simple symbolic expression as the exponent to show what was going on:\nf[x,y]^z//FullForm\n\n\nPower[f[x,y],z]\n\n\nSimilarly, Derivative doesn't correspond to Superscript. They are syntactically different despite the visual similarities.\nStick with D[f[x,y],y] and so on. If you need the vector derivative, you can use the syntax:\n D[f,{{x1,x2,x3...}}]\n\nas described in the documentation.\n", "Can this code be written in a more functional style": "\nTwo more ways:\n   parti1[a_, p_] := SortBy[a, {Sign[# - p] &, # == # &}]\n\nor\n   parti2[a_, p_] := Join[Select[a, # < p &], {p}, Select[a, # >= p &]]\n\nWith\n  a = {3, 5, 6, 7, 2, 1, 2}; (* and *) p =3\n\nboth give\n  {2, 1, 2, 3, 5, 6, 7}\n\nUpdate: While the two methods above and Heike's two methods give exactly the same results, unfortunately, it turns out that Parti is a tougher nut than it seemed at first glance and none of these functions replicate Parti except for very special inputs. Here is why:\nThese functions, in effect, partition a list into lower and upper contour sets of the element p preserving the original ordering of the elements in each subset. With Parti, on the other hand, the orginial ordering is preserved only for the lower contour set, and the ordering of the elements in the upper contour set is not preserved. That is, when an element in the lower contour set moves it moves to the right of his previous left sibling and stays there, while an element on the upper contour set can move many times during the operation of Parti depending on the pattern of elements on its right. \nFor example, for the input list {3, 2, 5, 6, 2, 1} all four functions agree with Parti, i.e.,\n Parti[{3, 2, 5, 6, 2, 1}, 3]==parti1[[{3, 2, 5, 6, 2, 1}, 3]=={2, 2, 1, 3, 5, 6}\n\nYet, with a slight change in the list to {3, 2, 5, 2, 6, 1}, we get\n  Parti[{3, 2, 5, 2, 6, 1}, 3] (* => {2, 2, 1, 3, 6, 5} *)\n\nwhile parti1 and its siblings give\n  parti1[{3, 2, 5, 2, 6, 1}, 3] (* => {2, 2, 1, 3, 5, 6} *)\n\nAnother example: for the input list {3, 2, 5, 6, 7, 8, 9, 2, 1}\n   Parti[{3, 2, 5, 6, 7, 8, 9, 2, 1},5]   (* =>  {3, 2, 2, 1, 5, 8, 9, 6, 7}, but *)\n   parti1[{3, 2, 5, 6, 7, 8, 9, 2, 1},5]  (* =>  {3, 2, 2, 1, 5, 6, 7, 8, 9}      *)\n\nThus, the elements of the upper contour set always move to the right but their final positions relative to each other cannot be determined in a simple manner without using finer pattern information.\nSo ... it seems that the parties are interesting, at best, as a first step towards an answer to OP's question, and, quite possibly, as just answers seeking an interesting question.\nA new attempt: Try ReplaceRepeated and pattern matching:\n  partiReplace[a_List, p_] := \n  With[{leftlist = Alternatives[Sequence @@ Select[a, # < p &]], \n  rightlist =  Alternatives[ Sequence @@ Select[a, # >= p &]]}, \n  (Drop[a, Flatten[Position[a, p]]] \n  //. {Shortest[beg___], i : rightlist, \n  Shortest[rgtn : rightlist ...], \n  j : leftlist, k : leftlist ..., end___} \n  -> {beg, j, rgtn, i, k, end}) \n  // Insert[#, p, 1 + Length@(leftlist)] &]\n\nTests: For the examples considered above, partiReplace gives the same result as Parti. \nFor a limited set of test data\n  testdata = RandomReal[{0, 10}, {100, 21}];\n\nwe get\n   Parti[Most@#, Last@#] == partiReplace[Most@#, Last@#] & @@ testdata \n   (* => True  *)\n\n", "calculus and analysis - How to evaluate the $0/0$ type limit in Mathematica?": "\nEdit \nThe answer is \"ambiguous\" because you have two parameters, $\\alpha$ and $k$, and in this case the limit depends on the value of $\\alpha$. What you can try is the following: \nf[k_, \u03b1_] := ((k + 2) (\u03b1^2 - Sqrt[\u03b1^4 + k]) + k)/(\u03b1^2 - Sqrt[\u03b1^4 + k] + 2 k)\nSimplify[Limit[f[k, \u03b1^(1/4)], k -> 0] /. \u03b1 -> \u03b1^4, \u03b1 \u2208 Reals]\n\n\n$\\frac{2 \\left(\\alpha ^2-1\\right)}{4 \\alpha ^2-1}$\n\nWhat I did is to remove all powers of $\\alpha$ from under the square roots, so that the $k\\to 0$ limit makes them look like $\\sqrt{k+\\alpha}\\to \\sqrt{\\alpha}$ which manifestly cancels with the already present $\\sqrt{\\alpha}$ terms. At the end, I replace $\\alpha$ by $\\alpha^4$ to return to the original definition.\nWhat follows below are the steps that led me to finally settle on the above approach. The upshot is that we have to avoid handing Mathematica expressions such as $\\sqrt{\\alpha^4}-\\alpha^2 = 0$ because it doesn't simplify them at an early enough stage in the evaluation, even when the domain is real.\nInitial answer\nFirst assume simply that $\\alpha$ is real:\nAssuming[\u03b1 \u2208 Reals, Limit[f[k, \u03b1], k -> 0]]\n\n\n2\n\nNow say explicitly that $\\alpha>0$:\nAssuming[\u03b1 > 0, Limit[f[k, \u03b1], k -> 0]]\n\n\n$\\frac{2 \\left(\\alpha ^2-1\\right)}{4 \\alpha ^2-1}$\n\nThe behavior can be illustrated with a contour plot of f[k, \u03b1] around {0,0}:\nContourPlot[f[k, \u03b1], {k, 0, .1}, {\u03b1, -.3, .3}, FrameLabel -> {\"k\", \"\u03b1\"},\n    PlotRange -> {1, 5}, ContourLabels -> True]\n\n\nIn the plane of $k, \\alpha$, Mathematica acts as if it preferred to choose the \"easiest\" approach to the $k=0$ axis by taking $\\alpha = 0$ in the first case. But what it should have done is to return the more general result, or a ConditionalExpression (not necessary in this particular case because the general result goes smoothly to 2 for $\\alpha\\to0$). \nThe first result is a bug, I would say: Since $\\alpha$ is a constant while the limit is taken, setting it to zero when it's allowed to be any real number is just too restrictive. This preliminary conclusion that it's a bug is strengthened  below where I try to understand why it may be happening, and whether the function f[k, \u03b1] can be made to look less pathological before doing the limit.\nWork-around\nFrom the comments in the other answers, it is clear that Mathematica doesn't use the assumption of real variables at a sufficiently early stage in the calculation. You can even see that without taking any limit:\nf[0, \u03b1]\n\n\n2\n\nThe reason for this result is that it can't see the simplification $\\sqrt{\\alpha^4}-\\alpha^2 = 0$ which is always true for real $\\alpha$. It knows this fact, but isn't using it. To check this, we can do\nRefine[0 == (Sqrt[\u03b1^4] - \u03b1^2), \u03b1 \u2208 Reals]\n\n\nTrue\n\nIf this guess about the bug is right, then it's basically a problem of the order of two non-commuting limits. In addition to doing $k\\to0$, the assumption of real $\\alpha$ amounts to taking the limit $\\Im(\\alpha)\\to 0$ (zero imaginary part). If you do the latter limit last, it gives $2$, but we are interested in the opposite order of limits.\nTo avoid this problem, one can eliminate the variable $k$ in terms of a new variable that gets rid of the square root:\nFirst transform to variables $x=\\sqrt{k}$ and $y=\\alpha^2$ to end up with at most squares:\nClear[g];\ng[x, y] = Simplify[f[x^2, Sqrt[y]]]\n\n\n$\\frac{\\left(x^2+2\\right)\\left(y-\\sqrt{x^2+y^2}\\right)+x^2}{-\\sqrt{x^2+y^2}+2x^2+y}$\n\nNext, define a third new variable $z\\equiv y-\\sqrt{x^2+y^2}$  that incorporates the unwanted square root, \nnewg = g/.First@Solve[Eliminate[{g == g[x, y], z == -Sqrt[x^2 + y^2] + y}, x],g]\n\n\n$\\frac{2 y z+2 y-z^2-z-2}{4 y-2 z-1}$\n\nFinally, observe that the limit $k\\to0$ is the same as the limit $z\\to0$ provided that we make the assumption $\\lim_{x\\to 0}(y-\\sqrt{x^2+y^2})=0$ (which is true because $y\\ge0$). Therefore, we can take the desired limit by setting\nnewg /. z -> 0\n\n\n$\\frac{2 y-2}{4 y-1}$\n\nThis is the correct limit if we reinstate $y=\\alpha^2$. Note that I didn't have to use Limit at all because the function is well-behaved in this simplified form.\n", "editing - Is it possible to colorize brackets in the notebook editor to see matches more easily?": "\n\nIf there's no way to colorize bracket nesting, is there a keyboard\n  shortcut for \"Check Balance\" like shift-% in VIM for C-code?\n\nYes, right from the help file:\n\nCheck Balance \u00a0\u00a0\u00a0 Shift+Ctrl+B\n\n", "evaluation - Module variable scoping in Scheduled Tasks?": "\nYou hit a rather subtle behavior, related to the garbage-collection and the Temporary attribute, and the semantics of Module regarding returning expressions. The thing is, to achieve your goal, you need the Module-generated variable (function)'s definition(s) to be exported outside Module (to be persistent). But, since you return not the symbol itself, but its r.h.s. (which is a chunk of code with delayed evaluation, either Function or ScheduledTaskObject in this case), the definitions of runNextTask are destroyed because it has a Temporary attribute, despite the fact that code containing this variable has been exported outside Module. \nTo illustrate my point, here are two work-arounds which both will lead to your desired effect:\n\nInstead of assigning runNextTask to Unique[], insert a line ClearAll[runNextTask] right after the Module declarations. This will remove the Temporary attribute and the definition of runNextTask will persist.\nWrap your final call in Hold (so, return Hold[runNextTask[]]), and then use ReleaseHold outside Module.\n\nThis is your code for this option:\nres = \n Module[{state = 0, runNextTask},\n   runNextTask[] :=\n     StartScheduledTask@\n       CreateScheduledTask[\n         state = state + 1;\n         If[state < 4,\n           (Print[state]; runNextTask[])\n         ],\n         {0.10}];\n   Hold@runNextTask[]]\n\nReleaseHold[res]\n\nIn this case, the definition also persists. \nNote that this problem is not seen in examples where all evaluation happens at the time when Module is left: the following code will execute promptly\nModule[{f, n = 0},\n  f[] := (n++; If[n < 10, Print[\"*\"]; f[]]);\n  f[]]\n\neven though all definitions for f are destroyed at the end - because the execution here is immediate (the same evaluation process, so that f still has all definitions during this evaluation), while delayed and asynchronous code induces a separate evauation process.\n", "calculus and analysis - Derivative of real functions including Re and Im": "\nThe functions Re and Im (just as Conjugate) don't satisfy the Cauchy-Riemann differential equations and are therefore not analytic. That means their derivative is not uniquely defined in the complex plane. That's the reason why Re' and Im' can't be simplified. \nTherefore, we have to be more specific about how we want the limit to be done that corresponds to the desired derivative. The cleanest way of doing that is this simple replacement for the derivative:\nLimit[(Gamma[I (x + \u03b5)] - Gamma[I x])/\u03b5, \u03b5 -> 0]\n\n\n$i \\Gamma (i x) \\psi ^{(0)}(i x)$\n\nNow I'll try to apply this to the real part instead:\nAssuming[Element[x, Reals], Limit[(Re[Gamma[I (x + \u03b5)]] - Re[Gamma[I x]])/\u03b5, \u03b5 -> 0]]\n\n\n$-\\Im(\\psi ^{(0)}(i x)) \\Re(\\Gamma (i x))-\\Im(\\Gamma (i x))\n   \\Re(\\psi ^{(0)}(i x))$\n\nSo we don't get any of the pesky Re' here. For those who don't like the $\\LaTeX$ format, here is the real output:\n-Im[PolyGamma[0, I x]] Re[Gamma[I x]] - Im[Gamma[I x]] Re[PolyGamma[0, I x]]\n\nEdit: generalization\nMotivated by the discussion of Heike's answer, I wrote a definition of a directional derivative in an arbitrary direction in the complex plane. I did this to show that such a definition can be made without in any way modifying SystemOptions (see in particular \"More Information\").\ndirDeriv[f_, var_, angle_: 0] := Module[{g, x},\n  g = f /. var -> x;\n  Assuming[x \u2208 Reals,\n   D[g, x] /. (h_'[p_] :> h'[p]/D[p, x]) /. (h_'[p_] :> \n       Limit[(h[p /. x -> x + \u03b5 Exp[I angle]] - \n            h[p])/\u03b5/Exp[I angle], \u03b5 -> 0]) /. \n    x -> var\n   ]\n  ]\n\nThe first argument is the function to be differentiated, the second argument is the name of the independent variable, which will be treated as a real number. The third (optional) argument is the phase angle of the line in the complex plane along which the limit for the derivative is taken. By default this angle is zero corresponding to the real axis (the result depends on the angle only if the first argument is non-analytic).\nHere is how to apply this function as a replacement for the standard derivative:\ndirDeriv[Re[Gamma[I x]], x]\n\n\n$-\\Im(\\psi ^{(0)}(i x)) \\Re(\\Gamma (i x))-\\Im(\\Gamma (i x))\n   \\Re(\\psi ^{(0)}(i x))$\n\nA simpler example is\ndirDeriv[Re[Exp[I x^2]], x]\n\n\n$-2 x \\sin \\left(x^2\\right)$\n\nThe function works by doing the standard derivative and then looking for any occurrences of Re', Im' and others (in fact, anything looking like h_'[p_]). These patterns are then replaced by first undoing the chain rule that Mathematica automatically applies (that's the division by D[p, x]), and then calculating the directional derivative  as a limit analogous to the example above.\nWith this function one can easily explore the direction dependence of the derivative for non-analytic functions. For example,\nTable[dirDeriv[Re[x], x, angle], {angle, 0, Pi, Pi/4}]\n\n\n{1, 1/2 - I/2, 0, 1/2 + I/2, 1}\n\nEdit 2: numerical functions\nThe above discussion concerns symbolic directional derivatives of possibly non-analytic functions. The situation is in some ways much simpler if the goal is to do  numerical differentiation, i.e., calculate the derivative of a function f[x] which is numeric when the argument x is numeric. \nFor that case, one can go straight to the numerical approach by doing this:\nNeeds[\"NumericalCalculus`\"];\nND[Re[Gamma[I x]], x, 1]\n\nWith the numerical derivative ND, you can for example make plots directly. Here is a comparison of the symbolic result with the numerical one:\nPlot[{\n  -Im[PolyGamma[0, I x0]] Re[Gamma[I x0]] - \n   Im[Gamma[I x0]] Re[PolyGamma[0, I x0]], \n   ND[Re[Gamma[I x]], x, x0]},\n  {x0, 0, 5}, PlotStyle -> {Thin, Dotted}]\n\n\n", "pattern matching - Split a Unicode string maintaining uppercase characters": "\nYou can do the lower case conversion as a condition on the pattern, and thereby retain the original:\nStringCases[\"Ttatt\u00c1atT\", c__ /; MemberQ[List@@alt, ToLowerCase[c]]]\n\n\n{\"Tt\", \"a\", \"tt\", \"\u00c1\", \"a\", \"tT\"}\n\n", "evaluation - Difficulty catching thrown errors in asynchronous tasks": "\nWhy this does not work\nThe problem here seems to be that Catch can only catch exceptions thrown by some code down the same evaluation stack, corresponding to the same evaluation process. However, the asynchronous mechanism you use (based on CreateScheduledTask etc) induced a different evaluation at a specified time, with another evaluation stack, and at a later time. So, at any given iteration, your Catch is watching for the stack number n, while your exception, if thrown, will be in a stack number n+1 - in other words, your Catch is always one evaluation too early.\nIn order to catch your exceptions, you'd have to place Catch inside CreateScheduledTask (so that it watches the correct evaluation stack), which would largely destroy the purpose. Therefore, I'd suggest to communicate the state and status of your system (error or not) via flags, which are set inside your code in CreateScheduledTask, and checked in your function, rather than using exceptions. You can, of course, still use exceptions to short-circuit the failure inside the code in CreateScheduledTask, but not as a communication mechanism between that code and the function which creates it (but see also below).\nTime travel and lazy evaluation, or how to make it work\nHowever, using exceptions in the fashion you want is not impossible, thanks to the lazy evaluation, available in Mathematica. If you insist on minimal modification for your code, then here is how: make your function runNextTask accept some arbitrary code as a parameter, and hold it, evaluating only inside body. Then:\nModule[{state = 0, runNextTask, catchResult,\n    defaultCatchResult =  Unique[]},\n    (*the following device removes the \"Temporary\" \n      attributes from \"runNextTask\" and \"catchResult.\"*)\n    ClearAll[runNextTask, catchResult];\n    SetAttributes[runNextTask, HoldAll];\n    runNextTask =\n     Function[\n        code,\n        catchResult =\n          Catch[\n             code;\n             If[state < 4,\n              (*the following invocation techniques make \n                the body here asynchronous.*)\n                 StartScheduledTask@\n                   CreateScheduledTask[\n                     state = state + 1;\n                     runNextTask[If[state < 2, Print[state], Throw[state]]],\n                     (*This is the amount of time with which to separate \n                      asynchronous invocations.*)\n                     {0.10}\n                   ]\n             ]; (* If *)\n             defaultCatchResult\n          ]; (* Catch *)\n          If[catchResult =!= defaultCatchResult, Print[\"ERROR\"]],\n          HoldAll\n     ]; (* Function *)\n     runNextTask[Null]]\n\nNote that the function is now HoldAll, as well as the runNextTask (the latter isn't really necessary though). By using this construct, I basically pass the code from the \"future\" to the \"past\" (from the stack-matching perspective. Of course, it is really the other way around), making it evaluate in a different evaluation stack, now the same as that where Catch is - and now it works.\n", "parallelization - Setting $RecursionLimit across all parallel kernels": "\nAs sebhofer pointed out, my previous solution didn't work \u2014 a fact that I missed because I wrote it without an mma to test. The users who voted for it also must've missed it, because on the surface it looks like a straightshot answer, but no. So, here's Jackson's solution that works \u2014 Use ParallelEvaluate as:\nParallelEvaluate[$RecursionLimit = 10^6]\n\n\nHere's my previous solution that doesn't work, but I'm leaving it here so that others will not try something similar.\nBlock[{$RecursionLimit = Infinity},\n    SetSharedVariable[$RecursionLimit]\n    (* your parallel code *)\n]\n\nUsing Block allows you to temporarily modify $RecursionLimit so that the global value is unaffected andSetSharedVariable declares that the variable's value is synchronized across all kernels.\n", "faq - Can I simplify an expression into form which uses my own definitions?": "\nDaniel Lichtblau and Andrzej Koslowski posted a solution in mathgroup, which I adjusted marginally. (I like to use german identifiers, because they will never clash with Mma builtins). That's the code:    \nSetAttributes[termErsetzung,Listable];\ntermErsetzung[expr_, rep_, vars_] := \nModule[{num = Numerator[expr], den = Denominator[expr],\n        hed = Head[expr], base, expon},\n  If[PolynomialQ[num, vars] && PolynomialQ[den, vars] && ! NumberQ[den], \n    termErsetzung[num, rep, vars]/termErsetzung[den, rep, vars], (*else*)\n    If[hed === Power && Length[expr] === 2,        \n       base  = termErsetzung[expr[[1]], rep, vars];\n       expon = termErsetzung[expr[[2]], rep, vars];\n       PolynomialReduce[base^expon, rep, vars][[2]],        (*else*)\n      If[Head[Evaluate[hed]] === Symbol && \n        MemberQ[Attributes[Evaluate[hed]], NumericFunction], \n        Map[termErsetzung[#, rep, vars] &, expr],    (*else*)\n       PolynomialReduce[expr, rep, vars][[2]] ]]]\n];\n\nTermErsetzung[rep_Equal,vars_][expr_]:=\n  termErsetzung[expr,Evaluate[Subtract@@rep],vars]//Union;\n\nUsage is like this:\na*b/(a + a*Cos[a/b]) // TermErsetzung[k b == a, b]\n\n\na/(k (1 + Cos[k]))\n\nThe first parameter is the \"replacement equation\", the second the variable (or list of variables) to be eliminated:\na*b/(a + a*Cos[a/b]) // TermErsetzung[k b == a, {a, b}] \n\n\n{b/(1 + Cos[k]), a/(k (1 + Cos[k]))}\n\n", "graphics - How can I extract data points from a black and white image?": "\nUPDATE: Added a few workarounds for bugs / features introduced in Mathematica v10 or later.\n\nMain issue involved LocatorPane whose Appearance option no longer correctly handles more than one Graphics object [CASE:4984027]. This bug was introduced somewhere after v11.3 and is present in v.13.1.  Additional issues concerned the scaling of the graphics used in the various panels, which was incorrect. Perhaps a different default was introduced somewhere after v9 where the code worked as intended.\n\n\nOriginal text\nHere the contours of a method to do this half-automatic selection you are looking for. It is heavily based on an example on the ImageCorrelate doc page of Waldo fame. First, you interactively select an example of the plot marker you want to look for:\nimg = Import[\"http://i.stack.imgur.com/hhPr9.png\"];\n\npt = {ImageDimensions[img]/4, ImageDimensions[img]/2};\nLocatorPane[\n Dynamic[pt],\n Dynamic[\n  Show[\n   img,\n   Graphics[\n    {\n     EdgeForm[Black], FaceForm[], Rectangle @@ pt\n     }\n    ]\n   ]\n  ], Appearance -> Graphics[{Red, AbsolutePointSize[5], Point[{0, 0}]}]\n ]\n\n\nThen you use Mathematica v8's image processing tools to find similar structures:\nres =\n  ComponentMeasurements[\n   MorphologicalComponents[\n    ColorNegate[\n     Binarize[\n      ImageCorrelate[\n       img,\n       ImageTrim[img, pt],\n       NormalizedSquaredEuclideanDistance\n       ], 0.18\n      ]\n     ]\n    ], {\"Centroid\", \"Area\"}, #2 > 1 & (*use only the larger hits*)\n   ];\n\nThe coordinates are now in res. I'll show them below. Many are correct, sometimes you get some spurious hits and misses. It depends on the Binarize threshold value and the \"Area\" size chosen in ComponentMeasurements third argument.\nShow[img, Graphics[{Green, Circle[#, 5] & /@ res[[All, 2, 1]]}]]\n\n\n\nEDIT: Here a more complete application. It is not robust as it is (no error handling at all), but nevertheless already quite useful.\nThe function getMarkers is called with an image as argument and the name of a variable in which the final markers are returned:\n\nYou get the app with tabs that represent processing stages:\n\nIn the first tab you define the axes by dragging the colored dots to the locations on the x and y axis with the highest known value and to the origin of the plot. Here, you also enter the values for the bottom left and top right corners of the rectangle that they define:\n\nIn the next tab you then indicate the marker you want to have detected:\n\nThe detection results are presented in the next tab and you can drag a slider to increase or decrease the number of results:\n\n\n\nYou can manually adjust the detected markers in the next tab. Markers can be dragged, removed (alt-click an existing marker) and added (alt-click on an empty spot). Actually, this is so easy to do that I would be tempted to say that I could do without the marker-detection  phase.\nThe end result can be seen in the Results tab. If something is wrong you can go back to an earlier tab:\n.\nThe data plotted in the Results tab is also copied in the variable passed to the function, test in this example.\ntest\n\n(*\n==> {{400.5159959, 0.007353847123}, {450.3095975, \n  0.005511544915}, {499.8452012, 0.004129136525}, {550.9287926, \n  0.002664992936}, {600.4643963, 0.001702431875}, {653.869969, \n  0.000764540446}, {685.6037152, 0.0002398789942}, {764.7123323, \n  0.0002481309886}, {801.7027864, 0.0001989932135}}\n*)\n\nThe code:\nfindMarkers[img_, pt_, thres_, minArea_] :=\n  ComponentMeasurements[\n    MorphologicalComponents[\n     ColorNegate[\n      Binarize[\n       ImageCorrelate[img, ImageTrim[img, pt],\n        NormalizedSquaredEuclideanDistance\n        ], thres]\n      ]\n     ],\n    {\"Centroid\", \"Area\"},\n    #2 > minArea &\n    ][[All, 2, 1]];\n\nSetAttributes[getMarkers, HoldRest];\ngetMarkers[img_, resMarkers_] :=\n DynamicModule[\n  {\n   pt = {ImageDimensions[img]/4, ImageDimensions[img]/2},\n   axisDefinePane, defineMarkerPane, findMarkerPane, editMarkersPane, \n   finalResultPane, xAxisBegin, xAxisEnd, yAxisBegin, yAxisEnd, \n   myMarkers, myTransform, \n   xoy = {{1/2, 1/8} ImageDimensions[img], {1/8, 1/8} ImageDimensions[\n       img], {1/8, 1/2} ImageDimensions[img]}},\n  axisDefinePane =\n   Grid[\n    {\n     {\n      LocatorPane[\n       Dynamic[xoy],\n       Dynamic[\n        Show[\n         img,\n         Graphics[{Line[xoy]}],\n         ImageSize -> ImageDimensions[img]\n         ]\n        ],\n       Appearance ->\n        {\n         Graphics[{AbsolutePointSize[5], Red, Point[{0, 0}]}],\n         Graphics[{AbsolutePointSize[5], Green, Point[{0, 0}]}],\n         Graphics[{AbsolutePointSize[5], Blue, Point[{0, 0}]}]\n         }\n       ]\n      },\n     {Row[{\"x(1): \", \n        InputField[Dynamic[xAxisBegin], Number, FieldSize -> Tiny], \n        \" x(2): \", \n        InputField[Dynamic[xAxisEnd], Number, \n         FieldSize -> Tiny]}]}, {Row[{\"y(1): \", \n        InputField[Dynamic[yAxisBegin], Number, FieldSize -> Tiny], \n        \" y(2): \", \n        InputField[Dynamic[yAxisEnd], Number, \n         FieldSize -> Tiny]}]}}];\n  \n  defineMarkerPane =\n   LocatorPane[\n    Dynamic[pt],\n    Dynamic[\n     Show[\n      img,\n      Graphics[{EdgeForm[Black], FaceForm[], Rectangle @@ pt}],\n      ImageSize -> ImageDimensions[img]\n      ]\n     ],\n    Appearance -> Style[\"\\[FilledSmallCircle]\", Red]\n    ];\n  \n  findMarkerPane =\n   Manipulate[\n    Show[\n     img,\n     Graphics[{Red, \n       Circle[#, 5] & /@ (myMarkers = findMarkers[img, pt, t, 1.05])}],\n     ImageSize -> ImageDimensions[img]\n     ],\n    {{t, 0.2, \"Threshold\"}, 0, 1},\n    TrackedSymbols -> {t},\n    ControlPlacement -> Bottom\n    ];\n  \n  editMarkersPane =\n   LocatorPane[\n    Dynamic[myMarkers],\n    img,\n    Appearance -> \n     Graphics[{Red, Circle[{0, 0}, 1]}, ImageSize -> 10],\n    LocatorAutoCreate -> True\n    ];\n  \n  finalResultPane =\n   Dynamic[\n    myTransform = \n     FindGeometricTransform[{{xAxisEnd, yAxisBegin}, {xAxisBegin, \n          yAxisBegin}, {xAxisBegin, yAxisEnd}}, xoy][[2]] // Quiet;\n    ListLinePlot[resMarkers = myTransform /@ Sort[myMarkers], \n     Frame -> True, Mesh -> All, ImageSize -> ImageDimensions[img]],\n    TrackedSymbols -> {myMarkers, xoy, xAxisEnd, yAxisBegin, \n      xAxisBegin, yAxisBegin, xAxisBegin, yAxisEnd}\n    ];\n  \n  TabView[\n   {\n    \"Define axes\" -> axisDefinePane,\n    \"Define marker\" -> defineMarkerPane,\n    \"Find Markers\" -> findMarkerPane,\n    \"Edit Markers\" -> editMarkersPane,\n    \"Results\" -> finalResultPane\n    }\n   ]\n  ]\n\n", "import - Importing a large Excel file": "\nFrom a very pragmatic point of view, it might be easier to use an external tool such as xlsx2csv (Python script, but other alternatives exist). Then simply import the comma-separated values:\nImportString[StringJoin\n  @Riffle[ReadList[OpenRead[\"!./xlsx2csv.py test.xlsx\"], \"String\"], \"\\n\"], \"CSV\"];\n\nOn a 21\u00a0MB XLSX file on my Mac Book Pro, the above takes 115 seconds. xlsx2csv accounts for 95 of those, and 20 seconds for the Mathematica import. It can be made even faster with a temporary file (and then directly importing instead of using string operations), reducing the timing of the Mathematica part down to 10 seconds.\n", "front end - Finding a Specific Line in a Package": "\nThere is a certain impedance mismatch between lines of code and Mathematica expressions, because Mathematica code is written more or less directly in the parse trees, and the syntax (which encourages nested expressions) was not particularly designed to make lines a  really good concept here. That said, this would be a problem in any language, to various extents, because, while you know what you meant in the code and what the error is, the parser may interpret things differently (this is the difference between syntax and semantics). For example, your particular error which you mentioned in the question will be interpreted as a bracket not closed at the end of file, not where you think it really happens (because the parser thinks that the rest of the code is within an opening bracket of Protect). \nIn any case, the following function will (hopefully) at least tell you what parser thinks, in terms of line numbers:\nClearAll[getErrorLine];\ngetErrorLine[filename_String] :=\n Module[{code, lengths},\n    code = Import[filename, \"Text\"];\n    lengths = StringLength /@ StringSplit[code, \"\\n\"] + 1;\n    With[{sl = SyntaxLength[code]},\n      LengthWhile[Accumulate[lengths], # < sl &]\n    ]\n ]\n\nFor a test package like this (all new lines intact):\nBeginPackage[\"SyntaxTest`\"]\n\nf::usage;\n\nBegin[\"`Private`\"]\n\ng[x_]:= x^2;\n\nf[x_]:=Sin[g[x]\n\nEnd[]\n\nEndPackage[]\n\nit gives\ngetErrorLine[\"C:\\\\Temp\\\\SyntaxTest.m\"]\n\n\n13\n\nwhich is, at the end of the package. And this is correct, since you can not assign a well-defined semantics to a syntactically broken code, so you can only ask what parser thinks.\n", "Getting Integrate to perform numerical integration": "\nUse NIntegrate to perform numerical integration (simply replace Integrate with NIntegrate in the definition of R21). On my laptop, it spits out the numerical value of the result in 0.3\u00a0s (and the result is 9.46643, by the way).\n", "syntax - Integrating with multiple indicator functions": "\nA better construct for your indicator function would be using Piecewise. So you'd define an indicator function $I_{(a,b]}$ as:\nindicator[a_, b_][x_] := Piecewise[{{1, a < x <= b}, {0, True}}]\n\nHowever, there are other issues in your code that could be improved. \n\nFirst, avoid using capital letters for your variables/functions. This is because Mathematica uses that notation for its own functions and invariably, you'll (at some point) be bitten by it.\nDefine your functions by appropriately scoping the variable. For example you defined Js = 6 s (1 - s). However, if s had a pre-existing value (you never know... sometimes it could be in a different notebook but shared context), then you're assigning to Js the result based on that value of s.\nUse Set (=) instead of SetDelayed (:=) when you use D. Otherwise, you'll end up calculating the derivative at each integration point. See this answer for an example of why this matters.\n\nMy suggested rewrite of the definitions part of your problem would be something like this:\nj[s_] := 6 s (1 - s);      (*weight function*)\nj1[s_] = D[j[s], s] ;      (*first derivative of Js*)\nj2[s_] = D[j[s], {s, 2}];  (*second derivative of Js*)\nf[s_] := 1/(1 + Exp[-(s)]) (*Fs*)\nfinv[s_] := -Log[-1 + 1/s] (*F inverse*)\nfinv1[s_] = D[finv[s], s]; (*derivative of F inverse*)\n\nYou can try working with this and the indicator function above to see if it makes any difference or if you're getting the answer you expect.\n", "numerics - Numerical underflow for a scaled error function": "\nIf you have an analytic formula for f[x_] := Erfc[x]*Exp[x^2] not using Erfc[x] you could do what you expect.  However it is somewhat problematic to do in this form because Erfc[x] <  $MinNumber for x == 27300.\n$MinNumber\n\n\n1.887662394852454*10^-323228468\n\n\nN[Erfc[27280.], 20]\n\n\n5.680044213569341*10^-323201264\n\n\nEdit\nA very good approximation of your function f[x] for values x > 27280 you can get making use of these bounds ( see e.g. Erfc on Mathworld) :\n\nwhich hold for x > 0.\nHere we find values of the lower and upper bounds with  relative errors for various x:\nT = Table[ \n          N[#, 15]& @ {2 /(Sqrt[Pi] (x + Sqrt[2 + x^2])), \n                       2 /(Sqrt[Pi] ( x + Sqrt[x^2 + 4/Pi])), \n                       1 - ( x + Sqrt[x^2 + 4/Pi])/(x + Sqrt[2 + x^2]),\n          {x, 30000 Table[10^k, {k, 0, 5}]}];\n\nGrid[ Array[ InputField[ Dynamic[T[[#1, #2]]], FieldSize -> 13] &, {6, 3}]]\n\n\nTherefore we propose this definition of the function f (namely the arithetic mean of its bounds for x > 27280 )  :\nf[x_]/; x >= 0 := Piecewise[ { { Erfc[x]*Exp[x^2],                      x < 27280 },\n\n                               { 1 /( Sqrt[Pi] ( x + Sqrt[2 + x^2])) \n                               + 1 /( Sqrt[Pi] ( x + Sqrt[x^2 + 4/Pi])), x >= 27280}}\n                           ]\nf[x_] /; x < 0 := 2 - f[-x]\n\nI.e. we use the original definition of the function f for 0 < x < 27280, the approximation for x > 27280 and for x < 0 we use the known symmetry of the Erfc function, which is relevant when we'd like to calculate f[x] for  x < - 27280. \nNow we can safely use this new definition for a much larger domain :\n{f[300], f[300.], f[30000.], f[-30000.]}\n\n\n{E^90000 Erfc[300], 0.0018806214974, 0.0000188063, 1.99998}\n\n\nand now we can make plots of f around of the gluing point ( x = 27280.)\nGraphicsRow[{ Plot[ f[x], {x, 2000, 55000}, \n                      Epilog -> {PointSize[0.02], Red, Point[{27280., f[27280.]}]}, \n                      PlotStyle -> Thick, AxesOrigin -> {0, 0}], \n              Plot[ f[x], {x, 27270, 27290}, \n                      Epilog -> {PointSize[0.02], Red, Point[{27280., f[27280.]}]}, \n                      PlotStyle -> Thick]}]\n\n\n", "How to apply or map a list of functions to a list of data?": "\nHere's how you can do it in a simple way:\nfunctionMap[funcs_List, data_] := Module[{fn = RotateRight[funcs]}, \n    First[(fn = RotateLeft[fn])][#] & /@ data]\n\nUse it as:\nfunctionMap[{f1, f2, f3}, Range[20]]\n(* {f1[1], f2[2], f3[3], f1[4], f2[5], f3[6], f1[7], f2[8], f3[9], f1[10],\n    f2[11], f3[12], f1[13], f2[14], f3[15], f1[16], f2[17], f3[18], f1[19], f2[20]} *)\n\n", "Delayed evaluation of assignment": "\nI think this does what you want, it is like a Block that accepts the local variables given as rules. Using Block instead of With should solve the problem that some of your parameters are \"hidden in complicated functions\":\nClearAll@blockrules\n\nSetAttributes[blockrules, HoldAll]\n\nblockrules[rules_, expr_] := Block @@ Join[\n   Hold @@ {rules} /. Rule -> Set,\n   Hold[expr]\n   ]\n\nuse it like e.g.:\nblockrules[ass1, NDSolve[diffEq, {x}, {t, 0, 1}]]\n\nWhile I think this should solve the problem you were describing, you probably should think about rearranging your code so that it does not use global symbols hidden deeply in complicated functions as parameters but rather make those parameters explicit arguments to those functions. You are asking for all kind of hard to detect errors with those \"hidden\" parameters...\n", "front end - How to visualize/edit a big matrix as a table?": "\nBased on the approach of F'x this is a version aimed rather at large arrays. It should perform reasonably well independent of the array size and lets one edit the given variable directly. Performance suffers only from the maximal number of rows and columns to be shown, which can be controlled with the second argument. I did choose to use the \"usual\" syntax for controllers with a Dynamic wrapper, which basically just serves as a Hold in the function definition pattern. With the Interpretation-wrapper it will evaluate to just the array it shows. There are a lot of possible improvements, so everyone is welcome to make such improvements. Here is the code:\neditMatrix[Dynamic[m_], maxfields_: {10, 10}] := \n  With[{maxrows = Min[maxfields[[1]], Length[m]], \n    maxcols = \n     If[(Depth[m] - 1) == 2, Min[maxfields[[2]], Length[m[[1]]]], 1]},\n    Interpretation[\n    Panel[DynamicModule[{rowoffset = 0, coloffset = 0}, \n      Grid[{{If[Length@m > maxrows, \n          VerticalSlider[\n           Dynamic[rowoffset], {Length[m] - maxrows, 0, 1}]], \n         Grid[Table[\n           With[{x = i, y = j}, \n            Switch[{i, j}, {0, 0}, Spacer[0], {0, _}, \n             Dynamic[y + coloffset], {_, 0}, \n             Dynamic[x + rowoffset], _, \n             If[(Depth[m] - 1) == 2, \n              InputField[Dynamic[m[[x + rowoffset, y + coloffset]\n   ]\n             ], \n               FieldSize -> 5], \n              InputField[Dynamic[m[[x + rowoffset]]], FieldSize -> 5]\n   ]\n      ]\n            ],\n         {i, 0, maxrows}, {j, 0, maxcols}]]}, {Spacer[0], \n         If[Length@First@m > maxcols, \n          Slider[Dynamic[coloffset], {0, Length[m[[1]]] - maxcols, \n            1}]\n    ]}}]\n      ]\n    ],\n    m]\n];\n\nYou can test it with, e.g.:\na = RandomReal[1, {1000, 300}];\n\neditMatrix[Dynamic[a], {10, 6}]\n\n\nThis will confirm that a will actually be changed when editing the corresponding InputField:\nDynamic[a[[1, 1]]]\n\n", "Plotting contours of a function for different values of a parameter": "\nUse Table to generate the values for different t:\nContourPlot[Evaluate@Table[(x - t)^2 + (y - t^2)^2 == t^2, \n    {t, -20, 20, 1}], {x, -110, 110}, {y, -110, 110}]\n\n\n", "How do I calculate the probability of reaching mean residual life": "\nThis topic is a bit unfamiliar to me but here's my take. I believe you can simplify your life a bit by looking at an alternative definition of mrl.\nUsing the definition for continuous distributions...\nExpectation[x - t \\[Conditioned] x > t, x \\[Distributed] dist] ==\nExpectation[x - t, x \\[Distributed] TruncatedDistribution[{t, Infinity}, dist]] ==\nExpectation[x, x \\[Distributed] TruncatedDistribution[{t, Infinity}, dist]] - t\n\ngiving us...\n mrl[t_] = Mean[TruncatedDistribution[{t, Infinity}, dist]] - t\n\nThis gives an easy way to obtain another measure which, according to Klein and Moeschberger (a book I highly recommend), is preferable for skewed distributions. This is the median residual life:\nmdrl[t_] =  Median[TruncatedDistribution[{t, Infinity}, dist]] - t\n\nFor fun, lets compare them for dist = LogNormalDistribution[1.75, .65].\nPlot[{mrl[t], mdrl[t]}, {t, 0, 40}, PlotStyle -> {Red, Blue}]\n\n\nNow the probability that someone survives mrl (or mdrl) units beyond time t given they have survived to time t is relatively easy to compute in that we can state it exactly as we say it.\npMRL[t_] := NProbability[x > t + mrl[t] \\[Conditioned] x > t, x \\[Distributed] dist]\npMDRL[t_] := NProbability[x > t + mdrl[t] \\[Conditioned] x > t, x \\[Distributed] dist]\n\nNot surprisingly, the plot for pMDRL is not very exciting compared to pMRL.\nPlot[{pMRL[t], pMDRL[t]}, {t, 0, 10}, PlotStyle -> {Red, Blue}]\n\n\n", "plotting - Fixing quirky typesetting in plot labels": "\nTo fix the superscript placement and the italic m, you can use the options ScriptBaselineShifts and SingleLetterItalics in Style. For example\nPlot[1 - Exp[-x], {x, 0, 3}, AxesLabel -> {\"thickness (\u03bcm)\",\n  Style[Row[{\"power density \", Style[\"(\",Larger], \"W/m^2\", Style[\")\", Larger]}],\n    ScriptBaselineShifts -> {0, .5},\n    SingleLetterItalics -> False, \"TraditionalForm\"]}]\n\n\nThere are some other options in Style that might help. For example if you want a smaller font for the superscript, you can use the option ScriptSizeMultipliers.\n", "graphics - Rotate doesn't work with BarChart and BoxWhiskerChart": "\nYou left off the angle to rotate through:\nRotate[BarChart[RandomReal[1, {4, 5}], ChartLayout -> \"Percentile\"], 90 Degree]\n\n\nRotate[BarChart[RandomReal[1, {4, 5}], ChartLayout -> \"Percentile\"], 45 Degree]\n\n\nStrange that it didn't throw an error, though.\n", "numerics - Finding real roots of negative numbers (for example, $\\sqrt[3]{-8}$)": "\nMathematica 9 introduces two new functions, CubeRoot and Surd, that give real-valued roots:\nIn[1]:= CubeRoot[-8]\nOut[1]= -2\n\nIn[2]:= Surd[-32, 5]\nOut[2]= -2\n\nYou can use these to plot real roots:\nPlot[CubeRoot[x], {x, -3, 3}]\n\n\nNote that these functions are undefined for complex numbers:\nIn[5]:= CubeRoot[1 + I]\n\nCubeRoot::preal: The parameter 1+I should be real valued. >>\n\nOut[5]= Surd[1 + I, 3]\n\nand the typeset form has a small \"tail\" at the end of the overbar to visually distinguish them from the usual roots:\n\n", "import - Stream CSV or TSV files": "\nHere is a function which may help:\nClear[readRows];\nreadRows[stream_, n_] :=\n   With[{str = ReadList[stream, \"String\", n]},\n      ImportString[StringJoin[Riffle[str, \"\\n\"]], \"Table\"] /; str =!= {}];\nreadRows[__] := $Failed;\n\nI tested on your file and it works all right (it may make sense to read rows in batches, this is much faster):\nn=0;\nstr = OpenRead[\"C:\\\\Temp\\\\EUR_USD_Week1.csv\"];\nWhile[readRows[str, 1000] =!= $Failed, n++];\nClose[str];\nn\n\n(*  82   *)\n\nBy the way, speaking of practicality of Import - I agree, but do read this answer - it is based on the same idea as above code, and makes importing whole files quite practical IMO. In particular, using the readTable function from there, I get your file read in its entirety under 3 seconds on my machine:\nIn[64]:= readTable[\"C:\\\\Temp\\\\EUR_USD_Week1.csv\",2000]//Short//AbsoluteTiming\nOut[64]= {2.4775391,{{lTid,cDealable,CurrencyPair,RateDateTime,RateBid,RateAsk},\n  <<81172>>,{1385715072,D\\[Ellipsis] SD,2011-01-07,\\[Ellipsis] }}}\n\nwith a very decent memory usage:\nMaxMemoryUsed[]\n\n(* 71652808 *)\n\nmeaning 50 Mb of net usage (when you subtract the startup memory usage) - for this particular example. You can tweak the second parameter to trade run-time for memory efficiency. See the linked post for more details.\n", "How can one nested list be used to find the positions of those values in another nested list?": "\nHow about mapping Position like so\nPosition[listb, #] & /@ lista\n(*{{{3}}, {{4}}, {{5}}, {{6}}, {{7}}, {{8}}, {{9}}, {{1}}, {{2}}}*)\n\nwhich gives the position of each sublist of lista in listb?\nTo get only the first instance, use\nPosition[listb, #, 1, 1] & /@ lista\n\n(the last argument of Position specifies how many positions found to return; the penultimate argument specifies the level at which to search).\n", "graphics - Plotting Error Bars on a Log Scale": "\nI always use the package ErrorBarLogPlots. From the website:\n\nErrorBarLogPlots.m is a package which adds log-scale plotting functions similar to the standard ErrorListPlot provided in Mathematica 6. The added functions are ErrorListLogPlot, ErrorListLogLinearPlot, and ErrorListLogLogPlot.\"\n\n", "export - Exporting and reimporting a list of lists changes the dimensions": "\nWhat is happening is that your data is imported as strings:\ndummy = Table[{k, 2*k}, {k, 1, 3}, {m, 1, 3}]\nDimensions[dummy]\nExport[\"~/Desktop/dummy.dat\", dummy]; dummyImport = \n Import[\"~/Desktop/dummy.dat\"]\nDimensions[dummyImport] \nMap[Head, dummy, {-1}]\nMap[Head, dummyImport, {-1}]\n\n\nOne way to fix it is to force the save to occur in some particular format:\ndummy = Table[{k, 2*k}, {k, 1, 3}, {m, 1, 3}]\nDimensions[dummy]\nExport[\"~/Desktop/dummy.dat\", dummy, \"MAT\"]; dummyImport = \n Import[\"~/Desktop/dummy.dat\", \"MAT\"]\nDimensions[dummyImport] \n\nMap[Head, dummy, {-1}]\nMap[Head, dummyImport, {-1}]\n\n\nAlternatively, DumpSave, which uses an OS-dependent format, may be used to save and reload parts of the environment\nDumpSave[\"~/Desktop/dummy.mx\", dummy];\nClearAll[dummy];\ndummy\nImport[\"~/Desktop/dummy.mx\"]\ndummy\n\n", "performance tuning - Getting lengths of sublists that sum to more than one": "\nVery good question / problem. Generally, this problem seems to belong to the class of problems where Compile is the best choice if maximum efficiency is looked for, since it is, by its nature, not a good fit for the Mathematica paradigm of working with lots of data at once. However, your last solution can be, in a somewhat modified form, brought to the same performance level while only partly compiled:\nClear[split, thresholdSemiCompiled];\nsplit = Compile[{{nums, _Real, 1}}, \n   FoldList[If[# > 1, 0, #] &[#1 + #2] &, 0.0, nums], \n   CompilationTarget -> \"C\"];\n\nthresholdSemiCompiled[l_List] := \n   Flatten@Differences[SparseArray[Unitize[split[l]] - 1][\"NonzeroPositions\"]]\n\nIt turns out that Clip was a major bottleneck in the compiled split, and once I replaced it with If, it became an order of magnitude faster. This one is on par with your fastest fully compiled solution, in terms of performance.\nEdit (by Oleksandr R., at Leonid's request)\nIn version 8, provided that an integer argument is used rather than a pattern, Position can be compiled down into a call to a new kernel/VM function \"Position\". This allows the above to be implemented in purely compiled code and avoids the need to use SparseArray in an undocumented and perhaps unintuitive way to get the positions of the zeros without unpacking the input array:\nthresholdCompiled = Compile[{{nums, _Real, 1}},\n  Flatten@Differences@Position[\n    Unitize@FoldList[If[# > 1, 0, #] &[#1 + #2] &, 0.0, nums],\n    0\n  ], CompilationTarget -> \"C\"\n ];\n\nThe performance gained by doing this is, perhaps surprisingly, relatively minor: this version returns timings of about 7/8ths those of the semi-compiled approach, irrespective of compilation to MVM bytecode or to C, probably due to the ability to locate zeros directly rather than having to subtract 1 from the array and find nonzero elements, and by avoiding the need to return a large intermediate array. (Unitize, Differences, Position, and Flatten are all compilable, but in version 8 they are compiled into simple function calls, so the only situation in which we would expect a performance gain through compilation is when, as here, it allows a larger problem to be dealt with entirely in compiled code.)\n", "Using several anonymous functions mixed together": "\nYou can always use Function to create anonymous functions:\nFunction[{a},a^2]\n\nis equivalent to\n#^2&\n\nand can be used as such, but it is unambiguous.\nIt can be used as:\nFunction[{a},a^2][2]\n\n(* ==> 4  *)\n\n", "programming - Cases[data,Colon[key,_]] vs. Cases[data,key:_] toward XPath, XQuery": "\nI'd like to discuss two points:\nCases, destructuring and escaping in patterns\nThere indeed can be a problem when using Cases to destructure expressions involving rules, because Cases has an extended syntax which uses rules, and interprets them differently. For example:\ndataR = {row1 -> {key1 -> value1, key2 -> value2}, \n    row2 -> {key1 -> value3, key2 -> value4}}\n\nHere is a naive attempt that will fail:\nCases[dataR, row1 -> _]\n\n(* {} *)\n\nThis will work:\nCases[dataR, p : (row1 -> _)]\n\n(* {row1 -> {key1 -> value1, key2 -> value2}} *)\n\nThe reason is that the colon (which is a short-cut for Pattern) serves as an escaping mechanism in this case. The \"politically correct\" way to perform escaping in patterns is however to use Verbatim:\nCases[dataR, Verbatim[Rule][row1, _]]\n\n(* {row1 -> {key1 -> value1, key2 -> value2}} *)\n\nIn some cases, particularly when you only need to collect some parts of the expression involving rules, this may be unnecessary since the escaping will be naturally achieved by the destructuring rule. Example:\nCases[dataR, (row1 -> x_) :> x]\n\n(* {{key1 -> value1, key2 -> value2}} *)\n\nBetter ways to destructure trees\nYou can use the fact that your tree is made of rules, to destructure it better. There were a few questions here about it, particularly this and this. Let me just show you a simple construct here:\nClearAll[destructure];\ndestructure[tree_, keys__List] :=\n   Fold[If[#2 === All, Flatten[#1[[All, 2]]], #2 /. #1] &, tree, keys]\n\nThis uses the fact that each branch is itself a set of rules. Some examples of use:\ndestructure[dataR,{row1,key1}]\n\n(* value1 *)\n\ndestructure[dataR,{row1,All}]\n\n(* {value1,value2} *)\n\ndestructure[dataR,{All,All}]\n\n(* {value1,value2,value3,value4} *)\n\n", "programming - Mathematica implementation of Earth Movers Distance?": "\nIn Mathematica 9, it is already implemented under ImageDistance.\nSee Similarity Graph of Images Using Earth Mover Distance.\n", "export - My donut has holes in it!": "\nAnswer\nApparently, the mesh lines generate points which are too close to the triangle vertices, and VRML is not being able to handle them correctly.\nTo prove the theory, try the example without meshes:\np = ParametricPlot3D[{(2 + Cos[v]) Sin[u], (2 + Cos[v]) Cos[u], \n   Sin[v]}, {u, 0, 2 Pi}, {v, 0, 2 Pi}, PlotStyle -> Red, Mesh -> None];\n\nExport[\"test.x3d\", p];\n\nIt should look OK using FreeWRL:\n\nSo the possible solution is to isolate meshes from the surface, i.e. generate them separately and let them be two different graphics complex so that they wouldn't share any points.\nWe already know how to generate the surface without mesh. To generate only meshes, this would do it (plotting with PlotStyle->None):\np2 = ParametricPlot3D[{(2 + Cos[v]) Sin[u], (2 + Cos[v]) Cos[u], \n   Sin[v]}, {u, 0, 2 Pi}, {v, 0, 2 Pi}, PlotStyle -> None]\n\nThe result is:\n\n\n\nNow, combine those two using Show and export.\nExport[\"test.x3d\", Show[p, p2]];\n\nThe result is perfect:\n\nNow, you got your wholly donut back. Enjoy!\nNote: I am using Windows version of FreeWRL so the result may be different on other platform. In that case, it may as well a bug in FreeWRL, not Mathematica's problem.\nBonus\nOK. I shouldn't advocate the use of undocumented features. But if you really want more solid looking meshes, not shamble lines (many format/renderer is not so great at pure line drawing, more so with 3D printing...), this syntax may help you: MeshStyle->Tube[thickness] (thickness in user coordinate scale).\nFor instance:\np2 = ParametricPlot3D[{(2 + Cos[v]) Sin[u], (2 + Cos[v]) Cos[u], \n   Sin[v]}, {u, 0, 2 Pi}, {v, 0, 2 Pi}, PlotStyle -> None, MeshStyle -> Tube[.02]]\n\nwill create:\n\n\n\nDisclaimer There is no guarantee that the syntax will work on the future version of Mathematica. So if you value compatibility, you should not use this. But the resulting 3D graphics will be always valid since it is using our Tube primitive. Tube is supported for export formats. For instance, if you export it to x3d:\nExport[\"test.x3d\", Show[p, p2]];\n\n(It may take quite a while, since Mathematica is converting tubes into polygons for compatibility during exports), the result will be:\n\nAgain, it is not a permanent solution but if you really need better mesh lines for export or 3d printing, it will give you a temporary relief.\n", "syntax - Accept Infinity as an Integer argument": "\nYou can do this by using Alternatives to have the pattern accept either an integer or Infinity as an argument, like so:\nPillsy`Foo[x : (_Integer | Infinity)] :=\n Module[{limit = Min[x, 10], i = 1},\n  While[i <= limit, ++i];\n  i - 1]\n\nIt helps that Mathematica functions like Min and Max usually do the right thing with Infinity as an argument.\n", "plotting - Printing exported PDF graphics fails (version 8)": "\nYou might also have luck if you specify the ImageSize\nExport[filename, plot, \"PDF\", ImageSize -> 8*72]\n\nI have also been able to print files when using the Print As Image option (under Advanced from the Print menu of Adobe). \n", "time series - Stationarity tests": "\nThe three best-known tests for stationarity (or rather, unit roots) in time series econometrics are:\n\nDickey-Fuller including Augmented Dickey-Fuller\nPhillips-Perron\nKPSS\n\nThere are also Bayesian tests of unit roots, as implemented in this conference presentation. If you have access to JSTOR or another way of getting at old journals, this article might be of interest.\nAs far as I'm aware, nobody has created a pre-digested package for unit root testing in Mathematica. The notebook I wrote - about a decade ago - only includes the KPSS test, and I can give no warranties about whether I did it right. It was written for version 3 and would need considerable updating to work with version 8, as it has dependencies on several packages that have been made obsolete when the functionality was rolled into the main kernel.\n", "How to create a list of pre-defined functions?": "\nWhat you want is best accomplished in two steps. First, you want to construct your list of PDFs as a list of pure functions, like so:\npeaks = Table[\n  With[{factor = factors[[i]]},\n   Composition[factor*# &, \n    PDF@CauchyDistribution[pos[[i]], gamma1]]],\n  {i, Length@factors}]\n\nConveniently, PDF, when applied to a distribution as its only argument, returns a pure function; I use Composition to multiply the result returned by that function by factor[[i]]. The With statement is there to insert factors[[i]] into Function despite its non-standard evaluation; you could also use Evaluate. Now that you have a list of functions, you can index into them to apply them one at a a time:\nIn[69]:= peaks[[1]][0.1]\nOut[69]= 0.376381\n\nYou can also use Through to apply all the functions in a list to a single argument:\nIn[70]:= Through[peaks[0.1]]\nOut[70]= {0.376381, 0.0953388}\n\n", "Export long filename truncated": "\nThe problem is not with Mathematica, but with the quicktime plugin/codec. The reason you see this error is that earlier versions of OSX (version 9 and below) had an upper limit of 31 characters for the filename (27, if you include the extension). Today's systems allow up to 255 characters, but the plugin still forces the filename to be backwards compatible. It is not related to a temporary file not being renamed.\nStringLength[\"Lorem-ipsum-dolor-s#123C8BE.mov\"]\nOut[1]= 31\n\nFinal Cut Pro's manual tells you about this (but leaves the choice of truncating to the user):\n\nAlthough current file systems such as HFS+ (used by Mac OS X) allow you to create filenames with a 255-character limit, you may want to limit your filename length if you intend to transfer your files to other operating systems. Earlier versions of the Mac OS allow only 31-character filenames, and if you want to include a file extension (such as .fcp, .mov, or .aif), you need to shorten your Mac OS 9-compatible filenames to 27 characters.\n\nCouple of other examples where people have been bitten by this behavior. AFAIK, the workaround is to rename the file after exporting.\n", "syntax - Why can't D[] be used in place here?": "\nPlot has attribute HoldAll which means in this case that D[Sin[x], x] isn't evaluated until after x is replaced with some number, so you end up with something like D[Sin[-6.28], -6.28] etc. which causes the errors since you can't take a derivative with respect to a number. \nOne way to get around this is to use Evaluate to evaluate the derivative before the numbers are plugged in, i.e. to do something like\nPlot[Evaluate[{Sin[x], D[Sin[x], x]}], {x, -2 Pi, 2 Pi}]\n\n\n", "graphs and networks - Is UndirectedEdge[a,b] the same edge as UndirectedEdge[b,a]?": "\nThis is not inconsistent at all. You're using MemberQ, which only looks at the structural form and UndirectedEdge[1, 4] and UndirectedEdge[4, 1] are not the same, even though you know they mean the same thing. To check if an edge is in a graph, use EdgeQ\nEdgeQ[g, 1 \\[UndirectedEdge] 4]\nEdgeQ[g, 4 \\[UndirectedEdge] 1]\n(* True, True *)\n\n\nI think it's probably just an oversight on WRI's part to not include the Orderless attribute and such oversights are not uncommon. I can't think of a reason why it shouldn't be Orderless. One can always add this to the definition as follows:\nUnprotect[UndirectedEdge];\nSetAttributes[UndirectedEdge, Orderless];\nProtect[UndirectedEdge];\n\nNow using MemberQ as in the question will yield True in both cases. However, I would not recommend doing this, because I think it is worth it to understand the structural and semantic differences between the two and one should always use the one appropriate for the task (and in this case, also has a more meaningful name). \n", "formatting - Managing formatted usage messages in Wolfram Workbench": "\nThis problem exists because WB encourages you to edit the .m file directly. If you created and edited an .nb (package) file -which automatically creates and updates a .m file - this  problem (and others) would not exist. Indeed, if you work with the .nb (package) file you have all the cell organizational/styling facilities available.  So when I recently moved to WB, I wanted WB for creating documentation, Munit testing, ect...TOGETHER WITH front end .nb editing capabilities. Is this possible? Fortunately yes. Here is how (very detailed for beginners):\nIf you have a xyz.m file, create next to it (ie. in the SAME folder, which is inside the WB workspaces folder) a package file xyz.nb (you create this file in MMA or even in WB, I think). WB will- by default - load MMA front end whenever you want to edit this .nb file.  You put in this .nb file all the code you may already have written in the .m file. You may leave the code in Code cells, but (much) preferably you put it in Input-Initialization cells. Then you save the .nb file. This will automatically erase and update your old .m file (so back it up - BEFOREHAND - the first time, just in case). Now you have a .nb file next to a synchronized .m file. Next time you want to edit your code, double-click the .nb file in WB. This will automatically load MMA front end and update the .m file when saving the .nb file. If you want to debug, just use the .m file in WB, but remember that any changes you make should in the end be made to the .nb, if you want to keep them.\nSo we can have the best of WB and MMA together.\nAdvantages of .nb (package) editing: \n\nnicely hierarchically formatted .nb package file\nnicely formatted usage messages\nsyntax highlighting\npossibility to add text cells for comments, explanation, ect\n\nHTH\n", "formatting - Usage displays properly only after second call": "\nI think I have found a solution to this issue, which has been a problem since at least Mathematica version 6 and continues through at least version 11.0. The problem occurs when a user-defined usage message has complex formatting, for example, subscripts, entered using 2D input.     \nSuppose we have a function with usage message defined as\n\nwhich also can be input as \nf::usage = \"\\!\\(\\*SubscriptBox[\\(test\\), \\(1\\)]\\)\\n\\!\\(\\*SubscriptBox[\\(test\\), \\(2\\)]\\)\"\n\nIf we evaluate ?f once, we get \n\nwhich is incorrectly formatted, but if we evaluate it again in the same input cell, without deleting the output cell, we get the correct version:\n\nTo see what's going on, we can run Trace[Information[f]], but that produces an enormous output, most of which has nothing to do with formatting the output string. To look for mentions of the usage string itself, we can use\nTrace[Information[f], x_String /; !StringFreeQ[x, \"test\"], TraceBackward -> True] \n\n\nThis fingers the function System`Dump`fixmessagestring as a possible culprit. The function definition can be found with\nInputForm@Definition[System`Dump`fixmessagestring]\n\nwhich returns\nSystem`Dump`fixmessagestring[System`Dump`s_] :=\n  StringJoin[\n    \"\\\"\",\n    StringReplace[System`Dump`s, {\"\\n\" -> \"\\\\n\", \"\\\\\" -> \"\\\\\\\\\", \"\\\"\" -> \"\\\\\\\"\"}], \n    \"\\\"\"\n  ]\n\nThis function converts some special characters in the string to explict form, as is done in InputForm. However, there are many kinds of formatting that this function doesn't address, which may be part of the problem. We can redefine this function to do a more thorough job by evaluating \nSystem`Dump`fixmessagestring[System`Dump`s_] := ToString@InputForm@System`Dump`s\n\nand now ?f returns the correct result every time. It's still not clear to me why the original version would cause a problem on the first evaluation, but not on the second, but, regardless, it seems that we have a fix.\nA concern might be if this has an effect on built-in usage messages, but in my testing, the built-in messages display identically.\nThe redefinition could be done inside the user-defined package, making the fix invisible.\nAlso, with the command On[System`Dump`fixmessagestring], we can have Mathematica send us a trace message whenever System`Dump`fixmessagestring is called. That will let us see if the function is ever called anywhere outside of Information[], where the redefinition might have other consequences. So far it seems that the function is just confined to Information[] and ?.\nSince there seems to be a one-line fix to this problem, it would be nice if it were eventually fixed in Mathematica itself.\n", "How to set the return type of a compiled function? (Compile::noinfo warning)": "\nI think Leonid\u2019s comment is spot on. You could work around the issue with a completely different approach:\nMakeInPeriodicCell = Compile[{{x, _Real}, {cellwidth, _Real}},\n   If[x < -(cellwidth/2.), x + cellwidth, \n    If[x > cellwidth/2., x - cellwidth, x]]\n   ];\n\n", "scoping - How to use local variables with indices in a Mathematica Block environment?": "\nThe problem is that the definition which makes Subscript[a,i] evaluate to 6 is stored in the DownValues of Subscript. The down values of Subscript don't care about the blocking of a and will still exist when Block exits. You can check that by evaluating DownValues[Subscript]. You could use TagSet (shortcut: /:) to store that value in the UpValues of the localized a, which would behave as you expect (i.e. the rule in UpValues of a is removed when Block exits):\nClearAll[f, a, Subscript]\nSubscript[f, i_][x_] := Block[{a},\n  a /: Subscript[a, i] = 3 x;\n  Subscript[a, 1]\n]\n\non the other hand I wouldn't actually recommend to use such subscripted variables, what you have seen is probably only one of several unexpected things that could happen.\nSide Note:It probably should be mentioned that the definition for Subscript[f,i_][x_] is also not associated with f but with Subscript, which can be checked by evaluating SubValues[Subscript]. Unfortunately this can not be changed by using TagSet for f, since Mathematica here will complain about f being too deep in the left hand side expression. One possibility to change that is to reformulate the function definition to e.g.:\nf /: Subscript[f, i_] = Function[x,\n  Block[{a},\n   a /: Subscript[a, i] = 3 x;\n   Subscript[a, 1]\n   ]\n  ]\n\nwhich will behave the same as the original in most practical cases but of course is not exactly the same thing. You can use UpValues[f] to check that this rule is now really associated with f.\n", "syntax - Extracting equations from Piecewise expressions": "\nHere is a way to separate your equation into different subparts. It uses Reap and Sow to tag parts of the expression as either \"equation\" or \"conditions\" or \"constants\".\nf = Which[FreeQ[#, x], Sow[#, \"constants\"],\n        MemberQ[{Equal, Unequal, Greater, GreaterEqual, Less, LessEqual, And, Or}, Head[#]], \n        Sow[#, \"conditions\"],True, Sow[#, \"equation\"]] &;\n\nLast@Reap[Scan[f, List @@ PDF[LogNormalDistribution[1.75, 0.65], x] // Flatten], \n    {\"equation\", \"conditions\", \"constants\"}] ~Flatten~ 1\n\n(* Out[1]= {{(0.613757 E^(-1.18343 (-1.75 + Log[x])^2))/x}, {x > 0}, {0}} *)\n\nSo now you have your equations in the first sublist, conditions in the second and constants in the third. If you need only the first, you need to Reap only that. This should work with your second example too.\nNote that you'll have to be careful to ensure that x above does not have any value \u2014 using formal symbols is better.\n", "compile - Expression evaluation inside of FindRoot inside a Compiled Function": "\nI think you're going after it the wrong way. FindRoot is not compilable, and it's expected to be the most CPU-expensive part of your loop, so the possible benefits of compilation seem scarce.\nTo quote this most excellent answer by halirutan:\n\nTo summarize: Usually you don't need any list of supported functions, because the rule of thumb is, that compile will not work with already optimized, complicated Mathematica-methods. This includes NIntegrate, FindRoot or NMinimize. Nevertheless, Compile can easily be used to make those function-calls really fast. What you have to do is to compile your target function, because the most time with stuff like NIntegrate is spent, evaluating the integrand. The same is true for FindRoot, NMinimize and many more methods.\n\n(emphasis mine).\n", "graphics - Animating a Voronoi Diagram": "\nThe first step is to rasterize the points, so let's just start there as an example:\nn = 512;\ng = Image[Map[Boole[# > 0.001] &, RandomReal[{0, 1}, {n, n}], {2}]]\n\nThe trick is to exploit the distance image.  Almost all the work is done here (and it's fast):\ni = DistanceTransform[g] // ImageAdjust // ImageData;\n\nWe need a little more precomputation of the final boundaries.  Rasterizing a vector-based Voronoi tessellation would be faster, but here's a quick and dirty solution:\nmask = Image[WatershedComponents[Image[i]]]\n\nNow the animation is instantaneous: it's done simply by thresholding the distances.  (Colorize it if you like.)  Have fun!\nManipulate[\n ImageMultiply[\n  Image[MorphologicalComponents[Image[Map[1 - Min[c, #] &, i, {2}]], 1 - c]], mask],\n {c, 0, 1}\n ]\n\n\n", "cdf format - Understanding CDF": "\nActually this is just meant as a side note to your own answer, but it became too long for a comment. As you can guess I'm interested in this myself and have done some testing, most of what I mentioned is from that experience. It has been reported that there would be differences in what the player would allow depending on whether Mathematica is installed or not. I don't believe that this is true, at least not by design, but as of now this is one of the things I have not explicitly checked..\nI think some of the confusion about what can be done in a CDF format comes from the fact that one has to make a distinction between:\n\nCDF as a format\nrestrictions of the Wolfram Player Pro (called Mathematica Player Pro for vs. 6 and 7)\nrestrictions of the free CDF-Player\nrestrictions of the browser plugin (full window mode)\nrestrictions of the browser plugin (embedded cdf in html)\nrestrictions of the pre version 8 Mathematica Reader\nrestrictions of the demonstration site\n\nand of course it doesn't help that some of the WRI documentation seems to not be very precise concerning these distinctions. The most relevant statement on restrictions seems to be this, from here\n\nCan I use any Mathematica functionality that I want?\nYes. Almost all of Mathematica's computational functions can be incorporated into CDFs. However, in files saved straight out of Mathematica 8 for the free CDF Player, some functionality is not available: non-numeric input fields, dialog windows, and data import and export (except from Wolfram-curated data sources, e.g. ChemicalData, CountryData, and WordData). Please contact us about activating higher-level application content in CDFs.\n\nTo me it looks like the CDF format itself does not imply any restrictions, meaning that when you open a CDF document with a full version of Mathematica, it just behaves like a normal notebook (NB) file. The main difference seems to be a signature that is added to the CDF but not the NB files. I guess it is this signature that will be checked by the various players to see which restrictions are to be used when e.g. showing the dynamic content. While saving with Mathematica will create a signature that will only let the free CDF player use some functionality, it seems possible (but only by WRI) to create signatures that will allow the free CDF-Player to allow more or all (?) functionality. It is most probably this possibility that they are calling \"activate higher-level application content in CDFs\" or \"CDFs with enhanced functionality\". You would need to contact WRI to make use of that possibility, of course. This is a very different approach from using the Wolfram Player Pro, which already could show and play dynamic content within normal notebook files in earlier versions and of course can do so with CDF files as well. Unlike the CDF-Player, the Wolfram Player Pro will even allow shift-return-evaluations and import and export external files, including loading packages, which must be Encoded, though.\nI think you got the restrictions mostly sorted right by now in your own answer, except for some details:\nComplex Functions\nI think the restriction that only a very limited set of functions is allowed in dynamic content of a CDF document is only enforced for the CDF browser plugin, but the standalone free CDF Player will run dynamic content that makes use of almost every function. The CDF will then be shown with a warning header about potentially dangerous content but after explicitly enabling dynamics there the dynamic content will work alright. Unlike mentioned elsewhere I also don't think that the way how you create the CDF document will make a difference concerning these restrictions. It is the use of the CDF browser plugin for showing that document that makes a difference. If you deploy to be embedded in html the formatting of the CDF document will be slightly changed to something more condensed. But when opening the CDF document created that way with the standalone CDF Player, it behaves mostly like one that is deployed as \"Standalone\" or saved directly as CDF (except for the mentioned formatting).\nEdit: I just learned that there is another distinction, since the browser plugin will behave differently when it is embedded in html or running in a \"full screen\" mode which will fill the full browser window. The difference is that in the latter it can show the docked cell to let the user allow \"dynamic content for potential dangerous code\" while it can't do so in the embedded mode. If the user allows dynamic content then some of the restrictions of the browser-plugin are released, but I think there will still be some more than with the standalone player. There is a workaround which allows for that docked cell to appear even in when the cdf is embedded in html, which was obviously uncovered here, but that might have problems with resizing (and probably other) and is not officially supported, so could even go away with future versions. In any case, the difference seems again not be within the CDF document but in by which program and how it is shown.\nManipulate\nFrom all test I have done there seems to be no need to use a Manipulate, despite the fact that this is mentioned in the WRI docs. It is just the most comfortable way to get the initialization of your dynamic content right, especially if the dynamic content depends on nontrivial functionality (that is many functions/symbols). Using the SaveDefinitions option is much more convenient than putting all the function definitions in the Initialization option of a DynamicModule or Dynamic by hand, and it is only available for Manipulate, not e.g. DynamicModule. Nevertheless, the following will make your first example work well in the (standalone) free CDF-Player, with no Manipulate involved at all:\nDynamicModule[{x = 0},\n Panel[Column@{InputField[Dynamic@x, Number], Dynamic@func@x}],\n Initialization :> (func[x_] := 100*x)\n]\n\nFor most practical considerations I think you can think of SaveDefinitions as an option that will create a correct Initialization option for you by inspecting the code, trying to determine dependencies and save all definitions that the code depends to that Initialization option. This can go wrong, and whether it works or not most probably doesn't have anything to do with what the CDF document or any of the ways to show such a document would allow to be run.\nNeeds\nFor the Needs restriction I think the point is that it's not possible to read external files in the free CDF-Player from CDF-documents created from a normal Mathematica, and thus it's not possible to load an external package file in the free CDF-Player from such a CDF-document. I don't have seen any restrictions concerning anything related to the name spaces (Contexts) so I think as long as you manage to get the initialization right (so that all dynamic content will work correctly) the symbols used can live in any namespace you want. It's just not that easy to achieve this, as has been discussed in e.g. this post (which I think you know about), and in some cases the SaveDefinition option probably isn't getting things right, too.\nI think it's worth repeating here that you will need to enclose all code (\"function definitions\") and all data that is used by the dynamic content in the CDF document for it to work in the free CDF Player or the browser plugin. Only when shown in Wolfram Player Pro or Mathematica, code and data could come in separate files as well.\nEdit: I just learned that Import will actually work for nonlocal url's, so it should be possible to load data from a public webserver with the CDF-Player and even the browser plugin, but probably not for every format that Mathematica supports. But it's definitely not supposed to be possible to load data from a local filesystem, neither in the standalone version nor the browser plugin.\nNontrivial Example\nDuring my tests I was trying to get as far as I could in deploying an application in the free CDF player. The following is what I managed to do, some of it is still worth improving and the whole example is just a proof of concept, but I think it shows that one can do a lot more in the free CDF player than is obvious at first sight.\nCurrentValue[EvaluationNotebook[], TaggingRules] = {\n   \"Context\" -> \"cdfapp`\",\n   \"Code\" -> Compress[\"\n       BeginPackage[\\\"cdfapp`\\\"];\n       run::usage=\\\"run[]\\\";\n       clear::usage=\\\"clear[]\\\";\n       Begin[\\\"`Private`\\\"];\n       run[]:=With[{cntxt=CurrentValue[ButtonNotebook[],{TaggingRules,\\\"Context\\\"}]},\n        Set@@Join[\n         ToExpression[cntxt<>\\\"content\\\",InputForm,Hold],\n        Hold[Manipulate[Plot[x^n,{x,0,1},PlotRange->{0,1}],\n        {n,1,100},AppearanceElements->None]]\n        ]\n       ];\n       clear[]:=With[{cntxt=CurrentValue[ButtonNotebook[],{TaggingRules,\\\"Context\\\"}]},\n        Unset@@ToExpression[cntxt<>\\\"content\\\",InputForm,Hold]\n       ];\n       End[];\n       EndPackage[];\n       \"\n     ]\n   };\n\nSetOptions[EvaluationNotebook[], DockedCells -> {\n   Cell[BoxData[ToBoxes[\n      Row[{\n        Button[\"Run\",\n         ToExpression[\n          Uncompress[\n           CurrentValue[ButtonNotebook[], {TaggingRules, \"Code\"}]]]; \n         Symbol[\"run\"][], Method -> \"Queued\"\n         ],\n        Button[\"Clear\",\n         ToExpression[\n          Uncompress[\n           CurrentValue[ButtonNotebook[], {TaggingRules, \"Code\"}]]]; \n         Symbol[\"clear\"][], Method -> \"Queued\"\n         ],\n        Spacer[30],\n        Button[\"Quit\", FrontEnd`FrontEndToken[\"EvaluatorQuit\"], \n         Evaluator -> None],\n        Spacer[30],\n        Button[\"Show Packed Code\", \n         CreateDialog[\n          CurrentValue[ButtonNotebook[], {TaggingRules, \"Code\"}],\n          WindowSize -> {500, 500}], Method -> \"Queued\"],\n        Button[\"Show Clear Code\", \n         CreateDialog[\n          Uncompress@\n           CurrentValue[ButtonNotebook[], {TaggingRules, \"Code\"}],\n          WindowSize -> {500, 500}], Method -> \"Queued\"]\n        }]\n      ]], \"DockedCell\"]\n   }];\n\nDynamic[Replace[cdfapp`content, s_Symbol :> \"\"], \n TrackedSymbols :> {cdfapp`content}]\n\nTo run this do the following: create a new CDF document in Mathematica, copy the above code to it and evaluate. It should add a docked cell to the document and an empty output cell. Delete everything except for the empty output cell and save it. Then open it with the free CDF player and try the buttons in the docked cells.\nDisclaimer\nAs I said, much is just deduced from my experiments, some I learned from the CDF-Workshop and the documentation. Anyway I'm glad to hear about any corrections or improvements to these statements.\n", "import - Importing HDF5 with compound data": "\nI have created h5dumpImport, an open source Mathematica Package that provides a platform independent way to import HDF5 (.h5) file's datasets with compound datatypes while hiding much of the HDF5 implementation from the user.  The package with documentation, examples, and unit test is located here.\nCurrently, the h5dumpImport package does not directly import the HDF5 (.h5) file format. The h5dumpImport package imports an ASCII dump of a dataset generated by the h5dump command line tool.\nSource code and pre-built binary distributions of the HDF5 Software which includes the h5dump command line tool can be found at the The HDF Group's website.\nBasic Example\nNeeds[\"h5dumpImport`\"]\ndatasets = Import[\"testData.h5\", {\"Datasets\"}];\ndumpFile = h5dump[\"/usr/bin/h5dump\", \"testData.h5\", datasets[[1]]];\ndumpImport = h5dumpImportNew[h5dumpImport[], dumpFile];\ndumpImport.h5dumpImportData[All]\ndumpImport.h5dumpImportClose[];\n\n\nResults:\n{{1, 11, 111, 1111, 11111, 111111, 1111111, 1.1, 11.11, \"one\"},\n {2, 22, 222, 2222, 22222, 222222, 2222222, 2.2, 22.22, \"two\"},\n {3, 33, 333, 3333, 33333, 333333, 3333333, 3.3, 33.33, \"three\"}}\n\nDetailed installation instructions, usage information, and documentation, examples, and unit tests can be found here.\n", "output formatting - ArcTan expressed as a radian fraction?": "\nShort answer: no, ArcTan[2] is not fraction of $\\pi$. But this is more of a mathematics question than pertaining to Mathematica.\nIf you want to \u201ccheck\u201d that the result is not expressable as a fraction of $\\pi$, you can check for the continued fraction reprentation of $\\arctan(2)/\\pi$, and see that it does not seem to converge:\nTable[FromContinuedFraction@ContinuedFraction[ArcTan[2]/\\[Pi], n], {n, 20}]\n\n\n", "bugs - Dialog crashes Mathematica": "\nUpdated: It seems like this bug has been ironed out in version 9. as it does not cause a crash anymore.\n\nInstead of comments, let's gather here the information we have:\n\nCrash happens on Mathematica 8.0.0.0 through 8.0.4, seemingly on all OS (reported confirmed on: WinXP/32, Mac OS 64-bit, Ubuntu 64bit, Win7/32).\nMathematica 7 doesn't crash, at least on Mac OS.\nMM Support provided R Hall a new Mac OS binary that fixes the crash on 8.0.4.\n\n", "probability or statistics - Histograms with pre-counted data": "\nHistogram doesn't have any built-in support for weighted data, although it's an interesting idea, and most of the binning algorithms should be amenable to working with it.\n\nThat being said, here's a WeightedHistogram function, with some feedback from Andy Ross.  It accepts \n\nweighted values (in the same format as RandomChoice and EmpiricalDistribution)\nbinning specifications\nHistogram options.  \n\nIt doesn't support the height functions, since they'd have to be manually implemented.  (This isn't hard, just a bit tedious since there are several of them.)\nThe implementation creates a representative sample of the data to compute the bins from.  This is combined with the list of actual values to make sure we cover the extremes, which might have low weights and otherwise not show up in the sample.\nOptions[WeightedHistogram] = \n   Append[Options[Histogram], \"SampleSize\" -> 1000];\n\nWeightedHistogram[weights_ -> values_, o : OptionsPattern[]] :=\n   WeightedHistogram[weights -> values, Automatic, o]\n\nWeightedHistogram[weights_ -> values_, bins_, o : OptionsPattern[]] :=\n   Block[{sample, newbins, valuelists, partitions},\n      sample = Join[\n         RandomChoice[weights -> values, OptionValue[\"SampleSize\"]],\n         values];\n      newbins = First[HistogramList[sample, bins]];\n      partitions = Partition[newbins, 2, 1];\n      valuelists = \n         Total[Pick[weights, Thread[# <= values < #2]]] & @@@ partitions;\n      Histogram[values, {newbins}, valuelists &, \n         FilterRules[Flatten[{o}], Options[Histogram]]]\n      ]\n\nNow let's try it out with some data that is easily weighted:\ndata = RandomVariate[PoissonDistribution[30], 10^5];\n{values, weights} = Transpose[Tally[data]];\n\nHere's the Histogram applied to the original data:\nHistogram[data]\n\n\nHere's the weighted data, in vanilla and rainbow flavors:\nRow[{\n   WeightedHistogram[weights -> values], \n   WeightedHistogram[weights -> values, {1}, ChartStyle -> \"Rainbow\"]\n   }]\n\n\n", "How do I use the result of Solve in a function definition?": "\nYou're doing a replacement to get the solution, not evaluating a function in the Z /. part, so it can really be any variable. You'll end up with a recursion with a definition like Z[x_]:= f[Z[x]...]. So try something like:\nZ[amax_] := Max[z /. Solve[FullSimplify[PowerF[amax], z \u2208 Reals] == P0, z]]\n\nIf you want the variable that you're solving for to look similar to your function variable, then use formal symbols. It would look something like this:\n\nAs always, the standard warning to not use capital letters as function names and variables applies here.\n", "programming - GeoDirection and GeoDistance Memory Leaks: How to Recover the Memory?": "\nWolfram Research has prepared a patch that eliminates this memory leak.  I sent a problem demo notebook to support at WRI, and WRI responded with updated versions for two GeoFunctions.mx files.  Replacing the installed GeoFunctions.mx files with these updated patch versions eliminates the memory loss.  \nI asked WRI if I could upload this patch for others to use, and WRI requested that anyone desiring the patch files contact WRI support directly. They will then provide the patch files and the directions for their use. \nThank you for taking the time to investigate this problem and suggest possible solutions.  I admire your contributions to this forum.\n", "export - Saving high-quality graphics through commands": "\nControl image size as Graph option:\ng = CompleteGraph[100, ImageSize -> 2000];\nExport[\"mysuperawesomegraph.png\", g]\n\nAlso if you already have graphics produced, you can use Show to programmatically resize it:\ng = CompleteGraph[100, GraphStyle -> \"LargeNetwork\"];\ngmag = Show[g, ImageSize -> 2000];\nExport[\"mysuperawesomegraph.png\", gmag]\n\nIn Mathematica there is a difference between Graphics objects and images:\nRandomImage[1, {100, 100}]\n\n\nIn[1]:= % // Head\nOut[1]= Image\n\nGraphics[Raster[RandomReal[1, {100, 100}]]]\n\n\nIn[2]:= % // Head\nOut[2]= Graphics\n\nImageResize is used for images and may result in the loss of resolution. Changing shown size of Graphics with Show will not result in loss of resolution. \n", "list manipulation - 3x+1 on arithmetic chains, tree pruning and NestList": "\nI think you can get the non repeated terminal symbols after round N by using the following (not optimized)\nCollatz[Null] = Null;\nCollatz[Subscript[m_, d_] /; EvenQ[m] && EvenQ[d]] := \n  Collatz[Subscript[m, d]] = check@Subscript[m/2, d/2];\n\nCollatz[Subscript[m_, d_] /; OddQ[m] && EvenQ[d]] := \n  Collatz[Subscript[m, d]] = check@Subscript[3 m + 1, 3 d];\n\nCollatz[Subscript[m_, d_] /; OddQ[d]] := \n  Collatz[Subscript[m, d]] = \n   Collatz /@ {check@Subscript[m, 2 d], check@Subscript[m + d, 2 d]};\n\nCollatz1[x__] := (p = (DownValues@Collatz /. \n      HoldPattern[_[q_] :> _] :> q)[[2 ;; -4]]; Collatz[x])\n\ncheck[t_] := If[Cases[p, t, Infinity] == {}, t, Null]\n\nSetAttributes[Collatz, Listable];\nSetAttributes[Collatz1, Listable];\n\nNestList[Collatz1, Subscript[1, 1], 12][[-1, 1]]\n\n", "Function as an option to a function": "\nShort answer:\nYou supply a pure function to an option when you want to override the built-in options. In this case, \"Diamond\" and 0.2 resolve to certain functions or are used as values in certain functions internally which is then used for the respective option. The short names are merely a convenient way for you to remember and enter the option.\nLonger answer:\nIt might help to understand what is done internally, so consider this simple example. We construct a function f that takes in a numeric argument x, and an optional value p (with default value 1) and we raise x to power p:\nf[x_?NumericQ, opts : OptionsPattern[p -> 1]] := x^OptionValue[p]\n\nf[2]\nf[2, p -> 2]\nf[2, p -> 3]\n(* 2, 4, 8 *)\n\nSo far so good. Now let's say you'd like to supply arguments like \"square\" and \"cube\" instead of 2 and 3 and let the function figure out what to do with it. So you do something like:\nClear[f]\nf[x_?NumericQ, opts : OptionsPattern[p -> 1]] := Module[{pow},\n    pow = OptionValue[p] /. {\"square\" -> 2, \"cube\" -> 3};\n    x^pow\n]\n\nf[2, p -> \"square\"]\nf[2, p -> \"cube\"]\n(* 4, 8 *)\n\nYou have now built a definition for f that can take simple options for p both as \"square\" or as 2, which gives you additional flexibility.\nExtending the idea to a function that accepts functions as option values. I'll define a function g, taking inputs as g[x, p -> func], returning func[x] and also let it take arguments as g[x, p -> \"string\"] for some values of \"string\"\nClear[g]\ng[x_?NumericQ, opts : OptionsPattern[p -> (# &)]] := Module[{func},\n    func = OptionValue[p] /. {\"square\" -> (#^2 &), \"cube\" -> (#^3 &)};\n    func[x]\n]\n\ng[2, p -> \"square\"]\ng[2, p -> \"cube\"]\n(* 4, 8 *)\n\nSuppose you get bored of the vanilla pre-defined options and want to fancy it up, you can do that by supplying your own pure function as an option to p. For example:\nPlot[g[x, p -> (Sin[Exp[#]] &)], {x, 0, \u03c0}]\n\n\nBy now, you can begin to see how this is useful. If you had a complicated function that needed to be input as an option or is used repeatedly, you'd want to make things simple for the end user (most likely yourself) and so you pre-define it and provide a short form that is easy to remember and conveys the intent without ambiguity. Any time this needs to be overridden (possibly for a one time use case), you can supply your own function.\nAlso read this answer for why you need to wrap your custom pure functions in parentheses when supplying as an option value.\n", "fitting - FindFit returns Infinity::indet error when data contains {0,0}": "\nWell, FindFit works by calculating a Jacobian of your expression, which is a matrix of derivatives with respect to all variables. Analytically, because $b$ is a real variable (and not an integer), you have $q^b = \\exp(b \\log q)$, so you see how that might become difficult when $q$ becomes zero.\nHowever, the documentation for FindFit describes exactly your problem, and a possible solution. (I found it by looking for \"FindFit Jacobian\" in the documentation, so it's possible to find from your original error message.)\n\nSpecify the model gradient to avoid problems with a removable singularity: [\u2026] Gradient -> \"FiniteDifference\"\n\nThis works for you too:\nIn:=  FindFit[data, a*q^b, {a, b}, q, Gradient -> \"FiniteDifference\"]\nOut=  {a -> 2., b -> 2.}\n\n", "mathematical optimization - Minimizing a function of many coordinates": "\nTo get arbitrarily many formal variables, you can use Array. But with those variables, your function definition won't work because of the Apply statement. So I modified your definition as follows (I reduced the point number for testing purposes):\npts = Apply[{ArcCos[2 #2 - 1], 2 \\[Pi] #1} &, RandomReal[1, {10, 2}], 1];\nClear[energy];\nClear[a];\nvars = Array[a, {Length[pts], 2}];\nenergy[p_] := \n  Module[{cart}, \n   cart = Map[{Sin[#[[1]]]*Cos[#[[2]]], Sin[#[[1]]]*Sin[#[[2]]], \n       Cos[#[[1]]]} &, p];\n   Total[Outer[Exp[-Norm[#1 - #2]] &, cart, cart, 1], 2]];\nFindMinimum[energy[vars], Transpose[{Flatten@vars, Flatten@pts}]]\n\n\n{32.2548, {a[1, 1] -> 1.93787, a[1, 2] -> 1.72361, a[2, 1] -> 1.11355,\n     a[2, 2] -> 0.893035, a[3, 1] -> 6.21077, a[3, 2] -> 2.1405, \n    a[4, 1] -> 3.06917, a[4, 2] -> 2.14062, a[5, 1] -> 1.06997, \n    a[5, 2] -> 2.50937, a[6, 1] -> 4.21367, a[6, 2] -> 1.69561, \n    a[7, 1] -> 5.07748, a[7, 2] -> 2.48594, a[8, 1] -> 4.31041, \n    a[8, 2] -> 0.111206, a[9, 1] -> 4.25016, a[9, 2] -> 3.31368, \n    a[10, 1] -> 5.11923, a[10, 2] -> 0.955784}}\n\nThe form of the array passed to energy matches the $N\\times2$ dimension list that is expected by the line creating the cart variable. In the FindMinimum statement the dummy variables and initial conditions are specified as a single list of pairs by using Flatten on both. \nThere is the usual wrinkle that the minimization may need to be tweaked for precision, but that's a different issue.\nFinally, to get the minimizing point list, you have to do \nvars/.Last[%]\n\nEdit\nDepending on the function to be optimized, it's sometimes faster to avoid the use of derivatives by specifying the initial conditions for FindMinimum in the form of three numbers:\nFindMinimum[energy[vars], \nTranspose[{Flatten@vars, Flatten@pts, Flatten@pts - .1, Flatten@pts + .1}]]\n\nEdit 2\nI did get a significant speed-up with this for your example, but the performance depends on the random starting points (and on the choice of bracket width) so I can't say anything definitive. That seems like a topic for a different question.\nEdit 3\nThough I didn't look at the speed issue in detail, forcing FindMinimum to work with numerical derivatives may be the worst option here. That will happen if you define your function energy only for numerical arguments, as in \nenergy[p : {{_?NumericQ, _?NumericQ} ..}] := \n\nfollowed by either your own or my initial definition above. So although that's a common advice people give in these applications, it is not going to be the fastest approach here.\nEdit 4\nI just had another idea on how to improve the speed of my solution: the use of Norm might make it harder to estimate the Hessian for this function. And indeed, when I got rid of Norm there was a significant speed gain (note that the initial solution above is already faster than the _?NumericQ approach even when the latter is compiled while mine is not). I think this is worth adding here because Norm seems like a natural thing to use in pair potentials, even if the energy expression becomes more complicated than the one in this question.\nSo here is the new version, with Norm replaced by Sqrt[(#1 - #2).(#1 - #2)]. Observe that I have now put back the original particle number of 100 because on my laptop this takes less than 8 seconds to evaluate!\npts = Apply[{ArcCos[2 #2 - 1], 2 \\[Pi] #1} &, RandomReal[1, {100, 2}], 1];\nClear[energy];\nClear[a];\nvars = Array[a, {Length[pts], 2}];\nenergy[p_] := \n  Module[{cart}, \n   cart = Map[{Sin[#[[1]]]*Cos[#[[2]]], Sin[#[[1]]]*Sin[#[[2]]], \n       Cos[#[[1]]]} &, p];\n   Total[Outer[Exp[-Sqrt[(#1 - #2).(#1 - #2)]] &, cart, cart, 1], 2]];\nFindMinimum[energy[vars], Transpose[{Flatten@vars, Flatten@pts}]]\n\nOh, and one more thing I changed (unrelated to the question), is to switch your definitions of polar and azimuthal angles in pts.\n", "How to thrad a list - Mathmatica Stack Exchang": "\nIf your lists are long, there are faster approaches using high-level functions and structural operations. Here are two alternatives.\nFirst we try Outer and Flatten:\ndata = {{a1, a2}, {b1, b2}, {c1, c2}, {d1, d2}};\nFlatten[Outer[List, List@First[data], Rest[data], 1], {{2}, {1, 4}}]\n\n\n{{{a1, b1}, {a2, b2}}, {{a1, c1}, {a2, c2}}, {{a1, d1}, {a2, d2}}}\n\n\nAnd now Distribute and Transpose:\nTranspose[Distribute[{List@First[data], Rest[data]}, List], {1, 3, 2}]\n\n\n{{{a1, b1}, {a2, b2}}, {{a1, c1}, {a2, c2}}, {{a1, d1}, {a2, d2}}}\n\n\nEvidently, they give the correct result. Now for a Timing comparison:\ndata = RandomReal[{0, 1}, {10^6, 2}];\n\nThe timings, in rank order, are:\n\nkptnw's Table/Transpose method: 0.297 seconds\nOuter/Flatten: 0.812 seconds\nDistribute/Transpose: 0.891 seconds\nrcollyer's Thread/Map approach: 2.907 seconds\nR.M's Transpose/FoldList method: 3.844 seconds\nparadox2's solution with Riffle and Partition: 7.407 seconds\n\nThe Outer/Flatten and Distribute/Transpose approaches are quite fast, but clearly Table is much better-optimized than Distribute, since while these two methods are conceptually similar, kptnw's solution using the former is by far the fastest and most memory-efficient. The other solutions, not using structural operations, are considerably slower, which is not unexpected.\n", "Combining heads of lists so that you can create a nested list from two sublists": "\nYou can do\nTranspose@{ Range@20000 - 1, yourList }\n\nOr more generally if yourList is of varying length\nTranspose@{ Range@First@Dimensions@yourList - 1, yourList }\n\nExtracting a part of the list, say from index i to index j can be done with Partor Take\nnewList = Transpose@{ yourList, Range@First@Dimensions@yourList };\nnewList[[i;;j]]\n(* or *)\nTake[newList,{i,j}]\n\n", "graphics - Computing and plotting a spectrogram in Mathematica": "\nGet a sample sound:\nsnd = ExampleData[{\"Sound\", \"SopranoSaxophone\"}];\n\nThis gives us a Sound data structure with a SampledSoundList as first element. Extracting the data from it:\nsndData = snd[[1, 1]];\nsndSampleRate = snd[[1, 2]];\n\nPlotting the data:\nListPlot[sndData, DataRange -> {0, Length[sndData]/sndSampleRate }, \n ImageSize -> 600, Frame -> True, \n FrameLabel -> {\"Time (s)\", \"Amplitude\", \"\", \"\"}, \n BaseStyle -> {FontFamily -> \"Arial\", FontWeight -> Bold, 14}]\n\n\nFind the lowest amplitude level (used as reference for dB calculations):\nmin = Min[Abs[Fourier[sndData]]];\n\nA spectrogram is made by making a DFT of partitions of the sample. The partitions usually have some overlap.\npartSize = 2500;\noffset = 250;\nspectroGramData = \n  Take[20*Log10[Abs[Fourier[#]]/min], {2, partSize/2 // Floor}] & /@ \n   Partition[sndData, partSize, offset];\n\nNote that I skip the first element of the DFT. This is the mean level. I also show only half of the frequency data. Because of the finite sampling only half of the returned coefficient list contains useful frequency information (up to the Nyquist frequency).\nMatrixPlot[\n  Reverse[spectroGramData\\[Transpose]], \n  ColorFunction -> \"Rainbow\", \n  DataRange -> \n    Round[\n     {{0, Length[sndData]/sndSampleRate }, \n     {sndSampleRate/partSize, sndSampleRate/2 }}, \n     0.1\n    ], \n  AspectRatio -> 1/2,  ImageSize -> 800, \n  Frame -> True, FrameLabel -> {\"Frequency (Hz)\", \"Time (s)\", \"\", \"\"}, \n  BaseStyle -> {FontFamily -> \"Arial\", FontWeight -> Bold, 12}\n]\n\n\nA 3D spectrogram (note the different offset value):\npartSize = 2500;\noffset = 2500;\nspectroGramData = \n  Take[20*Log10[Abs[Fourier[#]]/min], {2, partSize/2 // Floor}] & /@ \n   Partition[sndData, partSize, offset];\n\nListPlot3D[spectroGramData\\[Transpose], ColorFunction -> \"Rainbow\", \n DataRange -> \n  Round[{{0, Length[sndData]/sndSampleRate }, {sndSampleRate/partSize,\n      sndSampleRate/2}}, 0.1], ImageSize -> 800, \n BaseStyle -> {FontFamily -> \"Arial\", FontWeight -> Bold, 12}]\n\n\n", "Map and Apply a function on a nested list": "\nYou can define a function as :\nmyF[alist_, f_] := Map[{#[[1]], f[#[[2]]]} &, alist]\n\nmyF[{{1, 2}, {4, 2}, {6, 4}}, Log]\n\n(* {{1, Log[2]}, {4, Log[2]}, {6, Log[4]}} *)\n\nOr you can generalize to :\nmyF2[alist_, f_] := Map[{f[[1]][#[[1]]], f[[2]][#[[2]]]} &, alist]\n\nmyF2[alist, {# &, Log}]\nmyF2[alist, {Sin, Log}]\n\n(* {{1, Log[2]}, {4, Log[2]}, {6, Log[4]}} *)\n(* {{Sin[1], Log[2]}, {Sin[4], Log[2]}, {Sin[6], Log[4]}} *)\n\n", "plotting - Creating legends for plots with multiple lines?": "\nIn case you want more flexibility, it's also possible to design your own legends, for example along the lines of this MathGroup post. For your example, the process would start with the function legendMaker. \nInstead of repeating the same definition as in the above post, I've overhauled legendMaker in response to image_doctor's answer, to separate out the handling of options better.\nI've tried to make the spacings and widths of the legends more customizable, and also separated the automatic extraction of the line and marker styles into a separate function extractStyles so that it's easier to modify if needed later.\nHere I'm listing all the functions in one code block to make them easier to copy. Below, I'll go through the usage examples for these functions in the order they were written: i.e., from the low-level legendMaker to the high-level deployLegend.\nlegendMaker allows individual line styles and plot markers to have the value None. This makes it easier to specify custom legends, in particular when combining a line plot without markers, and a list plot without lines. This is motivated by a related answer here, so I posted an example there.\nEdit July 14, 2013\nA year has passed since the last update to this code, because Mathematica version 9 introduced the new command  PlotLegends which in many cases should make this answer obsolete. However, I tried to keep this answer compatible with versions 8 and 9. This is why this update is necessary, since some functionality was broken in recent Mathematica versions. \nThe major changes were in the function extractStyles which tries to guess what lines and markers are being used in a given plot. This relies on the internal structure of the plots, and is therefore fragile. I tried to make it more robust.\nI also added usage messages and made sure that autoLegend (the simplest legending function in this answer) accepts the full range of options of legendMaker (the more lower-level legend drawing function). All the examples below are unchanged, except that I added more information at the end.\nOptions[legendMaker] = \n  Join[FilterRules[Options[Framed], \n    Except[{ImageSize, FrameStyle, Background, RoundingRadius, \n      ImageMargins}]], {FrameStyle -> None, \n    Background -> Directive[Opacity[.7], LightGray], \n    RoundingRadius -> 10, ImageMargins -> 0, PlotStyle -> Automatic, \n    PlotMarkers -> None, \"LegendLineWidth\" -> 35, \n    \"LegendLineAspectRatio\" -> .3, \"LegendMarkerSize\" -> 8, \n    \"LegendGridOptions\" -> {Alignment -> Left, Spacings -> {.4, .1}}}];\n\n\nlegendMaker::usage = \n  \"Create a Graphics object with legends given by the list passed as \\\nthe first argument. The options specify any non-deafult line styles \\\n(using PlotStyle -> {...}) or plot markers (using PlotMarkers -> \\\n{...}). For more options, inspect Options[legendMaker]\";\n\nlegendMaker[textLabels_, opts : OptionsPattern[]] := \n  Module[{f, lineDirectives, markerSymbols, n = Length[textLabels], \n    x}, lineDirectives = ((PlotStyle /. {opts}) /. \n       PlotStyle | Automatic :> Map[ColorData[1], Range[n]]) /. \n     None -> {None};\n   markerSymbols = \n    Replace[((PlotMarkers /. {opts}) /. \n         Automatic :> (Drop[\n              Normal[ListPlot[Transpose[{Range[3]}], \n                  PlotMarkers -> Automatic][[1, 2]]][[1]], -1] /. \n             Inset[x_, i__] :> x)[[All, -1]]) /. {Graphics[gr__], \n         sc_} :> Graphics[gr, \n         ImageSize -> (\"LegendMarkerSize\" /. {opts} /. \n             Options[legendMaker, \n              \"LegendMarkerSize\"] /. {\"LegendMarkerSize\" -> 8})], \n      PlotMarkers | None :> \n       Map[Style[\"\", Opacity[0]] &, textLabels]] /. \n     None | {} -> Style[\"\", Opacity[0]];\n   lineDirectives = PadRight[lineDirectives, n, lineDirectives];\n   markerSymbols = PadRight[markerSymbols, n, markerSymbols];\n   f = Grid[\n     MapThread[{Graphics[{#1 /. None -> {}, \n          If[#1 === {None} || (PlotStyle /. {opts}) === None, {}, \n           Line[{{-.1, 0}, {.1, 0}}]], \n          Inset[#2, {0, 0}, Background -> None]}, \n         AspectRatio -> (\"LegendLineAspectRatio\" /. {opts} /. \n             Options[legendMaker, \n              \"LegendLineAspectRatio\"] /. {\"LegendLineAspectRatio\" -> \\\n.2}), ImageSize -> (\"LegendLineWidth\" /. {opts} /. \n             Options[legendMaker, \n              \"LegendLineWidth\"] /. {\"LegendLineWidth\" -> 35}), \n         ImagePadding -> {{1, 1}, {0, 0}}], \n        Text[#3, FormatType -> TraditionalForm]} &, {lineDirectives, \n       markerSymbols, textLabels}], \n     Sequence@\n      Evaluate[(\"LegendGridOptions\" /. {opts} /. \n          Options[legendMaker, \n           \"LegendGridOptions\"] /. {\"LegendGridOptions\" -> {Alignment \\\n-> Left, Spacings -> {.4, .1}}})]];\n   Framed[f, \n    FilterRules[{Sequence[opts, Options[legendMaker]]}, \n     FilterRules[Options[Framed], Except[ImageSize]]]]];\n\nextractStyles::usage = \"returns a tuple {\\\"all line style \\\ndirectives\\\", \\\"all plot markers\\\"} found in the plot, in the order \\\nthey are drawn. The two sublists need not have the same length if \\\nsome lines don't use markers \"; \nextractStyles[plot_] := \n Module[{lines, markers, points, \n   extract = First[Normal[plot]]},(*In a plot,\n  the list of lines contains no insets,so I use this to find it:*)\n  lines = \n   Select[Cases[Normal[plot], {___, _Line, ___}, Infinity], \n    FreeQ[#1, Inset] &];\n  points = \n   Select[Cases[Normal[plot], {___, _Point, ___}, Infinity], \n    FreeQ[#1, Inset] &];\n  (*Most plot markers are inside Inset,\n  except for Point in list plots:*)\n  markers = Select[extract, ! FreeQ[#1, Inset] &];\n  (*The function returns a list of lists:*){(*The first return value \\\nis the list of line plot styles:*)\n   Replace[Cases[\n     lines, {c__, Line[__], ___} :> \n      Flatten[Directive @@ Cases[{c}, Except[_Line]]], \n     Infinity], {} -> None],\n   (*Second return value:marker symbols*)\n   Replace[Join[\n     Cases[markers//. Except[List][i_Inset, __] :> i, \n       {c__, Inset[s_, pos_, d___], e___} :> If[\n        (*markers \"s\" can be strings or graphics*)\n\n        Head[s] === Graphics,\n        (*Append scale factor in case it's needed later;\n        default 0.01*)\n        {s,\n         Last[{.01, d}] /. Scaled[f_] :> First[f]\n         },\n        If[\n         (*For strings,\n         add line color if no color specified via text styles:*)\n             FreeQ[ s, _?ColorQ], Style[s, c], s]\n        ],\n      Infinity\n      ],\n     (*\n     Filter out Pointsize-legends don't need it:*)\n\n     Cases[points, {c___, \n        Point[pt__], ___} :> {Graphics[{c, Point[{0, 0}]}] /. \n         PointSize[_] :> PointSize[1], .01}, Infinity]\n     ], {} -> None]}]\n\nautoLegend::usage = \n  \"Simplified legending for the plot passed as first argument, with \\\nlegends given as second argument. Use the option Alignment -> \\\n{horizontal, vertical} to place the legend in the PlotRegion in \\\nscaled coordinates. For other options, see Options[legendMaker] which \\\nare used by autoLegend.\";\nOptions[autoLegend] = \n  Join[{Alignment -> {Right, Top}, Background -> White, \n    AspectRatio -> Automatic}, \n   FilterRules[Options[legendMaker], \n    Except[Alignment | Background | AspectRatio]]];\nautoLegend[plot_Graphics, labels_, opts : OptionsPattern[]] := \n Module[{lines, markers, align = OptionValue[Alignment]},\n  {lines, markers} = extractStyles[plot];\n  Graphics[{\n    Inset[plot, {-1, -1},\n     {Left, Bottom},\n     Scaled[1]\n     ],\n    Inset[\n     legendMaker[labels, PlotStyle -> lines, PlotMarkers -> markers, \n      Sequence @@ \n       FilterRules[{opts}, \n        FilterRules[Options[legendMaker], Except[Alignment]]]],\n     align,\n     Map[If[NumericQ[#], Center, #] &, align]\n     ]\n    },\n   PlotRange -> {{-1, 1}, {-1, 1}}, \n   AspectRatio -> (OptionValue[AspectRatio] /. \n       Automatic :> (AspectRatio /. Options[plot, AspectRatio]) /. \n      Automatic :> (AspectRatio /. \n         AbsoluteOptions[plot, AspectRatio]))]]\n\nNotes for legendMaker:\nThe horizontal width of the line segment in the legend can be changed with the option \"LegendLineWidth\", and its aspect ratio is set by \"LegendLineAspectRatio\". The size of the markers in the legend is set by \"LegendMarkerSize\" (all these options have reasonable default values), and they can also be passed to the higher-level functions below.\nThe only required argument for this version of legendMaker is a list of labels. Everything else is optional. I.e., the function automatically determines what to do about the matching line colors and plot marker symbols (if any). \nPlot markers can be defined as String or Graphics objects. To control the line colors, you can specify the option PlotStyle: with PlotStyle -> Automatic, the default plot styles are used. If you have instead prepared the plot with a different list of plot styles, you can enter that here. The option PlotStyle -> None is also allowed. This should be used when labeling a ListPlot that has no connecting lines between the points.\nWith the setting PlotMarkers -> Automatic, the legend will also display marker symbols according to the default choices that I extract from a temporary ListPlot that is then discarded. The default setting for legendMaker is PlotMarkers -> None.\nTo make the plots look nice, you can add other options for the legend appearance, e.g.:\nopts = Sequence[Background -> LightOrange, RoundingRadius -> 10];\n\nHere I allow all options that Frame can handle, except for ImageSize. \nNow we prepare a plot:\ndata = {{1, 2}, {3, 4}, {5, 4}};\npoints = Table[{#1, Log[b, #2]} & @@@ data, {b, 2, 10, 2}];\nplot = ListLinePlot[points];\n\nThe list labels creates the text that you were asking for:\nlabels = Table[Row[{Subscript[\"Log\", b], x}], {b, 2, 10, 2}]\n\n\n$\\left\\{\\text{Log}_2x,\\text{Log}_4x,\\text{Log}_6x,\\text{Log}_8x,\\text{Log}_{10}x\\right\\}$\n\nThe legend is now displayed as an overlay over the original plot:\nnewPlot = \n Overlay[{plot, legendMaker[labels, opts]}, Alignment -> {Right, Top}]\n\n\nThe Overlay that is created here can still be exported and copied even though it's not a graphics box. A good way to copy it to an external editor is to highlight the plot and select Copy As... PDF from the Edit menu (that's at least where it is on Mac OS X).\nA different application of legendMaker can be found in this post. That's also a good example for the difference in appearance to the standard Legends package, which many people consider sub-par (it's slow, old-fashioned and even crashes sometimes).\nNotes for autoLegend\nIn response to the comment by Ajasja, I added another layer of automation that makes use of the function legendMaker defined above, but attempts to deduce the colors and marker symbols from the provided plot in a fully automatic way. \nAs an example, I took\np = ListPlot[Evaluate[Table[RandomInteger[3 i, 10] + 2 i, {i, 3}]], \n  PlotMarkers -> Automatic, Joined -> True]\n\nand added labels by calling\nautoLegend[p, {\"Small\", \"Big\", \"Bigger\"}, \n Background -> Directive[LightOrange, Opacity[.5]], \n Alignment -> {Right, Top}]\n\n\nThe function autoLegend takes the same options as legendMaker, plus the Alignment option which follows the conventions for Overlay.\nHere is an example wit graphical markers:\np = ListPlot[Evaluate[Table[RandomInteger[3 i, 10] + 2 i, {i, 3}]], \n  PlotMarkers -> {{Graphics@{Red, Disk[]}, .05}, {Graphics@{Blue, \n       Rectangle[]}, .05}}, Joined -> True];\nautoLegend[p, {\"Small\", \"Big\", \"Bigger\"}, Alignment -> {-.8, .8}]\n\n\nautoLegend is still limited in the sense that its automatic extraction doesn't yet work with GraphicsGrid or GraphicsRow (but I'll add that at some point). But at least it seems to behave reasonably when you give it several plots at once, e.g. as in this example:\nplot1 = Show[Plot[{Sin[x], Sinh[x]}, {x, -Pi, Pi}], \n  ListPlot[Join[{#, Sin[#]} & /@ Range[-Pi, Pi, .5], {#, Sinh[#]} & /@\n      Range[-Pi, Pi, .5]]]];\nautoLegend[plot1, {\"Sin\", \"Sinh\"}]\n\n\nEdit July 5, 2012\nBy creating the plot legend as an overlay, one gains flexibility because the legend created with legendMaker doesn't have to be \"inside\" any particular graphics object; it can for example overlap two plots (see also my MathGroup post). \nHowever, overlays aren't so convenient in other respects. Importantly, the graphics editing tools that come with Mathematica can't be used directly to fine-tune the plot and/or legend when it's in an overlay. In an Overlay, I can't make both the plot and legend selectable (and editable) at the same time. \nThat's why I changed autoLegend such that it uses Insets instead of Overlay. The positioning just requires a little more code because Inset needs   different coordinate systems to determine its placement and size. To the user, the placement happens in pretty much the same way that the Alignment works in Overlay: you can either use named positions such as Alignment -> {Left, Bottom} or numerical scale factors such as Alignment -> {0.5, 0}. In the latter case, the numbers range from -1 to 1 in the horizontal and vertical direction, with {0, 0} being the center of the plot.\nWith this method, the plot is fully editable, as shown in the movie below. The movie uses a differently named function deployLegend, but from now on we can define deployLegend = autoLegend\ndeployLegend[p, {\"Label 1\", \"Label 2\", \"Label 3\"}]\n\n\nThis is a screen capture of how the legend is now available as part of the graphics object. First, I make a color change in one of the labels to show that the legend preserves formatting. Then I double-click on the Graphics and start editing. I select the legend, making sure I don't have parts of the plot selected. Then I drag the legend around and rotate it. \nThese manipulations leverage the built-in editing tools, so I didn't see any reason to use Locators to make the legend movable, as was done with individual labels in this post.\nThe positioning of the legend is not restricted to the inside of the plot. To make a legend appear off to the side, you just have to Show the plot with a setting for PlotRegion that leaves space wherever you need the legend to go.\nHere is an example:\nparam = ParametricPlot[{{3 Cos[Pi t], \n     Sin[2 Pi t]}, {1 + Cos[Pi t], \n     Sin[2 Pi t + Pi/3]}}, {t, 0, 2}];\n\nautoLegend[param, {\"Curve 1\", \"Curve 2\"}]\n\n\nSo to move the legend out of the picture, you might do this:\nautoLegend[\n Show[param, PlotRegion -> {{0, .7}, {0, 1}}], {\"Curve 1\", \"Curve 2\"},\n  Alignment -> {Right, Center}]\n\n\nThe legend placement is relative to the enclosing image dimensions, as you can see - not relative to the plot range of the ParametricPlot. The plot region may not be the only thing you want to change, though. autoLegend tries to determine the total aspect ratio automatically, but we see that there is a bit too much white space at the top now. For that reason, I also added the option AspectRatio so we can set a manual value:\nparamWithLegend = autoLegend[\n Show[param, PlotRegion -> {{0, .7}, {0, 1}}], {\"Curve 1\", \"Curve 2\"},\n  Alignment -> {Right, Center}, AspectRatio -> .25]\n\nThis produces the same picture as above but with less white space on top. \nIf you want to change the relative size of the legend and/or plot, I'd suggest playing around with ImageSize and Magnify, as in this example:\nMagnify[Show[paramWithLegend, ImageSize -> 300], 2]\n\nFor some code in autoLegend, I should credit the answer to the question \"ShowLegend values\" where I made a similar legend for color bars in contour plots.\nIf autoLegend doesn't cut it,  use legendMaker\nLimitations of the automatic style recognition in autoLegend may occur if you combine different types of plot with Show, as in the following example from the comments:\nmyplots = \n  Show[Plot[Sin[x], {x, 0, 2 Pi}, PlotRange -> All, \n    PlotStyle -> {Red, Thick}], \n   ListPlot[\n    Table[{x, Sin[x] + RandomReal[{-0.1, 0.1}]}, {x, 0, 2 Pi, 0.1}], \n    PlotRange -> All, PlotMarkers -> Automatic, Joined -> True]];\n\nmyStyles = extractStyles[myplots]\n\n\n{{Directive[Hue[0.67,0.6,0.6],RGBColor[1,0,0],Thickness[Large]],Directive[Hue[0.67,0.6,0.6]]},{\\[FilledCircle]}}\n\nOverlay[{myplots,\n  legendMaker[{\"Sin(x)-theory\", \"Sin(x)-data\"},\n   PlotStyle -> myStyles[[1]],\n   PlotMarkers -> Prepend[\n     myStyles[[2]], \"\"]]}, Alignment -> {Right, Top}]\n\n\nHere, the problem is that we have two lines with distinct styles, but not the same number of distinct plot markers (just \\[FilledCircle]). To get one line with and one line without marker, I call legendMaker with a two-element list for PlotMarkers, one of which is an empty string \"\".\n", "list manipulation - Part extraction vs functions like First, Last?": "\nYou cannot make assignments to First, Last, Rest, or Most the way you can with Part.  Therefore, there is greater consistency in using Part for all operations.  See this answer for an example of and argument for this consistency.\nAlso, you must change functions if you need to update your code to index a different element or change an element to a Span.  By using Part from the beginning you have the greatest flexibility without changing functions.  This can make comparing different code revisions easier.  It can also make a user defined function more flexible, e.g.: f[x_, part__ : 1] := foo @ x[[part]]\nLess importantly x[[1]] is more terse than First@x, especially in the FrontEnd using \u301a \u301b, and I am a fan of terse coding.\n", "kernel - Unsaved notebook is crashing: is there any way I can save the state of the MathKernel before I kill it?": "\nIf there is such a thing, I want to know it for windows and linux based OS'es also.\nBattling with the same problem I have found 2 partial solutions:\n\nctrl+s before hitting shift+enter (I think it's command+s for Mac's)\nif you ignored #1 then you might still be able to screenshot the code and reenter it\n\nI have tried TextRecognize to restore the text from the image, but it's still a bit off.\n\nEdit:\nIf your UI is not locked, you can \n\nQuit the kernel, Evaluation -> quit kernel -> local (or add a shortcut for it) \nInterrupt evaluation\n\non notebook interfaces: alt + , or Cmd + Option + .\non text-based interfaces: ctrl + C\n\n\n", "plotting - Plot legend inside a Show": "\nUse ShowLegend when you need to use the package's functionality with Show. Here's an example:\neqns = {Sin[3 Tanh[#]], Sin[Erf[#]]} &;\ncolors = {Blue, Red};\nlegends = TraditionalForm /@ eqns[x];\n\nplot1 = Plot[Evaluate@eqns[x], {x, 0, \u03c0}, PlotStyle -> colors, \n    Filling -> {1 -> {{2}, LightGreen}}];\nplot2 = ListPlot[Select[RandomReal[{0, Pi}, {1000, 2}], \n    IntervalMemberQ[Interval[Sort[eqns[First@#]]], Last@#] &], PlotStyle -> Darker@Green];\n\nShowLegend[Show[plot1, plot2], {{Graphics[{#1, Thick, Line[{{0, 0}, {1, 0}}]}], #2} & @@@ \n   Transpose[{colors, legends}], LegendPosition -> {-0.65, -0.5}, \n   LegendSpacing -> 0, LegendShadow -> None, LegendSize -> 0.6}]\n\n\n", "calculus and analysis - Integration with vector coefficients": "\nIt helps to do a little analysis to simplify the problem.  This expression is integrating over a line through $\\mathbf{b}$ in the direction of $\\mathbf{a}$.  By choosing a suitable coordinate system you can arrange for $\\mathbf{a} = (x,0,0)$ where, to assure a unit Jacobian, $x = \\|\\mathbf{a}\\|$ (and you can even make $\\mathbf{b} = (0,b,0)$ if you like, but let's just stop here and generically take $\\mathbf{b} = (a,b,c)$).  Brute force now succeeds:\nClearAll[x, a, b, c];\nIntegrate[{x, 0, 0} \u03bc / Norm[{x, 0, 0} \u03bc - {a, b, c}]^3, \n  {\u03bc, -Infinity, Infinity}, \n  Assumptions -> Im[a] == 0 && Im[b] == 0 && Im[c] == 0 && Im[x] == 0 && a b c != 0]\n\nThe output, after 5 seconds, is\n{ConditionalExpression[(2 a Abs[x])/((b^2 + c^2) x^2), x != 0], 0, 0}\n\nChange back to the original coordinates to obtain the general answer.\nThe key is to specify the assumptions implicit in the question: namely, that these are real vectors and that the line does not pass through the origin (where the integral diverges).\n", "What is an efficient way of selecting multiple colors via Manipulate?": "\nWith this one you just click the circle to be color-edited. No need to pick an index number first.\nDynamicModule[{x = 1},\n Manipulate[c[[x]] = color;\n  Grid[\n   Table[\n    Setter[Dynamic[x, (color = c[[#1]]; x = #1) &], i*4 + j, \n     Graphics[{FaceForm[c[[i*4 + j]]], Disk[]}, ImageSize -> 40]\n     ], {i, 0, 2}, {j, 4}\n    ]\n   ], {color, Red},\n  Initialization :> {c = ConstantArray[Black, 12]}]\n ]\n\n\nNote that I used Dynamic's alternative syntax form, where you determine what should happen if the argument needs to be updated. In this case I use it to set the starting color of the color selector to be the current color of the circle being clicked. Otherwise the color of the circle would be set by the current setting of the color setter. This may be or may not be how you want the control to behave. Just change it to Dynamic[x] if you want to have the other behavior.\n", "plotting - Aligning plot axes in a graphics object": "\nThis is a common (and very big) annoyance when creating graphics with subfigures.  The most general (but somewhat tedious) solution is setting an explicit ImagePadding:\nGraphicsColumn[\n {Show[a, ImagePadding -> {{40, 10}, {Automatic, Automatic}}], \n  Show[b, ImagePadding -> {{40, 10}, {Automatic, Automatic}}]}]\n\n\nThis is tedious because you need to come up with values manually.  There are hacks to retrieve the ImagePadding that is used by the Automatic setting.  I asked a question about this before.  Using Heike's solution from there, we can try to automate the process:\npadding[g_Graphics] := \n With[{im = Image[Show[g, LabelStyle -> White, Background -> White]]},\n   BorderDimensions[im]]\n\nip = 1 + Max /@ Transpose[{First@padding[a], First@padding[b]}]\n\nGraphicsColumn[\n Show[#, ImagePadding -> {ip, {Automatic, Automatic}}] & /@ {a, b}]\n\nThe padding detection that's based on rasterizing might be off by a pixel, so I added 1 for safety.\nWarning: the automatic padding depends on the image size!  The tick marks or labels might \"hang out\" a bit.  You might need to use padding@Show[a, ImageSize -> 100] to get something that'll work for smaller sizes too.\nI have used this method myself several times, and while it's a bit tedious at times, it works well (much better than figuring out the image padding manually).\n", "How to Map a subset of list elements to a function?": "\nYou might first partition your list and then use Map as usual :\nf[#[[1]], #[[2]]] & /@ Partition[{1,2,3,4}, 2, 1]\n\n(* {f[1, 2], f[2, 3], f[3, 4]} *)\n\n", "plotting - GridLines in LogPlot or LogLogPlot": "\nAfter some fiddling around I came up with this function:\nClear[gitter]\ngitter[xspec_, yspec_, logPlot_: False] :=\n\n  Module[{min, max, d, xlines, ylines, i},\n   xlines = ylines = None;\n   Switch[xspec,\n    Automatic, xlines = Automatic,\n    {_?NumericQ, _?NumericQ, _?NumericQ},\n    {min, max, d} = xspec;\n    xlines = Range[min, max, d],\n    {_?NumericQ, _?NumericQ, _List},\n    {min, max, d} = xspec;\n    If[logPlot == False,\n     xlines = (Log10[#] &) /@ Flatten[Table[10^i*d, {i, min, max}]],\n     xlines = Flatten@Table[10^i d, {i, min, max}]]\n    ];\n   Switch[yspec,\n    Automatic, ylines = Automatic,\n    {_?NumericQ, _?NumericQ, _?NumericQ},\n    {min, max, d} = yspec;\n    ylines = Range[min, max, d],\n    {_?NumericQ, _?NumericQ, _List},\n    {min, max, d} = yspec;\n    If[logPlot == False,\n     ylines = (Log10[#] &) /@ Flatten[Table[10^i*d, {i, min, max}]],\n     ylines = Flatten@Table[10^i d, {i, min, max}]]];\n   {xlines, ylines}];\n\nIt handles three cases:\n(1) Linear scale: The parameters have the form {min, max, step}\n(2) logarithmic scale in a normal Plot: The parameters have the form {min, max, istOfValues}\n(3) LogPlot or LogLogPlot: as in (2) but the optional Parameter LogPlot has to be set to True.  \nExamples: \ngrid = gitter[{-1, 1, {1, 2, 5, 7}}, {-5, 5, {1, 2, 5, 7}}, True];\nlp = LogLogPlot[2 x^5/3, {x, 0.1, 10}, GridLines -> grid, \n  PlotRangePadding -> 0, AspectRatio -> 1, \n  Ticks -> {Automatic, Table[10.^i, {i, -5, 5}]}]\n\ngives:\n \nand\nyticks = Tickmarken[0, 5, {1}, {2, 3, 5, 7}];\ngitter = Gitter[{-2, 10, 1}, {0, 5, {1, 2, 3, 5, 7}}];\nplot = Plot[Log10[2 E^x], {x, -2, 10}, Ticks -> {Automatic, yticks}, \n  GridLines -> gitter]\n\ngives:\n\nTickmarken is a function, I use to make Ticks.\n", "numerical integration - Solving an ODE numerically": "\nIf you are willing to settle for $y(5) = 0$ instead of $y(\\infty) = 0$, the commands to solve it are\nsol = First@NDSolve[\n  {-2 x y'[x] == 47.21` (-3.9582` + 10.586` x - 8.0588` x^2 + 3.048` x^3 - \n         0.6087` x^4 + 0.0614` x^5 - 0.0025` x^6)^2 Erfc[x] + y''[x], \n   y[0.6] == 0, y[5] == 0}, \n   y, {x, 0.6, 5}]\n\n\nPlot[y[x] /. sol // Evaluate, {x, 0.6, 5}]\n\n\nIncreasing the upper bound from 5 to a larger number won't change much, so I believe using $y(5) = 0$ might be a good enough approximation.\nThere are completely analogous examples in the NDSolve documentation.  Please check them.\n", "How to specify the InputField as a String in Manipulate": "\nI thought this was undocumented, but actually it just seems to be obscure. The documentation for ControlType mentions, under the \"More Information\" section,\n\nArbitrary controls can be set up in Manipulate by giving control specifications of the form {u, func}.\n\nSo,\nManipulate[InputForm[col], {col, \"AB\", InputField[#, String] &}]\n\ngives (with a different string entered for demonstrative purposes):\n\n", "evaluation - Force function to make assumptions about its input variables in Mathematica": "\nThe following just works:\nAssuming[x > 0, Simplify[Sqrt[x^2]]]\n\n(*\n==> x\n*)\n\nYour code:\nn[x_/; x > 0 && Element[x,Reals]]:=x^(1/2);\nn[x_]:=Assuming[x > 0 && Element[x,Reals],FullSimplify[x^(1/2)]];\n\ndoesn't work because the x that is passed  after a call of n[x^2] isn't x but x^2. So you're assuming x^2>0 or Element[x^2,Reals].\n", "programming - Finding a \"not-shortest\" path between two vertices": "\nYou can try giving your edges random weights so that FindShortestPath is forced to take a different path. Here are some different possible paths \u2014\nTable[HighlightGraph[lab = Graph[edges, EdgeWeight -> RandomInteger[1000, Length[edges]]], \n    PathGraph[s = FindShortestPath[lab, 1, 125]], VertexLabels -> \"Name\",\n    ImagePadding -> 10, GraphHighlightStyle -> \"Thick\", ImageSize -> 600], {6}\n] ~Partition~ 3 // Grid\n\n\n", "graphics - Using one table for multiple arguments": "\nAdding an additional (optional) parameter for increment, define\n datalistPlot[a_Integer, b_Integer, c_Integer, d_Integer, e_Integer: 1] := \n Module[{left = Mean@RandomInteger[{a, b}, c]},{\n Transpose@\n Table[{left=(n - 1) left/n + RandomInteger[{a, b}]/n, n left/(n - 1)}, {n, c, d, e}], \n {c, d}, \n (a + b)/2\n }] \n // ListLinePlot[#[[1]], \n GridLines -> {None, {{#[[3]], Directive[Red, Thick]}}}, \n DataRange -> #[[2]], PlotRange -> {Automatic, #[[3]] + {-1, 1}}] &\n\nand use as\ndatalistPlot[list[0, 10, 10, 500, 10]\n\nto get\n\n", "functions - Mapping and Interpolation": "\nYour question isn't very clear, but I think you need the Rescale function, especially its 3 argument form:\nRescale[#, {1, 100}, {7, 20}] & /@ Range[1, 100, 5] // N\n(* Out[1]= {7., 7.65657, 8.31313, 8.9697, 9.62626, 10.2828, 10.9394, 11.596, 12.2525, 12.9091, \n    13.5657, 14.2222, 14.8788, 15.5354, 16.1919, 16.8485, 17.5051, 18.1616, 18.8182, 19.4747}\n *)\n\n", "plotting - CustomTicks and small ranges": "\nAs soon as I posted, I realized I could check whether there were any options for LinTicks that might be useful:\nOptions@LinTicks // TableForm\n\nScanning that list, I saw:\nTickLabelFunction -> Automatic\n\nOn a hunch, I added \nTickLabelFunction -> TraditionalForm\n\nTo the ticks definition from the question, and things worked:\n\n", "keyboard - Custom setting of HOME and END keys on mac": "\nThe file KeyEventTranslations.tr which can be found in the directory $InstallationDirectory/SystemFiles/FrontEnd/TextResources/Macintosh couples key events to actions in Mathematica. The two lines that define the behaviour of Home and End are\nItem[KeyEvent[\"Home\"], \"ScrollNotebookStart\"],\nItem[KeyEvent[\"End\"], \"ScrollNotebookEnd\"],\n\nTo change the behaviour of these two keys you could replace \"ScrollNotebookStart\" and \"ScrollNotebookEnd\" to \"MoveLineBeginning\" and \"MoveLineEnd\", respectively. \nTo be on the safe side, you could copy the file to the directory $UserBaseDirectory/SystemFiles/FrontEnd/TextResources/Macintosh first and edit that file instead of the original in $InstallationDirectory. \n", "Import DCD (CHARMM/NAMD binary trajectory) file": "\nI ported most of the matlab package to Mathematica. Here is the result\n(*Some utility functions*)\nSetAttributes[MapShowIt, {HoldAll, Listable}];\nMapShowIt[code__] := MapShowIt[{code}];\nMapShowIt[code_] := With[{y = code}, Defer[code = y]]\n\nClearAll[Puts]\nSetAttributes[Puts, HoldAll];\nOptions[Puts] = {DisplayFunction -> Shallow};\n$VerbosePrint = False;\nPuts[msg_, data_, opt : OptionsPattern[]] := \n  If[$VerbosePrint, Print[msg, OptionValue[DisplayFunction][data]]];\nPuts[msg_List] := If[$VerbosePrint, Print[MapShowIt[msg]]];\nPuts[msg_] := If[$VerbosePrint, Print[msg]];\n(*warning this is still unsafe ... it should be done as \\\nanswered  herehttp://mathematica.stackexchange.com/a/4189/745*)\n\nUnprotect[Dot];\nSetAttributes[Dot, HoldRest];\nDot[h_, key_Symbol | key_String] := \n  System`Utilities`HashTableGet[h, ToString[Unevaluated[key]]];\nDot /: Set[Dot[h_, key_Symbol | key_String], value_] := (\n   Quiet[\n      System`Utilities`HashTableRemove[h, ToString[Unevaluated[key]]]\n    , System`Utilities`HashTableRemove::norem];\n   System`Utilities`HashTableAdd[h, ToString[Unevaluated[key]], \n    value]);\nProtect[Dot];\nOn[Assert];\n\nClearAll[readDCDHeader];\nOptions[readDCDHeader] = {\"Verbose\" -> False};\nreadDCDHeader::nonintframes = \n  \"Number of frames calculated from files size (`1`) is not an \\\ninteger!\";\nreadDCDHeader::diffframes = \n  \"Header claims `1` frames, but there are `2` frames!\";\nreadDCDHeader[fileName_, opts : OptionsPattern[]] :=\n  Module[{str, magicnum, h, i, newsize, newsize1, numlines, fint}, \n   Block[{$VerbosePrint = OptionValue[\"Verbose\"]},\n      h = System`Utilities`HashTable[];\n\n      str = OpenRead[fileName, BinaryFormat -> True];\n\n\n      fint = BinaryRead[str, \"Integer32\"];\n      (*if we don't read an 84 then try to reverse the endianes\n      If[fint=!=84,(*then*)\n        Close[str];\n       str= OpenRead[fileName,BinaryFormat -> True,\n    ByteOrdering->-$ByteOrdering];]*)\n      Assert[fint == 84, \"First integer must be 84\"];\n      h.stream = str;\n      magicnum = BinaryReadList[str, \"Character8\", 4];\n\n      Assert[magicnum == {\"C\", \"O\", \"R\", \"D\"}, \"CORD not present\"];\n\n      h.nset = BinaryRead[str, \"Integer32\"];\n      h.istart = BinaryRead[str, \"Integer32\"];\n      h.nsavc = BinaryRead[str, \"Integer32\"];\n\n      (*read free indexes*)\n      SetStreamPosition[str, 40];\n      h.numfree = BinaryRead[str, \"Integer32\"];\n\n      Puts[{h.nset, h.istart, h.nsavc, h.numfree}];\n\n      (*find out if is charmm DCD*)\n      SetStreamPosition[str, 84];\n      i = BinaryRead[str, \"Integer32\"];\n      If[i == 0, (*then*)\n         h.charmm = False;\n       ,(*else*)\n       h.charmm = True;\n\n       (* check for extra block*)\n       SetStreamPosition[str, 48];\n       i = BinaryRead[str, \"Integer32\"];\n       h.charmm$extrablock = (i == 1);\n\n                     SetStreamPosition[str, 52];\n                      i = BinaryRead[str, \"Integer32\"];\n       h.charmm$4dims = (i == 1);\n       ];\n\n      Puts[{h.charmm, h.charmm$extrablock, h.charmm$4dims}];\n\n      (*read the timestep*)  \n      SetStreamPosition[str, 44];\n      If[h.charmm, (*then*)\n       h.DELTA = BinaryRead[str, \"Real32\"];\n       ,(*else*)\n       h.DELTA = BinaryRead[str, \"Real64\"];];\n      h.step = h.DELTA;\n\n      (*get the title*)\n      SetStreamPosition[str, 92];\n      newsize = BinaryRead[str, \"Integer32\"];\n      numlines = BinaryRead[str, \"Integer32\"];\n      (*TODO check for curoupted Ntitle values*)\n      h.title = \n     StringJoin@BinaryReadList[str, \"Character8\", numlines*80];\n      newsize1 = BinaryRead[str, \"Integer32\"];\n      Assert[newsize == newsize1];\n      Puts[h.title];\n      i = BinaryRead[str, \"Integer32\"]; \n    Assert[i == 4, \"4 must be read before num of atoms\"];\n      h.numatoms = BinaryRead[str, \"Integer32\"];\n      h.N = h.numatoms;\n      i = BinaryRead[str, \"Integer32\"]; \n    Assert[i == 4, \"4 must be read after num of atoms\"];\n      Puts[{h.DELTA, h.N}];\n\n      (*love this comment from the original matdcd package*)\n      (*stuff with freeindexes.  Just smile and nod.*)\n      If[ h.numfree =!= 0, (*then*)\n          i = BinaryRead[str, \"Integer32\"];  (* should be N-\n     NAMNF*4*)\n\n     h.freeindexes = BinaryReadList[str, \"Integer32\", h.N - h.numfree];\n          i = BinaryRead[str, \"Integer32\"];  (* should be N-\n     NAMNF*4*)\n       ];\n\n    h.headerend = StreamPosition[str];  \n    (*calculate one frame size in bytes*)\n    h.framesize = 3*(h.numatoms*4 + 2*4(*for the blocksize*))\n        + If[h.charmm$extrablock, 12*4 + 2*4, 0]\n        + If[h.charmm$4dims, +h.numatoms*4 + 4*2, 0];\n\n    h.numframes = (FileByteCount[fileName] - h.headerend)/h.framesize;\n    (* Warn if noninteger frame number and if the actuaal frames \\\ndiffer from h.nset*)\n    If[Head[h.numframes] =!= Integer,(*then*)\n       Message[readDCDHeader::nonintframes, h.numframes]];\n    If[Head[h.numframes] != h.nset,(*then*)\n       Message[readDCDHeader::diffframes, h.nset, h.numframes]];\n\n    Return[h];\n    ]];\n\n\nClearAll[readDCDStep];\nOptions[readDCDStep] = {\"Verbose\" -> False,\n\n   \"Atoms\" -> All(*or a one based list of atoms to take*)};\nreadDCDStep[h_System`Utilities`HashTable, opts : OptionsPattern[]] :=\n\n\n  Module[{x, y, z, str, blocksize, ind}, \n   Block[{$VerbosePrint = OptionValue[\"Verbose\"]},\n      ind = OptionValue[\"Atoms\"];\n      Assert[h.numfree == 0, \n     \"Fixed atoms anad free indices are not supported\"];\n      str = h.stream;\n\n      If[h.charmm && h.charmm$extrablock, (*then*)\n       (*unit cell info*) \n         blocksize = BinaryRead[str, \"Integer32\"];\n         Puts[\n      \"Skipping unit info cords. (blocksize: \" <> \n       ToString[blocksize] <> \")\"];\n         Skip[str, \"Byte\", blocksize];\n\n         Assert[blocksize == BinaryRead[str, \"Integer32\"], \n      \"Wrong blocksize in extra block \"];\n       ];\n     (* Get x coordinates *)\n      blocksize = BinaryRead[str, \"Integer32\"];\n      Puts[\n     \"Getting x cords. (blocksize: \" <> ToString[blocksize] <> \")\"];\n      x = BinaryReadList[str, \"Real32\", blocksize/4]; \n      If[Head[ind] == List, x = Part[x, ind]];\n      Puts[\"x:\\n\", x];\n      Assert[blocksize == BinaryRead[str, \"Integer32\"], \n     \"Wrong blocksize in x coords\"];\n\n      (* Get y coordinates *)\n      blocksize = BinaryRead[str, \"Integer32\"];\n      Puts[\n     \"Getting y cords. (blocksize: \" <> ToString[blocksize] <> \")\"];\n      y = BinaryReadList[str, \"Real32\", blocksize/4];\n      If[Head[ind] == List, y = Part[y, ind]];\n      Puts[\"y:\\n\", y];\n      Assert[blocksize == BinaryRead[str, \"Integer32\"], \n     \"Wrong blocksize in y coords\"];\n\n      (* Get z coordinates *)\n      Puts[\n     \"Getting z cords. (blocksize: \" <> ToString[blocksize] <> \")\"];\n      blocksize = BinaryRead[str, \"Integer32\"];\n      z = BinaryReadList[str, \"Real32\", blocksize/4];\n      If[Head[ind] == List, z = Part[z, ind]];\n      Puts[\"z:\\n\", z];\n      Assert[blocksize == BinaryRead[str, \"Integer32\"], \n     \"Wrong blocksize in z coords\"];\n\n      (*skip 4th dimension if it exists*)\n      If[h.charmm && h.charmm$4dims,(*then*)\n         Puts[\"Skipping w cords.\"];   \n         blocksize = BinaryRead[str, \"Integer32\"];\n                       Skip[str, \"Byte\", blocksize];\n\n     Assert[blocksize == BinaryRead[str, \"Integer32\"], \n      \"Wrong blocksize in 4th dim\"];\n       ];\n    Assert[Length[x] == Length[y] == Length[z], \n     \"Wrong size of x or y or z\"];  \n    Return[Developer`ToPackedArray[Transpose@{x, y, z}]];\n    ]];\n\nClearAll[CloseDCD];\nCloseDCD[h_System`Utilities`HashTable] := Close[h.stream];\n\nClearAll[ImportDCD];\nOptions[ImportDCD] = Evaluate[Options[readDCDStep]];\nImportDCD[fileName_, options : OptionsPattern[]] :=\n  Module[{h, data, ropts, opts}, \n   Block[{$VerbosePrint = OptionValue[\"Verbose\"]},\n      opts = \n     DeleteDuplicates[{options}~Join~Options[ImportDCD], \n      ToString[First[#1]] == ToString[First[#2]] &];\n      Puts[opts];  \n      h = readDCDHeader[fileName, Verbose -> OptionValue[\"Verbose\"]];\n\n      ropts = Evaluate[FilterRules[opts, Options[readDCDStep]]];\n      data = (readDCDStep[h, ropts])\n                  & /@ Range[h.numframes];\n      CloseDCD[h];\n\n      Return[data]\n    ]];\n\nSome example usage:\n\nRead the header\nh = readDCDHeader[\"wat.dcd\", Verbose -> True];\nCloseDCD[h];\nRead one step\nh = readDCDHeader[\"wat.dcd\", Verbose -> True];\ndata = readDCDStep[h, Verbose -> True];\nShort[data]\nCloseDCD[h];\nImport the whole trajectory\ndata = ImportDCD[\"wat.dcd\", Verbose -> False];\nDimensions[data]\n(*and for fun plot it:*)\nManipulate[\n pdata = Sphere[#] & /@ data[[i]];\n Graphics3D[pdata]\n , {i, 1, Length[data], 1}]\n\n\nIts also possible to specify a list of one based indexes of which atoms to load using the \"Atoms\" option. \nI really should put this on github and convert it into a package...\n", "functions - Plotting a simple relationship with Plot[] results in empty graph": "\nIt's important to realize that when setting something up of the type:\nf[x_]:=x\n\nThat you are setting a replacement rule, not creating a function. See Functions vs. patterns for a further discussion of this. \nIn the current situation, what you wrote has the following effect. First, you define:\nplotFunction[b_, c_] := Plot[a, {d, 0, 10}];\n\nwhen you call\nplotFunction[2, 3]\n\nMMA does something like the following. \"Oooh, I found a pattern that matches plotFunction[b_, c_], I need to replace it, and then evaluate it!\" Replacing it makes the right hand side look like:\nPlot[a, {d, 0, 10}]\n\nSince there wasn't anything for b and c to replace, the above is what MMA will now evaluate. Evaluating the expression, it says \"Ooooh, oooh, I know how to deal with a!\", so it replaces it:\nPlot[(b + c)/d, {d, 0, 10}]\n\nThen it tries to actually call the replacement-rule (\"built-in-function\") Plot which fails, since b and c are not numbers, as you saw. However, if you define:\na[b_,c_,d_]=(b + c)/d    \nplotFunction[b_, c_] := Plot[a[b, c, d], {d, 0, 10}];\n\nAnd call:\nplotFunction[2, 3]\n\nMMA first replaces plotFunction with:\nPlot[a[2, 3, d], {d, 0, 10}]\n\nThen evaluates that, at which point it sees that there is another pattern it knows how to deal with (a[b_,c_,d_]=(b + c)/d) and replaces that:\nPlot[(2 + 3)/d, {d, 0, 10}]\n\nAnd only then plots it, which results in the correct plot.\nFor dealing with these types of replacement problems, I strongly suggest the use of WReach's traceView functions. For Plots, this doesn't always help, but can be instructive.\n", "How to programmatically create a Manipulate in another Manipulate?": "\nEDIT to make the sliders work, in response to comments:\nHere's one possible solution, wrapping your inner Manipulate in With statement that defines both the thing that you want to manipulate, and the Sequence of controls, like so:\nManipulate[\n With[{\n   value    = Column[Table[x[i], {i, 1, n}]],\n   controls = Sequence @@ Table[{{x[i], 0.5}, 0, 1}, {i, 1, n}]},\n  Manipulate[\n   value,\n   controls]],\n {n, Range[6]}]\n\nBoth value and controls need to be defined in the same place because Manipulate, like some other constructs (including Module, Function and RuleDelayed) does some sort of symbol renaming for expressions inside of it, and you need the x in value to be the same x in controls.\nThis gives you a setup that looks like this: \n\nIf you try it out in a notebook, you will have n sliders in the inner Manipulate.\n", "plotting - Align Array Plots - Mathmatica Stack Exchang": "\nIn this particular instance, you can align the two array plots within a row by specifying each ImageSize to have the form {Automatic, h}, for some common h, and also making PlotRangePadding and ImagePadding both be none, like so:\nRow[{\n  ArrayPlot[List /@ lista, ImageSize -> {Automatic, 250}, \n   Frame -> False,\n   PlotRangePadding -> None, ImagePadding -> None],\n  ArrayPlot[Transpose@listb, AspectRatio -> 1/GoldenRatio,\n   ImagePadding -> None, PlotRangePadding -> None,\n   ImageSize -> {Automatic, 250}, Frame -> None]}\n]\n\nThis yields:\n\n", "Front-end glitch when interacting with dynamic content": "\nUpgrading to a newer computer solved the problem. Perhaps it was RAM- or grpahics-card-related, we'll never know.\n", "Add lists with unequal lengths together to create a matrix": "\nI don't have a free kernel to try your question on, so here's a smaller generalized approach that I could construct in my head. In the end, I'll mention how you can adapt it to yours.\nFirst, consider a non-rectangular list similar to yours:\nlist = {{{1, a}, {2, b}}, \n        {{3, a}, {2, c}, {4, f}}, \n        {{3, b}, {6, f}, {4, c}, {5, e}}};\n\nThe output expected here is a 3x6 matrix with each column corresponding to the unique elements and each row having the corresponding element or zero. Obtaining the unique elements and constructing a larger matrix, as the following, we get:\nWith[{un = Union@Flatten@list[[All, All, 1]]},\n    (un /. Rule@@@#&)/@list /. _Integer -> 0\n]\n\n(* Out[1] = {{a, b, 0, 0, 0, 0}, \n             {0, c, a, f, 0, 0}, \n             {0, 0, b, c, e, f}} \n*)\n\nwhich, I believe, is what you want. If you want the first row to be the list of unique elements, simply join un with the rest as:\nWith[{un = Union@Flatten@list[[All, All, 1]]},\n    {un} ~Join~ ((un /. Rule@@@#&)/@list /. _Integer -> 0)\n]\n\n(* Out[2]= {{1, 2, 3, 4, 5, 6}, \n            {a, b, 0, 0, 0, 0}, \n            {0, c, a, f, 0, 0}, \n            {0, 0, b, c, e, f}} \n*)\n\nNow the only change that's required for this to work on your data is to use _SQLDateTime instead of _Integer in the With construct above.\n", "functional style - Composite graphics with Row, Column, data aggregation and layout control": "\nThis is more an idea than an answer.\nThat kind of graphical output seems ideal for multi cell output. This way, if the output is very long, Mathematica handles the page breaks for you (in case you need to print or generate a PDF report).\nTry this:\nCellPrint /@ Table[Graphics[{Gray, Rectangle[{0, 0}, {10, 1}]}], {10}]\n\n\n", "Printing a Dynamic variable inside Dynamic": "\nShort answer\nFor me a Print from within a Dynamic goes to the Messages notebook. Have you checked that with a very simple case? If I evaluate this:\nColumn[{Slider[Dynamic[x]],Dynamic[Print[x];x]}]\nand play with the slider, the Messages notebook will be opened and the x-values are printed to it. If that is not also happening for you, you should provide more detailed information (version, operating system, any special settings?)\nDebugging and Organization of User Interface code\nHonestly, I think there are some misunderstandings in your code fragment about how to use Dynamic, so I think your real problem is that you don't know how to efficiently organize and debug your user interface code. It doesn't become clear from neither your example nor your description what the complications with your code actually are, so I can just give some general advice. \nFirst of all I would consider it essential to separate any programming logic from the user interface functionality. I would absolutely discourage to use code within a Dynamic to update variables (or even do parts of your calculation) as a side effect, as e.g. Dynamic[{n, xVariable = mQ[n]}] does. I don't think that Dynamic was ever meant to be used like that.\nIf you want to create a 3D-plot from the values of many sliders, then write a function which accepts all those values as arguments and calculates the 3D-plot. Keep this function completely free from any user interface code, that is any Dynamic whatsoever. This function can be debugged and tested in the usual way (using Print, Trace or the debugger). When it produces the plot you want, only in the end write a user interface that makes use of that function. From what you described even a simple Manipulate would do, e.g.:\ncomplicatedPlot3D[a_, b_, c_] := \n Plot3D[x^a + y^b - x*y^c, {x, -1, 1}, {y, -1, 1}]\nManipulate[\n complicatedPlot3D[a, b, c], {a, 1, 5}, {b, 2, 5}, {c, 5, 6}]\nIf you find a Manipulate will not provide enough flexibility, I think you should try to learn as much as possible from the tutorials on the topic before you try to build something more complicated on your own. I would consider Introduction to Dynamic a must read and Advanced Dynamic Functionality to also be helpful (reading them in the documenation center and actually executing the examples is to be recommended). \nAdditional Remarks on Example Code\nThere are some details in the example code that -- at least without a larger picture -- do not seem to make much sense to me:\n\nIt seems useless to wrap a Dynamic around everything. Doing so will actually not do anything because all appearances of the values that are changed are in nested Dynamics. If there would be such expressions which were not nested, it would redefine the functions mQ and mV and recreate the sliders on every change of n or t, but neither of these does in any way depend on those variables. In that latter case the sliders would also start to behave strangely.\nNeither the second argument Automatic nor the ContinuousAction->False option to the nested Dynamic do seem to achieve anything.\nAs it is written, it uses the product of lists to arrange it's various parts. The product is probably just a typo and the whole construct looks more like an accident altogether. There are special functions which allow to control the arrangement of the various parts of a gui, like Grid, Column or Row.\nYour question about Print and the placement of ; make me believe that you are not fully aware of the difference between the return value that any expression will give on evaluation and the side effect of writing to a notebook that Print achieves and how all that is linked to the dynamic functionality.\n\nBasically I think the answer of @CHM already gives you something that will work, but I think it might make sense to go one step further and remove all things that seem strange. Here is a version that would do what your example does:\nmQ[n_] := \n  75.63510582933174 - 35.87130621205199 n + 86.18343750838301 n^2 - \n   55.324190072519976 n^3;\nmV[t_] := -29.619999999999976 + 5.499999999999998 t + \n   18.333333333333325 t^2;\n\nGrid[{\n  {Slider[Dynamic[n, (n = #; xVariable = mQ[n]) &]], \n   Dynamic[{n, xVariable}]}, {Slider[\n    Dynamic[t, (t = #; yVariable = mV[t]) &]], \n   Dynamic[{t, yVariable}]},\n  {Dynamic[xVariable + 2 - yVariable], SpanFromLeft}\n  }]\n\nThese are the changes: function definitions are made outside of the user interface code, I removed any arguments and options that are not necessary and arranged all parts of the user interface in a Grid. Also I do now set xVariable and yVariable in the functions given as second argument to the Dynamic in the sliders. All other Dynamic are now only showing current values and have no side effects. The overall Dynamic did go away altogether, since it only will make a difference in the initialization of the code, which I will address in the following paragraph.\nThis code has now two drawbacks, one of that you probably tried (and partially did) solve with that overall Dynamic: 1) the function definitions will not automatically be defined when the resulting gui is shown with a new Kernel and 2) all variables are global. This both can be solved by making proper use of DynamicModule, which would look like this:\nDynamicModule[{n = 0, t = 0, xVariable, yVariable},\n xVariable = mQ[n];\n yVariable = mV[t];\n Grid[{{\n    Slider[Dynamic[n, (n = #; xVariable = mQ[n]) &]],\n    Dynamic[Row[{\n       \"n=\", NumberForm[n, {5, 3}],\n       \", x=\", NumberForm[xVariable, {5, 3}]\n       }]]\n    }, {\n    Slider[Dynamic[t, (t = #; yVariable = mV[t]) &]],\n    Dynamic[Row[{\n       \"t=\", NumberForm[t, {5, 3}],\n       \", y=\", NumberForm[yVariable, {5, 3}]\n       }]]\n    }, {\n    Panel[Dynamic[NumberForm[xVariable + 2 - yVariable, {5, 3}]]],\n    SpanFromLeft\n    }\n   }],\n Initialization :> (\n   mQ[n_] := \n    75.63510582933174 - 35.87130621205199 n + 86.18343750838301 n^2 - \n     55.324190072519976 n^3;\n   mV[t_] := -29.619999999999976 + 5.499999999999998 t + \n     18.333333333333325 t^2;\n   )\n ]\n\nYou will find more information about the details of these constructs in the mentioned tutorials. Note that I have also added some means to make the behaviour of the user interface somewhat more appealing.\n", "programming - When should I, and when should I not, set the HoldAll attribute on a function I define?": "\nThe way Mathematica works is that when it encounters a function with arguments it will try to evaluate the arguments first before proceeding to evaluate the function. This behavior can be modified by specifying the various HoldAll, HoldFirst, HoldRest, etc. attributes for a given function.\nSo in your example f[x+1] will be immediately replaced by f[6] internally.\nTo answer your question: You need HoldAll or one of it's siblings if you construct functions that need to know the actual parameters with which the function was called. For example, I sometimes need to make file names using ToString on variables that the function is called with regardless of whether those variables evaluate to something.\nIn general HoldAllis not necessary if you just do arithemtic functions or other simple data manipulating functions. Once you start getting more into the swing of functional programming style of MMA you'll soon realize when and where you need arguments to stay unevaluated.\nIn the cases you mentioned it becomes obvious why you would want to specify HoldAll. In, e.g., the \"checking evaluation\" case you want the code argument to only be evaluated once you are inside the Block, not immediately when Mathematica encounters the function that specifies the Block.\nThe case in the syntax highlighting question is similar; the list of vars you supply should be passed as is to the Block, or the function will not work if the vars evaluate to something that does not make sense within the Block (numerical values in this case):\n\n", "graphs and networks - Finding all shortest paths between two vertices": "\nDirected Shortest Paths\nHere's a friendly amendment to Heike's solution that shows the distance remaining to the finish vertex (in white).  The starting vertex is green. Edges are directed to show the appropriate direction toward the finish.  According to the documentation on GraphDistance, \"For a weighted graph, the distance is the minimum of the sum of weights along any path between s and t.\" So it should automatically work with weighted graphs.\nFirst, here's Heike's routine, which does most of the heavy lifting, with a simple tweak to produce directed edges:\npaths[gr_, {i_, j_}] := \n  Module[{sub, dist, indices, dd, nbrs}, dist = GraphDistance[gr, i, j];\n  indices = {};\n  dd = dist;\n  Reap[Nest[Function[{vv}, dd -= 1;\n  nbrs = VertexList[NeighborhoodGraph[gr, #]] & /@ vv;\n  nbrs = Pick[#, GraphDistance[gr, #, j] & /@ #, dd] & /@ nbrs;\n  Sow /@ Flatten[Thread /@ Thread[vv \\[DirectedEdge] nbrs]];\n  Union[Flatten[nbrs]]], {i}, dist]][[2, 1]]]\n\nThe following produces the directional routes. Numbers refer to GraphDistance from the current vertex to the finish vertex.\ngr = RandomGraph[{30, 40}];\nends = {1, 30};\nsub = paths[gr, ends];\ne = EdgeList[gr] /. {x_ \\[UndirectedEdge] y_ /; \n GraphDistance[gr, x, 30] < GraphDistance[gr, y, 30] :> y \\[DirectedEdge] x, \n   x_ \\[UndirectedEdge] y_ /; \n GraphDistance[gr, y, 30] <= GraphDistance[gr, x, 30] :>  x \\[DirectedEdge] y}\ngr1 = Graph[e, ImagePadding -> 15];\n\nHighlightGraph[gr1, {Graph[sub], Style[1, Green], Style[30, White]}, \n VertexLabels ->  Table[i -> Style[GraphDistance[gr1, i, 30], 16], {i, \n    Union[Level[sub, {-1}]]}], \n    VertexSize -> {1 -> Large, 30 -> Large}, \n    GraphHighlightStyle -> \"Thick\", ImagePadding -> 15]\n\n\n\nBelow is a variant that  displays (a) the vertex indices (small font size) and the distance from the finish vertex on the EdgeLabel (large font).\nHighlightGraph[gr1, {Graph[sub], Style[1, Green], Style[30, White]}, \n   VertexLabels -> (v = Union[Level[sub, {-1}]]) /. {i_Integer :> (i -> i)},\n   EdgeLabels -> sub /. {x_ \\[DirectedEdge] y_ :> (x \\[DirectedEdge] y) -> \n   Style[ GraphDistance[gr, x, 30], 14, Background -> White]},\n   VertexSize -> {1 -> Large, 30 -> Large}, \n   GraphHighlightStyle -> \"Thick\", ImagePadding -> 15, ImageSize -> 600]\n\n\n", "front end - Is it possible to Print expressions in reverse order?": "\nThis is admittedly messy, but something along these lines might work:\ninsertBelowEvaluationCell[expr_] := \n  (SelectionMove[EvaluationNotebook[], After, EvaluationCell]; \n   NotebookWrite[EvaluationNotebook[], Cell[BoxData@ToBoxes[expr], \"Print\"]])\n\nThis function moves the insertion point just below the evaluation cell before inserting the text or expression to be printed.\nLet's test it:\ninsertBelowEvaluationCell /@ Range[10]\n\nProblems:\n\nThis messes with the insertion point in the notebook which can be modified interactively as well.  Perhaps it's better to write the output into a separate notebook instead.  \nIt does not work in command line mode (without a front end).\nIt's slow (noticeably slower than Print).\n\n", "function construction - Picking random items out of a list only once": "\nHow about making a closure?  A closure is a function with an internal state.\nmakeDrippingBucket[list_] := \n Module[{bucket = list}, \n  If[bucket === {}, {}, \n    With[{item = RandomChoice[bucket]}, \n     bucket = DeleteCases[bucket, item]; {item}]] &]\n\nThen use this to make a \"bucket\", like this:\nbucket = makeDrippingBucket[{1,2,3,4,5}]\n\nThis object has an internal state that changes every time you call it.  Every time you call bucket[], it will give you a new number, until it gets empty.\nbucket[]\n\n(* ==> {3} *)\n\n\nEDIT\nThe same thing, using @Eli's solution of pre-randomizing the list:\nmakeDrippingBucket[list_] := \n Module[{bucket = RandomSample[list]}, \n  If[bucket === {}, {}, \n    With[{item = Last[bucket]}, bucket = Most[bucket]; {item}]] &]\n\n", "complex - Why doesn't FullSimplify drop the Re function from an expression known to be real?": "\nThe problem is due to Mathematica thinking that the version with the Re[] is actually simpler. This is because the default complexity function is more or less LeafCount[], and \nIn[332]:= ArcTan[-Re[x+z],y]//FullForm\nOut[332]//FullForm= ArcTan[Times[-1,Re[Plus[x,z]]],y]\n\nwhereas\nIn[334]:= ArcTan[-x-z,y]//FullForm\nOut[334]//FullForm= ArcTan[Plus[Times[-1,x],Times[-1,z]],y]\n\nHere is a function that counts leaves without penalizing negation:\nIn[382]:= f3[e_]:=(LeafCount[e]-2Count[e,Times[-1,_],{0,Infinity}])\n{LeafCount[x],LeafCount[-x],f3[x],f3[-x]}\nOut[383]= {1,3,1,1}\n\nIf you tell mathematica to simplify using this complexity function then you get the expected result:\nFullSimplify[ArcTan[-Re[x+z],y],(x|y|z)\\[Element]Reals,ComplexityFunction->f3]\n\n\nOut[375]= ArcTan[-x-z,y]\n\n", "Torn edge paper effect for images": "\nA bit lengthy, but here's my attempt. The parameters in torn are the base image img and an array describing which edges should be torn. This array is of the form {{left, right}, {bottom, top}}, where a 0 corresponds to a straight edge and any non-zero value to a torn edge, so {{0, 0}, {1, 0}} would correspond to an image where only the bottom edge is torn. \nOptions[torn] = {\"amplitude\" -> .04, \"frequency\" -> 50, \"offset\" -> {10, 10}, \n   \"opacity\" -> .7, \"gaussianBlur\" -> 4};\n\ntorn[img_, {{l_, r_}, {b_, t_}}, OptionsPattern[]] := \n Module[{ratio, left, right, bottom, top, poly, img1, shadow, amp, dx, offset},\n  ratio = #2/#1 & @@ ImageDimensions[img];\n  amp = OptionValue[\"amplitude\"] {Min[1/ratio, 1], Min[ratio, 1]};\n  dx = 1/(OptionValue[\"frequency\"] {Min[1/ratio, 1], Min[ratio, 1]});\n  offset = Abs[{##}] UnitStep[{#1 {-1, 1}, #2 {1, -1}}] & @@ OptionValue[\"offset\"];\n\n  left = If[l == 0, {{0, 1}, {0, 0}}, \n   Table[{RandomReal[{0, 1} amp[[2]]], i}, {i, 1 - amp[[2]], dx[[2]], -dx[[2]]}]];\n  right = If[r == 0, {{1, 0}, {1, 1}}, \n   Table[{1 + RandomReal[{-1, 0} amp[[2]]], i}, {i, dx[[2]], 1 - amp[[2]], dx[[2]]}]];\n  bottom = If[b == 0, {{0, 0}, {1, 0}}, \n   Table[{i, RandomReal[{0, 1} amp[[1]]]}, {i, dx[[1]], 1 - amp[[1]], dx[[1]]}]];\n  top = If[t == 0, {{1, 1}, {0, 1}}, \n   Table[{i, 1 + RandomReal[{-1, 0} amp[[1]]]}, {i, 1 - amp[[1]], dx[[1]], -dx[[1]]}]];\n  poly = Join[left, bottom, right, top];\n\n  {img1, shadow} = \n    Image@Graphics[#, ImagePadding -> OptionValue[\"gaussianBlur\"], \n        PlotRangePadding -> None, AspectRatio -> ratio, Background -> None, \n        ImageSize -> ImageDimensions[img] + 2 OptionValue[\"gaussianBlur\"]] & /@\n     {{Texture[img], EdgeForm[Black], Polygon[poly, VertexTextureCoordinates -> poly]}, \n      {Polygon[poly]}};\n  img1 = ImagePad[img1, offset, {1, 1, 1, 0}];\n  shadow = ImagePad[GaussianFilter[shadow, OptionValue[\"gaussianBlur\"]],\n      Reverse /@ offset, {1, 1, 1, 0}];\n  ImageCompose[img1, {shadow, OptionValue[\"opacity\"]}, Center, Center, {1, 1, -1}]]\n\nThere are a number of options which control various image parameters. These are the amplitude of the tears \"amplitude\", the frequency of the jags, \"frequency\", the opacity of the shadow, \"opacity\", and the blurriness of the shadow \"gaussianBlur\". The offset of the shadow towards the lower right corner is controlled by the option \"offset\" which is off the form {right, bottom} where right and bottom are in points. Negative values for right and bottom indicate a shadow pointing towards the left and/or top of the image.\nExample\nimg = ExampleData[{\"TestImage\", \"Mandrill\"}];\ntorn[img, {{0, 1}, {1, 0}}, \"offset\" -> {20, 20}, \"gaussianBlur\" -> 10]\n\n\nEdit\nApparently, under certain circumstances Mathematica doesn't render a transparent background for img1 which results in a white region between the image and the shadow. I managed to reproduce this behaviour in version 8.0.1 for OS X with img = Image@Plot[Sin[x], {x, 0, 2 Pi}], but not in 8.0.4. It seems that setting the ImageSize in Graphics is the culprit. To resolve this issue I replaced {img1, shadow} = Image@Graphics... in torn with\n{img1, shadow} = \n  Rasterize[\n     Graphics[#, ImagePadding -> OptionValue[\"gaussianBlur\"], \n      PlotRangePadding -> None, AspectRatio -> ratio, \n      Background -> None], \n     ImageSize -> ImageDimensions[img] + 2 OptionValue[\"gaussianBlur\"], \n     Background -> None] & /@ \n   {{Texture[img], EdgeForm[Black], Polygon[poly, VertexTextureCoordinates -> poly]}, \n    {Polygon[poly]}};\n\n", "pattern matching - Why doesn't Cases match all instances of XMLElement, given Infinity levelspec?": "\nThe reason your approach fails is because Cases works slightly differently than what you've intended in the question. Cases does a depth-first scanning and once it finds its first match, it transforms it and starts traversing the tree backwards, looking for other matches. Consider this simple example:\nlist = {p[1, 2], q, {p[3, 4], p[5, p[6, 7]]}};\nCases[list, p[a_, b_] :> f[a, b], Infinity]\n(* Out[1]= {f[1, 2], f[3, 4], f[6, 7], f[5, p[6, 7]]} *)\n\nYou can see that all 4 instances of p[_, _] are found by Cases, but the rule replacement is only done to the output before returning \u2014 i.e., the tree is not modified in place \u2014 so when it walks back up a node, it does not see the replacement to the deeper p[_, _] because the tree was never modified. \nThe TreeForm below gives an idea of how the last two matches are handled. The third match is the deepest one, p[6, 7] which returns f[6, 7] and in the second one, the one just above it is matched without modifying the inner p[_, _] (because that's the replacement rule given). \n\n\nThis is exactly the case in your situation, where one XMLElement has another within it.\nOne possible solution is to extract them all first with Cases and then use ReplaceRepeated:\nCases[list, _p, Infinity] //. p[a_, b_] :> f[a, b]\n(* Out[2]= {f[1, 2], f[3, 4], f[6, 7], f[5, f[6, 7]]} *)\n\nSo for the example in the question, it would be:\nCases[Import[\"http://www.weather.gov/data/current_obs/KOAK.xml\",\"XMLObject\"],\nXMLElement, _XMLElement, Infinity] //. XMLElement[tag:_, _, value:_] :> (tag -> value)\n\n\nAs Albert Retey rightly points out (also, thanks to him for the helpful suggestions and corrections), what Cases does with a rule replacement is the same as Cases with no rule, followed by ReplaceAll:\nCases[list, _p, Infinity] /. p[a_, b_] :> f[a, b]\n\nwhereas ReplaceRepeated is what's needed here.\n", "plotting - PieChart with radial coloring/color function": "\nYour wedge function is a good starting point, and with a few small modifications can be used as a custom ChartElementFunction for PieChart.\nwedge[fun_, {minangle_, maxangle_}, colorrange_, divs_: 25] := \n   First[ParametricPlot[\n      {v Cos[u], v Sin[u]}, {u, minangle, maxangle}, {v, 0, 1}, \n      ColorFunction -> (ColorData[{\"Rainbow\", colorrange}][fun[#4]] &), \n      ColorFunctionScaling -> False, Mesh -> False, ImagePadding -> All, \n      BoundaryStyle -> Directive[Thick, Black], Frame -> False, \n      Axes -> False, PlotPoints -> divs, PlotRange -> {-1.2, 1.2}, \n      Background -> Transparent]]\n\nThe main differences are that \n\nwe're using First to extract the main primitives and directives from the plot\nwe've added a divs parameter to allow us to get better resolution of the colors\nwe've removed the text, since we're going to do that differently\n\n(With this approach several of the options (Frame, Axes, etc...) become irrelevant, but I haven't removed them.)\nI then split out the colorbar function, mainly to improve the readability of the code.  I didn't pass the options through, so it probably lost a small amount of control.\ncolorbar[colorFunction_, range_, divs_: 25] := \n   DensityPlot[\n      y, {x, 0, .1}, {y, First@range, Last@range}, \n      AspectRatio -> 10, PlotRangePadding -> 0, PlotPoints -> {2, divs}, \n      MaxRecursion -> 0, FrameTicks -> {None, Automatic, None, None}, \n      ColorFunctionScaling -> False, ColorFunction -> colorFunction]\n\nNow we come to the main SectorPlot.\nSectorPlot[func_List, label_List, colorrange_: {0, 66.7}, \n   opts:OptionsPattern[]] /; Length[func] == Length[label] := \n   Module[{div, size},\n      size = 300;\n      Row[{\n         PieChart[Table[1 -> f, {f, func}], \n            ChartLabels -> Placed[label, \"RadialCallout\", \n               Style[#, Bold, FontFamily -> \"Times\"] &], \n            ChartElementFunction -> (wedge[First[#3], First[#1], colorrange, 50] &), \n            ImageSize -> {Automatic, size}, ImagePadding -> 20], \n         Show[colorbar[ColorData[{\"Rainbow\", colorrange}], colorrange], \n            ImageSize -> {Automatic, size}, ImagePadding -> 20]\n          }]\n       ]\n\nThe main things to note here:\n\nwe use -> to assign the functions as metadata for the (constant-size) sectors\nwe use ChartLabels and Placed for the sector labels, which provides easy access to several built-in label locations\nwhen we call wedge as a ChartElementFunction\n\nFirst[#1] is the angle range for the sector\n#3 contains a list of all metadata for a sector, we extract the function with First\n\n\nHere's the final result:\nSectorPlot[\n   {(60 Sin[4.3 # + 0.3]) &, \n    (50 Sin[12 # + 0.1]) &, \n    (66 Cos[7.3 # + 0.3]) &, \n    (60 Tan[1.2 #]) &, \n    (60 Cos[23.5 # - 0.1]) &}, \n   {\"1\", \"2\", \"3\", \"4\", \"5\"}, \n   {0, 70}]\n\n\n(As a note, really big labels are generally problematic, especially inside Graphics which have a constrained size.)\n", "graphics - Computing the bounding boxes for Text objects": "\nHere a test text. I use a gray background to show how large the bounding box actually is.\nt = Graphics[Text[\"Test\", BaseStyle -> {128}, Background -> Gray]]\n\n\nd = ImageDimensions[ImageCrop[t]];\nGraphics[{\n  FaceForm[], EdgeForm[Red],\n  Text[\"Test\", {0, 0}, {-1, -1}, BaseStyle -> {128}],\n  Rectangle[{0, 0}, Offset[d, {0, 0}]],\n  PointSize[0.05], Point[{0, 0}]\n}]\n\n\nIf you want a closer cut for your bounding box, just remove the Background option and ImageCrop again. However, note that offsets in the Text function are with respect to the bounding box Mathematica uses (indicated by the gray box).\nt = Graphics[Text[\"Test\", BaseStyle -> {128}]];\nd = ImageDimensions[ImageCrop[t]];\nGraphics[{\n  FaceForm[], EdgeForm[Red],\n  Text[\"Test\", {0, 0}, {-.97, -0.6}, BaseStyle -> {128}],\n  Rectangle[{0, 0}, Offset[d, {0, 0}]],\n  PointSize[0.05], Point[{0, 0}]\n}]\n\n\nNote the {-.97, -0.6} offset?\n", "How use Mathematica fonts with LaTeX": "\nThe instructions you mention are rather outdated.\n\nModify wolfram.map to have .pfa instead of .pfb (to reflect the format of the font files) and remove all from Janson Text onwards, as those fonts are not provided.\nCopy wolfram.map to\n/usr/local/texlive/texmf-local/fonts/map/dvips/wolfram/wolfram.map\n\nCopy all subfolders from texmf/fonts (afm/wolfram \u2026) to the corresponding folders in /usr/local/texlive/texmf-local/fonts.\nCopy the directory texmf/tex/latex/wolfram to /usr/local/texlive/texmf-local/tex/latex/wolfram\nCopy texmf/doc/wolfram to /usr/local/texlive/texmf-local/doc/latex/wolfram\nRun mktexlsr so that TeX Live will know about these files\nRun updmap-sys --enable Map=wolfram.map\nEnjoy\n\nAll steps from 2 to 7 should be done as Administrator (prefix the commands with sudo, typing the Administrator's password when requested)\nNote that the 7z archive linked to in the blog article seems to be corrupt, while the .zip file is good.\n\nUpdate\nFrom TeX Live 2013 onwards, it's better to add the line\nMap wolfram.map\n\nto the file\n/usr/local/texlive/texmf-local/web2c/updmap.cfg\n\n(also requires Administrator privileges) and subsequently run\nupdmap-sys\n\nwithout options. This replaces step 7 above.\n", "How to match a sequence of complex patterns?": "\nWe needn't use Map and Apply as in ziyuang's answer. We can make use of PatternSequence with Repeated (..) or RepeatedNull (...) instead, e.g.\nlist = {{a1, b1} -> {x1, y1}, {} -> {x3, y3}, {a2, b2} -> {x1, y2}, \n        {} -> {x6, y6}, {} -> {x5, y5}, {} -> {x0, y0}, {a3, b3} -> {x3, y3}, \n        {a4, b4} -> {x4, y4}};\n\nNow we can test various approaches :\n{ MatchQ[ #, { PatternSequence[{___} -> {_, _}] ..}]& @ list, \n  MatchQ[ #, {({PatternSequence[]} | {_, _} -> {_, _}) ..}]& @ list,\n  MatchQ[ #, {({PatternSequence[___]} -> {_, _}) ..}]& @ list }\n\n\n{True, True, True}\n\n\nThe advantage of PatternSequence is seen when we'd like to deal with more sophisticated cases of pattern matching.\n", "data structures - Short syntax for accessing System`Utilities`HashTableAdd and System`Utilities`HashTableGet": "\nIf you're willing to use a slightly different syntax to invoke System`Utilities`HashTableAdd, you can create your own wrapper around System`Utilities`HashTable that does most of what you want without modifying any built-in functions. The loss of the convenient hashTable.key = value syntax is unfortunately necessary because you can't use TagSet to set a tag more than one level deep in an expression, but personally I think that the postfix form hashTable.key.set[value] isn't much worse. Edit: by introducing a wrapper symbol specifically for this functionality it is also possible to overload Dot reasonably safely and enable the use of infix form as per the question (see below).\nHere's the code:\nClearAll[hashTableWrapper];\n\n(* Create new hash table *)\nhashTableWrapper /: new[hashTableWrapper] :=\n  hashTableWrapper@System`Utilities`HashTable[];\n\n(* Check existence of a key *)\nhashTableWrapper /: Dot[\n   hashTableWrapper[h_System`Utilities`HashTable], key_, existsQ[]\n  ] := System`Utilities`HashTableContainsQ[h, Unevaluated[key]];\n\n(* Clear key value/delete key *)\nhashTableWrapper /: Dot[\n   hashTableWrapper[h_System`Utilities`HashTable], key_, clear[]\n  ] /; System`Utilities`HashTableContainsQ[h, Unevaluated[key]] :=\n  System`Utilities`HashTableRemove[h, Unevaluated[key]];\n\n(* Nonexistent keys can't be cleared, but let's not complain *)\nhashTableWrapper /: Dot[\n   hashTableWrapper[h_System`Utilities`HashTable], key_, clear[]\n  ] = Null;\n\n(* Set key value (clearing first if necessary) *)\nClearAll[set]; SetAttributes[set, SequenceHold];\nhashTableWrapper /: Dot[\n   w : hashTableWrapper[h_System`Utilities`HashTable], key_, set[val___]\n  ] := (\n   w.Unevaluated[key].clear[];\n   System`Utilities`HashTableAdd[h, Unevaluated[key], Unevaluated[val]];\n   val\n );\n\n(* Set delayed key value (again, clearing first if necessary) *)\nClearAll[setDelayed]; SetAttributes[setDelayed, {HoldAll, SequenceHold}];\nhashTableWrapper /: Dot[\n   w : hashTableWrapper[h_System`Utilities`HashTable], key_, setDelayed[val___]\n  ] := (\n   w.Unevaluated[key].clear[];\n   System`Utilities`HashTableAdd[h, Unevaluated[key], Unevaluated[val]]\n );\n\n(* Get key value *)\nhashTableWrapper /: Dot[\n   hashTableWrapper[h_System`Utilities`HashTable], key_, optional : get[] : get[]\n  ] /; System`Utilities`HashTableContainsQ[h, Unevaluated[key]] :=\n  System`Utilities`HashTableGet[h, Unevaluated[key]];\n\n(* Deal with query of nonexistent key *)\nhashTableWrapper /: Dot[\n   hashTableWrapper[h_System`Utilities`HashTable], key_, optional : get[] : get[]\n  ] = $Failed;\n\nAs a demonstration, let's say we find ourselves forgetting what 1 + 1 is and want to store it in a hash table. And perhaps we want to store the inverse of this operation as well. (These contrived examples help to demonstrate usage with unevaluated expressions for both the key and the value.)\nhash = new[hashTableWrapper];\nhash.Unevaluated[1 + 1].set[2];\nhash.(2).setDelayed[Print[\"the value was evaluated\"]; 1 + 1];\n\nAs this example shows, the key is evaluated unless otherwise specified using Unevaluated. (The parentheses in hash.(2).set[...] are necessary as otherwise this will be interpreted as a multiplication: 0.2 hash set[...].) Now we can write:\nhash.Unevaluated[1 + 1].get[]\n\nor simply (since get[] is an optional argument)\nhash.Unevaluated[1 + 1]\n\nand get back 2. Similarly, if we write hash.(2).get[] or hash.(2), \"the value was evaluated\" is printed and the unevaluated value 1 + 1 is evaluated to return 2.\nMaybe we think that the second definition isn't very useful since it'll be evaluated every time. So, we redefine it:\nhash.(2).set@Unevaluated[1 + 1];\n\nwhich clears the previous definition automatically. (Printing \"the value was evaluated\" in the process. This is the result of System`Utilities`HashTableRemove's own behaviour which is to return the value associated with the key that was removed, if any.) Now hash.(2) will give, more usefully, Unevaluated[1 + 1].\nFinally we come to our senses and decide to get rid of these trivial hash table entries. Again, because this calls System`Utilities`HashTableRemove, the values of the keys to be cleared are returned:\nhash.Unevaluated[1 + 1].clear[]\n\n\n2\n\n\nand\nhash.(2).clear[]\n\n\nUnevaluated[1 + 1]\n\n\nSystem`Utilities`HashTableRemove throws an error if invoked on a nonexistent key, but clearing such in this way simply does nothing, returning Null, as I thought this behaviour was more useful. However, an attempt to read undefined keys still fails:\nhash.undefined\n\n\n$Failed\n\n\nIncidentally, you can have keys containing Dot without any problems, thanks to Dot's attributes Flat and OneIdentity. This one contains Dot in two different ways:\nhash.this.is.a.key.containing.Dot.set[\"hello\"];\nhash.this.is.a.key.containing.Dot\n\n\n\"hello\"\n\n\nEdit: implementing infix syntax for Set\nLeonid makes a point very well here regarding overloading Set, which actually applies to any built-in function. When overloading any built-in, one has to ask oneself:\n\nIf two people did this at the same time, without being aware of each other, could it result in a conflict?\n\nObviously, the only acceptable overloads are those for which we can answer, \"No\". In practice this usually means creating an \"environment\" using Internal`InheritedBlock within which different semantics apply, introducing one's own symbols that are not likely to conflict with anyone else's (or even, using Module, ones that are unable in principle to cause a conflict), and writing definitions carefully so that the scope is tightly constrained and no evaluation leaks are introduced. In this spirit, here is my suggestion for how to implement, by means of the code above, the hashTable.key = value syntax (and SetDelayed and Unset at the same time, why not):\nClearAll[withHashTableSetSemantics];\nwithHashTableSetSemantics[expr_] :=\n  Internal`InheritedBlock[{Dot},\n   Unprotect[Dot];\n   Dot /: Set[Dot[w_, key_], val_] /; Head[w] === hashTableWrapper :=\n    w.Unevaluated[key].set[val];\n   Dot /: SetDelayed[Dot[w_, key_], val_] /; Head[w] === hashTableWrapper :=\n    w.Unevaluated[key].setDelayed[val];\n   Dot /: Unset@Dot[w_, key_] /; Head[w] === hashTableWrapper :=\n    w.Unevaluated[key].clear[];\n   Protect[Dot];\n   expr\n  ];\nSetAttributes[withHashTableSetSemantics, HoldAll];\n\nBe aware, however, that although the semantics are close to those of Set, SetDelayed, and Unset, they aren't exactly the same because of the implementation in terms of the hash table functions themselves. Nor are they exactly the same as for the postfix form: for example, while one can write e.g. hash.(2).set@Unevaluated[1 + 1] to set an unevaluated value, the equivalent in the infix form requires two applications of Unevaluated, i.e. hash.(2) = Unevaluated@Unevaluated[1 + 1] (which is consistent with Set itself).\nIf, in a session, one wishes for these semantics to apply over a number of evaluations, a good way to propagate the environment is to set $Pre = withHashTableSetSemantics. This way, no global settings are modified, and the environment can be disabled again if it causes problems or when no longer needed by Unseting $Pre.\n", "Make EventHandler work for clicks and keys in a Dynamic display": "\nTry using NotebookEventActions\ndisplaying = True;\n\nSetOptions[EvaluationNotebook[], \n NotebookEventActions :> {\"UpArrowKeyDown\" :> (If[! displaying, \n      Print[\"up press\"]]), \n   \"DownArrowKeyDown\" :> (If[! displaying, Print[\"down press\"]]), \n   \"MouseClicked\" :> (If[displaying, displaying = False])}]\n\n", "syntax - How do you set an Optional parameter with a global variable on a Function defined in a Package": "\nYou'll have to point to the global variable using its full context path as Global`IndexLoopPlot. Otherwise, the optional variable will be interpreted as YourPackage`IndexLoopPlot. The following example shows how:\nQuiet@Remove[a, \"test`*\"];\nBeginPackage[\"test`\"];\nf[x_: Global`a] := {x}\nEndPackage[];\n\n\n", "equation solving - Find roots of polynomial in field extension $GF(2^n)$?": "\nWell, for your example $p(x)=x^8 + x^7 + x^5 + x^3 +1$, the associated extension $GF(2^n)\\cong \\frac{GF(2)[x]}{\\langle p(x) \\rangle}$ is a vector space over $GF(2)$ of dimension $8$.  The elements of this field can be written as polynomials $a_0+a_1x+\\ldots +a_7x^8$ for $a_i\\in GF(2)$.  By quotienting we've insisted that $p(x)=0$, so the multiplication between these elements defined by first multiplying the polynomials as usual (taking addition modulo 2), then reducing by $p(x)$.   For example, $(x^2+x^4+x^6+x^7)x=1$.\nA quick and dirty Mathematica mockup to implement this is\nmodpoly[p_] := Module[{J},\n  J = Mod[#, 2] & /@ CoefficientList[p, x];\n  Total[Table[J[[i]] x^(i - 1), {i, 1, Length[J]}]]\n  ]\nmultiply[p_, q_] := Module[{K},\n  modpoly[\n   PolynomialMod[modpoly[Expand[p q]], x^8 + x^7 + x^5 + x^3 + 1]]\n  ]\n\nwhich yields, for example,\nmultiply[x^2 + x^5 + x^6, x + x^6 + x^7]\n\n> 1 + x + x^2 + x^5\n\n", "manipulate - How To interactively create a Polygon in a Graphic?": "\nThis isn't exactly what you asked for, but it might do the trick. This solution allows you to create a number of different shapes (circle, polygon, line, Bezier curve, etc.). To add a shape, press the \"New object\" button. You can add points to an existing shape by clicking anywhere in the plane. \nNote that I'm using LocatorAutoCreate -> All instead of True which means that you don't need a modifier key to add points. Deleting locators is the same as with LocatorAutoCreate -> True. \nYou can edit an existing object by pressing the \"Edit object\" button and choosing the right object. The \"Print shapes\" button prints a list of the shapes where each shape is represented by a list of coordinates and a string indicating the type.\nDynamicModule[{types, fun},\n types = {\"Circle\", \"Disk\", \"Polygon\", \"Line\", \"Bezier\", \"Spline\"};\n fun[{}, ___] := {};\n fun[{a_}, ___] := {};\n fun[pts_, type_] := Switch[type,\n   \"Circle\", Circle[pts[[1]], Norm[pts[[2]] - pts[[1]]]],\n   \"Disk\", Disk[pts[[1]], Norm[pts[[2]] - pts[[1]]]],\n   \"Polygon\", {EdgeForm[Black], FaceForm[Opacity[.5]], Polygon[pts]},\n   \"Line\", Line[pts],\n   \"Bezier\", BezierCurve[pts],\n   \"Spline\", BSplineCurve[pts]];\n\n Manipulate[\n  ptlst[[object]] = pts;\n  typelst[[object]] = type;\n  grlst = MapThread[fun, {ptlst, typelst}];\n  Graphics[grlst, PlotRange -> {{-3, 3}, {-3, 3}}],\n\n  {{pts, {}}, Locator, LocatorAutoCreate -> All},\n  {{ptlst, {{}}}, None},\n  {{typelst, {\"Line\"}}, None},\n  {{object, 1}, None},\n  {grlst, None},\n  {{type, \"Line\", \"Object type\"}, types},\n  Row[{Button[\"New object\",\n     If[Length[ptlst[[-1]]] > 0,\n      AppendTo[ptlst, {}]; AppendTo[typelst, type];\n      object = Length[typelst];\n      pts = {}]],\n    Dynamic@PopupView[Graphics[#, ImageSize -> 50] & /@ grlst,\n      Dynamic[object, (object = #; pts = ptlst[[#]]; type = typelst[[#]]) &],\n       Button[\"Edit object\"]],\n    Button[\"Print shapes\", Print[Transpose[{ptlst, typelst}]]]}]\n  ]]\n\n\n", "Solving inequalities for positive Integers": "\nReduce allows you to specify the domain of Reals, Complexes, or Integers as the third parameter. But, positivity is not directly specifiable at that point. Instead, it must be added to the expr being reduced as an added condition. A simple form of this condition would be\n And @@ Thread[all > 0]\n\nwhich is equivalent to \n\na > 0 && b > 0 && c > 0 && d > 0 && e > 0\n\n\nCombining this with the Integers domain gives this form for Reduce:\nReduce[# >= 0 && And @@ Thread[all > 0], all, Integers] &\n\nAs a word of caution, this will result in a very, very large output as Reduce uses GeneratedParameters for its unknown integer coefficients. For the second inequality, this results in 34 unknown coefficients.\n", "pattern matching - Splitting a list in which figures vary from negative to positive": "\nTry \nSplit[data, Not[#2>0 && #1<0] &]\n\nNote that Split[list, test] splits list between two elements when test fails. In this case you want to to split the list iff #2>0 && #1<0 &[e1, e2] == True which is equivalent to Not[#2>0 && #1<0]&[e1, e2] == False.\n", "visualization - How can I visualize features found in an image?": "\nShow can combine Image and Graphics:\na = ExampleData[{\"AerialImage\", \"Oakland2\"}];\nb = Graphics[{Red, Thick, Circle[{400, 400}, 300]}];\nShow[a, b]\n\n\nIn this way you can do it in a programmatic way. But you can also do this manually and interactively via right-click menu access to Drawing Tools:\n\n\n", "export - How to convert a 2D image into a 3D graphics?": "\nThis maybe helpful if you want to convert image structure into 2D/3D line primitives, MorphologicalGraph does some astonishing things out of the box:\nimg = Import[\n   \"https://upload.wikimedia.org/wikipedia/commons/c/ce/Spinnennetz_\\\nim_Gegenlicht.jpg\"];\n\n\ng = MorphologicalGraph[img // MorphologicalBinarize, \n   VertexCoordinates -> Automatic, EdgeWeight -> Automatic];\n\nedges = EdgeList[g];\n\nextracting the actual connections can be done like this (although more streamlined solutions would be welcome):\nvertices = \n  Thread[Rule[VertexList[g], PropertyValue[g, VertexCoordinates]]];\n\nlines = ((edges /. vertices) /. \n    UndirectedEdge[a_, b_] :> Line[{a, b}]);\n\nGraphics[lines]\n\n\nor with a 3D touch:\nGraphics3D[\n Tube[#] & /@ (lines /. {x_?NumericQ, y_?NumericQ} :> {x, 0, y})]\n\n\nAfter that, you can choose your preferred 2D/3D vector format for Export.\n", "symbolic - Why does this sum not simplify properly?": "\nBefore I answer your question, I would like to share some results. Since there was no guarantee that the Christoffel\u2013Darboux formula would be invariant under such a change of variables, I did a simple check:\nIn[25]:= Sum[(HermiteH[k, -x] HermiteH[k, y])/(2^k k!), {k, 0, 3}]\n\nOut[25]= 1 - 2 x y + 1/8 (-2 + 4 x^2) (-2 + 4 y^2) \n       + 1/48 (12 x - 8 x^3) (-12 y + 8 y^3)\n\nIn[26]:= Sum[(HermiteH[k, x] HermiteH[k, y])/(2^k k!), \n             {k, 0,n}] /. {x -> -x, n -> 3}\n\nOut[26]= ((12 - 48 x^2 + 16 x^4) (-12 y + 8 y^3) - (12 x - \n8 x^3) (12 - 48 y^2 + 16 y^4))/(96 (-x - y))\n\nIn[34]:= (-1/96)(PolynomialReduce[Numerator@%26, {x + y}, {x, y}])[[1, 1]] \n        == %25 // Expand\n\nOut[34]= True\n\nAnd, it works at higher values of n, also. Similarly,\nIn[39]:= Sum[(HermiteH[k, -x] HermiteH[k, y])/(2^k k!), {k, 0, n}];\n         (% /. n -> 3) == %25 // Expand\n\nOut[40]= True\n\nThis leads me to believe that the answer you're given is absolutely correct, just not in its simplest form.\nAs to why Mathematica does not recognize the simplification, the answer is simply because it does not know everything, and while such a variable transformation seems easy to us, it is not necessarily straightforward to program. \nEdit: Sum behaves this way because the form \nSum[(HermiteH[k, x] HermiteH[k, y])/(2^k k!), {k, 0,n}]\n\nis recognized and the substitution can be made immediately. To allow for the more complex simplification that you wish, we need to create a custom rule for it, as follows\nUnprotect[Sum]\nSum[(HermiteH[k_, x_] HermiteH[k_, y_])/(2^k_ (k_)!), {k_, 0, n_}] := \n (2^(-1 - n) (HermiteH[n, y] HermiteH[1 + n, x] \n  - HermiteH[n, x] HermiteH[1 + n, y]))/((x - y) n!)\nProtect[Sum]\n\nwhich when used with \nSum[(HermiteH[k, -x] HermiteH[k, y])/(2^k k!), {k, 0, n}]\n\ngives the desired result.  \nA couple of words of caution, though. This is deliberately overriding the built-in behavior of Sum and may affect its behavior in uncertain ways. So, if you decide to take this route, make the substitutions as specific as possible, so that you do not run into unintended behavior.\n", "implementation details - How does Interpolation really work?": "\nInterpolation function methods\nInterpolation supports two methods:\n\nHermite interpolation (default, or Method->\"Hermite\")\nB-spline interpolation (Method->\"Spline\")\n\nHermite method\nI really can't find any good reference to Hermite method within Mathematica's documentation. Instead, I recommend you to take a look at this Wikipedia article.\nThe benefits of Hermite interpolation are:\n\nYou can compute them locally at the time of evaluation. No global system solving required. So construction time is shorter, and the resulting InterpolatingFunction is smaller.\nMulti-level derivatives can be specified at each point.\n\nOne problem is that the resulting function is not continuously differentiable ($C^1$ or higher), even if InterpolationOrder->2 or higher is used. See the following example:\n\nSpline method\nTo be specific, we are using B-spline interpolation with certain knot configuration--depending on the distribution of sample points. I could not find a good web source to describe the method (the Wikipedia article is not great). Although, you can find a step-by-step description of the method in 1D case within Mathematica's documentation (BSplineCurve documentation, Applications -> Interpolation section). Multi-dimension is simply tensor product version.\nThe benefits:\n\nInterpolationOrder->d always guarantees a smooth function of $C^{d-1}$ class.\n\nEvaluation/derivative computation is very fast.\nYou can take BSplineFunction out of the resulting InterpolatingFunction (it's the 4th part), which is compatible with BSplineCurve and BSplineSurface for fast rendering.\n\nThe problems (of current implementation in V8):\n\nIt is machine precision only--although, it is not hard to implement it manually for arbitrary precision using BSplineBasis.\nIt does not support derivative specification.\nInitially it solves global linear system and store the result. So the resulting function is much larger than Hermite method (this is not implementation problem).\n\nOther functions\nSome plot functions such as ListPlot3D have their own methods. Sometimes they call the B-spline method, sometimes they use a method based on distance field (for unorganized points), etc. But probably it is not useful here since they are only supported as a visual measure.\n", "programming - Is there a Mathematica/Lisp link?": "\nHave a look at SchemeLink.\n", "dynamic - How to add several Locators to a Graphic with a mouse click?": "\nHere are two possible solutions. In both cases, one click brings locators up, another click will make them disappear.\nSolution 1\nUsing multiple dynamic locators. The Map (or /@) is needed, since Dynamic inside Locator should have evaluated part number for pts.\nDynamicModule[{pts = {{0, 0}, {0, 1}, {1, 0}}, locs = {}}, \n Graphics[{EventHandler[\n    Polygon[Dynamic[\n      pts]], {\"MouseClicked\" :> (locs = \n        If[locs === {}, \n         Locator[Dynamic[pts[[#]]]] & /@ Range[Length[pts]], {}])}], \n   Dynamic[locs]}, PlotRange -> 1, PlotRangePadding -> Scaled[.05]]]\n\nA slightly weird behavior of locators (washed out color when it appears first)... which I don't know why.\nSolution 2\nUsing LocatorPane. Simpler, but Dynamic needs to refresh both locPts and pts when locs is assigned (Dynamic[expr, f] syntax).\nDynamicModule[{pts = {{0, 0}, {0, 1}, {1, 0}}, locPts = {}},\n LocatorPane[Dynamic[locPts, (If[locPts =!= {}, pts = locPts = #]) &], \n  Graphics[{EventHandler[\n     Polygon[Dynamic[\n       pts]], {\"MouseClicked\" :> (locPts = If[locPts === {}, pts, {}])}]},\n    PlotRange -> 1, PlotRangePadding -> Scaled[.05]]]]\n\n", "gui construction - How to make a dynamic stopwatch?": "\nHere's my first stab at a solution based on the idea of a closure. Maybe it has some elements that you can draw on for inspiration.\nFunction to create a timer function\nmakeTimer[] := Module[{start = AbsoluteTime[]}, Switch[#,\n    \"now\", AbsoluteTime[] - start,\n    \"lap\", AbsoluteTime[] - start,\n    \"reset\", (start = AbsoluteTime[]; 0)]\n   &]\n\nTimers can now be created with timer = makeTimer[] and utilised with actions such as timer[\"lap\"] to get the current lap time. Timers are quiescent unless asked to do something.\nYou could extend this to handle a pause function if that's required.\nTimer with buttons\nCreate a timer and some buttons to access it, associate the timer with a dynamic variable time.\nGrid[{{Button[\"Start\", timer = makeTimer[]; time = 0]}, \n      {Button[\"Lap\",   time = timer[\"lap\"]]}, \n      {Button[\"Reset\", time = timer[\"reset\"]]}, \n      {Button[Dynamic[time]]}}]\n\nSchedule a task to update the timer/clock\nCreate a scheduled task to run every 2 seconds to update the displayed elapsed time or clock.\nRunScheduledTask[time = timer[\"now\"], 2]\n\nScheduled tasks can be removed thus:\nRemoveScheduledTask[ScheduledTasks[]]\n\n", "Collaboration on Mathematica Work": "\nI'm just going to address the second part of your question about licences. Incidentally, I will say that this having been moved to Meta has provided an incentive for me to answer, since it's appropriate here to give personal views and opinions, whereas on Main it's not.\nProbably by far the best known licence for open source work is the GNU GPL, and the fact that it's so well-known undoubtedly contributes to its continuing popularity. However, I consider this unfortunate in some ways, because of its (quite deliberate) almost total incompatibility with any other licence and expansive definitions of \"linking\" and \"combined works\".\nFor example, if one program produces any output (e.g., a file on disk) that another program reads and processes in an automated way, these programs are considered linked for the purposes of the GPL. Obviously, this is highly divergent from the ordinary concept of linking in software engineering (which is precisely the LGPL's reason for being, in that it reflects the typical meaning rather than this broader sense). Furthermore, if these two programs are distributed together in a non-incidental way (which by itself results in them constituting a \"combined work\"), if either one of them is licensed under the GPL, then the combined work must be also.\nThe net effect of these factors is to render the GPL highly inconvenient to use for any project that incorporates, even indirectly, commercial/closed-source (\"proprietary\") code; this certainly applies to Mathematica, for which the interpreter, runtime environment, and standard library all form part of a closed-source commercial product that is implicitly required by all Mathematica-language code. In my opinion, the fact that WRI asserts that the language itself is proprietary also calls into question whether the GPL can be applicable to any Mathematica project due to its absolute exclusivity toward other licences. The LGPL doesn't really help us here except if we limit ourselves to distributing LibraryLink programs (in source form only, as the LibraryLink headers aren't GPL-compatible). Mathematica does incorporate some libraries licensed under the LGPL--for example, GMP--but this is of little consequence to us as users seeking to distribute our own code. The legal issues are overall so problematic that personally I would be willing to contribute code to any GPL or LGPL-licensed Mathematica project only in the narrowest of circumstances.\nSo, having argued that we shouldn't use the GPL or LGPL if we wish to avoid making things unduly difficult for ourselves and other contributors to our projects, what options are still open to us? For this I think the OSSCC's licence list is a very useful resource. Their suggestions are:\n\nIf you want a licence with strong copyleft provisions, choose the CDDL\nIf you want a permissive licence, use the Apache License 2.0\n\nOf these, I would personally prefer the latter, but I think the choice between copyleft and permissive is mainly guided by one's own political views, so legitimate disagreement is possible.\nOne caveat: the Apache License is long, and this level of legal detail might put some potential contributors (or even users) off. The main difference between the Apache License and the much shorter MIT License or New (2-clause) BSD License is that the former requires contributors to grant a licence to any patent rights they may have in their contributions, so as to avoid patent trolling. Where this is not an issue--for example, in code you've written yourself and just want to distribute to the community--I would probably prefer to use one of the shorter permissive licences as a matter of convenience.\nEdit\nSjoerd asks:\n\nWhat about SE's license?\n\nIn my opinion, while generally appropriate for the site, this is also highly problematic as far as software packages are concerned. The Creative Commons Attribution-ShareAlike 3.0 licence is a copyleft licence intended for literary and artistic works, not computer code, and as a result makes the assumptions that:\n\nLicensed works have a single Original Author, and that if adaptations are made then it is practical to credit or not credit each of the contributors in relation to their contributions according to their wishes. For software with multiple contributors who each build on each other's contributions, it can become impossible after a number of revisions have been made to determine who is the legitimate Original Author for each aspect of the project (however \"aspect\" should be defined). This is in fact the central problem of the original (3-clause) BSD License, which prompted the creation of the New BSD License by removing the \"endorsement\" clause.\nThe qualitative nature of a licensed work is not substantially changed by any adaptations. For example, while it would certainly violate the spirit of the licence, it's somewhat unclear whether it would be technically admissible to take a work licensed under CC-by-SA 3.0 and \"adapt\" it as part of a machine-locked, Encoded commercial package, provided that the latter (now rather meaninglessly) adopted the same licence. As copyleft is of little value for software without availability guarantees for the source code, the appropriateness of this licence is called into question.\nThe licensed work is purely artistic, not the embodiment of an invention, and therefore patents cannot apply to it. This leaves open the possibility of patent trolling.\n\nOther miscellaneous problems in attempting to interpret the CC-by-SA 3.0 licence in the context of computer code also arise from the fact that the licence is clearly not intended for this purpose. Therefore, my suggestion would be not to use it for software packages, and if you want to use code presented on this site in a package, to contact the author and ask whether they'll grant you a licence under alternative terms more suitable for the purpose. (I added a notice to my profile specifying my licensing terms; perhaps it would be helpful if others did the same.)\n", "dynamic - Locking a value when Manipulating variables": "\nWell, I have needed before to link variables within a manipulate object, and I always get complicated dynamic things, for your example if you want to add constraints to your variables, you could come up with something like this:\nModule[{spaces, boxes, lastboxes, lastspaces, condition, solvebox, \n  solvespace},\n condition[s_, b_] := 4 s + 3 b == 640;\n solvebox[s_] := b /. First[Solve[condition[s, b], b]];\n solvespace[b_] := s /. First[Solve[condition[s, b], s]];\n lastboxes = 100;\n lastspaces = solvespace[lastboxes];\n Manipulate[{spaces, boxes}, \n  Control[{{boxes, lastboxes, \"Boxes\"}, 0, 640}], \n  Control[{{spaces, lastspaces, \"Spaces\"}, 0, 640}], \n  Dynamic[If[! condition[spaces, boxes], \n    If[lastboxes === boxes, \n      With[{newbox = solvebox[spaces]}, \n       If[newbox < 0, spaces = solvespace[boxes], lastboxes = boxes; \n        boxes = solvebox[spaces]]], \n      With[{newspaces = solvespace[boxes]}, \n       If[newspaces < 0, boxes = lastboxes, lastboxes = boxes; \n        spaces = newspaces]]];]; \"\"], ControlPlacement -> Left, \n  Deployed -> True]\n ]\n\nThat Dynamic after Control objects comes pretty good to do that stuff, but does your code become bigger.\n", "import - How to test if file exists and stop": "\nYou might consider using Messages instead of Print.  You should also consider using TrueQ if either root or filename might not be a string.\nfile::nodir = \"Directory `1` does not exist.\";\nfile::nofile = \"File `1` does not exist.\";\n\nIf[! TrueQ @ DirectoryQ @ root, Message[file::nodir, root]; Abort[]];\nIf[! TrueQ @ FileExistsQ @ filename, Message[file::nofile, filename]; Abort[]];\n\n", "How to extract edgeweights from a graph": "\nYou can still use WeightedAdjacencyMatrix and massage the output to a nicer form \u2014\ng = Graph[{1 <-> 2, 2 <-> 3, 3 <-> 1}, EdgeWeight -> {2, 3, 4}];\nReplace[Most@ArrayRules@UpperTriangularize@WeightedAdjacencyMatrix[g], \n    {x_, y_} :> UndirectedEdge[x, y], {2}]\n\n\n", "Export animation of a Manipulate autorun sequence?": "\nUPDATE: I recently wrote a related post:\nShowcasing Manipulate[\u2026] via .GIF animations\nOLDER: It is already automated. You can just Exportthe Manipulate output to get your movie:\nm=Manipulate[Plot[Sin[a x + b], {x, -3, 3}], {a, 1, 10}, {b, -3, 3}]\nExport[\"MyAutorun.avi\", m]\n\nThis tutorial discuss it. Here is the summary:\n\nBy default Export will generate an animation by running the Manipulate through one Autorun cycle\nWhen a Manipulate output containing explicit bookmarks is exported to a video animation format using Export, the resulting video will be one cycle through the sequence generated by Animate Bookmarks.\n\n", "pattern matching - How can I mix the behaviors of StringReplace and ReplaceAll in a single rule?": "\nThe following works:\nlist /. {ys_String, p_} :> {StringReplace[ys, \n    y : NumberString ~~ __ ~~ m : NumberString ~~ __ :> y <> \"+\" <> m <> \"/12\"], p} // \n        ToExpression//N\n\n(* Out[1]= {{65.25, 75.}, {65.3333, 75.1}} *)\n\nThe reason your construct failed is because the replacement rule, y+m/12 is not a string (you're performing additions and divisions on strings...). The following example makes it clear as to the difference:\nStringReplace[\"abc\", \"a\" -> \"x + y\"]\n(* Out[1]= \"x + ybc\" *)\n\nStringReplace[\"abc\", \"a\" -> \"x\" + \"y\"]\n(* Out[2]= \"x\" + \"y\" ~~ \"bc\" *)\n\n~~ is otherwise known as StringExpression.\n", "export - How to save animation in mp4 format instead of avi?": "\nEdit 2\nStrictly speaking, the answer to the question \"How to save animation in mp4 format\" is simply this:\nExport[\"MyAutorun3.mov\", m, \"VideoEncoding\" -> \"MPEG-4 Video\"]\n\nI'm adding this for completeness. The .mov file contains an MPEG-4 encoded video, whereas the default with Mathematica is Cinepak. The reason why we have to jump through additional hoops is that this  output file doesn't appear to work with the flash-based video players that ship with media9. \nEdited: use Quicktime Player instead of ffmpeg\nOn Mac OS X, there's an easier alternative to ffmpeg to create a movie that works with media9. It requires no additional software. \nFirst use the example from this post\nm=Manipulate[Plot[Sin[a x + b], {x, -3, 3}], {a, 1, 10}, {b, -3, 3}]\n\nExport as Quicktime, as F'x also suggested:\nExport[\"MyAutorun.mov\", m]\n\nOpen this movie in Quicktime Player (built-in on Mac) and choose File > Export ... with format 480p. The newly created movie (let's call it MyAutorun2.mov) can be incorporated in your $\\LaTeX$ file, as in this example:\n\\documentclass{article}\n\\usepackage[english]{babel}\n\\usepackage{media9}\n\n\\begin{document}\n\n\\includemedia[\n  activate=pageopen,\n  width=200pt,height=170pt,\n  addresource=MyAutorun2.mov,\n  flashvars={%\nsrc=MyAutorun2.mov\n&scaleMode=stretch}\n]{}{StrobeMediaPlayback.swf}\n\\end{document}\n\nYou could also export the Manipulate as SWF,\nExport[\"MyAutorun.swf\", m]\n\nFlash seems to do everything mp4 would do in your case: it's small and can be embedded in PDF for Adobe Reader using the movie15 or media9 packages. \nTo understand possible errors you may be seeing, I'll be more specific in describing what works for me:\nNow create a $\\TeX$ file with the contents\n\\documentclass{article}\n\\usepackage{media9}\n\\usepackage[english]{babel}\n\n\\begin{document}\n\\includemedia[\n  activate=pageopen,\n  width=393pt,height=334pt\n]{}{MyAutorun.swf}\n\\end{document}\n\nThe result displays and runs for me in Adobe Reader X 10.1.2 on Mac OS X Lion. I think swf is the easiest way to get movies from Mathematica to PDF. Everything else requires some detour.\nThe disadvantage of directly embedding Mathematica's SWF export into the PDF is that there are no actually useable playback controls. For that, the video player solution is needed. So here is how that works for me:\nWith an exported 'mov`, run the following:\nffmpeg -i MyAutorun.mov -s 540x360 -vcodec libx264 MyAutorun.mp4\n\nWhat I added here is an explicitly even pair of numbers as the frame size, and the codec info. Hopefully, this will help prevent the errors you're seeing.\nFinally, I embed the resulting mp4 file with this $\\LaTeX$ source:\n\\documentclass{article}\n\\usepackage[english]{babel}\n\\usepackage{media9}\n\n\\begin{document}\n\n\\includemedia[\n  activate=pageopen,\n  width=200pt,height=170pt,\n  addresource=MyAutoRun.mp4,\n  flashvars={%\nsrc=MyAutoRun.mp4\n&scaleMode=stretch}\n]{}{StrobeMediaPlayback.swf}\n\\end{document}\n\nI didn't worry about reproducing the aspect ratio of the movie correctly here. The main thing is of course that your ffmpeg sizes should be big enough to avoid a blurry image for the desired player width. This worked for me. \n", "A question about transforming one List into two Lists with additional requirements": "\nAssuming valid data, I think this does what you need:\nvalid = {{1, 2}, {1, 3}, {{1, 0}, {0, 1}}, {1, 2}}\n\na={};\nb=valid/.{x:List[_?NumericQ,_?NumericQ]:>(Position[a,x]/.{}:>{{Length[AppendTo[a,x]]}})[[1,1]]};\na\nb\n\n", "plotting - Visualizing a Complex Vector Field near Poles": "\nHere are two suggestions for the function\nf[z_] := 1/z;\n\nFirst, instead of defining a region to omit from your plot, you should base the omission criterion on the length of the vectors (so that you don't have to adjust the criterion manually when switching to a function with different pole locations). That can be achieved like this:\nWith[{maximumModulus = 10},\n VectorPlot[{Re[f[x + I*y]], Im[f[x + I*y]]}, {x, -1.5, 1.5}, {y, -1, \n   1}, VectorPoints -> Fine, \n  VectorScale -> {Automatic, Automatic, \n    If[#5 > maximumModulus, 0, #5] &}]\n ]\n\n\nThe main thing here is that as the third element of the VectorScale option I provided a function that takes the 5th argument (which is the norm of the vector field) and outputs a nonzero vector scale only when the field is smaller than the cutoff value maximumModulus.\nAnother possibility is to encode the modulus not in the vector length at all, but in the color of the arrows:\nVectorPlot[{Re[f[x + I*y]], Im[f[x + I*y]]}, {x, -1.5, 1.5}, {y, -1, \n  1}, VectorPoints -> Fine, \n VectorScale -> {Automatic, Automatic, None},\n VectorColorFunction -> (Hue[2 ArcTan[#5]/Pi] &), \n VectorColorFunctionScaling -> False]\n\n\nWhat I did here is to suppress the automatic re-scaling colors in VectorColorFunction and provided my own scaling that can easily deal with infinite values. It's based on the ArcTan function.\nAs a mix between these two approaches, you could also use the ArcTan to rescale vector length. \n", "graphics - How to separate paths from the output of EdgeDetect?": "\nYou can use MorphologicalComponents to get the different loops:\nWith[{components = MorphologicalComponents@EdgeDetect@Graphics[Style[Text[\"8\"], 400]]},\n    ColorNegate@Image[1 - Unitize[components - #]] & /@ Range[Max[components]]]\n\n\nTrying this on other similar characters \u2014 {\"A\", \"B\", \"g\", \"9\"}\n\n", "programming - What is the proper method to load a Mathematica package inside a DynamicModule": "\nWhile Initialization is a useful option, it is only evaluated when the body of the DynamicModule is displayed on screen. See some explanation on the evaluation sequence here.\nWith DynamicModule\nI've constructed a TestPackage` for this case, it contains the globally exported variable $Test, with a value of 123. The following example shows that the package is not loaded (note that you have to clear dynamic content and variables (e.g. restart kernel) for each example below to start from a clear state of memory):\nDynamicModule[{}, $Test, Initialization :> (Needs[\"TestPackage`\"])]\n\n\n$Test\n\nIt doesn't work with an explicit TestPackage`$Test call either indicating that $Test (and thus the body) is evaluated before the Initialization code. This is somewhat contraintuitive, as one expects the initialization code to be evaluated before anything else. I should note here that the package is loaded, it is just loaded too late. Any later cells calling for $Test return the correct value though. One way to overcome this in the given setup is to use the explicit name of $Test in a dynamic output, which updates the unrecognized $Test output when the package is finally loaded during evaluation:\nDynamicModule[{}, Dynamic[TestPackage`$Test], Initialization :> Needs[\"TestPackage`\"])]\n\n\n123\n\nThe second example is even more strange. While the package loading code is included in the body, $Test is still not recognized:\nDynamicModule[{}, Needs[\"TestPackage`\"]; $Test]\n\n\nUsing the explicit name of the variable helps here, indicating that parsing (done before evaluation) causes $Test to be a local variable that is not recognized as TestPackage`$Test:\nDynamicModule[{}, Needs[\"TestPackage`\"]; TestPackage`$Test]\n\n\n123\n\nOf course the easiest way is:\nNeeds[\"TestPackage`\"];\nDynamicModule[{}, $Test]\n\n\n123\n\nUpdate\nAnd the Wolfram way is (see this conference material):\n\n\"Can be solved by two Needs[] statements...one to fulfill Shift+Enter\n  evaluation and one to fulfill Dynamic evaluation. Note that this is\n  only an issue because of $ContextPath. Any other initialization code\n  could have safely appeared one time inside of Initialization.\"\n\nNeeds[\"TestPackage`\"]; \nDynamicModule[{}, Dynamic[$Test], Initialization :> Needs[\"TestPackage`\"])]\n\n\n123\n\nWith Manipulate\nFollowing the Wolfram way, one needs the outer package loading, but in Manipulate, SaveDefinitions works correctly grabbing the definition of $Test from the package:\nNeeds[\"TestPackage`\"];\nManipulate[$Test, {$Test, None}, SaveDefinitions -> True]\n\n\n123\n\nWith Dynamic\nAccording to the above examples, with Dynamic (each cell should be evaluated in a fresh kernel):\nDynamic[$Test, Initialization :> (Needs[\"TestPackage`\"])]\n\n\nGlobal`$Test\n\nDynamic[TestPackage`$Test, Initialization :> (Needs[\"TestPackage`\"])]\n\n\n123\n\nDynamic[Needs[\"TestPackage`\"]; $Test]\n\n\nGlobal`$Test\n\nDynamic[Needs[\"TestPackage`\"]; TestPackage`$Test]\n\n\n123\n\n", "functions - FunctionInterpolation Errors / Question re Evaluation Order and Options": "\nI don't think InterpolatingFunction is intended to work on vector functions. The doc page doesn't say anything about it. Try for instance\nf = FunctionInterpolation[{x, x}, {x, 0, 6}]\n\nAnd\nTable[f[x], {x, 0, 6, 1}]\n\nreturns   \n(*\n==> {0., 0.9999652778, 1.998576389, 3., 4.004131944, \\\n4.994409722, 6.}\n*)\n\nSo, no two dimensional output.\nIt's probably better to come up with three separate interpolating functions for each of the three components of the output.\n\nHaving said that, it doesn't look like this is the end of the problems.\nxyz2llaPhi = GeoPosition[GeoPositionXYZ[obs + # look, \"WGS84\"]][[1, 1]] &;\nfPhi = FunctionInterpolation[xyz2llaPhi[d], {d, 2000000, 3700000}]\n\nyields\n\nWhereas\nxyz2llaPhi[200000]\n\nyields a nice numerical result:\n(*\n==> -34.86629487\n*)\n\nIt looks like the combination of FunctionInterpolation and GeoPosition isn't a healthy one. Somehow, the index d is held unevaluated.\nA workaround would be to generate a table of values and then use ListInterpolation.\n", "How to divide a graph into connected components?": "\nHere is one way:\nSubgraph[g, #, VertexLabels -> \"Name\", ImagePadding -> 10] & /@ \n    ConnectedComponents[UndirectedGraph[g]]\n\n\nThe proper terminology for what you asked, as hinted by the code, is connected components of a graph. I had to convert a graph to undirected one, since connectivity in a directed graph is a stronger condition, and not what you were after here.\n", "machine learning - Linear separability for a sum of kernel functions": "\nOld question, but:\nI'll assume first that the kernels correspond to finite feature maps. Say that $K_1(x, y) = \\varphi_1(x)^T \\varphi_1(y)$, $K_2(x, y) = \\varphi_2(x)^T \\varphi_2(y)$. Then\n$$K_1(x, y) + K_2(x, y) = \\begin{bmatrix}\\varphi_1(x) \\\\ \\varphi_2(x)\\end{bmatrix}^T \\begin{bmatrix}\\varphi_1(y) \\\\ \\varphi_2(y)\\end{bmatrix}.$$\nThus, if a hyperplane defined by $(w_1, b_1)$ separates the dataset under the $\\varphi_1$ map, the hyperplane defined by $\\left(\\begin{bmatrix}w_1 \\\\ 0\\end{bmatrix}, b_1 \\right)$ will separate the points in the same way under the combined mapping.\nYou can generalize this feature maps in any Hilbert space, since the space defined by $K_1 + K_2$ is the product of the spaces defined by $K_1$ and $K_2$ similar to vector concatenation in the finite case.\n", "image processing - What's the difference between EdgeDetect and MorphologicalPerimeter (for a white background)?": "\nNo, they're not the same, and will not, in general, give the same result because they're two very different operations.\n\nMorphologicalPerimeter gives a Boolean output according to the following logic:\n\n1 \u2014 If the pixel value is 1 (i.e., white) and at least 1 pixel in its 8-pixel neighbourhood is 0.\n0 in all other cases. \n\nHere's an example with a simple 20x20 image with 1 black pixel along the diagonal. You can actually follow the logic above to verify the output (assume 0 outside the edge for pixels along the border)\nimg = ColorNegate@Image@IdentityMatrix[20];\nMorphologicalParameter[img]\n\n\nEdgeDetect, by default, uses the Canny edge detector which is a lot more complicated, multi-step algorithm unlike MorphologicalPerimeter. Roughly speaking, it convolves it with a Gaussian filter, followed by a non-maximum suppression step, which basically sets all pixels that aren't a local-maxima to zero. You can read more about it in the Wikipedia article.\nPerforming an edge detection on the above image gives you:\nEdgeDetect[img]\n\n\nYou can visibly see the difference between the two images above, especially at the corners and the borders.\n\n", "Is the Wolfram | Alpha output in Mathematica not Alpha Pro?": "\nI can't say that all the Alpha Pro features are available through V8 of Mathematica, but certainly many are.  Here are three examples:\nType \"derivative of x^2\" into Alpha.  If you are not logged into the Pro version, you will be unable to access the result, other than as a visual image.  In particular, you can't easily copy and paste results.\nOr try, just \"z^2-1\" in Alpha.  You'll notice a number of pods that have an \"Enable Interactivity\" button.  If you press such a button, Alpha generates some type of groovy interactive CDF content, if you are logged into Pro.  Without Pro, you can't interact with that content.  In Mathematica, all those interactives are switched on by default.\nFinally, Alpha Pro gives you direct access to scads of data for queries like \"US Population history\".  You need Pro to do this or, again, you can do it directly through Mathematica without Pro.\nI would be surprised if all Pro features work immediately through Mathematica.  Do you have specific examples that you were thinking of?\n", "Growth of functions - Mathmatica Stack Exchang": "\nYes, Mathematica can be used to characterize the asymptotic behaviour of functions, but maybe not in the straightforward way you intended. Let's see a few examples (I'll focus on asymptotic behaviour as $x\\rightarrow\\infty$, but behaviour around any other point works the same) of what we can do by looking at limits (using the Limit function):\n\nHow to check if $f(x) \\in o(g(x))$, or $g(x) \\in \\omega(f(x))$\nThere, the question we can ask Mathematica is: what is the limit of $f(x)/g(x)$:\n\nIf the limit is zero, then $f$ is dominated by $g$, as in the example below, where\n$$f(x)=x^2e^{-\\sqrt x}\\ \\ \\text{  and }\\ \\ g(x)=e^{-x}$$\nIn[1]:= Limit[(x^2*Exp[-Sqrt[x]])/Exp[x], x -> \u221e]\nOut[1]= 0\n\nIf the limit exists, but is not zero (it can be a finite number, an infinity, or an Interval): $f$ is not dominated by $g$ (and if the limit is $\\infty$, then in fact $g$ is dominated by $f$). Three examples:\nIn[2]:= Limit[(3*x^2 + x + 1)/x^2, x -> \u221e]\nOut[2]= 3\n\nIn[3]:= Limit[Gamma[x]/Exp[x], x -> \u221e]\nOut[3]= \u221e\n\nIn[4]:= Limit[x*Sin[x]/Sqrt[x], x -> \u221e]\nOut[4]= Interval[{0, \u221e}]\n\nIf the limit is unknown to Mathematica, then you haven't learnt anything.\n\n\nHow to check if $f(x) \\in O(g(x))$\n$f(x) \\in O(g(x))$ means that, for large enough $x$, $\\left\\vert f(x)/g(x)\\right\\vert$ is bounded. So, our options are as such:\n\nIf $\\left|f(x)/g(x)\\right|$ converges to a finite number (including zero, but not $\\infty$), then that's it: $f(x) \\in O(g(x))$\nIn[5]:= Limit[(3*x^2 + x + 1)/(Erf[x]*x^2), x -> \u221e]\nOut[5]= 3\n\nIf $|f(x)/g(x)|$ converges to an interval which does not include any infinity, the same is true:\nIn[6]:= Limit[Abs[Sin[x]/(2 + Cos[x])], x -> \u221e]\nOut[6]= Interval[{0, 1}]\n\nIf $\\left|f(x)/g(x)\\right|$ converges to $\\infty$ or to an interval containing $\\infty$, then $f(x) \\not\\in O(g(x))$.\nOtherwise, you have learnt nothing.\n\n\nThe fine print: in many examples above, I calculate $f/g$ instead of $|f/g|$ because I know that the functions both have positive values. Also, if $g(x)$ takes zero as a value in more than a finite number of points, you need to be a little bit more careful than just calculating $f/g$.\n", "sound - Can one find the beat of a tune with Fourier analysis?": "\nHere's a possible starting point for a solution. It splits the sample list into chunks and measures the Norm of the sample Differences in each chunk, and then does the FFT on that data.\nbpmplot[snd_, bpmmax_: 300] := \nModule[{samples, minfreq, signal, fft},\nsamples = snd[[1, 1, 1]];\nminfreq = snd[[1, 2]]/Length[samples];\nsignal = (Norm[Differences[#]]) & /@ Partition[samples, 128];\nfft = Abs[Fourier[signal][[;; Floor[bpmmax/(120 minfreq)]]]];\nfft[[;; 10]] *= 0; (* remove very low frequencies *)\nListLinePlot[MapIndexed[{120 (#2[[1]] - 1) minfreq, #1} &, fft], \nPlotRange -> All, Frame -> True, FrameLabel -> {\"BPM\", \"Signal\"}, \nBaseStyle -> {FontFamily -> \"Calibri\", 20}]];\n\nsnd = Import[\"C:\\\\Users\\\\Simon\\\\Desktop\\\\02 - Money For Nothing.wav\"];\n\nbpmplot[snd]\n\n\nGoogle tells me that the BPM for this track is 134, and you can see that it has picked that frequency out quite well, though there are many other peaks too, especially the harmonic at 268 bpm.\n", "probability or statistics - Is there a function to calculate studentized range?": "\nI do not think there's one built-in, but it's fairly easy to write a function for it:\nstudentizedRange[data_List] := (Max[data] - Min[data])/StandardDeviation[data]\n\nBut I would also check out the ANOVA package for related functionality.\n", "evaluation - How can I completely ban usage of some functions in output and mandate use of others?": "\nYou may try for example something like:\nf[e_] := 100 Count[e, _Pochhammer, {0, Infinity}] + LeafCount[e];\nFullSimplify[Pochhammer[k, n], ComplexityFunction -> f]\n\n(*\n->Gamma[k + n]/Gamma[k]\n*)\n\n", "stylesheet - Why does Installing small caps fonts in OS X cause notebook Text cells to use that font?": "\nThe Text style uses FontFamily->\"Times\".  Your fonts are almost certainly set to have the same family name as the built-in font that Mathematica normally uses, and leaves the system with two possible sets of fonts to choose from.  Even though the internal font name being used is, e.g., Times-RomanSC, that's not the actual family name...that's the style name (I'm not sure how standard the term \"style name\" is, but it's the term that FontLab uses for this).\nAs a result, Mathematica asks for \"Times\", and this font shows up in the list of candidates.  Mathematica will choose the first font the system offers from that list.  I would have expected Mathematica to understand that this is a small caps variant, and not use the font unless you wanted small caps, but it's entirely possible that the variant information in the font is not declared in a way that Mac OS X recognizes, probably due to it using older, Type 1 technology.  I wouldn't be surprised if other applications on your system have similar problems.\nIf you could edit your small caps fonts to change the font family name, that would certainly fix things.  This isn't about the filenames being used by the font...this is about the inherent family name set as a property of the font itself.  You'll probably need to change the style name to match as well.\nOtherwise, you could use the Format->Show Fonts menu item to see if it's possible to pick the correct Times font and, if so, determine what the properties are by looking at the underlying cell expression (Cell->Show Cell Expression).  Armed with that information, an expert could help you figure out how to modify options/styles to avoid this.\n", "programming - Why does Mathematica choose the second function definition?": "\nAs far as I can tell, it should match the catch all rule. That's because _ isn't of the form x[]\nNow, when you test the MatchQ expression, both arguments are first evaluated. So, you're actually doing MatchQ[maybe, maybe] which of course returns True.\nYou can do the checking as you intended to by first holding the arguments\nMatchQ[Hold@PatternImplies[_Integer, _], \n Hold@PatternImplies[(x : (Verbatim[Blank] | Verbatim[BlankSequence] |\n         Verbatim[BlankNullSequence]))[h_], x[]]]\n\nFalse\n\nEDIT:\nI now see what you intended with x[]. You could do x_[] instead. That would mean \"any no-argument expression whose head coincides with the previous pattern labelled x. If you write x[] it matches literally\n", "functions - What default theoretical distribution does Mathematica use in PearsonChiSquareTest?": "\nAccording to the documentation you linked, difference is:\n\nPearsonChiSquareTest[data, NormalDistribution[]] tests whether the data is distributed according to a normal distribution of mean 0 and standard deviation 1.\nPearsonChiSquareTest[data] is actually more flexible, and checks whether your data is distributed according to any normal distribution.\n\nThe difference becomes flagrant with data from a different distribution:\ndata = RandomVariate[NormalDistribution[1, 0.1], 10^4];\nPearsonChiSquareTest[data]\n(* Out[33]= 0.419701 *)\n\nPearsonChiSquareTest[data, NormalDistribution[]]\n(* Out[34]= 2.712072730217051*10^-23123 *)\n\n\nIn short, the following two statements are equivalent:\nPearsonChiSquareTest[data]\nPearsonChiSquareTest[data, NormalDistribution[\u03bc, \u03a3]]\n\nwhere the second one uses symbolic parameters in the distribution. You can retrieve information about the test by doing:\nPearsonChiSquareTest[data, NormalDistribution[\u03bc, \u03a3], \"HypothesisTestData\"]\n\nand exploring the different properties of this object. All properties can be listed by:\nPearsonChiSquareTest[data, NormalDistribution[\u03bc, \u03a3], \"HypothesisTestData\"][\"Properties\"]\n\nand the fitted distribution is recovered with:\nPearsonChiSquareTest[data, NormalDistribution[\u03bc, \u03a3], \"HypothesisTestData\"][\"FittedDistribution\"]\n\nEnjoy!\n", "bugs - Random variables with transformed discrete distributions cannot be applied to Probability[] function?": "\nThe following computes the probability you asked for, but I'm at a loss to understand why your notation won't work. It seems correct to me.\nProbability[\n 3 x + 1 > y, {Distributed[x, Dx], Distributed[y, Dy]}]\n\n(*\n==> 147/289\n*)\n\nThe Probability / Distribution functions are quite young and hence not fully bulletproofed and I have encountered a number of bugs myself. I suppose/hope that in the next release they will be solved. I suggest you contact Wolfram support (support@wolfram.com). But perhaps someone else here may find out what's wrong.\nA few of mine:\nNo random variates from PDFs that stem from multivariate distributions:  \ndist = ProbabilityDistribution[\n   PDF[BinormalDistribution[{0, 0}, {1, 1}, 0]][{x, \n     y}], {x, -Infinity, Infinity}, {y, -Infinity, Infinity}];\nRandomVariate[dist]\n\nThis works for 3, but not for 5 (and higher):\nExpectation[x,x\\[Distributed] OrderDistribution[{GeometricDistribution[0.1], 3}, 3]]\nExpectation[x,x\\[Distributed] OrderDistribution[{GeometricDistribution[0.1], 5}, 5]]\n\nThe following crashes the kernel after a minute or so (so, DO NOT EXECUTE):\nPDF[TransformedDistribution[Sin[u], u \\[Distributed] NormalDistribution[0, 1]], 0]\n\n", "plotting - Aligning a DensityPlot with a Plot": "\nAbsoluteOptions shows there to be several differences between the  output settings of the first and second plots:\nGrid[Prepend[Transpose[\n     AbsoluteOptions[#, {PlotRangePadding, AspectRatio, \n           Frame}] & /@ {plot1, plot2}], {\"first\", \"second\"}], Frame -> All]\n\n\nIt'll look better if you use the same aspect ratio (I used 1/GoldenRatio) and a frame in each picture. I also set PlotRangePadding-> None in the second case.\n\n", "programming - Can a Table iterator \"leak\" into a Module?": "\nI know the reason for the second giving you the error: i has been set to 1. Under normal operations, this will not happen as Table has the Attribute HoldAll, so even if i has a value, Table should be shielded from it. For example,\ni = 5\nTable[ i, {i , 3}]\n(* Out[1] = 5 \n   Out[2] = {1, 2, 3}\n*)\n\nHowever, in the large block of code, you use this construct:\nWith[{i = i}, Table[ ..., {i, ...} ]\n\nSo, it is likely that the second Table is executed in a similar manner, and that is where the problem lies. For instance,\nWith[{i = 1}, Table[i, {i, 5}]]\n(* Table::itraw: Raw object 1 cannot be used as an iterator. >>\n   Out[3] = Table[1, {1, 5}]\n*)\n\nWith operates by replacing i in Table with its value prior to Table doing anything which circumvents the HoldAll.  Neither, Block nor Module have the same effect, so I would advise using them, instead, for this type of thing.\n\nIn your code for run2, you effectively have this code\nTable[ With[{i2 = i1}, Table[ ..., {i2, ...}]], {i1, ...}]\n(* I have renamed the variables for clarity, but the results are the\n   same with them all set to i*)\n\nHere, i1 is localized to the outer Table and the With sets i2 to the value of i1 which causes the error you're seeing.  The reason this shows up inside errorcorrection is that i1 is not localized to errorcorrection, but takes on the global (to it) value. \nIncidentally, this reveals that Table is using Block or Internal`InheritedBlock to perform its scoping. Consider, \nf[x_] := {x, i}\nBlock[{i = 3}, f[q]]\nInternal`InheritedBlock[{i = 3}, f[q]]\nModule[{i = 3}, f[q]]\nWith[{i = 3}, f[q]]\n(*\nOut[131]= {q, 3}\nOut[132]= {q, 3}\nOut[133]= {q, i}\nOut[134]= {q, i}\n*)\n\nwhich reveals one of the key differences between the different scoping constructs. Here i in f is interpreted as Global`i, but Module and With effectively use Unique[i], instead. So, they return Global`i unevaluated.  (With actually performs a rewriting operation, but the effect is the same.) Block and Internal`InheritedBlock effectively define Unique[]`i and without any context qualifier on i in f, it is subsumed into the new context. The difference between them is that Block assumes that no definitions of i exists. But, Internal`InheritedBlock pulls in the global definitions into Unique[]` allowing for small changes to be made easily.\nIn the code, if i was not specified in the outer Table (as in the code for run3), then yes With would work as expected. But, the moral of the story is that Table need not be wrapped in any of scoping constructs as it does the scoping itself.\n", "graphs and networks - How to display edge labels above edges?": "\nGraphPlot[{{1 -> 2, \"1\\[Rule]2\"}, 4 -> 1, {2 -> 4, \"2\\[Rule]4\"}, 1 -> 5, 2 -> 5, 5 -> 4}, \n EdgeRenderingFunction -> \n   ({If[#3 =!= None, \n           {Line[#], Inset[#3, Mean[#1], Automatic, Automatic, #[[1]] - #[[2]], \n           Background -> White]}, Line[#]]} &)]\n\n\n", "return value - Compile and \"True should be a machine-size real number...\" Error": "\nFor the error handling use the compilers error handling mechanism:\ncffail = Compile[{{x, _Real, 1}}, Exp[x], \n   \"RuntimeOptions\" -> {\"RuntimeErrorHandler\" -> Function[$Failed]}];\ncffail[{1000.}]\n\nThe Function can be anything (Throw[..],...).\nFor the summation you could use Total in stead:\nCompile[{{x, _Real, 1}}, Total[x]]\n\n", "Conditional break point in Wolfram Workbench?": "\nOne way that works already is to put a break point inside an If statement.\nIf[condition,\n   dummyInstruction;\n];\n\nAnd put a breakpoint at dummyInstruction. I don't know if something like this could be done without modifying the code in break point properties like in some other environments.\n", "Support for pro font families?": "\nGetting the names of the fonts is pretty easy. I like Heike's solution, but I can remember the following procedure better. \nJust format the text in some text cell with any font style you like and then enter the menu command Cell > Show Expression (ctrlshiftE on a PC) revealing the formatting instructions.\nCell[TextData[StyleBox[\"aaaaa\",\n FontFamily->\"Myriad Pro Light\",\n FontWeight->\"Demi\",\n FontSlant->\"Italic\"]], \"Text\",\n CellChangeTimes->{{3.543584575138007*^9, 3.5435845788282185`*^9}}]\n\nUsing this information:\nColumn[{\n  Style[\"Myriad Pro\", FontFamily -> \"Myriad Pro\", 80],\n  Style[\"Myriad Pro Cond\", FontFamily -> \"Myriad Pro Cond\", 80],\n  Style[\"Myriad Pro Cond Italic\", FontFamily -> \"Myriad Pro Cond\", \n   FontSlant -> \"Italic\", 80],\n  Style[\"Myriad Pro Cond Bold\", FontFamily -> \"Myriad Pro Cond\", \n   FontSlant -> \"Plain\", FontWeight -> \"Bold\", 80],\n  Style[\"Myriad Pro Cond Bold Italic\", \n   FontFamily -> \"Myriad Pro Cond\", FontSlant -> \"Italic\", \n   FontWeight -> \"Bold\", 80],\n  Style[\"Myriad Pro Cond Semibold\", FontFamily -> \"Myriad Pro Light\", \n   FontWeight -> \"Demi\", 80],\n  Style[\"Myriad Pro Cond Semibold Italic\", FontFamily -> \"Myriad Pro Light\", \n   FontWeight -> \"Demi\", FontSlant -> \"Italic\", 80]\n  }\n ]\n\n\n\nBy the way: Although it is often quite possible to specify slant and weight in the font name, there is a good reason to specify them separately. Compare the parenthesis in the following:\nStyle[\"Text (x) Text\", FontFamily -> \"Myriad Pro-Bold-Italic\", 80]\n\n\nand\nStyle[\"Text (x) Text\", FontFamily -> \"Myriad Pro\", FontWeight -> Bold,\n  FontSlant -> Italic , 80]\n\n\nFor a lot of symbols, Mathematica substitutes the Mathematica font version for the one in the specified font. If you have specified slant and weight in the font name MMA doesn't pick up those font specifications, ending up with symbols that are unmatched in style to the rest of the text.\n", "graphics - Procedure to find direction of triangle": "\nGiven that the triangle might not exactly be isosceles, let's characterize this direction as being from the triangle's center towards the most distant vertex:\nClearAll[direction];\ndirection[t_List] := \n With[{center = Mean[t]}, \n  t[[First[Ordering[N[Norm /@ (# - center & /@ t)], -1]]]] - center]\n\n(Edit As @R.M. notes, N needs to be applied for Ordering to work consistently and correctly.)\nOne advantage of this approach is that it works for any polygon.  Another is that it does not require any additional specification such as a tolerance for testing approximate equality of sides.\nAs an example,\nt = {{30.07, 11.04}, {20.07, 35.905}, {40.905, 19.095}};\ncenter = Mean[t];\nGraphics[{White, EdgeForm[Black], Polygon[t], Red, Arrow[{center, center + direction[t]}]}]\n\n\nNote that the direction is given as a vector (which carries the additional information about the distance from the triangle's center towards this extreme vertex).  For other forms of output, this is readily converted into a unit vector (by normalizing it) or an angle.\n\nEdit\nNotice that for squat, flat isosceles triangles (where the apex angle exceeds 60 degrees), this solution determines that the \"pointing direction\" is from the center towards one of the base vertices, not towards the apex.  If that is not the intention, then additional analysis is needed.  One way is to determine that among all the possible directions from the center, the one most different from the other two is the one to pick:\ndirection[t_List] := Block[{center = Mean[t], s, l, a},\n  s = # - center & /@ t;\n  l = Norm /@ s;\n  a = Abs[RotateLeft[l, 1] - RotateLeft[l, 2]];\n  s[[First[Ordering[N[a], 1]]]]\n  ]\n\nIn this implementation (which is written for clarity rather than brevity), s lists the three possible directions, l lists their lengths, and for each entry in l, a lists the differences in lengths between the other two.  The last line returns the direction where that difference is the smallest (as a vector from the center to the vertex, exactly as before).\n", "symbolic - Sophistication of Series[...]": "\nTry this\nNormal@Series[expr/.{f->x f, g->x^2 g, h->x^3 h},{x,0,4}] /.x->1\n", "Memory not freed after running Clear when using a Table": "\nHave you tried setting $HistoryLength to zero:\n$HistoryLength=0;\n\nThe memory is not freed, because the previous data is still available by Out[nn] or %nn.\nNote that if you do this, using %, %%, %n etc., which some people use in example code will not work. And when a large data set is shown the \"Show More\" and \"Show Less\" buttons do not work. You can bypass both problems by setting $HistoryLength to 1 while still conserving a lot of memory.\n", "chemistry - Automatic formatting of isotope symbols in a text cell": "\nYou can set it as an option as follows \u2014\nSetOptions[SelectedNotebook[], InputAutoReplacements -> {\"1H\" -> SuperscriptBox[\"H\", \"1\"]}]\n\nNow if you enter $1\\mathrm{H}$ in a text cell, it will automatically convert it to $\\mathrm{H}^1$.\nAnother possibility is using InputAliases, where you enter the replacement as Esc1HEsc. IMHO, this is a better way to handle auto replacements, because the intent to replace is quite clear, whereas with the first approach, it'll replace it even when you don't want it to (e.g., addresses in some countries). You can set an alias as: \nSetOptions[SelectedNotebook[], InputAliases -> {\"1H\" -> SuperscriptBox[\"H\", \"1\"]}]\n\n\nCreating auto-replacements for all isotopes:\nI don't think creating a blind pattern based rule replacements to handle isotope auto-replacements is a good way to approach it, because you wouldn't want invalid isotopes like 2C or 207U to actually be replaced \u2014 you'd rather they be untransformed so that it serves as a visual error/typo check. A better and safe approach would be to whitelist the known isotopes and create rules only for those isotopes.\nFortunately, you can use Mathematica itself to query this info and create your custom rules as follows:\n(* get info about known isotopes *)\nisotopeInfo = {ElementData[#, \"Abbreviation\"], ElementData[#, \"KnownIsotopes\"]} & /@ \n    ElementData[]; \n\n(* function to assemble the superscripts *)\ncreateSuperscripts[{e_String, w_List}] := \n    ToString[#] <> e -> SuperscriptBox[e, ToString[#]] & /@ w\n\n(* map over all elements and create the aliases *)\nisotopeRules = createSuperscripts /@ isotopeInfo // Flatten;\nSetOptions[SelectedNotebook[], InputAliases -> isotopeRules]\n\nWith this set, you can now enter valid isotopes between two Esc presses and it will convert it to a superscript.\n\nYou can also extend this to include the atomic number by default as seen in common notation (although it is redundant info). Here's an example (you can do the styling as you please) that shows how, and it also uses an \\[InvisibleSpace] from my very first question\n(*get info about known isotopes*)\nisotopeInfo = {ElementData[#, \"Abbreviation\"], \n     ElementData[#, \"AtomicNumber\"], ElementData[#, \"KnownIsotopes\"]} & /@ ElementData[];\n\n(*function to assemble the subsuperscripts*)\ncreateSuperscripts2[{e_String, n_Integer, w_List}] := \n    ToString@# <> e -> RowBox[{SubsuperscriptBox[\"\\[InvisibleSpace]\", ToString@n, \n    ToString@#], e}] & /@ w\n\nThe last two steps are the same (except, use this function instead). Here's how it looks on mine:\n\n", "calculus and analysis - Maximizing a function with assumptions": "\nMaximize does not take $Assumptions into account by default, but wants the assumptions to be given explicitly:\nAssuming[Abs[x]>=3,Maximize[-x^2,x]]\n(*\n==> {0, {x -> 0}}\n*)\n\nMaximize[{-x^2,Abs[x]>=3},x]\n(*\n==> {-9, {x -> -3}}\n*)\n\nHowever you can inject $Assumptions explicitly:\nAssuming[Abs[x]>=3,Maximize[{-x^2,$Assumptions},x]]\n(*\n==> {-9, {x -> -3}}\n*)\n\nHowever for your particular example, Maximize doesn't seem to be able to find the maximum anyway.\n", "probability or statistics - Identifying subsets with minimal standard deviation": "\nA general solution:\ngetMinStdDev[data_?ListQ] := Module[{ip, fp, allowedParts},\n  ip = IntegerPartitions[Length@data, Length@data, Range[3, Length@data]];\n  fp = Flatten[Permutations /@ ip, 1];\n  allowedParts = (data[[#[[1]] ;; #[[2]]]] & /@ \n                  Thread[List[(Accumulate@Join[{1}, #])[[;; -2]],Accumulate@#]]) & /@ fp;\n  allowedParts[[Ordering[Total /@ Map[StandardDeviation[#]^2 &, allowedParts, {2}], 1]]]];\n\nUsage\ngetMinStdDev@{10, 11, 10, 15, 14, 16, 9, 8, 7, 6, 8, 7}\ngetMinStdDev@{10, 11, 15, 12, 9, 8, 7, 6, 8} (*Yours*)\ngetMinStdDev@Join[RandomInteger[{1,5},5],RandomInteger[{5,10},5], RandomInteger[{10,15},5]]\n(*\n->\n{{{10, 11, 10}, {15, 14, 16}, {9, 8, 7, 6, 8, 7}}}\n{{{10, 11, 15, 12}, {9, 8, 7, 6, 8}}}\n{{{3, 3, 5, 3, 2}, {9, 9, 5, 8, 8, 11}, {13, 15, 15, 13}}}\n*)\n\n", "plotting - Using ContourPlot3D on a region in $\\mathbb{R}^3$": "\nYou can use the RegionFunction option with ContourPlot3D as follows:\n  ContourPlot3D[x^2 + y^2 + z^2, {x, -3, 3}, {y, -3, 3}, {z, -3, 3}, \n  Contours -> 4, \n  RegionFunction -> Function[{x, y, z}, -4 < x + y < 4 && -4 < y + 2 z < 4 && -4 < x + z < 3], \n  ContourStyle -> {Red, Green, Yellow, Orange}, Mesh -> None]\n\nwhich gives\n\nOr, for a specific contour with the same region function, you can use\n  ContourPlot3D[x^2 + y^2 + z^2 == 10, {x, -3, 3}, {y, -3, 3}, {z, -3, 3}, \n  RegionFunction ->  Function[{x, y, z}, -4 < x + y < 4 && -4 < y + 2 z < 4 && -4 < x + z < 3], \n  ContourStyle -> {Red, Green, Yellow, Orange}, Mesh -> None]\n\nto get\n\n", "list manipulation - Combining values in one column (or part) when values in another column (or part) match": "\nThe following also works (though its a bit messy to look at) and will probably be faster than pattern matching if you have large input data.\nTranspose[{#[[All, 1, 1]], \n      Total[#[[All, All, 2]], {2}]}] &[#] & /@ (GatherBy[#, First] & /@\n    data)\n\nEDIT:\nI should point out that there are at least a couple of different problems being solved in the answers posted here. The results posted by myself and @RM attempt to preserve the structure of the original data and so do not gather like dates if they are present in multiple sublists.\nAnswers posted by @David Carraher and @rcollyer ignore the structure of the original data and gather all like dates.\nI'm not sure which is the correct approach in this case but it felt worth pointing out the difference.\n", "Automatically generating a dependency graph of an arbitrary Mathematica function?": "\nPreamble\nThe problem is not as trivial as it may seem on the first glance. The main problem is that many symbols are localized by (lexical) scoping constructs and should not be counted. To fully solve this, we need a parser for Mathematica code, that would take scoping into account. \nOne of the most complete treatments of this problem was given by David Wagner in his Mathematica Journal article, and replicated partially in his book. I will follow his ideas but show my own implementation. I will implement a sort of a simplistic recusrive descent parser which would take scoping into account. This is not a complete thing, but it will illustrate certain subtleties involved (in particular, we should prevent premature evaluation of pieces of code during the analysis, so this is a good excercise in working with held/unevaluated expressions).\nImplementation (for illustration only, does not pretend to be complete)\nHere is the code:\nClearAll[getDeclaredSymbols, getDependenciesInDeclarations, $OneStepDependencies,\n  getSymbolDependencies, getPatternSymbols,inSymbolDependencies, $inDepends];\n\nSetAttributes[{getDeclaredSymbols, getDependenciesInDeclarations, \n   getSymbolDependencies, getPatternSymbols,inSymbolDependencies}, HoldAll];\n\n$OneStepDependencies = False;\n\ninSymbolDependencies[_] = False;\n\nglobalProperties[] =\n    {DownValues, UpValues, OwnValues, SubValues, FormatValues, NValues, \n     Options, DefaultValues};\n\n\ngetDeclaredSymbols[{decs___}] :=\n    Thread@Replace[HoldComplete[{decs}], HoldPattern[a_ = rhs_] :> a, {2}];\n\ngetDependenciesInDeclarations[{decs___}, dependsF_] :=\n  Flatten@Cases[Unevaluated[{decs}], \n      HoldPattern[Set[a_, rhs_]] :> dependsF[rhs]];\n\ngetPatternSymbols[expr_] :=\n  Cases[ \n     Unevaluated[expr], \n     Verbatim[Pattern][ss_, _] :> HoldComplete[ss], \n     {0, Infinity},  Heads -> True];\n\ngetSymbolDependencies[s_Symbol, dependsF_] :=\n  Module[{result},\n    inSymbolDependencies[s] = True;\n     result = \n       Append[\n         Replace[\n            Flatten[Function[prop, prop[s]] /@ globalProperties[]],\n            {\n              (HoldPattern[lhs_] :> rhs_) :>\n                With[{excl = getPatternSymbols[lhs]},\n                 Complement[\n                   Join[\n                      withExcludedSymbols[dependsF[rhs], excl],\n                      Module[{res},\n                         (* To avoid infinite recursion *)\n                         depends[s] = {HoldComplete[s]};\n                         res = withExcludedSymbols[dependsF[lhs], excl];\n                         depends[s] =.;\n                         res\n                      ]\n                   ],\n                   excl]\n                ],\n              x_ :> dependsF[x]\n            },\n            {1}\n         ],\n         HoldComplete[s]\n       ];\n    inSymbolDependencies[s] =.;\n    result] /; ! TrueQ[inSymbolDependencies[s]];\n\ngetSymbolDependencies[s_Symbol, dependsF_] := {};\n\n\n(* This function prevents leaking symbols on which global symbols colliding with \n** the pattern names (symbols) may depend \n*)\nClearAll[withExcludedSymbols];\nSetAttributes[withExcludedSymbols, HoldFirst];\nwithExcludedSymbols[code_, syms : {___HoldComplete}] :=\n   Module[{result, alreadyDisabled },\n     SetAttributes[alreadyDisabled, HoldAllComplete];\n     alreadyDisabled[_] = False;\n     Replace[syms,\n       HoldComplete[s_] :>\n         If[! inSymbolDependencies[s],\n            inSymbolDependencies[s] = True,\n            (* else *)\n            alreadyDisabled[s] = True\n         ],\n       {1}];\n     result = code;\n     Replace[syms, \n        HoldComplete[s_] :> \n           If[! alreadyDisabled[s], inSymbolDependencies[s] =.], \n        {1}\n     ];\n     ClearAll[alreadyDisabled];\n     result\n ];\n\n\n(* The main function *)\nClearAll[depends];\nSetAttributes[depends, HoldAll];\ndepends[(RuleDelayed | SetDelayed)[lhs_, rhs_]] :=\n   With[{pts = getPatternSymbols[lhs]},\n      Complement[\n        Join[\n          withExcludedSymbols[depends[lhs], pts], \n          withExcludedSymbols[depends[rhs], pts]\n        ],\n        pts]\n   ];\ndepends[Function[Null, body_, atts_]] := depends[body];\ndepends[Function[body_]] := depends[body];\ndepends[Function[var_, body_]] := depends[Function[{var}, body]];\ndepends[Function[{vars__}, body_]] := \n   Complement[depends[body], Thread[HoldComplete[{vars}]]];\ndepends[(With | Module)[decs_, body_]] :=\n  Complement[\n    Join[\n      depends[body],\n      getDependenciesInDeclarations[decs, depends]\n    ],\n    getDeclaredSymbols[decs]\n  ];\ndepends[f_[elems___]] :=\n  Union[depends[Unevaluated[f]], \n    Sequence @@ Map[depends, Unevaluated[{elems}]]];\ndepends[s_Symbol /; Context[s] === \"System`\"] := {};\ndepends[s_Symbol] /; ! $OneStepDependencies || ! TrueQ[$inDepends] :=  \n   Block[{$inDepends = True},\n      Union@Flatten@getSymbolDependencies[s, depends ]\n   ];\ndepends[s_Symbol] := {HoldComplete[s]};\ndepends[a_ /; AtomQ[Unevaluated[a]]] := {};\n\nIllustration\nFirst, a few simple examples:\nIn[100]:= depends[Function[{a,b,c},a+b+c+d]]\nOut[100]= {HoldComplete[d]}\n\nIn[101]:= depends[With[{d=e},Function[{a,b,c},a+b+c+d]]]\nOut[101]= {HoldComplete[e]}\n\nIn[102]:= depends[p:{a_Integer,b_Integer}:>Total[p]]\nOut[102]= {}\n\nIn[103]:= depends[p:{a_Integer,b_Integer}:>Total[p]*(a+b)^c]\nOut[103]= {HoldComplete[c]}\n\nNow, a power example:\nIn[223]:= depends[depends]\nOut[223]= \n{HoldComplete[depends],HoldComplete[getDeclaredSymbols],\n HoldComplete[getDependenciesInDeclarations],HoldComplete[getPatternSymbols],\n HoldComplete[getSymbolDependencies],HoldComplete[globalProperties],\n HoldComplete[inSymbolDependencies],HoldComplete[withExcludedSymbols],\n HoldComplete[$inDepends],HoldComplete[$OneStepDependencies]}\n\nAs you can see, my code can handle recursive functions. The code of depends has many more symbols, but we only found those which are global (not localized by any of the scoping constructs). \nNote that by default, all dependent symbols on all levels are included. To only get the \"first-level\" functions / symbols on which a given symbol depends, one has to set the variabe $OneStepDependencies to True:\nIn[224]:= \n$OneStepDependencies =True;\ndepends[depends]\n\nOut[225]= {HoldComplete[depends],HoldComplete[getDeclaredSymbols],\nHoldComplete[getDependenciesInDeclarations],HoldComplete[getPatternSymbols],\nHoldComplete[getSymbolDependencies],HoldComplete[withExcludedSymbols],\nHoldComplete[$inDepends],HoldComplete[$OneStepDependencies]}\n\nThis last regime can be used to reconstruct the dependency tree, as for example suggested in the answer by @Szabolcs.\nApplicability\nThis answer is considerably more complex than the one by @Szabolcs, and probably also (considerably) slower, at least in some cases. When should one use it? The answer I think depends on how critical it is to find all dependencies. If one just needs to have a rough visual picture for the dependencies, then @Szabolcs's suggestion should work well in most cases. The present asnwer may have advantages when: \n\nYou want to analyze dependencies in an arbitrary piece of code, not necessarily placed in a function (this one is easily if not super-conveniently circumvented in @Szabolcs's approach by first creating a dummy zero-argument function with your code and then analyzing that)\nIt is critical for you to find all dependencies. \n\nThings like\n$functionDoingSomething = Function[var,If[test[var],f[var],g[var]]]\nmyFunction[x_,y_]:= x+ $functionDoingSomething [y]\n\nwill escape from the dependencies found by the @Szabolcs's code (as he mentioned himself in the comments), and can therefore cut away whole dependency sub-branches (for f, g and test here). There are other cases, for example related to UpValues, dependencies through Options and Defaults, and perhaps other possibilities as well. \nThere may be several situations when finding all dependencies correctly is critical. One is when you are using introspection programmatically, as one of the meta-programming tools - in such case you must be sure everything is correct, since you are building on top of this functionality. To generalize, you might need to use something like what I suggested (bug-free though :)), every time when the end user of this functionality will be someone (or something, like other function) other than yourself.\nIt may also be that you need the precise dependency picture for yourself, even if you don't intend to use it programmatically further.  \nIn many cases however, all this is not very critical, and the suggestion by @Szabolcs may represent a better and easier alternative. The question is basically - do you want to create user-level or system-level tools.\nLimitations, flaws and subtleties\nEDIT\nThe current version of the code certainly contains bugs. For example, it can not handle the GraphEdit example from the answer of @Szabolcs without errors. While I hope to get these bugs fixed soon, I invite anyone interested to help me debugging the code. Feel free to update the answer, once you are sure that you correctly identified and truly fixed some bugs.\nEND EDIT \nI did not intend this to be complete, so things like UpSetDelayed and TagSetDelayed are not covered, as well as probably some others. I did not also cover dynamic scoping (Block, Table, Do, etc), because in most cases dynamic scoping still means dependencies. The code above can however be straightforwardly extended to cover the cases missed here (and I might do that soon).\nThe code can be refactored further to have a more readable / nicer form. I intend to do this soon.\n", "plotting - Why plot returns empty in this example?": "\nIn your first example, the Plot is inside a Module that localizes t into something like t$23. So, when you run foo[s, t], you are actually running something similar to  \n t$23=t;\n r=E^-t$23 UnitStep[t$23];\n Plot[Chop@First@r,{t$23,0,20}]\n\nThe second line returns an expression of t. When you insert it in the last Plot, it doesn't run properly, because, the {t$23, ...} argument in Plot is held, it doesn't evaluate to t before plotting.\nIn the second example, however, you don't have this problem. r becomes an expression of whatever variable p you call in foo[s, p] (t in this case), and that's the same variable you are using in your Plot. Even if Plot holds its arguments, so it's \"immune to evaluation\", it's not immune to the lexical replacement Module does. \nFirst example analogy:\nModule[{x = x2},\n {x, Hold[x]}]\n\n{x2, Hold[x$14454]}\n\nSecond example analogy:\nModule[{},\n {x, Hold[x]}]\n\n{x, Hold[x]}\n\n", "debugging - How can I get TracePrint to treat certain functions as atomic?": "\nMaybe \n  TracePrint[g[1], TraceOff -> f]\n\n?\n", "export - How to solve issue with exporting / importing data to and from Excel": "\nThe last \"sheet\" in\ndata = {{{0.5, 0.166667}, {0.666667, 0.166667}, {0.166667, \n 0.333333}, {0.333333, 0.333333}, {0.5, 0.333333}, {0.666667, \n 0.333333}, {0.833333, 0.333333}, {0.166667, 0.5}, {0.333333, \n 0.5}, {0.5, 0.5}, {0.666667, 0.5}, {0.833333, 0.5}, {0.5, \n 0.666667}, {0.666667, 0.666667}}, {{1., 2., 6., 5.}, {3., 4., 9., \n 8.}, {4., 5., 10., 9.}, {5., 6., 11., 10.}, {6., 7., 12., \n 11.}, {10., 11., 14., \n 13.}}, {{RGBColor[0.9308155947203784, 0.9308155947203784, \n 0.9308155947203784]}, {RGBColor[1, 0, 0]}, \nRGBColor[0., 1., \n 0.14062714579995422], {RGBColor[1., 0.11317616540779736, \n 0.000015259021896696422]}, {RGBColor[1., 0.9651483939879454, \n 0.38461890592813003]}, {RGBColor[0.9685511558709087, \n 0.9685511558709087, 0.9685511558709087]}}}\n\n(i.e. list3) is the source of the problem. If you fix the third element RGBColor[0., 1., 0.14062714579995422] and put {RGBColor[0., 1., 0.14062714579995422]} like you have for the others it exports correctly, which each element of data as a table on its own sheet.\nAlso, you can always force it to Export sheets, by specifying:\nExport[\"file.xls\", data, \"Sheets\"]\n\n", "options - Factorizing polynomials over fields other than $\\mathbb{C}$": "\nAll of the polynomial functions, have an option Modulus which allows you to specify an integer field, like $\\mathbb{Z}_5$. In particular, Factor works on your example polynomial\nFactor[x^2+4, Modulus -> 5]\n(* (1 + x) (4 + x) *)\n\nAdditionally, IrreduciblePolynomialQ works to determine irreducibility of $x^2+2\r\n$, as follows\nIrreduciblePolynomialQ[x^2 + 2, Modulus -> 5]\n(* True *)\n\n", "programming - How do Forms affect the interpretation of Expressions?": "\nThe error is exactly what Part says:\n\nThere is no such level in that expression, and to convince yourself, look at {a, b}[[1, 2]] :)\nThe reason you see it in the *Forms is because they're all wrappers that affect display. In other words, although you see it as an undirected edge, its actual head is *Form.\nOutputForm[a \\[UndirectedEdge] b] // FullForm\n(* OutputForm[UndirectedEdge[a, b]] *)\n\nThe additional head now allows you to index [[1, 2]]. Going back to my earlier example:\nf[{a, b}][[1, 2]]\n(* b *)\n\n", "How to insert graphics primitives into a plot?": "\nYou can display graphics primitives in your plot by using the Show command\nShow[\n  Plot[{1/Sqrt[2*Pi] Exp[-1/2*x^2]}, {x, -3, 3}, Filling -> Axis],\n  Graphics[Line[{{1.6, 0}, {1.6, 0.4}}]],\n  Graphics[{Thick, Red, Line[{{-0.4, 0}, {-0.4, 0.4}}]}],\n  Graphics[Text[\"\u03a6\", {-.6, 0.38}]],\n  Graphics[Text[\"\u03bc\", {2, 0.1}]]\n]\n\nYou can actually just combine all the Graphics objects into one list but I always keep them separate for legibility and editability since otherwise you have to remember to switch back and forth between e.g. color and line weight specifications.\nShow[\n  Plot[{1/Sqrt[2*Pi] Exp[-1/2*x^2]}, {x, -3, 3}, Filling -> Axis],\n  Graphics[\n     {Line[{{1.6, 0}, {1.6, 0.4}}],\n      Thick, Red,\n      Line[{{-0.4, 0}, {-0.4, 0.4}}],\n      Thin, Black,\n      Text[\"\u03a6\", {-.6, 0.38}],\n      Text[\"\u03bc\", {2, 0.1}]}\n  ]\n]\n\n\nYou can also achieve the same result by using the Epilog or Prolog option for Plot\nPlot[\n  {1/Sqrt[2*Pi] Exp[-1/2*x^2]}, \n  {x, -3, 3}, \n  Filling -> Axis, \n  Prolog ->\n    {Line[{{1.6, 0}, {1.6, 0.4}}],\n    Thick, Red,\n    Line[{{-0.4, 0}, {-0.4, 0.4}}],\n    Thin, Black,\n    Text[\"\u03a6\", {-.6, 0.38}],\n    Text[\"\u03bc\", {2, 0.1}]}\n]\n\nThe difference between Prolog and Epilog is in placing your graphics primitives behind or in front of the Plot, this may be important in certain circumstances.\nOnce you have composed your plot you can use the standard Export command to save it to a format of your choosing.\n", "gui construction - Transparent background of content in a dialog window": "\nA workaround might be if your looking for one colour for the whole window including the plot is to call the background colour at another place?\nCreateDialog[\n DocumentNotebook[\n  Column@{Slider@Dynamic@n, \n    Dynamic@Plot[Sin@x, {x, 0, n \\[Pi]}, Frame -> True, Axes -> False,\n       ImagePadding -> 30, ImageSize -> 300]}, \n  Background -> LightGray]]\n\nthis gives:\n\n", "graphics - Scale Insetted Characters to Plot": "\n\"Vectorizing\" the font:\ncurve = First[First[ ImportString[ExportString[\n        Style[\"{\",FontFamily ->\"Times\",FontSize -> 72],  \"PDF\"], \"TextMode\" -> \"Outlines\"]]];\ncg = Graphics[curve]\n\nand then your code, replacing the Inset[] clause by\nInset[Pane[cg, ImageSizeAction ->  \"ResizeToFit\"], ....\n\nResult (scales OK when resizing the Plot):\n\nEdit\nFull code follows, just in case you decide to edit your code:\ncurve = First[First[\n    ImportString[\n     ExportString[Style[\"{\", FontFamily -> \"Times\", FontSize -> 72], \n      \"PDF\"], \"TextMode\" -> \"Outlines\"]]];\ncg = Graphics[curve];\nf = 1/x;\n\u03f5pl = \n  Plot[{f}, {x, 0, 1}, PlotStyle -> Black, \n   PlotStyle -> AbsoluteThickness[1]];\n\n\u03f51pl = \n  Plot[{f}, {x, 0.2, 0.4}, \n   PlotStyle -> Directive[Red, AbsoluteThickness[1.5]]];\n\u03f51dashed = \n  ListPlot[{{{0.1, f /. x -> 0.27}, {0.27, f /. x -> 0.27}}, {{0.1, \n      f /. x -> 0.3}, {0.3, f /. x -> 0.3}}}, \n   PlotStyle -> Directive[Red, Dashed, AbsoluteThickness[1]], \n   Joined -> True];\n\nShow[\u03f5pl, \u03f51pl, \u03f51dashed, \n PlotRange -> {{0, 1}, {0, 6}}, Axes -> False, Frame -> True, \n ImageSize -> 600, \n FrameStyle -> Directive[AbsoluteThickness[1], FontSize -> 24], \n FrameTicks -> False, FrameLabel -> {\"\\!\\(\\*\n   StyleBox[\\\"r\\\",\\nFontSlant->\\\"Italic\\\"]\\)\", \"\\!\\(\\*\n   StyleBox[\\\"\u03f5\\\",\\nFontSlant->\\\"Italic\\\"]\\)\"}, \n Epilog -> \n  Inset[Pane[cg, \n    ImageSizeAction -> \n     \"ResizeToFit\"], {0.095, ((f /. x -> 0.27) + (f /. x -> 0.3))/\n     2}, {0, 0}, {Automatic, (f /. x -> 0.27) - (f /. x -> 0.3)}]]\n\n", "graphics - Why is ListDensityPlot unable to plot datasets with extreme ranges": "\nThe reason why ListDensityPlot doesn't plot it is because the meshes aren't being generated correctly:\nListDensityPlot[data #, Mesh -> All, ImageSize -> 300] & /@ {1, 100, 10^3, 10^4}\n\n\nNow I don't know exactly how to fix this, but my guess is that the mesh function relies on the Delaunay triangulation of the set of points and somewhere in there, something is either dangerously close to machine precision or getting Chopped. Since the default tolerance for chopping is $10^{-10}$, it is plausible that this is what is happening.\n", "List-operations only when restrictions are fulfilled (Part 2)": "\nYou could define a transformation function according to \ntransform[list_] := Module[{n, y, u, res},\n  y = list[[1, 2]];\n  n = LengthWhile[list, #[[2]] == y&];\n  u = list[[n + 1, 2]];\n  res = (y - u)/n;\n  Join[Thread[{list[[;; n + 1, 1]], y + res}], list[[n + 2 ;;]]]]\n\nand map that to you transformed data list:\ndata = {{{3544128000, 80}, {3544732800, 80}, {3545337600, 80}, {3545942400, 80}, \n  {3545942400, 160}, {3546547200, 160}, {3547152000, 0}}};\ndata1 = Transpose[{#[[All, 1, 1]], Total[#[[All, All, 2]], {2}]}] & /@ \n  (GatherBy[#, First] & /@ data);\n\ntransform /@ data1\n\n\n{{{3544128000, 80/3}, {3544732800, 80/3}, {3545337600, 80/3}, \n  {3545942400, 80/3}, {3546547200, 160}, {3547152000, 0}}}\n\n\nBy the way, I get \ndata1 == {{{3544128000, 80}, {3544732800, 80}, {3545337600, 80}, {3545942400, 240}, \n  {3546547200, 160}, {3547152000, 0}}}\n\ninstead of \n{{{3544128000, 80}, {3544732800, 80}, {3545337600, 80}, {3545942400, 240},{3546547200, 160}}} \n\nas posted in the question which is why I get an extra term {3547152000, 0} in the result above. \n", "Coulomb potential as a Fourier transform": "\nThe problem here is that Mathematica doesn't recognize {x, y, z} as some kind of a vector object that should be treated as grouped together; instead, it substitutes in three independent variables, and probably starts integrating them one by one. The result is a very complicated integral.\nIf you do the coordinate transformation yourself, you can reproduce the result. Simply use $\\mathrm dp = \\mathrm d\\|p\\|\\|p\\|^2\\mathrm d\\vartheta\\sin(\\vartheta)$ to transform to spherical. The resulting integral can be calculated:\nAssuming[pAbs >= 0 && m > 0 && r > 0,\n    (1/(2*Pi)^3)*Integrate[ (* phi integral *)\n        Integrate[ (* |p| integral *)\n            Integrate[ (* theta integral *)\n                (Exp[I*r*pAbs*Cos[pTheta]]/(pAbs^2 + m^2))*pAbs^2*Sin[pTheta],\n                {pTheta, 0, Pi}\n            ],\n            {pAbs, 0, Infinity}\n        ],\n        {pPhi, 0, 2*Pi}\n    ]\n]\n\n\n$\\dfrac{e^{-mr}}{4\\pi r}$\n\n", "Possible to draw an Item in a Grid with only 3 sides of a Frame?": "\nHow about this?\nGrid[{{1, 2, 3}, {4, Item[5, Frame -> {{True, True}, {True, False}}], 6}}]\n\n\n", "list manipulation - Adding rules to permutations": "\nHaving no idea what sort of rules you might want to try. Here is a potential solution that generates the next permutation in lexicographic order and determines if it fits a particular criterion crit.\nGenerate next permutation where lst is the current permutation of Range[n], rng is the original range.\nnextP[lst_, rng_] :=\n Block[{k, l},\n  k = Pick[Most@rng, Thread[Most[lst] < Rest[lst]]];\n  If[k === {}, Return[{}]];\n  k = Last[k];\n  l = Pick[rng, Thread[lst[[k]] < lst]][[-1]];\n  Flatten[{#1[[1 ;; k]], Reverse[#1[[k + 1 ;; -1]]]}] &[\n   ReplacePart[lst, {k -> lst[[l]], l -> lst[[k]]}]]\n  ]\n\nThis takes a positive integer n and and a function crit.\nfilteredPermutations[n_Integer?Positive, crit_] :=\n Block[{res, rng},\n  res = rng = Range[n];\n  Reap[While[True, res = nextP[res, rng]; If[res === {}, Break[]]; \n     If[crit[res], Sow[res]]]][[2, 1]]\n  ]\n\nFor example, the permutations of Range[4] where the first element exceeds the last.\nfilteredPermutations[4, #[[1]] > #[[-1]] &]\n\n==> {{2, 3, 4, 1}, {2, 4, 3, 1}, {3, 1, 4, 2}, {3, 2, 4, 1}, {3,4, 1, 2},\n     {3, 4, 2, 1}, {4, 1, 2, 3}, {4, 1, 3, 2}, {4, 2, 1, 3}, {4, 2, 3, 1}, \n     {4, 3, 1, 2}, {4, 3, 2, 1}}\n\nNote: This is going to be pretty slow for even moderate n.\nEdit: This can be made quite a bit faster by using a compiled version of nextP.\nnextPC = Compile[{{lst, _Integer, 1}, {rng, _Integer, 1}},\n   Block[{out = lst, k = 1, n = Length[rng], \n     kbag = Internal`Bag[{-1}], lstk, l = 1, \n     lbag = Internal`Bag[{-1}]},\n    While[k < n,\n     If[lst[[k]] < lst[[k + 1]], Internal`StuffBag[kbag, k]];\n     k++\n     ];\n    k = Max[Internal`BagPart[kbag, All]];\n    If[k == -1,\n     lst\n     ,\n     lstk = lst[[k]];\n     While[l <= n,\n      If[lstk < lst[[l]], Internal`StuffBag[lbag, l]];\n      l++\n      ];\n     l = Max[Internal`BagPart[lbag, All]];\n     out[[k]] = lst[[l]];\n     out[[l]] = lst[[k]];\n     Join[out[[1 ;; k]], Reverse[out[[k + 1 ;; -1]]]]\n     ]\n    ]\n   ];\n\nThis one returns the last permutation rather than an empty list so we need a slightly modified version of filteredPermutations as well.\nfilteredPermutations2[n_Integer?Positive, crit_] := \n Block[{res, rng, rev}, res = rng = Range[n];\n  rev = Reverse[rng];\n  Reap[While[True, res = nextPC[res, rng]; \n     If[res === rev, If[crit[res], Sow[res]]; Break[]];\n     If[crit[res], Sow[res]]]][[2, 1]]]\n\nNow to test it. Here I'm looking for all permutations of Range[8] such that the last element is 1 and the second is even.  Note that direct computation is much faster so if its possible to store all of the permutations in memory at once, that will be the way to go.\nAbsoluteTiming[(r1 = filteredPermutations2[8, #[[-1]] == 1 && EvenQ[#[[2]]] &]);]\n\n==> {0.4524058, Null}\n\nAbsoluteTiming[(r2 = filteredPermutations[8, #[[-1]] == 1 && EvenQ[#[[2]]] &]);]\n\n==> {1.8564238, Null}\n\nAbsoluteTiming[(r3 = Select[Permutations[Range[8]], (#[[-1]] == 1 && EvenQ[#[[2]]]) &]);]\n\n==> {0.1092014, Null}\n\nr1 == r2 == r3\n\n==> True\n\n", "list manipulation - Threading behavior of SameQ vs. Equal": "\nThread doesn't hold its arguments. You can check its attributes.\nSo, before doing any threading, it evaluates its arguments. \nNow, understanding the behaviour you describe requires understanding the difference between Equal and SameQ. Equal is meant for math reasoning. For expressing an equality, which might involve a variable that at the time you don't yet know it's value. So, for example, x==8 returns unevaluated if x isn't defined.\nSameQ however is a predicate. It will always return either True or False if the constructs are exactly the same (after evaluation). \nSo, Thread[SameQ[{aa, bb, cc}, {dd, ee, ff}]] -> Thread[False]-> False\nOne can see this by running (thanks @rcollyer)\nTrace[Thread[SameQ[{aa, bb, cc}, {dd, ee, ff}]], \n TraceInternal -> True]\n\nOut[1] = {{{aa, bb, cc} === {dd, ee, ff}, False}, Thread[False], False}\n\nIf you want to thread SameQ without evaluation, just use Unevaluated\nThread[Unevaluated@SameQ[{aa, bb, cc}, {dd, ee, ff}]]\n\n{False, False, False}\n\nAnother construction that gives the result you want is the one suggested by @kguler in his comment and supported by @rcoller and his upvoters: MapThread. I'd suggest you search the docs if you don't know it\nMapThread[SameQ, {{aa, bb, cc}, {dd, ee, ff}}]\n\n", "equation solving - Number of iterations in NSolve": "\nThe main algorithm behind NSolve is, I believe, the Jenkins-Traub algorithm, which is indeed iterative in nature.  I don't believe that you can specifiy the number of iterates directly, however.  Isn't it better to specify the desired precision, though?  Mathematica tries to find the solution to a certain precision, and you can specify the precision that you want, as in\neqs = {R1==fR1, R2==fR2, P4==fP4, rho==fRho};\nsols= NSolve[eqs, {P2, P4, a, rho}, Reals,\n  WorkingPrecision -> 20];\n\nYou can always check the quality of the results, as well, using something like so:\n(#[[1]] - #[[2]] & /@ eqs) /. sols\n\nThis will let you know exactly how close you are on each equation.\n", "probability or statistics - How can an InverseQuantile or an interval valued Quantile function be implemented in Mathematica?": "\nSomething like this should be close:\nInverseQuantile[list_, x_] := LengthWhile[list // Sort, # <= x &]/Length[list]\n\nDepending on your definition of quantiles you may choose to have the test be # < x & or # <= x &\nThis is with # <= x &:\nTable[\n   {x, Quantile[{1, 2, 2, 4}, InverseQuantile[{1, 2, 2, 4}, x]]}, \n   {x, 1, 4, 0.1}\n ]\n\n(* ==> {{1., 1}, {1.1, 1}, {1.2, 1}, {1.3, 1}, {1.4, 1}, {1.5, 1}, {1.6, 1}, \n {1.7, 1}, {1.8, 1}, {1.9, 1}, {2., 2}, {2.1, 2}, {2.2, 2}, {2.3, 2}, \n {2.4, 2}, {2.5, 2}, {2.6, 2}, {2.7, 2}, {2.8, 2}, {2.9, 2}, {3., 2}, \n {3.1, 2}, {3.2, 2}, {3.3, 2}, {3.4, 2}, {3.5, 2}, {3.6, 2}, {3.7, 2}, \n {3.8, 2}, {3.9, 2}, {4., 4}} *)\n\nor, with Interval:\nInverseQuantile[list_, x_] := \n Interval[\n  {\n   LengthWhile[list // Sort, # < x &]/Length[list], \n   LengthWhile[list // Sort, # <= x &]/Length[list]\n  }\n ]\n\nInverseQuantile[{1, 2, 2, 4}, #] & /@ {0, 0.5, 1, 1.5, 2, 3, 4, 5}\n(* {Interval[{0, 0}], Interval[{0, 0}], Interval[{0, 1/4}], Interval[{1/4, 1/4}], \n    Interval[{1/4, 3/4}], Interval[{3/4, 3/4}], Interval[{3/4, 1}], Interval[{1, 1}]} *)\n\nAnother approach would be to base InverseQuantile on empirical distributions and their CDF. Two possibilities are:\nInverseQuantile[list_, x_] := CDF[SmoothKernelDistribution[list], x]\n\nInverseQuantile[list_, x_] := CDF[HistogramDistribution[list], x]\n\nTable[\n   {x, Quantile[{1, 2, 2, 4}, InverseQuantile[{1, 2, 2, 4}, x]]}, \n   {x, 1, 4, 0.1}\n ]\n\n    (* ==> {{1., 1}, {1.1, 1}, {1.2, 1}, {1.3, 1}, {1.4, 1}, {1.5, 1}, {1.6, 2},\n            {1.7, 2}, {1.8, 2}, {1.9, 2}, {2., 2}, {2.1, 2}, {2.2, 2}, {2.3, 2},\n            {2.4, 2}, {2.5, 2}, {2.6, 2}, {2.7, 2}, {2.8, 2}, {2.9, 2}, {3., 2},\n            {3.1, 2}, {3.2, 2}, {3.3, 4}, {3.4, 4}, {3.5, 4}, {3.6, 4}, {3.7, 4}, \n            {3.8, 4}, {3.9, 4}, {4., 4}} *)\n\n", "Finding a vector field from a set of points": "\nI'll try to give you an answer complementary to Szabolcs\u2019, because I understood your question in another way. If by \u201cget a gradient using the points I have\u201d you mean having a continuous color gradient in your plot of the data (and not calculating a gradient, as in \u201cderivative\u201d), then you can simply use DensityPlot with an Interpolation.\nLet's get some data, taken at random points from the function $z=\\sin x\\ \\sin y$:\npoints = RandomReal[{-5, 5}, {500, 2}];\ndata = {#1, #2, Sin[#1]*Sin[#2]} & @@@ points;\n\nthen plot it:\nDensityPlot[\n Interpolation[data, InterpolationOrder -> 1][x, y], {x, -5, \n  5}, {y, -5, 5}, PlotRange -> {Full, Full, {-1, 1}}]\n\n\nwhich you can compare to the original function I drew points from:\nDensityPlot[Sin[x]*Sin[y], {x, -5, 5}, {y, -5, 5}]\n\n\n", "plotting - BoxWhiskerChart too slow on big datasets, how to speed it up?": "\nEven on my rather old laptop, calculating the various statistics used for plotting the whisker of data sets of that size takes less than a minute so I suspect the problem is the number of groups rather than the number of records in each group. For each box in your plot, Mathematica generates a Tooltip containing a DynamicsBox. With 300 boxes, this will slow down the front end quite a lot. \nIt's a bit more involved than using BoxWhiskerChart out of the box, but as an alternative you could build a chart by hand using graphics primitives, for example\nplot[data_] := DynamicModule[{n, min, max, q25, med, q75, fun},\n  n = Length[data];\n  {min, q25, med, q75, max} = \n   Transpose[\n    Through[{Min, Quantile[#, 1/4] &, Median, Quantile[#, 3/4] &, Max}[#]] & /@ data];\n  fun[dat_] := Transpose[{Range[n], dat}];\n  Dynamic[Tooltip[Graphics[{\n        {LightGray, Polygon[Join[fun[min], Reverse@fun[max]]]},\n        {LightBlue, Polygon[Join[fun[q25], Reverse@fun[q75]]]},\n        {Thick, Black, Line[fun[med]]},\n        {Gray, Line[{{#, min[[#]]}, {#, max[[#]]}}]},\n        {Thick, Blue, Line[{{#, q25[[#]]}, {#, q75[[#]]}}]}}, \n       Axes -> True, AspectRatio -> 1/GoldenRatio],\n      Grid[{{\"Index\", #}, {\"Max\", max[[#]]}, {\"75%\", \n         q75[[#]]}, {\"Median\", med[[#]]}, {\"25%\", q25[[#]]},\n        {\"Min\", min[[#]]}}, Frame -> All]] &@\n    Clip[Round[MousePosition[\"Graphics\"] /. None -> {1}][[1]], {1, n}]]]\n\ndata = Table[RandomVariate[NormalDistribution[i, i^2], 1000], {i, .1, 1, 1/300}];\n\nplot[data]\n\n\nHere, I've chosen to plot the boxes and whiskers as polygons since with 300 boxes side-by-side it's hard to distinguish the individual boxes anyway. \n", "mathematical optimization - Strange domain dependency with Maximize": "\nAs Szabolcs stated, Maximize is calling NMaximize.\nThe problem is that the call is not being done with appropriate options for your case. Just compare for example:\nNMaximize[{x*(1 - 0.01 x), x \u2208 Integers}, x]\n(*\nx-> 19\n*)\n\nwith\nNMaximize[{x*(1 - 0.01 x), x \u2208 Integers}, x, MaxIterations -> 300]\n(*\nx-> 50\n*)\n\nTo understand better what is happening you may see the evaluation process:\nf[x_] := x*(1 - .01 x);\n{sol, pts} = Reap[\n   NMaximize[{f[x], x \u2208 Integers}, x, MaxIterations -> 300,  \n    EvaluationMonitor :> Sow[{x, f[x]}]]];\n{sol1, pts1} = Reap[\n   NMaximize[{f[x], x \u2208 Integers}, x,  \n    EvaluationMonitor :> Sow[{x, f[x]}]]];\n\nGraphicsGrid[{{\n   Plot[f[x], {x, 0, 100}, Epilog -> Map[Point, Cases[First[pts] , x_]]],\n   Plot[f[x], {x, 0, 100}, Epilog -> Map[Point, Cases[First[pts1], x_]]]}}]\n\n\nEdit\nAs Szabolcs  commented below, the evaluation process is far from efficient.\nHere you have the number of evaluations done for each integer x while the algorithm is trying to find the Max:\nHistogram[(First@pts1)[[All, 1]], {-1, 20, 1}, AxesLabel -> {\"x\", \"# of evals\"}]\n\n\nEdit\nYou could run\nHistogram[Select[Length /@ Split@(First[pts1][[All, 1]]), # > 1 &]]\n\nTo see that it evaluates the same x several times is a row!\n", "databaselink - How can I connect to a database using the 32 Bit ODBC on a Windows 7 (64 Bit) machine?": "\nYou might be facing the problem documented in Microsoft's knowledge base as KB942976.  In a nutshell, the system call that enumerates DSNs on a 64-bit system will also list 32-bit DSNs -- even though those DSNs cannot be accessed from a 64-bit application.  The knowledge base article states that there is no current resolution to this problem in the interest of backward compatibility (?).\nIt seems that you have only two choices:\n\nRun the 32-bit version of Mathematica to continue using the 32-bit DSN, or\nCreate a new 64-bit DSN for use with 64-bit Mathematica.\n\n", "compile - tol and None in output of CompilePrint": "\nWithout seeing the code that generated the above this is only a guess. If you look in: \nFileNameJoin[{$InstallationDirectory, \"AddOns\", \"Applications\", \n  \"CompiledFunctionTools\", \"PrintCode.m\"}]\n\nyou'll find a line:\ntoInfixForm[_] := None\n\nAll infix form conversions not known (i.e. in that list in that file) are replaced by None.\nIt would be good to find out which expr is not mentioned in the toInfixForm such that it can be added. Presumably this is some compare function. In that same file you will also find tol.\n", "plotting - How can I influence the spaces between labels on a BarChart": "\nHere's one approach, which modifies the labels slightly to shift some of the labels down a bit.\nBarChart[datalist[[All, {2, 3}]], ChartLayout -> \"Stacked\", \n   ChartLabels -> {\n      MapIndexed[If[OddQ[First[#2]], #, Column[{\"\", #}]] &, Transpose[datalist][[1]]], \n      None\n      }]\n\n\n", "Question about scoping data in a multi-level Manipulate construction": "\nHow about this:\nDynamicModule[{k},\n  Manipulate[\n   Column[{j,\n     Manipulate[k, {k, 1, 5, 1}, LocalizeVariables -> False],\n     Button[\"Check\", Print[k]]\n   }],\n   {j, 1, 10, 1}]\n]\n\n", "equation solving - Using the Krylov method for Solve: Speeding up a SparseArray calculation": "\nI found a way to dramatically improve the performance of this algorithm by using the undocumented function SparseArray`KrylovLinearSolve. The key advantage of this function is that it seems to be a near-analog of MATLAB's pcg, and as such accepts as a first argument either:\n\na square matrix, or a function generating a vector of length equal to the length of the second argument.\n\nOne may discover this by giving incorrect arguments and noting the advice given in the messages produced as a result, in much the same way as one discovers the correct arguments for any undocumented function. In this case the message is SparseArray`KrylovLinearSolve::krynfa.\nYou only need to change one line in your code to use it, namely:\ns = SparseArray`KrylovLinearSolve[\n     alph l.# + AT[A[#]] &, g, \n     Method -> \"ConjugateGradient\", \"Preconditioner\" -> (p.# &), \n     Tolerance -> tol, MaxIterations -> maxit\n    ];\n\nwhere maxit should preferably be Automatic (meaning 10 times the size of the system to be solved) or larger. With the data given in your question it takes a few hundred iterations to converge to a tolerance of $10^{-4}$, but each iteration is quite fast, so it seems to make more sense to adjust the tolerance than the number of iterations if performance is still an issue. However, while I didn't investigate this, needing this many iterations to converge to a relatively loose tolerance may of course be symptomatic of a poorly conditioned system, so using a different preconditioner or the biconjugate gradient stabilized method (\"BiCGSTAB\") could perhaps reduce the number of iterations required.\nYou will note that the options are exactly the same as for LinearSolve's \"Krylov\" method, so we may surmise that this function is probably called more or less directly by LinearSolve when Method -> \"Krylov\" is specified. In fact, if we assume that this is indeed the case and try\ns = LinearSolve[\n     alph l.# + AT[A[#]] &, g, \n     Method -> {\"Krylov\",\n       Method -> \"ConjugateGradient\", \"Preconditioner\" -> (p.# &), \n       Tolerance -> tol, MaxIterations -> maxit\n      }\n    ];\n\nwe find that it works equally well, so evidently LinearSolve does in fact provide just the same functionality as pcg as far as the first argument is concerned, but without this actually being documented anywhere as far as I can tell. So, the overall conclusion is that you can just use LinearSolve directly after all.\n", "Is there a way to print out SQL queries made using DatabaseLink?": "\nIf you have full control over the MySQL database I think it lets you log every SQL statement from every client (query-log), which probably is the most simple way to get that information. You could also try to look at or even manipulate the sources, it looks like the relevant code is delivered as clear text in the following file in the Mathematica directory: SystemFiles/Links/DatabaseLink/Kernel/SQL.m. It isn't an easy read though and some of the relevant stuff might be buried in one of the java classes, but there seem to be sources also for those, if you really want to dig deep...\n", "string manipulation - Interpreting text entry and splitting it in a Manipulate text field?": "\nI think you can just use StringSplit at Whitespace characters.\nHere is a toy example that might get you started.\nManipulate[\n PieChart[MapThread[Labeled[#2, #1] &, \n   Transpose[Tally@StringSplit[ngram, Whitespace]]]], {{ngram, \n   \"One fish two fish red fish blue fish\", \"n-gram\"}}]\n\n\n", "finance - How do I define the \"Coupon\" within the function FinancialBond with a time-varying coupon": "\nThe More Information section of the help file says\n\n\nThe coupon may be specified as a single rate or a time-dependent payment function.\n\n\nSo, you should use\n\"Coupon\" -> (Piecewise[{{.04125, #1 < 3}, {.06, 3 <= #1 < 5}, {.0775, 5 <= #1 < 7}}] &)\n\nFor example,\nFinancialBond[{\"FaceValue\"->100,\n \"Coupon\" -> (Piecewise[{{.04125, #1 < 3}, {.06, 3 <= #1 < 5}, {.0775, 5 <= #1 < 7}}] &),\n \"Maturity\"->5},{\"InterestRate\"->r,\"Settlement\"->0}]\n\noutputs\n(* 100/(1+r)^5+(0.00125 (224.+375. r+345. r^2+165. r^3+33. r^4))/(1.+r)^5 *)\n\n", "graphics - Shading in squares crossed by a diagonal": "\nYou could do something like this\nManipulate[\n DynamicModule[{ptlst, height, length},\n  {length, height} = Round[pt];\n  ptlst = \n   Floor[1 + {height, length} #] & /@ \n    MovingAverage[\n     Union@Join[Range[0, 1, 1/length], Range[0, 1, 1/height]], 2];\n  Show[ArrayPlot[SparseArray[Thread[ptlst -> 1]], Mesh -> True, \n    MeshStyle -> Gray, DataReversed -> True],\n   Graphics[{Red, Line[{{0, height}, {length, 0}}]}],\n   PlotRange -> {{-1, 21}, {-1, 21}},\n   GridLines -> {Range[0, 21], Range[0, 21]},\n   GridLinesStyle -> LightGray]],\n {{pt, {10, 10}}, {1, 1}, {20, 20}, {1, 1}, Locator}\n ]\n\n\nExplanation of the code\nWe're representing the squares in the rectangle by an array of 0's and 1's. We're assuming that the rectangle has dimensions {length, height} and is aligned with the origin.  The array is such that the unit square with lower left corner {k,l} corresponds to the element at index {l + 1, k + 1} in the array (the reversal of indices is because ArrayPlot plots an m by n array as a n by m rectangle).\nThe diagonal from {0,0} to {length, height} can be parameterized by {length, height} t where 0<=t<=1. To find all squares that are intersected by this diagonal, we first calculate the intersection points of the diagonal with the grid, i.e. we find a list of values for t such that either length t or height t is an integer. For two consecutive elements in this list, t0 and t1, the line segment from {length, height} t0 to {length, height} t1 will lie completely within one unit square. The coordinates of the lower left corner of this square are equal to Floor[{height, length} (t0+t1)/2] which corresponds to the element at index 1 + Floor[{length, height} (t0+t1)/2] in the array. \n", "MatchQ and patterns for similar lists": "\nThe following patterns give the required output:\np1 = p : {{_?NumericQ} ..} /; ! Equal @@ p\np2 = {{s_?NumericQ} ..};\n\n\nMatchQ[#[[1]], #[[2]]] & /@ Tuples[{{list1, list2}, {p1, p2}}]\n\n(*\n==> {True, False, False, True}\n*)\n\n", "list manipulation - Computing the distance between two curves obtained from image data?": "\nLets start with an example image\nimg = Binarize@\n  Image[Plot[{Sin[2 x], 2 + Cos[3 x]}, {x, 0, 2 Pi}, Axes -> False, \n    PlotStyle -> Black, Background -> White, ImagePadding -> None, \n    PlotRangePadding -> {None, .1}]]\n\n\nTo find the distance between the two curves you could do something like\ndata = ImageData[img];\nw = Dimensions[data][[2]];\nscale = .1/w;\n\naverageRadiusList = Reap[Sow @@@ Position[data, 0], Range[w],\n    {scale #1, scale (Max[#2] - Min[#2])/2} &][[2, All, 1]];\n\nListPlot[averageRadiusList]\n\n\nWhat this code does is to find the indices of all black points in img. The combination of Sow and Reap will effectively group these coordinates by their column index and for each group return {scale c, scale (Max[rows]-Min[rows])/2} where c is the column index, and rows is a list of row indices of all black points in the plot that have column index c.\n", "plotting - Labeling individual curves in Mathematica": "\nYou can make use of the following options in Plot, e.g. :\nPlot[ Tooltip @ {x^2, x^3, x^4}, {x, -2, 2}, \n      PlotStyle -> {Red, Green, Blue}, \n      PlotRangePadding -> 1.1] /. {Tooltip[{_, color_, line_}, tip_] :>   \n                                   {Text[Style[tip, 14], {.1, 0} + line[[1, -1]]], color, line}}\n\n\nUpdate (05.02.2016)\nTried the above code in Mathematica 10.3.1 and it did not work. This code works:\nPlot[Tooltip@{x^2, x^3, x^4}, {x, -2, 2}, \n  PlotStyle -> {Red, Green, Blue}, \n  PlotRangePadding -> \n   1.1] /. {Tooltip[{___, dir_Directive, line_Line, ___}, \n    tip_] :> {Text[Style[tip, 14], {.1, 0} + line[[1, -1]]], dir, \n    line}}\n\nEdit\nSince there was another question in the comments I add another way of labeling curves. \nIf we have to plot a graph of a family of certain functions, and insert its definition i.e.\n\nwe can make use of Drawing Tools in the Front End (a shortcut Ctrl-D)  to insert some text supplemented by appropriate arrows pointing only  a few of all functions.\nWe paste a simple text i.e. output of Text[Style[\"n = 13\", Large, Bold, Blue]] or the definition of the functions, by double-clicking the right button of the mouse, next once the left one and selecting from menu Paste into Graphic to insert a data from the clipboard. Similarly we choose arrows from the section Tools of Drawing Tools and adjust them by dragging apprporiately.  Alternatively to pasting the definition of functions with Drawing Tools, we can make use of also PlotLabel option of Plot to insert it, i.e. PlotLabel -> Subscript[f, n][x] == (1 - x^2/6 + x^4/120)^n \nPlot[ Evaluate[(1 - x^2/6 + x^4/120)^n /. n -> Range[1, 30, 3]], {x, 0, Sqrt[6] },\n      AspectRatio -> Automatic, AxesOrigin -> {0, 0}, PlotStyle -> Thick ]\n\n\n", "import - Is it possible to use Mathematica to record sound and/or vision?": "\nSystemDialogInput[\"RecordSound\"] will bring up a dialog that let's you record sound.  It works both on Windows and Mac in v9, but only on Windows in earlier versions.  It doesn't work on Linux.\nBut what if you need to record sound without user interaction, and you want to avoid a modal dialog?  The right way is to use some external and documented tool (e.g. sox), but I happened to try to dissect the \"RecordSound\" dialog, and here are the results.  These may be Mac-specific.\nOn Mac, I believe some sort of initialisation may be needed, but I'm not entirely sure.  Evaluating\nFrontEndExecute[FrontEnd`RecordSound[7, 0]]\nFrontEndExecute[FrontEnd`RecordSound[8, 0]]\n\nwill probably do this.  This is the least clear point so far.  This may not be needed on Windows.\nNow,\n\nFrontEndExecute[FrontEnd`RecordSound[5]] will list the available devices by number\nFrontEndExecute[FrontEnd`RecordSound[6, deviceNumber]] will list the available formats for the device\nFrontEndExecute[FrontEnd`RecordSound[1, deviceNumber, formatNumber]] will start recording.  It returns control immediately.\nFrontEndExecute[FrontEnd`RecordSound[2]] will stop recording and return the duration.\nFrontEndExecute[FrontEnd`RecordSound[3]] will return the recorded sound (it's the \"OK\" button in the dialog)\nFrontEndExecute[FrontEnd`RecordSound[4]] will probably discard the recorded sound (it's the Cancel button)\nFrontEndExecute[FrontEnd`RecordSound[9, 0]] will return the current volume of the recorded sound, and is used for the progress indicator in the dialog.\n\nWarning: This functionality is undocumented, and not meant for end users. I'm just guessing at how it works.  There's a real risk that playing with these will crash your front end, mess up its internal state or will cause a memory leak.  Use at own risk.\n", "programming - Is there an open source implementation of Mathematica-the-language?": "\nI've been collecting these links for a while, so this question is a good excuse for a link dump. I'm not sure which project is the \"best\", but I think that mathics and symja are two of the more active and developed projects.\nLisp:\nMockMMA is probably the first implementation of the Mathematica language. It was written by Richard Fateman who had a bit of a scuffle with Wolfram Research over the code.\nPython:\nMathics (which you mentioned in the question) is primarily a syntax layer ontop of sympy and sage, not an independent implementation of the Mathematica language.\nPythonica is an abandoned python implementation of Mathematica.\nJava:\nsymja is a pure Java library for symbolic mathematics that uses Mathematica notation and supports Rubi Integration rules.\nomath is an project that is still under development that will have a Mathematica like syntax, but does not aim to blindly copy Mathematica.\nGo:\nexpreduce an experimental computer algebra system written in Go.\n\nThe omath page also has some interesting links to papers describing some of the Mathematica language's algorithms:\nMatching in flat theories by Temur Kutsia.\nA detailed description of Mathematica's flat pattern matching. (But quite technical!) (original link)\nMathematica as a Rewrite Language by Bruno Buchberger.\nOn the implementation of a rule-based programming system and some of its applications by Mircea Marin and Temur Kutsia.\nThese people obviously understand Mathematica's pattern matching enumeration system forwards and backwards.\nDiscussions about whether computer languages can be copyrighted, 1, 2, 3.\n", "java - Efficiently deleting rows in many large text files": "\nIf you'll accept solutions involving other technologies, then how about using sed? On a unix system, to read in file1, delete row n and output to file2, you'd do:\nsed -e 'nd' file1 > file2\n\nThe quotes in 'nd' are not necessary in this case, since there is only one instruction. However, if you're doing more complicated stuff with regular expressions, you should include the quotes so that the regex is not interpreted as something else. So it's safer to include it in general.\nIf you want to edit the file in place, then the command is\nsed -i '' -e 'nd' test\n\nNote that the ''after -i is necessary if you don't want a backup. If you omit that then sed assumes that the extension is being supplied via stdin, introducing additional files (which really are backups). \nIf you want to backup your file, just in case, then use -i.abc where abc is any string of your choice (need not be limited to 3 chars) and the file will be backed up to file.abc.\nYou can now run any of these commands from Mathematica via Run[command] (where command is the string with the actual command). Of course, replace n above with your actual row number or if variable, modify Run[...] accordingly.\n\nI don't use Windows, but cygwin should provide you with a linux environment for Windows.\nIf you only require sed then cygwin is an overkill (takes a lot of space and is quite slow). A native build of sed can be found as part of GnuWin32. Download here.\n", "plotting - Create a CDF file with a plot that cannot be edited by double-clicking": "\nWrap the output of the CDF (the Plot command in your case) into Deploy, or add the Deployed -> True option to your Manipulate.\nUsing the Deployed option however does not solve all the problems. The documentation states, that Deployed -> True disables:\n\n...general editing and selection in a cell\n\nGeneral editing/selection means that in the following example one can not select individual expressions of the list (e.g. \"text\"), but still graphics editing is possible, as the screenshot clearly shows:\nManipulate[{\"text\", Plot[x^n, {x, 0, 3}]}, {n, 0, 10}, Deployed -> True]\n\n\nThus to make output really bulletproof, wrap each Graphics object into Deploy as well:\nManipulate[{\"text\", Deploy@Plot[x^n, {x, 0, 3}]}, {n, 0, 10}, Deployed -> True]\n\n", "ocr - Can TextRecognize read digits?": "\n(* Get your image *)\ndigits = ImagePartition[Import[\"http://i.stack.imgur.com/cLncR.png\"], 50];\n\n(* Remove Borders and Binarize *)\nd1 = Binarize[ImageCrop[#, 37], .5] & /@ Flatten@digits;\n\n(* Keep only images with content (blanks affect the OCR) *)\nd2 = Select[d1, Min@ImageData@# == 0 &];\n\n(* Assemble as a line and \"read\" *)\nTextRecognize@ImageAssemble@d2\n(*\n-> \"64776958729385431752328231\"\n*)\n\nEdit\nThe following will reassemble your original image (but cleaner)\ntr    = TextRecognize@ImageAssemble@d2;\nposd2 = Flatten@Position[d1, x_ /; Min@ImageData@x == 0, {1}];\ntp2   = Thread@List[posd2, Characters@tr];\n(d1[[#[[1]]]] = Graphics[Text[Style[#[[2]], Large]], ImageSize -> 37]) & /@ tp2;\nia    = ImageAssemble@Partition[ImageCrop[#, 39] & /@ d1, 9]; \nia1   = Map[ImageCrop[#, ImageDimensions@ia/3 + 3] &, \n            ImagePartition[ia, ImageDimensions@ia/{3, 3}], {2}];\n\nGraphicsRow[{ImageAssemble@ia1, ImageAssemble@digits}]\n\n\n", "Symmetric difference of a sample of lists": "\nI think you are looking for this:\nComplement[Join[list1, list2, list3], \n Intersection[list1, list2, list3]]\n\nor as suggested in the comments:\nComplement[Union[list1, list2, list3], \n Intersection[list1, list2, list3]]\n\n(*\n=> {a, b, e, f, g, h}\n*)\n\nNote, that the h is present here but not the d. I assume this is a typo in the question.\n", "notebooks - How to make an unremovable modal window?": "\nNot 100% solution, but this may work. Define:\ndialog := \n CreateDialog[{TextCell[\"Click OK to close\"], DefaultButton[]}, \n  Modal -> True, NotebookEventActions -> {\"WindowClose\" :> dialog}]\n\nThen call:\ndialog\n\nAt least, it reappears :)\n", "Match patterns on list of Strings": "\nI am not sure how to do this using DeleteCases, but you can still use the Select function:\nSelect[data, StringTake[#, 1] != \"A\" &]\n\nwhich has the desired result.\nEdit Actually, you can also use DeleteCases like this:\nDeleteCases[data, _?(StringTake[#, 1] == \"A\" &)]\n\n", "plotting - Legend of a plot: how to increase the size of the line/marker?": "\nIf you're willing to abandon PlotLegends (which tkott advises in the comment and  many others would advise too), then you could work with the code posted in this related answer to achieve some customization. You'll have to execute the definitions in that post before trying the lines below.\nTake the following two plots which generate the same curve first as a line and then as points from a table, using plot markers:\np = Plot[Evaluate[Table[1/x + i, {i, 0, 3, 1}]], {x, 0, 3}, \n   PlotRange -> {0, 3}];\nq = ListPlot[\n   Table[Evaluate@Table[{x, 1/x + i}, {x, .5, 3, .5}], {i, 0, 3, 1}], \n   PlotRange -> {0, 3}, PlotMarkers -> Automatic];\n\nNow simply say\nautoLegend[Show[p, q], {\"Asymptote 1\", \"Asymptote 2\", \"Asymptote 3\"}]\n\nand the result is this:\n\nYou could replace autoLegend by deployLegend above if you want to be able to edit the result as a graphic. To customize the sizes inside the legend, I'll add some options:\nautoLegend[Show[p, q], {\"Asymptote 1\", \"Asymptote 2\", \"Asymptote 3\"},\n \"LegendLineWidth\" -> 20,\n \"LegendLineAspectRatio\" -> .5,\n \"LegendGridOptions\" -> {Alignment -> Left, Spacings -> {1, 1}}]\n\n\nThe \"LegendGridOptions\" setting takes the same options as Grid and determines the horizontal and vertical space between entries in the legend. The \"LegendLineWidth\" and \"LegendLineAspectRatio\" have to be changed in tandem to get the markers and lines to fill the space properly. \nEdit\nIf the two plots p and q represent independent data (such as experimental  data versus theory curves), then the legend should have six instead of three entries. This is something autoLegend isn't able to figure out, so we have to do it using the lower-level function legendMaker. It needs to be given the styles for the lines and markers explicitly, as lists of six entries each. To specify that there should be no line or no marker, use the entry None.\nThe following example first defines the text for the legend, and the styles that appear in the two plots:\ntextLabels = \n  Map[Style[#, FontFamily -> \"Helvetica\", \n     GrayLevel[.9]] &, {\"Asymptote 1\", \"Asymptote 2\", \"Asymptote 3\", \n    \"Data 1\", \"Data 2\", \"Data 3\"}];\n\nplotstyles = Map[ColorData[1][#] &, Range[3]];\n\nmanualPlotstyles = Join[plotstyles, {None, None, None}];\n\nmarkers = {Style[\"\\[FilledCircle]\", Hue[0.67, 0.6, 0.6], \n    FontSize -> 8.96], \n   Style[\"\\[FilledSquare]\", Hue[0.9060679774997897, 0.6, 0.6], \n    FontSize -> 8.96], \n   Style[\"\\[FilledDiamond]\", Hue[0.1421359549995791, 0.6, 0.6], \n    FontSize -> 10.88]};\n\nmanualMarkers = Join[{None, None, None}, markers];\n\nIn the variables manualPlotstyles and manualMarkers, I added None in the list positions where either the line or the marker should be omitted. The result is overlayed with the combined plots (produced by Show):\nOverlay[{\n  Show[p, q, PlotLabel -> Style[\"Comparison\", \"Subsection\"]],\n  legendMaker[\n   textLabels,\n   PlotStyle -> manualPlotstyles,\n   PlotMarkers -> manualMarkers,\n   Background -> Directive[Opacity[.5], Black],\n   \"LegendLineAspectRatio\" -> .3,\n   \"LegendGridOptions\" -> {Alignment -> Left, Spacings -> {.7, .1},\n     Background -> {{GrayLevel[.8], None}, None}\n     }\n   ]},\n Alignment -> {-.8, -.7}]\n\n\nThis shows how some of the optional parameters can be used to get a different legend appearance.\n", "functions - How to convert binary float to decimal float": "\nYou need to get the RealDigits first:\nFromDigits[RealDigits[1.111111], 2]\n\nThis gives (after N) 1.98438 which matches the value solved for here.\nIf you want to work between any two bases, say you wanted to know how to write the number 18 in hex:\nFromDigits[RealDigits[18, 16]]\n\n(* Out[]:= 12 *)\n\nAlternatively, if you just want to \"know\" what the number is, without needing to compute with it, you can use BaseForm:\nBaseForm[18, 16]\n\n", "How to create a list of pairs from 1d list(s)?": "\nAd. 1\nordering  not valid:\nSubsets[A, {2}]\n\n\n{{1, 2}, {1, 3}, {2, 3}}\n\n\nor with ordering\nPermutations[A, {2}]\n\nAd. 2\nOuter[List, A, B]\n\n\n{{{1, a}, {1, b}, {1, c}}, {{2, a}, {2, b}, {2, c}}, {{3, a}, {3, b}, {3, c}}}\n\n\nor exactly\nOuter[List, A, B] // Flatten[#, 1] &\n\n\n {{1, a}, {1, b}, {1, c}, {2, a}, {2, b}, {2, c}, {3, a}, {3, b}, {3, c}}\n\n\n", "replacement - How to replace all occurrences of an element in a list?": "\nYou can use:\nlist /. {2 -> \"Test\"}\n\n(* Out[]:= {1, \"Test\", \"Test\", \"Test\", 3} *)\n\n", "list manipulation - Append in For loop does not work": "\nHow about:\nresult = {};\nFor[i = 0, i < 6, i++, \n s = Check[If[i == 3, Message[FindRoot::jsing, x, 1], i], \"Nan\", \n   FindRoot::jsing];\n Print[s];\n If[s == \"Nan\", Break[], result = {result, s}];]\nFlatten[result]\n\nor\nresult = {};\nFor[i = 0, i < 6, i++, \n s = Check[If[i == 3, Message[FindRoot::jsing, x, 1], i], \"Nan\", \n   FindRoot::jsing];\n Print[s];\n If[s == \"Nan\", Break[], AppendTo[result, {s, dim}]];]\nresult\n\n", "graphs and networks - Coloring edges in GraphPlot": "\nl = {{1, 3}, {3, 4}};\nGraphPlot[{1 -> 2, 3 -> 4, 1 -> 3, 2 -> 4, 1 -> 2, 3 -> 4}, \n EdgeRenderingFunction -> (If[\n     Intersection[l, {#2}] != {}, {Red, Arrow[#1, .1]}, \n                                  {Blue,Arrow[#1, .1]}] &)]\n\n\nEdit\nUsing edge labels:\nl = {1, 3};\nGraphPlot[{{1 -> 2, 1}, {3 -> 4, 2}, {1 -> 3, 3}, {2 -> 4, 4}, {1 -> 2, 5}, {3 -> 4, 6}}, \n EdgeRenderingFunction -> (If[\n     Intersection[l, {#3}] != {}, {Red, Arrow[#1, .1]}, {Blue, Arrow[#1, .1]}] &)]\n\n\n", "list manipulation - Reproducing nested loops using Map?": "\nIs this what you want?\nl1 = {a, b, c};\nl2 = {aa, bb, cc};\nsth[#1, #2] & @@@ Tuples[{l1, l2}]\n\n\n{sth[a, aa], sth[a, bb], sth[a, cc], sth[b, aa], sth[b, bb], \n sth[b, cc], sth[c, aa], sth[c, bb], sth[c, cc]}\n\n\n", "plotting - Joining only particular dates with DateListPlot": "\nAdd in a Null data point to each series like this:\ndataset1 = {{{1997}, 98/79}, {{1998}, 26/61}, {{1999}, \n    22/15}, {{2000}, 100/63}, {{2001}, Null}, {{2007}, \n    284/57}, {{2008}, 226/31}, {{2009}, 15/4}, {{2010}, 221/63}};\n\ndataset2 = {{{1997}, 25/79}, {{1998}, 17/61}, {{1999}, \n    28/25}, {{2000}, 20/21}, {{2001}, Null}, {{2007}, \n    106/57}, {{2008}, 128/31}, {{2009}, 59/16}, {{2010}, 32/9}};\n\nThe plot then becomes:\nDateListPlot[{dataset1, dataset2}, Joined -> True]\n\n\n", "list manipulation - Problem with Union and Intersection": "\nYou're looking for Apply\n\nApply[Union, list]\n\nwhich can be written in short form as \nUnion@@list\n\n", "algebraic manipulation - Why doesn't Mathematica  expand Cos[x]^3 Sin[x]^2?": "\nThe function you want for this kind of case is TrigReduce:\n\nTrigReduce[expr]\n  rewrites products and powers of trigonometric\n  functions in expr in terms of trigonometric functions with combined\n  arguments.\n\nAnd it works:\n\n", "performance tuning - Data fitting with Image processing feature detection": "\nYou can use image processing like in the example below to find the enclosing circle. I use FillingTransform to fill in the binarized image, which gives something like the plot on the left. Then using ComponentMeasurements, I obtain the centroid and the radius of a disk that has the same area as the points in the original image. Here's how it looks\n\n\ndata = RandomReal[NormalDistribution[], {100000, 2}]; (* test data *)\np = ListPlot[data, AspectRatio -> 1, Axes -> None];\nf = FillingTransform@ColorNegate@Binarize@p // DeleteSmallComponents\n{c, r} = 1 /. ComponentMeasurements[f, {\"Centroid\", \"EquivalentDiskRadius\"}]    \nShow[Rasterize[p], Graphics[{Red, Circle[c, r]}]]\n\n", "How to get graph layout that reflects edge weights?": "\nUpdate: Since version 9, weighted layouts are available.  See this answer.\n\nThe short answer is, unfortunately no, in version 8.0.* at least, the built-in layout algorithms do not take edge weight into account. Consider a version of your example:\nUnweighted\nadjMat1 = {{Infinity, 1, 1, 1, 1}, {1, Infinity, 1, 1, 1}, {1, 1, \n    Infinity, 1, 1}, {1, 1, 1, Infinity, 1}, {1, 1, 1, 1, Infinity}};\n\nWeighted\nadjMat2 = {{Infinity, 8, 6, 3, 7}, {1, Infinity, 1, 1, 1}, {2, 5, \n    Infinity, 9, 4}, {1, 1, 1, Infinity, 1}, {1, 1, 1, 1, Infinity}};\n\nWeighted adjacency matrix converted to multiedge rule form\nmultiedge = DeleteCases[ Flatten@Table[\n    If[i == j, Null, Table[i -> j, {adjMat2[[i, j]]}]], {i, \n     Length[adjMat2]}, {j, Length@First@adjMat2}], Null]\n\n(* Output:   {1 -> 2, 1 -> 2, 1 -> 2, 1 -> 2, 1 -> 2, 1 -> 2, 1 -> 2, 1 -> 2, \n 1 -> 3, 1 -> 3, 1 -> 3, 1 -> 3, 1 -> 3, 1 -> 3, 1 -> 4, 1 -> 4, \n 1 -> 4, 1 -> 5, 1 -> 5, 1 -> 5, 1 -> 5, 1 -> 5, 1 -> 5, 1 -> 5, \n 2 -> 1, 2 -> 3, 2 -> 4, 2 -> 5, 3 -> 1, 3 -> 1, 3 -> 2, 3 -> 2, \n 3 -> 2, 3 -> 2, 3 -> 2, 3 -> 4, 3 -> 4, 3 -> 4, 3 -> 4, 3 -> 4, \n 3 -> 4, 3 -> 4, 3 -> 4, 3 -> 4, 3 -> 5, 3 -> 5, 3 -> 5, 3 -> 5, \n 4 -> 1, 4 -> 2, 4 -> 3, 4 -> 5, 5 -> 1, 5 -> 2, 5 -> 3, 5 -> 4} *)\n\nThis shows that any of the three plotting methods give essentially the same layout for the same layout (Method/GraphLayout) option.\nManipulate[\n Row[{GraphPlot[multiedge, MultiedgeStyle -> None, Method -> s], \n   GraphPlot[adjMat1, MultiedgeStyle -> None, Method -> s], \n   AdjacencyGraph[adjMat1 /. \\[Infinity] -> 0, \n    GraphLayout -> s]}], {s, {\"SpringElectricalEmbedding\", \n   \"SpringEmbedding\", \"HighDimensionalEmbedding\", \"CircularEmbedding\",\n    \"RandomEmbedding\", \"LinearEmbedding\"}}]\n\n\nIf you were to come up with your own algorithm for allowing for the weights, you could draw graphs using that algorithm using the VertexCoordinateRules option.\nThere is a Weighted option in the GraphUtilities package, but it doesn't apply to visualisation. \n", "simplifying expressions - What is the difference between a few simplification techniques?": "\nThe primary difference between Refine and the two *Simplify functions is that Refine only evaluates the expression according to the assumptions given. It might so happen to be the simplest form when evaluated, but it does not check to see if it is indeed the simplest possible form. You should use Refine when your goal is not to simplify the expression but to just see how the assumptions transform it (e.g., square root of a positive quantity).\nSimplify, on the other hand, performs basic algebraic simplifications and transformations to arrive at the \"simplest\" result. Refine is one among them, and is also mentioned in its doc page. Here, \"simplest\" might not necessarily fit your definition of simple. It is what appears simple to Mathematica, and that is defined by LeafCount. Here's an example showing the difference between the two:\nRefine[(x - 1)/Sqrt[x^2] + 1/x, x > 0]\n(* Out= 1/x + (-1 + x)/x *)\n\nSimplify[(x - 1)/Sqrt[x^2] + 1/x, x > 0]\n(* Out= 1 *)\n\nFullSimplify behaves the same as Simplify, except that it also does manipulations and simplifications when it involves special functions. It is indeed slower, as a result, because it has to try all the available rules. The list of special functions is found in guide/SpecialFunctions and it's not a non-standard usage of the term and you can also read about it on Wikipedia. So in all cases not involving special functions, you should use Simplify. You can certainly give FullSimplify a try if you're not satisfied with Simplify's result, but it helps to not start with it if you don't need it.\nHere's an example showing the difference between Simplify and FullSimplify:\nSimplify[BesselJ[n, x] + I BesselY[n, x]]\n(* BesselJ[n, x] + I BesselY[n, x] *)\n\nFullSimplify[BesselJ[n, x] + I BesselY[n, x]]\n(* HankelH1[n, x] *)\n\n\nA few more notes on Simplify and FullSimplify:\nAs you have noted, FullSimplify is slow \u2014 sometimes it can take hours on end to arrive at the answer. The default for TimeConstrained, which is an option, is Infinity, which means that FullSimplify will take its sweet time to expand/transform until it is satisfied. However, it could very well be the case that a bulk of the time is spent trying out various transformations (which might eventually be futile) and the actual simplification step is quick. It helps to try out with a shorter time, and the documentation has a good example that shows this. This holds for Simplify too.\nNote that setting the option TimeConstrained -> t does not mean that you'll get your answer in under t seconds. Rather, it means that Mathematica is allowed to spend at most t seconds for a single transformation/simplification step.\nSimilarly, you can exclude certain functions from being simplified using ExcludedForms or include other custom transformations using TransformationFunctions. You can even change the default measure of \"simplicity\" using ComplexityFunction, and here is an answer that uses this. However, these options are not available in Refine.\nThese are actually well documented in the documentation for both functions, but is not widely known and can often be the key to getting the result quickly or in the form you want.\n", "graphics - Create self-contained plots when Ticks or FrameTicks require external functions": "\nTry giving the ticks as pure functions, so they actually get replaced \nThe copying issue I don't quite get it. It seems that the returned box structure changed the integers into doubles (the last argument of FindDivisions, the 4, into 4. in this case). It could be fixed by rewriting the function as \nff=Function[{xmin, xmax}, ({#1, \"\", 0.03`} &) /@  \n FindDivisions[{xmin, xmax}, Round@4]]\n\nwith Ticks -> ({#, #} &[ff]) as you wrote in the comment\nI vote for bug, let's see what others think\n", "plotting - ListContourPlot-ColorFunction": "\nYou can Rescale your points that are passed to ColorFunction so that they're between 0.05 and 0.95 as in the example below:\ndata = Table[Sin[i + j^2], {i, 0, 3, 0.1}, {j, 0, 3, 0.1}];\nListContourPlot[data, ColorFunction -> (ColorData[\"Rainbow\"][\n    Rescale[#, {0, 1}, {0.05, 0.95}]] &)]\n\n\n", "functions - Create string from character code": "\nYou can use\nToCharacterCode[\"abcABC\u03b1\u03b2\u03b3\"]\n(*\n=>    {97, 98, 99, 65, 66, 67, 945, 946, 947}\n*)\nFromCharacterCode[%]\n(*\n=>    \"abcABC\u03b1\u03b2\u03b3\"\n*)\n\nTo create unique symbols, use\nUnique[\"x\"]\n\n", "Graph does not accept Property Options": "\nThe following works:\nClearAll[g];\nvertices1 = {1, 2, 3};\ng = Graph[vertices1, {1 \\[UndirectedEdge] 2, 2 \\[UndirectedEdge] 3}];\nPropertyValue[{g, 1}, VertexSize] = .3;\nPropertyValue[{g, 1}, VertexCoordinates] = {0, 3}; \nPropertyValue[{g, 2}, VertexCoordinates] = {1, 2};\nPropertyValue[{g, 3}, VertexCoordinates] = {3, 3};\ng\n\n\n", "graphics3d - Rotating 3DPlot into animated gif": "\nI suppose you don't want something like this? (Sorry about the 750KB GIF...)\n\ndata = Table[Sin[x y], {x , 0, Pi, Pi/20},  {y, 0, Pi, Pi/20}];\nanimation = Table[ListPlot3D[data,\n    DataRange -> {{-1, 1}, {-1, 1}},\n    SphericalRegion -> True,\n    Axes -> False, Boxed -> False,\n    ViewVector -> {5 Sin[t], 5 Cos[t], Sin[10 t]}], {t , 0, Pi, \n    Pi/40}];\nExport[\"animated.gif\", animation, \"DisplayDurations\" -> .1]\n\n", "string manipulation - Custom distance metric for agglomerative clustering in Mathematica": "\nThe tutorial tutorial/PartitioningDataIntoClusters has information on Distance functions (also for Strings, e.g. HammingDistance).\n", "version 8 - What is the most convenient way to change options for Graph[] objects?": "\nYou could use SetProperty. For example\ng = Graph[{1 -> 2, 2 -> 4, 3 -> 4}]\n\nSetProperty[g, VertexLabels -> {\"Name\", 2 -> \"Two\"}]\n\n\n\n", "How to recompute the layout of a Graph?": "\nImagine that you have a graph with quite a few complex custom properties - below every edge and vertex have their unique properties:\ng = Graph[Table[Style[j, Hue[j/2^8 - 1]], {j, 0, 2^8 - 1}], \n  Table[Style[j \\[UndirectedEdge] FromDigits[Drop[IntegerDigits[j, 2], 1], 2], \n    Hue[j/2^8]], {j, 0, 2^8 - 1}], GraphLayout -> \"RadialDrawing\", \n  GraphStyle -> \"LargeNetwork\"]\n\n\nTo keep these properties and change the GraphLayout:\nToExpression@StringReplace[ToString[InputForm[g]], \"RadialDrawing\" -> \"SpringElectricalEmbedding\"]\n\n\nAlternatively you could just use Shift+Ctrl+E and retype the GraphLayout option.\nYet another alternative, which avoids potentially unsafe string replacements, is the following:\nReleaseHold[\n ToExpression[ToString[InputForm[g]], InputForm, Hold] /. \n  \"RadialDrawing\" -> \"SpringElectricalEmbedding\"\n]\n\nThis converts the Graph object to a non-atomic Mathematica expression with the head Graph.  Since this expression is not atomic, standard expression manipulation functions, including ReplaceAll, can be used on it.\n", "programming - How to take several values out of a large expression?": "\nAs @Szabolcs points out in the comments, you can always use Part or Replace regardless what head your expression has.  I personally prefer ReplaceAll in cases such as this because I find it easier to tell what I intended with my code when I dig it up months or years later.\nef = \n  EdgeForm[Directive[Thickness[Large], Dashing[{Small, Small}], \n    Opacity[0.1`], RGBColor[0, 0, 1]]];\n\nef /. \n EdgeForm[Directive[Thickness[t_], Dashing[d_], Opacity[o_], \n    col_]] :> {t, d, o, col}\n\n==> {Large, {Small, Small}, 0.1, RGBColor[0, 0, 1]}\n\n", "Determining the week of a year from a given date": "\nSince I'm living in Europe I'm sticking to the European definition of week number which is equivalent to the ISO standard. According to this standard, a week starts on Monday and the first week is the week containing 4 January. Taking this into account you could do therefore do something like\nweekNumberISO[date_] := Module[{day0, year},\n  With[{days = {\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"}},\n   year = ToExpression[DateString[date, \"Year\"]] ; \n   day0 = DatePlus[{year, 1, 4}, \n      {1 - Position[days, DateString[{year, 1, 4}, \"DayNameShort\"]][[1, 1]], \"Day\"}];\n   1 + Floor[DateDifference[day0, date, \"Week\"][[1]]]]]\n\nFor the North-American definition of week number, i.e. week 1 is the week containing 1 January and a week starts on Sunday, you would get something like\nweekNumberUS[date_] := Module[{day0, year},\n  With[{days = {\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"}},\n   year = ToExpression[DateString[date, \"Year\"]] ; \n   day0 = DatePlus[{year, 1, 1}, \n      {1 - Position[days, DateString[{year, 1, 1}, \"DayNameShort\"]][[1, 1]], \"Day\"}];\n   1 + Floor[DateDifference[day0, date, \"Week\"][[1]]]]]\n\n", "equation solving - Trouble using FindInstance with MatrixRank": "\nThe problem with MatrixRank used in this way is explained in the Help:\n\n", "import - How to scrape the headlines from New York Times and Wall Street Journal?": "\nYou can always do Import[\"http://wsj.com\",\"XMLObject\"]. That has the side effect of producing some irregular XML whenever the underlying HTML doesn't quite map cleanly to XML, but it mostly produces an XMLObject[] expression tree that you can match over and extract data from, and I've never seen a web page for which it won't return something.\n", "plotting - How to plot a barycentric line": "\nA ternary plot is a plot on the nonnegative unit simplex in $\\mathbb{R}^3$, so apply an affine change of basis (and rescale f1 to be sure its values lie on the simplex):\nClearAll[f1];\nf1[x_] := {Abs[Sin[x]], Mod[x, 2], Abs[Cos[x]]};\n\nWith[{xyToTernary = {{0, 1, 1/2}, {0, 0, Sqrt[3]/2}}}, \n ParametricPlot[xyToTernary . (f1[x] / Total[f1[x]]), {x, 1, 3^5}, \n  AxesOrigin -> {0, 0}, PlotRange -> {0, 1}, \n  Prolog -> {White, EdgeForm[Black], Polygon[{{0, 0}, {1, 0}, {1/2, Sqrt[3]/2}}]}]\n ]\n\n\nDue to the nature of your function, it would be a good idea to break it at integral values of x by including the option Exclusions -> Range[3^5]:\n\nIf you would like to visualize the 3D to 2D relationship inherent in these plots, you can ask Mathematica to do the projecting for you (but the 2D quality is degraded):\nShow[\n Graphics3D[{White, EdgeForm[Black], Polygon[{{1, 0, 0}, {0, 1, 0}, {0, 0, 1}}]},  \n  ViewVector -> {1, 1, 1}, ViewPoint -> {-8, -8, -8}, \n  ViewVertical -> {0, 0, 1}, ViewCenter -> {1/3, 1/3, 1/3}, \n  ViewAngle -> \\[Pi]/2,  Lighting -> {{\"Ambient\", White}}],\n ParametricPlot3D[f1[x] / Total[f1[x]], {x, 1, 3^5}, \n  Exclusions -> Range[3^5]], Axes -> {True, True, True}\n ]\n\n(Image not shown.)\n", "list manipulation - Is there a faster way to create a matrix of indices from ragged data?": "\nA modest improvement when you replace Replace[...] with Transpose@Thread:\n (udata = Sort[DeleteDuplicates[Flatten@testData], Less]; \n dsptch = Dispatch[Thread[udata -> Range[Length[udata]]]]; \n out1 = Replace[testData /. dsptch, a_Integer :> {a, a}, 1];) // AbsoluteTiming \n (* {2.1282128, Null} *)\n\n (udata = Sort[DeleteDuplicates[Flatten@testData], Less]; \n dsptch = Dispatch[Thread[udata -> Range[Length[udata]]]]; \n out2 = Transpose@Thread[testData /. dsptch];) // AbsoluteTiming \n (* {1.9421942, Null} *)\n out1==out2\n (* True  *)\n\n", "front end - Command Completion": "\nChanging shortcuts isn't that complicated. All you have to do is change one line in the file KeyEventTranslations.tr in a location in your file system specified by this command:\nFileNameJoin[{$InstallationDirectory, \"SystemFiles\", \"FrontEnd\", \n  \"TextResources\", $OperatingSystem}]\n\nLocate the following line in a text editor and change the key into the one you want:\nItem[KeyEvent[\"F2\"], FrontEnd`CompleteSelection[True]]\n\nI wouldn't use tab, as that already has a built-in meaning.\nMore information can be found here.\n", "symbolic - Surprises simplifying simple polynomials": "\nWe get different results because Simplify, working with a smaller range of accessible transformations than FullSimplify does, applied to structurally very different expressions at the begining,  reaches only the local minimum of the default ComplexityFunction, being roughly close to LeafCount, unlike in case of FullSimplify even though its underlying ComplexityFunction may be the same.\nHaving defined :  \nbySum = Sum[k^2, {k, 1, n}];\nbyBernoulli = (BernoulliB[3, n + 1] - BernoulliB[3])/3;\n\nwe get : \nbySum == byBernoulli // Simplify\n\n\nTrue\n\n\nbecause \nSimplify[byBernoulli - bySum]\n\n\n0\n\n\neven though Simplify yields different results here :\n  {bySum, byBernoulli} // Simplify\n\n\nThis is because at the begining we have  very different forms of the expressions which  we can observe with help of TreeForm and LeafCount assessing the complexity :\nLeafCount /@ { bySum, byBernoulli, byBernoulli - bySum }\n\n\n{13, 26, 40}\n\n\nTreeForm /@ {bySum, byBernoulli}\n\n\nA kind of expression not involving special functions where  FullSimplify simplifies it in a much better way than Simplify one can find here. \nKnowing that algorithms behind FullSimplify contain a much wider range of transformations than Simplify the latter finds at certain stage  only a local minimum (not sufficient in case of byBernoulli // Simplify to reach the global minimum) of the actual complexity function  and therefore the resulting expressions are slightly different :\nLeafCount /@ {bySum // Simplify, byBernoulli // Simplify}\n\n\n{13, 15}\n\n\nTreeForm /@ {bySum // Simplify, byBernoulli // Simplify}\n\n\nunlike in case of FullSimplify :\n{bySum , byBernoulli } // FullSimplify\n\n\nWe needn't use FullSimplify to get the same expressions,  a simpler solution of the problem would be this :\n{bySum, byBernoulli} // Factor\n\n\nwhich is the same as the result of FullSimplify for the both expressions as well as Simplify for bySum. It should be mentioned here, that FullSimplify when applied to  a factorizable polynomials tends to give that polynomial in the factorized form, i.e. Factor[poly] yields by default its factorized form if poly is factorizable in the field of rationals, however if we extend the rationals appropriately the results will be different, e.g. Factor[1 - 10 x^2 + x^4, Extension -> {Sqrt[2], Sqrt[3]}] (see this answer). So this is rather a special case, a more genreal approach (also for polynomials not factorizable in the rationals)\nwould be :\n{bySum, byBernoulli} // Collect[#, n] & // Simplify\n\n\nThe result is the same as in the case of byBernoulli // Simplify. \n", "plotting - Changing the order of elements in a chart legend": "\nHistogram[{bottom, middle, top}, 10, \n          ChartLayout -> \"Stacked\", \n          ChartLegends -> {\"Bottom\", \"Middle\", \"Top\"}] /. \nColumn[l_List] :> Column[Reverse@l]\n\n\n", "export - Mathematica output format for big numbers": "\nYou could define your own definitions for formatting numbers and variables. For example\nWriteInput1[file_, var_, eqlist_] := \n Module[{text, removewhite, eq2, gg, hh, format},\n\n  format[a_?NumericQ] := Block[{Format},\n    ToString@NumberForm[a, 10,\n      NumberFormat -> (Module[{man},\n          man = #1;\n          If[StringTake[#1, -1] === \".\", man = man <> \"0\"];\n          If[#3 === \"\", man, Row[{man, \"*10^(\", #3, \")\"}]]] &)]];\n\n  gg /: Format[gg[a_], InputForm] := OutputForm[format[a]];\n  hh /: Format[hh[a_], InputForm] := OutputForm[\n    StringReplace[ToString[a], {\"[\" -> \"\", \"]\" -> \"\", \",\" -> \"\"}]];\n\n  eq2 = eqlist /. Join[(# -> hh[#]) & /@ var, {a_?NumericQ :> gg[a]}];\n\n  removewhite[x_String] := StringReplace[x, Whitespace -> \"\"];\n  (*write equations*)\n\n  text = Fold[# <> removewhite[ToString[#2, InputForm]] <> \";\\n\" &,\n    \"{\", eq2];\n  text = text <> \"}\";\n  WriteString[OpenWrite[file],text];\n  Close[file];\n  text\n  ]\n\nToString uses Format to decide how to convert expressions to strings.\nWhat I'm doing here is wrapping any occurrences of elements in var with hh and any numbers with gg and using TagSet to tell Format how to deal with expressions of the form gg[...] or hh[...]. \nExample\nWriteInput1[\"sys1.txt\", {x[1, 1], x[2, 1], x[1, 2]},\n    {3.998723445*10^6 x[1, 1]^2, x[2, 1]^2, x[1, 2]^2}]\n\n(* ==> {3.998723445*10^(6)*x11^2;\n       x21^2;\n       x12^2;\n       }\n*)\n\nWriteInput[\"sys1.txt\", {x[1, 1], x[2, 1], x[1, 2]}, \n    {3.0 x[1, 1]^2, x[2, 1]^2, x[1, 2]^2}]\n\n(* => {3.0*x11^2;\n      x21^2;\n      x12^2;\n      }\n*)\n\n", "programming - Figuring out how AbsoluteOptions works with Graphs": "\nThe difference in layout between g and g3 can be explained from the fact that their VertexLists are different:\ng = RandomGraph[{6, 11}, VertexStyle -> {1 -> Red, 2 -> Green}, \n  VertexSize -> {1 -> Large, 2 -> Large}, VertexLabels -> \"Name\", \n  ImagePadding -> 15, EdgeLabels -> \"Name\"];\n\nVertexList[g]\n\n(* ==> {1, 2, 3, 4, 5, 6} *)\n\ng3 = Graph[EdgeList[g], someOptions];\nVertexList[g3]\n\nVertexList[g3]\n\n(* ==> {1, 6, 3, 5, 2, 4} *)\n\nTry for example\n{g, Graph[VertexList[g], EdgeList[g], someOptions]}\n\n\n", "programming - Open Excel file with Mathematica": "\nYou don't need the initial InstallNET[].  That should come after Needs[\"NETLink\"].\nI made a post on this topic a while back, here: http://forums.wolfram.com/mathgroup/archive/2011/Oct/msg00386.html\nSome code to illustrate the method:\nNeeds[\"NETLink`\"]\nReadFromExcel[file_String, cell_String, rows_Integer, cols_Integer] :=\n   Module[{excel, workbook, worksheet, srcRange, data},\n   NETBlock[InstallNET[];\n    excel = CreateCOMObject[\"Excel.Application\"];\n    If[! NETObjectQ[excel], Return[$Failed],\n     excel[Visible] = True;\n     workbook = excel@Workbooks@Open[file];\n     worksheet = workbook@Worksheets@Item[1];\n     srcRange = worksheet@Range[cell]@Resize[rows, cols];\n     data = srcRange@Value;\n     workbook@Close[False];\n     excel@Quit[];\n     ]];\n   LoadNETType[\"System.GC\"];\n   GC`Collect[];\n   data];\n\nReadFromExcel[\"testdata.xlsx\", \"B1\", 2, 3]\n\n\n{{1., 2., 3.}, {4., 5., 6.}}\n\n\n", "inverse - How to invert an integral equation": "\nMy interpretation of the question is that you want to find $x$ for given $f$, $g_2$ and $g_1$. Then just define $F=f/g_1$ and differentiate with respect to $x$ on both sides:\n$\\frac{d}{dx}F(x)=g_2(x)$\nNow solve this equation for $x$. There's no integration involved. \n", "printing - How to print without having newline added automatically at the end?": "\nFor Example:\nWriteString[\"stdout\", \"First part of the result: \", DateString[]];\n(*Perform some calc*)\ni = 0;\nWriteString[\"stdout\", \" -- Addition to the result: \", DateString[],  \"\\n\"];\n\n\nFirst part of the result: Thu 15 Oct 2015 12:58:29 -- Addition to the result: Thu 15 Oct 2015 12:58:29\n\n", "What's a good style for inheriting Options[] of built-in function?": "\nI use the first style you gave:\nOptions[tListPlot]=Join[\n    Options[ListPlot],\n    Options[tLegend],\n    {\n        Rule[ShowLegend,False]\n    }\n];\n\nThe function is then defined as\ntListPlot[data_,options:OptionsPattern[]]:=...\n\nI don't see any reason to use SetDelayed (:=) in this context. EDIT As Brett Champion mentions in the comments, the default options for \nSystem`Plot\n\nwill change if you use SetOptions on Plot. Hence, if you want your custom plot to always have the same options as Plot, use :=. I would prefer to specifically change the options for my Plot separately, so I would still use simply Set (=).\nYou might also want to check out this instructive question on Options in custom functions: Functions with Options\n", "wavelet analysis - Detecting spikes by shrinking WaveletPacket basis using a specific threshold": "\nI don't know if you are wedded to wavelets but...\nHave you considered a \"compound median filter\" (q.v.) ?\nFor a list of data x and filter width 2r+1,  \nMedianFilterRoot[x_, r_] := FixedPoint[MedianFilter[#, r] &, x]  \nCompoundMedianFilter[x_, r_] := \n Fold[MedianFilterRoot[#1, #2] &, x, Range[r]]   \n\nPlotting CompoundMedianFilter[x,r-1]-CompoundMedianFilter[x,r] shows all spikes of width r. Your example with two consecutive spikes could be something like:  \ndata = Table[Sin[x] + Random[], {x, 1, 10, 0.1}]  \ndata[[20]] = 60; data[[21]] = 80; data[[40]] = 100;  \n\nRunning CompoundMedianFilter[data,0]-CompoundMedianFilter[data,1] returns two unit-width spikes of amplitude 20 and 100, at indices 21 and 40, respectively.\nSimilarly, CompoundMedianFilter[data,1]-CompoundMedianFilter[data,2] returns a width-2 spike of amplitude 59 at indices 20 and 21.\nHence, adjacent spikes are resolved with essentially undistorted amplitudes (for this example with relatively large spikes).  \nTo reconstruct the spike-free signal, subtract all spikes of significant amplitude (and any width) from the original data.\n", "syntax - Why does the Front End group backslashes into pairs?": "\nFrom the tutorial Special Characters - Strings And Characters\n\nexample\n\nComment/Uncomment behavior you describe also happens in version 8.0.4.0 on Vista.\n", "plotting - Mathematica slope fields": "\nI'm assuming here that the curves you mentioned are streamlines of the vector field. You can plot those automatically without having to solve any differential equations by using the options StreamPoints, for example to plot the stream lines going through the points\npoints =  Transpose@ArrayPad[{Range[-10, 16, 2]}, {{1, 0}, {0, 0}}]\n\n(* ==> {{0, -10}, {0, -8}, {0, -6}, {0, -4}, {0, -2}, {0, 0}, {0, 2}, {0, 4}, \n        {0, 6}, {0, 8}, {0, 10}, {0, 12}, {0, 14}, {0, 16}} *)\n\nyou can do\nslopefield = \n VectorPlot[{1, .005*p*(10 - p)}, {t, -1.5, 20}, {p, -10, 16}, \n  FrameTicks -> None, AxesLabel -> {t, p}, Axes -> True, \n  VectorScale -> {Tiny, Automatic, None}, VectorPoints -> 15, \n  StreamPoints -> points,\n  StreamStyle -> {Red, \"Line\"}]\n\n\n", "export - Save and call matrices with large output in Mathematica": "\nExport[\"A.wdx\", A];\n\nwill save matrix A in file \"A.wdx\" on disk. WDX format is binary, compressed, and cross-platform.\nRestart Mathematica and evaluate\nA = Import[\"A.wdx\"];\n\nThis will read \"A\" from disk file \"A.wdx\" and store it in symbol A.\nProceed with your computation.\n", "functions - How to use ForAll in Reduce": "\nThis is a simple example. Suppose you have the following equation and you want to get the coefficients of it: \ngl = a x^3 + b x^2 + c x + d == -x + (-3 + x) (5 + x^2);\nReduce[ForAll[x, gl]]\n\nYour output will be:\nd == -15 && c == 4 && b == -3 && a == 1\n\n", "graphics - Finding minimal region with padding and linear map to circle": "\nAs @whuber pointed it out in a comment, you are looking for \u03b1-shapes, where the parameter \u03b1 defines the \"tightness\" of the wrapping of the boundary of a shape. I've found an implementation by YZ here from 2009, which I've fine-tuned and made faster by compiling down frequently used functions. Slowest part is the Delaunay triangulation, but there are known methods to boost its performance.\nAbout the padding and linear mapping to a circle: it is left for someone else to do.\nemptyQ = Compile[{{center, _Real, 1}, {alpha, _Real}, {plist, _Real, \n     2}}, Module[{empty = True, n = 1, x, y},\n    While[empty && n <= Length@plist, {x, y} = plist[[n]] - center; \n     empty = Sqrt[Abs[x]^2 + Abs[y]^2] > alpha; n++];\n    If[empty, 1, 0]],\n   Parallelization -> True,\n   CompilationTarget -> \"C\"];\n\ncenter = Compile[{{alpha, _Real}, {p1, _Real, 1}, {p2, _Real, 1}}, \n   Module[{x, y, lhalf},\n    {x, y} = p2 - p1;\n    lhalf = Sqrt[Abs[x]^2 + Abs[y]^2]/2;\n    {(p2 + p1)/2 + Sqrt[(alpha/lhalf)^2 - 1] {{0, -1}, {1, 0}}.((p2 - p1)/2),\n     (p2 + p1)/2 + Sqrt[(alpha/lhalf)^2 - 1] {{0, 1}, {-1, 0}}.((p2 - p1)/2)}],\n   Parallelization -> True ,\n   CompilationTarget -> \"C\"];\n\nf[alpha_, plist_, {id1_, id2_}] := Module[\n   {p1 = plist[[id1]], p2 = plist[[id2]], c1, c2, lhalf, c1emptyQ, c2emptyQ},\n   If[alpha <= Norm[p1 - p2]/2, False,\n    {c1, c2} = center[N@alpha, p1, p2];\n    Sow[{c1, c2}];\n    c1emptyQ = emptyQ[c1, N@alpha, Delete[plist, {{id1}, {id2}}]];\n    c2emptyQ = emptyQ[c2, N@alpha, Delete[plist, {{id1}, {id2}}]];\n    (c1emptyQ == 1 && c2emptyQ == 0) || (c1emptyQ == 0 && c2emptyQ == 1)\n    ]];\n\nNow do the triangulation and check for each pair if the function f returns True or False:\nn = 1000; (* number of points *)\nalpha = .8;\n\nNeeds@\"ComputationalGeometry`\";\npoints = Select[RandomReal[{0, 10}, {n, 2}],\n    (Norm[# - {5, 5}] < 5 \\[And] Norm[# - {7.5, 5}] > 2.5) &];\n\ntriangulation = \n  Union[Sort /@ \n    Flatten[Thread[List @@ #] & /@ DelaunayTriangulation@points, 1]];\ncenterList = Last@Last@Reap[\n     boundary = Select[triangulation, f[alpha, points, #] &];\n     ];\n\n{\n ListPlot[points, PlotRange -> Full, AspectRatio -> 1, \n   ImageSize -> 300, Frame -> False, Axes -> False],\n Show[\n  Graphics[{Red, Opacity@.2, \n    Map[Circle[#, alpha] &, centerList, {2}]}, ImageSize -> 300],\n  Graphics@GraphicsComplex[points, Line@boundary]\n  ],\n Graphics[GraphicsComplex[points, Line@boundary], ImageSize -> 300]\n }\n\n\nTable[\n boundary = Select[triangulation, f[alpha, points, #] &];\n Graphics[GraphicsComplex[points, Line@boundary], PlotLabel -> Row@{\"\u03b1 = \", alpha}],\n {alpha, {.1, .2, .3, .4, .6, 1.}}]\n\n\n", "list manipulation - ReplaceAll inside an Iterator": "\nMathematica throws the error because Table has the HoldAll attribute which prevents the replacement from being performed before Table sees the iterator.  You can force evaluation using Evaluate:\nTable[x, Evaluate[{x, x0 - 3*xp, x0 + 3*xp, xp} /. exampleParams]]\n\nAlternatively, instead of ReplaceAll, use With:\nWith[{x0 = 0, xp = 1}, Table[x, {x, x0 - 3*xp, x0 + 3*xp, xp}]]\n\nIn similar situations I like to use a custom-defined With-like function that can take parameter lists.  I described this function here and I'm going to reproduce it in this answer as well for completeness:\nClearAll[withRules]\nSetAttributes[withRules, HoldAll]\nwithRules[rules_, expr_] :=\n  First@PreemptProtect@Internal`InheritedBlock[\n    {Rule, RuleDelayed},\n    SetAttributes[{Rule, RuleDelayed}, HoldFirst];\n    Hold[expr] /. rules\n]\n\nwithRules[exampleParams, Table[x, {x, x0 - 3*xp, x0 + 3*xp, xp}]]\n\n", "export - Exporting a CDF to HTML": "\nYou do not really need a tool to depoly your CDF to HTML. It is very simple to do by hand. Here is what I do\n\nopen your text editor and create a file called index.htm\n<HTML>    \n<BODY >\nThis is my CDF\n\n<p>\n\n<script src=\"http://www.wolfram.com/cdf-player/plugin/v1.0/cdfplugin.js\"\ntype=\"text/javascript\"></script><script type=\"text/javascript\">// \n<![CDATA[\nvar cdf = new cdf_plugin();\ncdf.addCDFObject(\"source\", \"source.cdf\",840,1435);\n// ]]></script>\n\n<P>\n</BODY>\n</HTML>\n\nFrom Mathematica, save your notebook as source.cdf (using SAVE AS->CDF). Save it to the same folder your created the above index.htm file to. So now your folder have 2 files in it: source.cdf and index.htm\nuse your ftp program and upload these 2 files to your web site tree where you want to put them.\nthat is all. Click on the index.htm and will run the CDF.\n\nps. If you want to just show the Manipulate part in your CDF and not the code around it, then before doing SAVE AS, select the code cells and do CELL->CELL properties-> and un check the open option so that the cell becomes closed. \nSo that the code cells (or any other cell you choose to close) are not open for view. This way, when someone sees your CDF, they only see the GUI part (i.e. the manipulate) and not any other cell you did not want them to see).\n", "programming - How to solve a problem in relative motion?": "\nOne of the nice things about Mathematica is that it supports many different styles of programming. I think your code has the aspect of more \"traditional\" code that one might write in a different programming language. Perhaps your code is correct in spirit, but it seems to me overly complicated and as written obviously is not okay because it throws a recursion error. \nYou could increase the $RecursionLimit and depending on what exactly is wrong that might help, but I think in this case it is better to rewrite.\nThis is more along the lines of what you need perhaps,\n Clear[Vx, Vy, Pxi, Pyi];\n Pxi = 30 Cos[0.5 Pi - 0.2 t];\n Pyi = 80 + 30 Sin[0.5 Pi - 0.2 t];\n Vx = D[Pxi, t];\n Vy = D[Pyi, t];\n Sxf = 150 - 10*t;\n Table[({Pxi /. t -> u + Vx*u, Sxf} /. u -> T) /. \n Solve[Pxi + Vx*T - (9.8/2)*T^2 == 0, T][[2]], {t, 0, 15, 0.1}]\n\nGiven expressions for position on the ferris wheel over time, it computes the components of the velocity vector. Then for a range of values of time, it prints out the pairs you requested. Needless to say this code is still not as elegant as it could be, I suspect, and I'm not sure the physics of the situation is correctly represented here, but you should be able to check against your analytical solution (this code produces an intersect of the boat and the jumpers at a position of around 10).\nNote that you will run into trouble using == to check for equality since you are using discrete time steps and inexact numbers. You may need to use FindRoot or NSolve.\n", "cluster analysis - Stopping Agglomerative clustering under a condition in Mathematica": "\n(After belisarius's comment)\nThe hierarchical clustering invoked by using Method -> \"Agglomerate\" can be further customized, by using the undocumented \"Linkage\" suboption. I assume this is ultimately provides the same functionality as the Linkage option in the HierarchicalClustering package, which accepts the following values:\n\n\"Single\"          smallest intercluster dissimilarity\n\"Average\"         average intercluster dissimilarity\n\"Complete\"        largest intercluster dissimilarity\n\"WeightedAverage\" weighted average intercluster dissimilarity\n\"Centroid\"        distance from cluster centroids\n\"Median\"          distance from cluster medians \n\"Ward\"            Ward's minimum variance dissimilarity\nf                 a pure function\n\n\ndata = {{-1.1, 2.6}, {3.9, -0.8}, {4.2, -3.7}, {3.3, 3.5}, {3.9, 5.2},\n    {4.1, -4.8}, {3.8, 3.7}, {5.6, 0.1}, {3.1, -5.2}, {-0.9, 2.3},\n    {2.9, 4.1}, {-2.3, 3.9}, {-2.5, 3.}, {2.6, -5.5}, {5.2, 1.9},\n    {-0.7, 1.3}, {0.9, 2.8}, {-1.5, 3.3}, {3.8, 1.2}, {2.6, -5.1},\n    {-0.8, 3.2}, {4.7, 0.7}, {3., 3.}, {3.9, 3.6}, {4.5, 1.4},\n    {4.2, 1.3}, {-1.1, 2.6}, {4.8, 2.4}, {3.3, -3.5}, {3.2, -4.6},\n    {3.3, -4.9}, {3., 3.5}, {0.7, 2.1}, {3.2, -4.3}, {-2., 0.5},\n    {-1.2, 2.}, {-1.6, 1.8}, {-3.5, 3.7}, {4.8, 0.2}, {3.3, 2.4},\n    {-0.1, 2.1}, {-1.3, 2.5}, {4.4, 3.9}, {3.5, 0.2}, {0.1, 2.9},\n    {-1., 1.6}, {-1.4, 4.5}, {3.2, 2.5}, {-1.6, 2.4}, {2.6, -5.1}};\n\n{\n ListPlot[FindClusters[data], PlotStyle -> PointSize@.05],\n ListPlot[FindClusters[data, \n   Method -> {\"Agglomerate\",\n      \"Linkage\" -> (If[#3 > 1.9`*^-6, #1 + #2, (#1 + #2)^2] &)}], \n  PlotStyle -> PointSize@.05]\n }\n\n\n", "data structures - How to create strong types?": "\nIn practice, enforcing strong types in Mathematica seldom pays off, just because, as mentioned by @belisarius, Mathematica is untyped (and perhaps more so than most other langauges, since it is really a term-rewriting system). So, most of the time, the suggestion of @Mr.Wizard describes what I'd also do. \nThe way to define ADT-s (strong types) was described in depth by Roman Maeder, in his books on Mathematica programming. This requires something more than what you provided in your question - namely, a more formal definition of what is in your data structure (so that we can form constructors, selectors and mutators). I will give here a very simple example to show how ADT can be implemented in Mathematica. The key points are using UpValues and (mostly inert) symbols to serve as heads of new types. Consider a simple \"pair\" type:\nClearAll[pair];\npair /: getFirst[pair[fst_, sec_]] := fst;\npair /: setFirst[pair[_, sec_], fst_] := pair[fst, sec];\npair /: getSecond[pair[fst_, sec_]] := sec;\npair /: setSecond[pair[fst_, _], sec_] := pair[fst, sec];\n\nWe can now define some function on this new type:\nClear[sortPairsByFirstElement];\nsortPairsByFirstElement[pairs : {__pair}, f_] :=\n     Sort[pairs, f[getFirst[#1], getFirst[#2]] &];\n\nAnd here is an example of use:\npairs = Table[pair[RandomInteger[10],RandomInteger[10]],{10}]\n\n\n{pair[0,10],pair[4,7],pair[5,3],pair[10,9],pair[9,2],pair[6,10],pair[3,7],\n       pair[4,2],pair[0,4],pair[3,9]}\n\n sortPairsByFirstElement[pairs,Less]\n\n\n{pair[0,4],pair[0,10],pair[3,9],pair[3,7],pair[4,2],pair[4,7],pair[5,3],\n        pair[6,10],pair[9,2],pair[10,9]}\n\nYou can enforce stronger typing on what can go into a pair. One thing I've done is to enforce that in the \"constructor\":\npair[args__] /; ! MatchQ[{args}, {_Integer, _Integer}] :=\n    Throw[$Failed, pair];\n\nThe technique just described produces truly strong types, in contrast to the pattern-based typing. Both are useful and complementary to each other. One reason why such strong typing as described above is rarely used in Mathematica is that all the rest of the infrastructure usual for the strongly-typed languages (compiler, type system, smart IDE-s, type-inference) is missing here (so you'd need to construct that yourself), plus often this will induce at least some overhead. For example, we may wish to represent an array of pairs as a 2-dimensional packed array for efficiency, but here the pair type will get in the way, and we'd have to write extra conversion functions (which will induce an overhead, not to mention the memory-efficiency). This is not to discourage this type of things, but just to note that over-using them, you may lose some advantages that Mathematica offers.\n", "output formatting - TeX and TraditionalForm": "\nIf you just want the output, well, write it manually. EscpwEsc gives you the piecewise bracket. Then you can insert a table (Insert->Table/Matrix) or learn the shortcuts with Ctrl, and CtrlReturn, etc.\nI got this box structure. You can see the result by running.\nRawBoxes@FormBox[\n  RowBox[{\"\\[Piecewise]\", \n    GridBox[{{RowBox[{\"0\", \",\"}], \n       RowBox[{\"t\", \"\\[LessEqual]\", \n         SubscriptBox[\"x\", \"min\"]}]}, {RowBox[{FractionBox[\n          RowBox[{\"t\", \"-\", SubscriptBox[\"x\", \"min\"]}], \n          RowBox[{SubscriptBox[\"x\", \"max\"], \"-\", \n            SubscriptBox[\"x\", \"min\"]}]], \",\"}], \n       RowBox[{SubscriptBox[\"x\", \"min\"], \"<\", \"t\", \"\\[LessEqual]\", \n         SubscriptBox[\"x\", \"max\"]}]}, {RowBox[{\"1\", \",\"}], \n       RowBox[{\"t\", \">\", SubscriptBox[\"x\", \"max\"]}]}}]}], \n  TraditionalForm]\n\nYou can then style it further to suit you...\n", "import - How to monitor the progress of Read?": "\nI am fairly sure that for files of this size, you'll have problems loading them into Mathematica (unless you have truly huge amount of RAM on your machine, but perhaps even in this case). If your file contains newline-terminated strings, or if you otherwise know its structure (types stored there), consider using ReadList or BinaryReadList. I gave one example in my post here. In this way, you can attach something like ProgressIndicator to it, and monitor the progress. Also, I would recommend to use something similar to  large data framework from this answer, to convert the contents of your file / parts of resulting expression, to a file-backed form, since operating on the entire dataset in-memory might not be possible and / or efficient for such huge amounts of data.\n", "programming - How to use Mathematica functions in Python programs?": "\nThis solution can work with several programming languages. Check this GitHub repository of mine.\nSee this link.\nI have found a solution. Works fine to me.\nSteps:\n1-Create a script named runMath with the content:\n#!/usr/bin/env wolframscript\n# for certain older versions of Mathematica replace 'wolframscript' by\n# 'MathematicaScript -script' in the shebang line\n\nvalue=ToExpression[$ScriptCommandLine[[2]]];\n\n(*The next line prints the script name.*)\n(*Print[$ScriptCommandLine[[1]]];*)\n\nPrint[value];\n\n2-I gave execution privilege to the file.\nsudo chmod +x runMath\n\n3-Moved the file to the execution path\nsudo mv runMath /usr/local/bin/\n\n4-Created a new script called run with the content:\n#!/usr/bin/python\nfrom subprocess import *\nfrom sys import *\n\ncommand='/usr/local/bin/runMath'\nparameter=argv[1]\n\ncall([command,parameter])\n\n5-Moved to the execution path\nsudo mv run /usr/local/bin\n\n6-Finally, tested it:\n$run Prime[100]\n541\n\n$run 'Sum[2x-1,{x,1,k}]'\nk^2\n\n$run Integrate[Log[x],x]\n-x + x*Log[x]\n\n$run 'Zeta[2]'\nPi^2/6\n\nYou can use with ou without '. The ' are needed to command with spaces.\n$run 'f[n_] := f[n] = f[n - 1] + f[n - 2]; f[1] = f[2] = 1; Table[f[n],{n,5}]'\n{1, 1, 2, 3, 5}\n\nHappy!\n", "polynomials - Why does Expand not work within a function?": "\nTo implement what you intended to do, I suggest to take a look at this approach :\nhermite[0, x_] := 1\nhermite[1, x_] := 2 x\nhermite[n_Integer /; n >= 2, x_] :=\n    hermite[n, x] = Expand[2 x*hermite[n - 1, x] - 2 (n - 1) hermite[n - 2, x]]\n\nNow you shouldn't have problems anymore. \nRecalling that there are in Mathematica the Hermite polynomials $H_{n}(x)$  since the version 1, namely HermiteH function, we can check if the above is correctly implemented : \nAnd @@ SameQ @@@ ({hermite[#, x], HermiteH[#, x]} & /@ Range[100])\n\n\nTrue\n\n\ne.g.\nhermite[10, x]\n\n\n-30240 + 302400 x^2 - 403200 x^4 + 161280 x^6 - 23040 x^8 + 1024 x^10\n\n\nThe problem with your approach appears with so-called memoization of \n2 x*hermite[n - 1, x] - 2 (n - 1) hermite[n - 2, x] \n\nbut not Expand[hermite[n, x]], so there you had i.e. \nhermite[5, x]\n\n\n2 x (12 - 48 x^2 + 16 x^4) - 8 (-8 x + 2 x (-2 + 4 x^2))\n\n\ninstead of \n\n120 x - 160 x^3 + 32 x^5\n\n\nWe solved the problem by remembering \nExpand[ 2 x*hermite[n - 1, x] - 2 (n - 1) hermite[n - 2, x] ]\n\nTo avoid another possible problems with the variable n, I included a condition in the definition of hermite[n, x]. In your approach you had i.e. hermite[1, x] = 2 x; and so evaluating i.e.\nPlot[{hermite[0, x], hermite[1, x]}, {x, -5, 5}]     (* A *)\n\na message is generated $RecursionLimit::reclim of  exceeded $RecursionLimit (by default its value is 256). To avoid this problem you have do this :\n Plot[ Evaluate @ {hermite[0, x], hermite[1, x]}, {x, -5, 5}]  (* B *)\n\nWith my approach you needn't evaluate the functions, so you can choose (* A *).\n", "data structures - Using Memoization with a Mutable Object": "\nFor such small trees I would memoize those that already have the element...\nClearAll[leftsubtree, rightsubtree, nodevalue, emptyTree, treeInsert]\nleftsubtree[{left_, _, _}] := left\nrightsubtree[{_, _, right_}] := right\nnodevalue[{_, val_, _}] := val\nemptyTree = {};\n\ntreeInsert[emptyTree, elem_] := {emptyTree, elem, emptyTree}\n\n(*This is the changed line*)\nt : treeInsert[tree_, elem_] /; ! FreeQ[tree, elem] := t = tree\n\ntreeInsert[tree_, elem_] /; \n  OrderedQ[{nodevalue[tree], elem}] := {leftsubtree[tree], \n  nodevalue[tree], treeInsert[rightsubtree[tree], elem]}\ntreeInsert[tree_, elem_] := {treeInsert[leftsubtree[tree], elem], \n  nodevalue[tree], rightsubtree[tree]}\n\n", "programming - Developing domain specific languages and computational knowledge engines using Mathematica": "\nSome generalities\nI'd first like to discuss some ideas behind DSLs, and why they are useful, and then give a few pointers to some specific examples. The main idea of a DSL (at least the way I understand it) is that, for a given domain, there may be a number of primitive operations, such that all or most other desired operations can be expressed as some combinations of these. The main difference between a DSL and a simple API approach is that in DSL, you can nest these operations, and combine them in non-trivial ways. Some typical ingredients of DSL construction may involve\n\nParsing and creating an AST (Abstract Syntax Tree) of your code. This part may or may not be present, since in Mathematica we more or less program already in parse trees (Mathematica expressions). One desired property for a parse tree is that it (and heads out of which it is built) is completely inert, so that no piece of it evaluates. For example, in the SymbolicC case, the heads constructing the Symbolic C expressions are completely inert. This is not an absolute requirement, since you may have other means to prevent evaluation, but, at least in my experience, it is often quite hard to control evaluation when some heads in the parse tree are allowed to evaluate.  I can see two kinds of situations when creating a separate parse tree (with different heads) may be needed:\n\nThe original expression (code) of the DSL can evaluate, and it is this evaluation which actually constructs the parse tree. This may be advantageous, since the original DSL code may be (much) more compact than the resulting AST.\nThe original DSL code is expressed in the \"wrong degrees of freedom\", which is, the operations natural for the end user of a DSL have a non-trivial mapping to the primitives, in which it is most natural to implement the desired operations. \n\nFor the (mentioned below) code formatter example, both of the above points were true.\nActual implementation of a DSL. This involves implementing the actual interactions between your DSL primitives. If your DSL will be interpreted, this is an interpreter which would execute your AST, if it will be compiled, this will be a code generator which would generate Mathematica code from your AST. Either way, this is a necessary step, which forms the essence of your DSL and defines composition of elements (language primitives).\nFrequent use of recursion. Recursion is natural in this setting, because it reflects the nested nature of programs, and composition of primitive operations. I would even consider its presence necessary for a DSL to be non-trivial. To give a few examples, CCodeGenerate function from SymbolicC is deeply recursive, and also in the code formatter  (mentioned below), all stages of the formatter heavily use recursion. Recursion is also central in the (also mentioned below) example from the book of Wellin et al.\n\nSpecific examples\nSymbolicC and DatabaseLink are two examples of Mathematica DSLs which map Mathematica expressions to C code and SQL queries respectively. You can read their source code, it is quite instructive. In some sense, JLink can also be considered a DSL. Also in some sense, the new Statistics-related functionality forms a DSL. For more simple examples, you can look at my code formatter, which implements a simple but non-trivial formatting DSL (although I did not perform the refactoring which would make this totally apparent). Another good example is a simple graphic DSL developed in \"Introduction to programming with Mathematica\" by Wellin, Gaylord and Kamin (for the purposes of a pure Mathematica DSL, you can skip the parsing stage, or, more precisely, skip the lexical analysis, replacing their custom syntax with Mathematica expression-based syntax). This may actually be the easiest example to start with. \nOther ways to implement DSLs\nOne can take a less formal route, and implement DSL-s through code-generation, achieved by writing macros. I mentioned macros in my  answer on metaprogramming, and also mentioned the complications which currently accompany writing macros in Mathematica. Perhaps, the largest one is that there are no true compile and macro-expansion stages, since Mathematica is interpreted. But it should be possible to write a framework, which would introduce these, and then use it. The advantage of this method is that you can figure out your DSL's details as you go, just by eliminating boilerplate code as you see it. This may be a big advantage when you find it hard to formally specify your DSL, either because you are still learning the domain, or because it is not a priori clear what would make a good set of primitives in your DSL.\n", "dynamic - Mathematica as a report generator": "\nIn addition to @Rojo's here's a more detailed explanation:\ntotal = Dynamic[x + y]\n\nDefine the variable total that dynamically sums x and y\nx = 10;\ny = 5;\n\nNow create a text cell by right clicking on the cell bracket at the right and choose style Text. I Type:\nWhen I count the value x plus y I get: total\n\nNow double click on total and right click and choose Create Inline Cell.\nA background color will appear on the word total. Now double click again again on the word total , right click, and choose Evaluate in Place.\nThe TEXT cell now changed to:\nWhen I count the value x plus y I get: 15\n\nEvery time x or y changes your text cell adjust the correct value\n", "evaluation - Numbers in alternate bases transcend the evaluator?": "\nTo understand what's happening, the difference between evaluation and parsing needs to be made clear:\n\nparsing means taking the string (the text) input to Mathematica and converting it to some internal representation of a Mathematica expression\nevaluation means taking a Mathematica expression and transforming it according to some rules the evaluator knows about\n\nThe string 16^^abcdef gets directly parsed into an Integer.  11259375 gets parsed to the very same integer.  The way Mathematica stores integers internally does not include the base in which the number was originally.  16^^abcdef and  11259375  are two ways to write the exact same Mathematica expression.\nThe information about the base is lost at parse time, the evaluator never sees it.\n\nIf you read 16^abcdef as input interactively or from a file, you need to make sure you read it as a string (e.g. InputString) and avoid parsing it into a Mathematica expression. Then you can analyse the string an find out what is the base.\n", "dynamic - Safely generating multiple controls from a list of variables": "\nThe best way may be to avoid such constructs, but, if you insist on using a list of variables like that, here is one way:\nThread[Hold[vars] /. OwnValues[vars]] /. Hold[v_] :> Slider[Dynamic[v], {0, 1}]\n\nYou can store variables wrapped in Hold rather than List, in which case the first step (involving OwnValues) can be skipped.\n", "Assignment rule to distribute matrix-multiplication over custom notation": "\nUnfortunately, this is not possible directly, at least as far as I know. The error message you are getting is just a manifestation of it. You are using UpValues, which have a fundamental limitation that they can only be attached to symbols on a level no deeper than 1. I discussed this more in my answer to this question.\nRedefining built-in functions, OTOH, especially such fundamental ones as Plus, Times and Dot, is a bad idea most of the time. What you can do, is to create a lexical environment, where they will be replaced by some functions myPlus, myTimes, and myDot:\nClearAll[env];\nSetAttributes[env,HoldAll];\nenv[code_]:= \n With[{rules = {Times->myTimes,Plus->myPlus,dot->myDot}},\n  Unevaluated[code]/.rules/.Reverse[rules,{2}]\n ] \n\nNow, for example, you can define (note that in the first definition, s comes with a blank _, which you missed):\nClearAll[myDot];\nmyDot[M_, myTimes[a_, Ket[s_]]] := \n   myTimes[a, VecToKet[myDot[M, KetToVec[Ket[s]]]]];\nmyDot[M_, myPlus[args__]] := \n   myPlus @@ Map[myDot[M, #] &, {args}];\n\nAnd you use this as\nenv[X.(a*Ket[s])]\n\n\na VecToKet[X.KetToVec[Ket[s]]]\n\nand also\nenv[X.(a*Ket[s1] + b*Ket[s2])]\n\n\na VecToKet[X.KetToVec[Ket[s1]]] + b VecToKet[X.KetToVec[Ket[s2]]]\n\nThe function env serves as a custom evaluator here. The disadvantage of this approach is that you will generally have to insert env everywhere in your code, because env binds lexically rather than dynamically. But as long as the operation of Times, Plus and Dot on your objects is simply undefined (which would be so for general symbolic objects), you may avoid this problem by replacing the simple implementation above with a more complex infinite-evaluation one:\nClearAll[env];\nSetAttributes[env, HoldAll];\nenv[code_] :=\n  With[{result = \n      With[{rules = {Times -> myTimes, Plus -> myPlus, Dot -> myDot}},\n         Unevaluated[code] /. rules /. Reverse[rules, {2}]\n      ]},\n     env[result] /; result =!= Unevaluated[code]\n  ]; \nenv[code_] := code; \n\nwhich should also cover composition.\nFinally, you can, if you wish, use $Pre to avoid typing env every time you compute things interactively: $Pre = env;\n", "numerics - Solving a Volterra integral equation numerically": "\nMathematica is an incredible tool for checking conjectures and making sketches. I'm going to demonstrate it below.\nLet's start with checking that in case when $R_0$ (I replaced it with $R$) is a polynomial, the solution of this Volterra equation reduces to linear ODE. Lets take some derivatives of the equation:\nClearAll[P, R, s, t];\neqn = P[t] == R[t] + Integrate[P[s] R[t - s], {s, 0, t}]\nTable[D[eqn, {t, n}], {n, 0, 2}] // TableForm\n\n\nWe see that this process is somehow similar to integration by parts. If $R^{(n)}$ is zero here, we get an ODE. Let's check it out.\nR = 1 + 2 #^2 &;\ndeg = Exponent[R[t], t];\nTable[D[eqn, {t, n}], {n, 0, deg + 1}] // TableForm\n\n\nThe required initial conditions are obtained using intermediate derivatives:\niconds = Table[D[eqn, {t, n}] /. t -> 0, {n, 0, deg}];\nTableForm[ndeqs = {D[eqn, {t, deg + 1}]}~Join~iconds]\n\n\nNow we can solve this either numerically or symbolically: \ndsol = DSolve[ndeqs, P, t][[1, 1]]\nndsol = NDSolve[ndeqs, P, {t, 0, 1}][[1, 1]]\nGraphicsRow[Plot[P[t] /. #, {t, 0, 1}, PlotRange -> All] & /@ {dsol, ndsol}]\n\n\nVerifying that the symbolic solution is exact:\neqn /. dsol // Simplify\n(* ==> True *)\n\n\nNow, if kernel is not polynomial we can just interpolate it taking Chebyshev points of second kind for higher accuracy:\nRR = Exp[-#] + #*Sin[#] - #*Cos[#^2] &;\ndeg = 9;\nnodes = Table[(1 + Cos[(j \\[Pi])/deg])/2, {j, 0, deg}] // N;\nR = Evaluate[InterpolatingPolynomial[Transpose@{nodes, RR /@ nodes}, #]] &;\nPlot[{RR[t] - R[t]}, {t, 0, 1}, PlotStyle -> Thickness[Large]]\n\n\nAs we see the error is rather small. Here I took kernel from Daniel Lichtbau's answer. Now we can reuse the above code and obtain the following plot of approximate solution:\n\nThis perfectly agrees with Daniel's results. Thank you.\n", "plotting - Is there a simple way to plot complex numbers satisfying a given criteria": "\nUse ContourPlot for equalities:\nContourPlot[\n    Evaluate[z + Conjugate[z] == Abs[z]^2 /. z -> x + I y],\n    {x, -2, 2},\n    {y, -2, 2},\n    FrameLabel -> Automatic\n]\n\n\n\n\n", "export - How to set PageWidth when using PutAppend to append expressions to a file?": "\nI believe you should use streams:\nstream = OpenWrite[\"wraptest.m\", PageWidth -> Infinity];\n\nDo[PutAppend[Table[i, {RandomInteger[100]}], stream], {i, 100}]\n\nYou can also use Write in place of PutAppend:\n Do[stream ~Write~ Table[i, {RandomInteger[100]}], {i, 100}]\n\nBe sure to Close your stream when you are done:\nClose[stream];\n\n", "dynamic - Rounding problems inside InputField": "\nThis seems to work for me, is it what you need?\nInputField[Dynamic[h2, If[NumericQ[#], h2 = Round[#, 0.001], h2 = h2] &]]\n\n", "function construction - Generating date ranges": "\nPerhaps this way:\nTable[DatePlus[{2012, 4, 24}, 28*i], {i, 1, 40}]\n\n\n{{2012, 5, 22}, {2012, 6, 19}, {2012, 7, 17}, {2012, 8, 14}, {2012, 9,\n         11}, {2012, 10, 9}, {2012, 11, 6}, {2012, 12, 4}, {2013, 1, \n        1}, {2013, 1, 29}, {2013, 2, 26}, {2013, 3, 26}, {2013, 4, \n        23}, {2013, 5, 21}, {2013, 6, 18}, {2013, 7, 16}, {2013, 8, \n        13}, {2013, 9, 10}, {2013, 10, 8}, {2013, 11, 5}, {2013, 12, \n        3}, {2013, 12, 31}, {2014, 1, 28}, {2014, 2, 25}, {2014, 3, \n        25}, {2014, 4, 22}, {2014, 5, 20}, {2014, 6, 17}, {2014, 7, \n        15}, {2014, 8, 12}, {2014, 9, 9}, {2014, 10, 7}, {2014, 11, \n        4}, {2014, 12, 2}, {2014, 12, 30}, {2015, 1, 27}, {2015, 2, \n        24}, {2015, 3, 24}, {2015, 4, 21}, {2015, 5, 19}}\n\nOf course you might want to finetune the number of 28-day intervals.\n", "plotting - Plot CSV-data; make statistical statements in Mathematica / WA": "\nIf your data is Imported say in data then you can use data[[All,{1,2}]] to use the first column as x and the second as y value. Plotting all three data sets would be\nListPlot[{data[[All, {1, 2}]], data[[All, {1, 3}]], data[[All, {1, 4}]]}] \n\nIf you want to print against row index, like in yopur figure you can use\nListPlot[{data[[All, 2]], data[[All, 3]], data[[All, 4]]}, Frame -> True,\n  PlotRange -> {0, 1000}, FrameLabel -> {\"row index\", None}]\n\nEdit:\nTo make sure that you import the data correctly you have to enforce \"CSV\" format. Using the \"Table\" format will give you the following data:\ndata // FullForm\n\n\n   List[List[\"0.005,116,148,32\"],List[\"0.005,352,30,322\"],List[\"0.005,249,49,200\"],List[\"0.005,23,336,313\"],List[\"0.0051,130,89,41\"],List[\"0.0051,363,46,317\"]]\n\n\nAs you see each line is interpreted as String. Use \ndata = Import[\"data.csv\", \"CSV\", \"HeaderLines\" -> 1]\n\ninstead.  Now\ndata // FullForm\n\ncorrectly gives a list of numerical list elements and the above ListPlot works.\n\nList[List[0.005`,116,148,32],List[0.005`,352,30,322],List[0.005`,249,49,200],List[0.005`,23,336,313],List[0.0051`,130,89,41],List[0.0051`,363,46,317]]\n\n\n", "equation solving - Can Reduce *really* not solve for x here?": "\nUse\nReduce[(1/x) Cosh[x/2] == Sqrt[2], x, Reals]\n\nor \nSolve[(1/x) Cosh[x/2] == Sqrt[2], x, Reals]\n\nthe latter yields\n{{x -> Root[{-E^(-(#1/2)) - E^(#1/2) + 2 Sqrt[2] #1 &,      0.75858229952537718426}]}, \n {x ->  Root[{-E^(-(#1/2)) - E^(#1/2) + 2 Sqrt[2] #1 &, 5.4693513860610533998}]}}\n\nFor transcendental equations you may get with Reduce or Solve roots  represented symbolically by Root though  they are in general transcendental numbers, so their  values are written numerically beside the transcendental function written in the form of a pure function.\nPlot[ (1/x) Cosh[x/2] - Sqrt[2], {x, -7, 7}, PlotStyle -> Thick, PlotRange -> {-4, 4}]\n\n\nEdit\nIt should be emphasized that using domain specifications in Reduce or Solve you may still get messages of unsolvability of a given equation or a system (of eqations or/and inequalities), e.g.\nReduce[ x Cos[x/2] == Sqrt[2], x, Reals]\n\n\nReduce::nsmet: This system cannot be solved with the methods available to Reduce. >>\nReduce[x Cos[x/2] == Sqrt[2], x, Reals]\n\n\neven though for a slightly different equation you can get the full solution, e.g. \nReduce[x Cos[x/2] == 0, x, Reals]\n\n\nIn these two cases there is an infinite number of solutions, but the latter case is much easier, because a solution satisfies one of the two conditions : x == 0 or  Cos[x/2] == 0. In the first case we need to restrict a region where we'd like to find solutions. There we find all of them with Reduce (as well as with Solve) if in a given region there is only  a finite number of solutions, e.g. restricting the domain to real numbers such, that -25 <= x <= 25 i.e. adding a condition -25 <= x <= 25 to a given equation (now we needn't specify explicitly the domain to be Reals because Reduce[expr,vars] assumes by default that quantities appearing algebraically in inequalities are real):\nsols = Reduce[x Cos[x/2] == Sqrt[2] && -25 <= x <= 25, x]\n\n\nDefining \nf[x_] := x Cos[x/2] - Sqrt[2]\n\nwe can easily check that sols are indeed the solutions :\nFullSimplify[ f[ sols[[#, 2]]]] & /@ Range @ Length[sols]\n\n\n{0, 0, 0, 0, 0, 0, 0}\n\n\nTo extract only numerical values of the roots combined with zero we can do (see e.g. this answer):\nTuples[{List @@ sols[[All, 2, 1, 2]], {0}}]\n\nNow we can plot the function with appropriately marked roots and the specified domain :\nPlot[ f[x], {x, -40, 40}, PlotStyle -> Thick, \n             Epilog -> {Thickness[0.003], Darker@Red, Line[{{-25, 0}, {25, 0}}], \n                        PointSize[0.01], Cyan, Point /@ Tuples[{List @@ sols[[All, 2, 1, 2]], {0}}]}]\n\n\nHere the dark red line denotes the domain of our interest, and the cyan points denote \nall roots of the function f in this region.\n", "How to set different labelstyles for controls in manipulate?": "\nYou can use Style for the labels:\nManipulate[{jj, kk},\n {{jj, 2, Style[\"Select j\", Bold, Larger]}, 1, 11},\n {{kk, 2, \"Select k\"}, 1, 11}]\n\n", "performance tuning - Shaving the last 50 ms off NMinimize": "\nAs promised in the comments on my first answer, here is an implementation of an all-compiled-code Nelder-Mead minimizer, which hopefully represents a more useful response to the question. The algorithm used here corresponds to that given by Lagarias et al. in SIAM J. Optim. 9 (1), 112 (1998) (abridged .pdf). It is compatible with Mathematica versions 6, 7, 8, and 9, but not 5.2 or any previous version. This is not only due to the use of the new-in-6 functions OptionsPattern, FilterRules, and OptionValue, but also to apparent limitiations of the compiler--in particular, the robustness of the type inference mechanism was not entirely satisfactory prior to version 6.\nThe code is many times faster than NMinimize in all versions, although I would recommend using Mathematica 8 or 9 if possible. The performance of the compiled code is much better here than in versions 6 and 7, and many more functions are supported for compilation. Compilation to native code via C can also result in substantially improved performance. In fact, LibraryLink and/or the Mathematica runtime seem to have gained additional performance improvements in version 9, so this seems to be the optimal version to use as of this posting, being about 25% faster even than version 8.\nA very important consideration is that, if the minimand is not compilable, performance will suffer due to calls out of compiled code to perform top-level evaluations. Indeed, these calls are so expensive that the resulting compiled function may easily be slower than the equivalent top-level code. It's also worth noting that FindMinimum possesses a very efficient implementation, so if only local optimization is needed, that function is likely to remain the best choice. For global optimization, an advantageous strategy might consist of using this package to quickly explore large parts of the parameter space (perhaps trying many different initial simplices) followed by the use of the optimized values as a starting point for FindMinimum, which will provide tight convergence to the final result.\nUnlike for NMinimize, constrained optimization is not supported, because the Nelder-Mead algorithm is fundamentally an unconstrained method. For constrained problems, NMinimize performs a sort of regularization of the minimand such that the minimum of the resulting function fulfils the Karush-Kuhn-Tucker conditions, thus allowing unconstrained methods to continue be used. I may include this in a future update, but currently it is not implemented. Another difference relative to NMinimize is the convergence criterion: the one used here can more easily distinguish slow convergence from the minimizer having stalled without finding a minimum, which is useful for poorly behaved minimands. Instead of PrecisionGoal/AccuracyGoal, one specifies a tolerance, \"ConvergenceTolerance\", for the minimum allowed change in the average function value (sampled at the vertices of the simplex) within a given number of iterations. The default settings typically result in tighter convergence than NMinimize achieves, while still terminating the optimization if it genuinely does not converge.\nThis latest update contains several fixes and improvements:\n\nOption handling for NelderMeadMinimize has been fixed--options given for this function were incorrectly being overridden by those of NelderMeadMinimize`Dump`CompiledNelderMead in previous versions, which would have been confusing to the user.\nIt is now possible to refer to NelderMeadMinimize`Private`dimension in options. This value represents the dimension of the problem and allows one to specify this parameter in an abstract way. An application of this will be demonstrated below.\nThe interpretation of values given for the \"InitialPoints\" option has been improved.\nDiagnostics in NelderMeadMinimize`Dump`CompiledNelderMead can now be enabled for any return type. When disabled (as by default), the operation counts will no longer be maintained and no reference to them will appear in the compiled code. When enabled, these values will be given along with their descriptions in NelderMeadMinimize`Dump`OperationCounts on return.\nThe code has undergone some general clean-up and should be easier to read as a result.\nAn additional test function, the rotated (nonseparable) hyperellipsoid, has been provided. The rotation should not present much of a hindrance for the Nelder-Mead algorithm, but this is not necessarily the case for other approaches, particularly when scaled to hundreds of dimensions, whereupon e.g. differential evolution begins to encounter difficulties with it. This function is therefore useful for comparative purposes.\n\nThe package can no longer be presented in a code block in this post because it is too long, so please download it from its GitHub repository here.\nBecause the question involves performing a large number of similar minimizations, and in order to avoid expensive calls out of compiled code, I decided to inline the minimand into the Nelder-Mead algorithm itself. For each function minimized with a given set of options, compiled code is generated on the first call and memoized in order to amortize the compilation overhead over subsequent calls. The minimization can be run again with a different starting simplex (or some other set of initial points, specified via the \"InitialPoints\" option), or with different settings for \"RandomSeed\", \"ConvergenceTolerance\", or MaxIterations without re-compilation. Changing any other parameters or options will result in a new minimizer being generated.\nTo further reduce overheads, very little error checking is done. In fact, only the forms of some of the arguments are verified. As a result, if incorrect parameters or options are specified, the resulting errors will be returned to the top level.\nFor testing, I've included a few simple problems: the n-dimensional shifted hyperellipsoid function and its rotated counterpart (Schwefel's problem 1.2) and the n-dimensional generalized Rosenbrock's function. Contrary to common belief, the latter is not a unimodal function for all n: as shown by Yun-Wei Shang and Yu-Huang Qiu in Evol. Comp. 14 (1), 119-126 (2006) (link), there are actually two minima for n $\\ge$ 4, and the Nelder-Mead algorithm (which is not strictly a global optimization algorithm) might converge to either of them. While these problems are not very difficult, I think they serve well enough for expository purposes. So, let's test the code. First, a simple usage example:\nNelderMeadMinimize[x^2 + y^2, {x, y}]\n\n(* or, equivalently, *)\nNelderMeadMinimize[Function[{x, y}, x^2 + y^2], {x, y}]\n\n(* or even: *)\nWith[{cf = Compile[{{x, _Real, 0}, {y, _Real, 0}}, x^2 + y^2]},\n NelderMeadMinimize[cf, {x, y}]\n]\n\n(* -> {4.53016*10^-20, {x -> 1.90885*10^-10, y -> 9.41508*10^-11}} *)\n\n(Note that when the minimand is passed as a pure or compiled function, the names of the variables are not actually important; they can be anything, as we demonstrate below. Note also that NelderMeadMinimize has HoldAll--although this can safely be removed if you prefer consistency with NMinimize to the convenience of not having to Block your variables.)\nNow, a performance comparison:\n(* Generate some variables *)\nvars = Block[{x}, Unique[ConstantArray[x, 10], Temporary]];\n\n(* First let's try NMinimize: *)\nNMinimize[\n  NelderMeadMinimize`Dump`Hyperellipsoid @@ vars, vars, \n  Method -> {\"NelderMead\", \"PostProcess\" -> False}, MaxIterations -> 10000\n ] // Timing\n\n(* -> {0.515625, {8.34607*10^-9, {\n                  x$405 -> 0.999988, x$406 -> 1.000010, x$407 -> 1.,\n              x$408 -> 1.000030, x$409 -> 0.999995, x$410 -> 1.00001,\n                  x$411 -> 0.999999, x$412 -> 1.000020, x$413 -> 1.00001,\n              x$414 -> 1.00001}}} *)\n\n(* Now NelderMeadMinimize: *)\nNelderMeadMinimize[\n NelderMeadMinimize`Dump`Hyperellipsoid, Evaluate[vars],\n CompilationTarget -> \"C\"\n] // Timing\n\n(* -> {0.391375, {1.73652*10^-16, {\n                  x$405 -> 1., x$406 -> 1., x$407 -> 1., x$408 -> 1.,\n                  x$409 -> 1., x$410 -> 1., x$411 -> 1., x$412 -> 1.,\n                  x$413 -> 1., x$414 -> 1.}}} *)\n\nWe've achieved much better convergence, somewhat faster than NMinimize. But this includes the time taken for compilation to C! Trying again now that the minimizer has already been generated reveals that almost all of the above timing is in fact due to the compilation step:\nDo[\n NelderMeadMinimize[\n  NelderMeadMinimize`Dump`Hyperellipsoid, Evaluate[vars],\n  CompilationTarget -> \"C\"\n ], {100}\n] // Timing\n\n(* -> {1.296875, Null} *)\n\nOn the second and subsequent minimizations, we beat NMinimize by a factor of around 40, despite a tighter convergence tolerance. Let's now even the odds, as it's well known that the Nelder-Mead algorithm is quite slow to converge to very tight tolerances:\nDo[\n NelderMeadMinimize[\n  NelderMeadMinimize`Dump`Hyperellipsoid, Evaluate[vars],\n  \"ConvergenceTolerance\" -> 10^-9,\n  CompilationTarget -> \"C\"\n ], {100}\n] // Timing\n\n(* -> {0.953125, Null} *)\n\nThat's a better than 50-fold improvement over NMinimize in a more or less fair test, with each minimization of this 10-dimensional function taking under 10\u00a0ms. It may be of interest in some cases to record the number of function evaluations and the types of steps taken by the Nelder-Mead algorithm. If so, we may set the option \"Diagnostics\" -> True: after re-running the optimization we then find the relevant information recorded in the value of NelderMeadMinimize`Dump`OperationCounts:\nNelderMeadMinimize`Dump`OperationCounts\n(* {\"Function evaluations\" -> 2441,\n    \"Reflections\" -> 1289, \"Expansions\" -> 80,\n    \"Contractions\" -> 347, \"Shrinkages\" -> 0} *)\n\nIf absolutely minimum overhead is required, the compiled minimizer can be called directly, with the requirements that the minimand is given as a Function or CompiledFunction and the starting simplex is fully specified (taking the form of an array of real numbers having dimensions {d + 1, d}, where d is the dimension of the problem). Also, to specify MaxIterations -> Infinity, the third parameter should be a negative integer. This works as follows:\nDo[\n NelderMeadMinimize`Dump`CompiledNelderMead[\n  NelderMeadMinimize`Dump`Hyperellipsoid, vars,\n  CompilationTarget -> \"C\"\n ][RandomReal[{0, 1}, {Length[vars] + 1, Length[vars]}], 10^-9, -1],\n {100}\n] // Timing\n\n(* -> {0.734375, Null} *)\n\nThis was a bit more work, but we have now achieved a 70-fold improvement over NMinimize. However, it should be noted that timings are generally much more sensitive to the initial simplex (and thus the number of iterations performed before convergence) than to the method in which the code is called. Working with the compiled minimizer directly is therefore perhaps better thought of as a means to incorporate it as a building block into other code (as shown below, where many minimizations are performed in parallel) than a means of achieving higher performance in its own right.\nNow, we try to minimize the 50-dimensional Rosenbrock's function, even though the performance of the Nelder-Mead algorithm is usually worse (both slower and less reliable) than other methods (e.g. Storn-Price differential evolution) for high-dimensional minimization:\nvars = Block[{x}, Unique[ConstantArray[x, 50], Temporary]];\n\nNelderMeadMinimize[\n NelderMeadMinimize`Dump`Rosenbrock, Evaluate[vars],\n \"RandomSeed\" -> 10, CompilationTarget -> \"C\"\n] // Timing\n\n(* -> {24.109375, {2.44425*10^-15, {\n                   x$567 -> 1., x$568 -> 1., x$569 -> 1., x$570 -> 1., x$571 -> 1.,\n               x$572 -> 1., x$573 -> 1., x$574 -> 1., x$575 -> 1., x$576 -> 1.,\n                   x$577 -> 1., x$578 -> 1., x$579 -> 1., x$580 -> 1., x$581 -> 1.,\n               x$582 -> 1., x$583 -> 1., x$584 -> 1., x$585 -> 1., x$586 -> 1.,\n                   x$587 -> 1., x$588 -> 1., x$589 -> 1., x$590 -> 1., x$591 -> 1.,\n               x$592 -> 1., x$593 -> 1., x$594 -> 1., x$595 -> 1., x$596 -> 1.,\n                   x$597 -> 1., x$598 -> 1., x$599 -> 1., x$600 -> 1., x$601 -> 1.,\n               x$602 -> 1., x$603 -> 1., x$604 -> 1., x$605 -> 1., x$606 -> 1.,\n                   x$607 -> 1., x$608 -> 1., x$609 -> 1., x$610 -> 1., x$611 -> 1.,\n               x$612 -> 1., x$613 -> 1., x$614 -> 1., x$615 -> 1., x$616 -> 1.}}} *)\n\nWe found the minimum in a reasonable time, although it required a non-default random seed to do so. As a performance comparison, a differential evolution minimizer I wrote in Python can minimize this function in about 21 seconds, which is certainly better considering that Python is interpreted while the result shown here is after compilation to C. However, this is still a huge improvement over NMinimize, which cannot detect convergence properly in this case, taking over 7 times as long trying (and ultimately failing) to find the minimum. In fact, we can do better if we employ the modified (\"adaptive\") scale parameters proposed by Fuchang Gao and Lixing Han in Comput. Optim. Appl. 51 (1), 259-277 (2012) (.pdf available from Gao's website):\nWith[{dim := NelderMeadMinimize`Private`dimension},\n NelderMeadMinimize[\n   NelderMeadMinimize`Dump`Rosenbrock, Evaluate[vars],\n   \"ReflectRatio\" -> 1, \"ExpandRatio\" :> 1 + 2/dim,\n   \"ContractRatio\" :> 3/4 - 1/(2 dim), \"ShrinkRatio\" :> 1 - 1/dim,\n   CompilationTarget -> \"C\"\n  ] // Timing\n]\n\n(* -> {16.781250, {1.5829*10^-15, { identical result omitted }}} *)\n\nAs described in the paper, these parameter values improve the efficacy of the expansion and contraction steps for high-dimensional problems and help to prevent the simplex from degenerating into a hyperplane, which otherwise would lead to failure of the Nelder-Mead algorithm. Convergence is thus achieved more reliably, to tighter tolerances, and without having to adjust the random seed. What is not so clear from this example is that, in favorable cases, the performance improvements can also be very dramatic: for the 35-dimensional hyperellipsoid function, for instance, the modified parameters yield a tenfold reduction in execution timing versus the classical values. I would thus strongly recommend at least trying the modified settings for larger problems, hence the incorporation of the symbol NelderMeadMinimize`Private`dimension to represent the problem dimension when doing so.\nEdit: response to Ajasja's edits\nRe-compilation of the minimizer on every call for a CompiledFunction objective function was a result of my inadequate testing of this case, so thanks go to Ajasja for noticing and reporting this issue, as well as the bug in handling specified initial points. Until it was pointed out to me by Leonid, I had somehow managed to overlook the fact that CompiledFunctions contain (in their second argument) patterns specifying the types of the arguments they accept. Pattern matching a CompiledFunction against itself will therefore not produce a match unless Verbatim is used to wrap the CompiledFunction being treated as the pattern, and memoization of function values similarly will not work where a CompiledFunction appears in an argument unless Verbatim is used in defining the applicable DownValue. This issue has now been fixed and compiled objective functions will be properly memoized by the updated version (both posted code and downloadable files) above.\nThe second point regards the question of how to incorporate parameters in the objective function other than the values actually being minimized. In fact this was possible without any additional modifications right from the first posted version of the code, although I didn't make this explicit or specify how it can be done. I hope to rectify this omission now, alongside describing how to obtain the best performance from this approach.\nLet's take an example related to the scenario described in the question: namely, fitting a model to data. Here we will perform least-squares fitting of a cubic polynomial, i.e. the minimand is,\nNorm[data - (a + b x + c x^2 + d x^3)]\n\nwith data (ordinate values only) and x (abscissae) given, and a, b, c, and d being the values under optimization. (In principle, using the monomials as basis functions is less than ideal because of its numerical instability, which combines poorly with the Nelder-Mead algorithm's tendency to get trapped in local minima. Practically speaking, it works well enough as an example.) This can be given to NelderMeadMinimize essentially directly:\nfitter = Block[{data = #},\n  NelderMeadMinimize[\n   Block[{x = Range@Length[data]}, Norm[data - (a + b x + c x^2 + d x^3)]],\n   {a, b, c, d}\n  ]\n ] &\n\nThe point to note here is that data appears lexically in the minimand, but not as a variable as far as NelderMeadMinimize is concerned. The first time this is called with actual data, compiled code will be generated that is a closure over the non-localized symbol data; where data is referenced, code is generated for a call into the main evaluator to retrieve its value. (The Block inside the minimand isn't relevant to this; it simply generates abscissae suitable for the given data and will be compiled completely since x is localized.) As it's the symbol data that appears inside the minimand and not actual data, compilation occurs only once rather than for every dataset fitted.\nWe try it:\ndatasets = Accumulate /@ RandomReal[{-1, 1}, {5, 100}];\nfits = fitter /@ datasets;\nfittedmodels = a + b x + c x^2 + d x^3 /. fits[[All, 2]];\n\nShow[\n { Plot[fittedmodels, {x, 1, Last@Dimensions[datasets]}],\n   ListLinePlot[datasets] }, PlotRange -> All\n]\n\nGiving:\n\nwhich seems like it was reasonably successful. So, this is a fine proof of principle, but quite slow ($\\approx$ 100 ms/fit) due to the expensive call out of compiled code on every objective function evaluation. Obviously, we can do much better.\nSince the aim is to completely eliminate calls into the main evaluator while fitting an arbitrary number of datasets, the new option \"ReturnValues\" of NelderMeadMinimize`Dump`CompiledNelderMead will come in useful. This enables compiled minimizers to be generated that produce any of several different return values, facilitating their use as building blocks in other compiled code. The possible option values are:\n\n\"OptimizedParameters\": return a list of the values of the variables that minimize the objective function.\n\"AugmentedOptimizedParameters\": as for \"OptimizedParameters\", but with the corresponding (minimal) value of the objective function prepended.\n\"Simplex\": like \"OptimizedParameters\", but now returning a list of all d + 1 points of the final simplex obtained by the Nelder-Mead algorithm.\n\"AugmentedSimplex\": as for \"Simplex\", but with each point having the corresponding value of the objective function prepended to it.\n\nIt seems to me that \"ReturnValues\" -> \"OptimizedParameters\" is the most suitable for the present application, so let's proceed as such. We now turn to the question of the parameter value accesses.\nAs Leonid has noted here, if compiled closures are inlined (using CompilationOptions -> {\"InlineCompiledFunctions\" -> True}) into other compiled code containing the values they close over, calls to the main evaluator can be eliminated entirely:\nWith[{\n   minimizer = NelderMeadMinimize`Dump`CompiledNelderMead[\n     Function[{a, b, c, d},\n      Block[{x = Range@Length[data]}, Norm[data - (a + b x + c x^2 + d x^3)]]\n     ], {a, b, c, d}, \"ReturnValues\" -> \"OptimizedParameters\"\n    ],\n   epsilon = $MachineEpsilon\n  },\n  serialFitter = Compile[{{datasets, _Real, 2}},\n    Table[minimizer[RandomReal[{0, 1}, {4 + 1, 4}], epsilon, -1], {data, datasets}],\n    CompilationOptions -> {\"InlineCompiledFunctions\" -> True},\n    RuntimeOptions -> {\"Speed\", \"EvaluateSymbolically\" -> False}, \n    CompilationTarget -> \"C\"\n   ];\n  parallelFitter = Compile[{{data, _Real, 1}},\n    minimizer[RandomReal[{0, 1}, {4 + 1, 4}], epsilon, -1],\n    CompilationOptions -> {\"InlineCompiledFunctions\" -> True},\n    RuntimeOptions -> {\"Speed\", \"EvaluateSymbolically\" -> False}, \n    CompilationTarget -> \"C\",\n    Parallelization -> True, RuntimeAttributes -> {Listable}\n   ];\n ];\n\nHere the same minimand as used above is enclosed in a Function to make it suitable for NelderMeadMinimize`Dump`CompiledNelderMead, which is then called with this objective function and the option \"ReturnValues\" -> \"OptimizedParameters\" to generate a compiled minimizer that can be used from within other compiled code. Two callers are defined: serialFitter simply loops over each dataset given in its argument, while parallelFitter is Listable and automatically parallelizes over multiple datasets. Let's check them:\nBlock[{x = Range[50]},\n Round@serialFitter[{3 + x - 4 x^2 + 2 x^3, -8 - 2 x + 7 x^2 - x^3}] == \n  Round@parallelFitter[{3 + x - 4 x^2 + 2 x^3, -8 - 2 x + 7 x^2 - x^3}] ==\n   {{3, 1, -4, 2}, {-8, -2, 7, -1}}\n]\n\nAs expected, we get True, so these can both correctly fit cubic polynomials. What about performance?\ndatasets = Accumulate /@ RandomReal[{-1, 1}, {1000, 100}];\n\nserialFitter[datasets]; // Timing\n(* 7.813 seconds *)\n\nparallelFitter[datasets]; // AbsoluteTiming\n(* 2.141 seconds *)\n\nSo, we have 7.8ms and 2.1ms per dataset, respectively. While these datasets, the model being fitted, and the convergence tolerances are admittedly all different to those in Ajasja's problem, that's still not too bad at all in my opinion. Furthermore, if you have a computer with support for simultaneous multithreading (SMT, e.g. Intel HT), the performance of parallelFitter can be further improved by evaluating SetSystemOptions[\"ParallelOptions\" -> \"ParallelThreadNumber\" -> n] (where the value n depends on the number of logical processors available). Evidently, Mathematica's compiled code is not quite optimal, even after being translated to C and compiled to native code, since I found that this setting provided about 20% better performance on an Intel i7-2600 CPU.\n", "recursion - How can I solve a difference-differential equation?": "\nFor the simple example in the question, FindSequenceFunction can be used to infer the general form:\ng[0]=Exp[2x];\ng[n_]:=g[n]=Expand[D[g[n-1],x]]\n\nFindSequenceFunction[g/@Range[5],n]\nOut[3]= 2^n E^(2 x)\n\n", "front end - Option to change cursor/caret shape": "\nAlas, MMA doesn't obey the system-wide insertion point cursor size setting in Windows 7's \"Ease of access center\". \nInstead, to find the position of your latest edit you could use the Cell > Notebook history menu which will get you a graphical overview of your edits:\n\nClicking on a point in the edits display brings you to the specific cell. Floating your cursor above a point gets you a tooltip with the specific cell content.Just look for the right-most point; that should be your latest edit.\n", "plotting - Display position information out of ListPlots inside a Manipulate": "\nYou may find a suggestion or two of interest in what follows (although it's not exactly what you asked for):\nlist1 = NestList[3 # (1.25 - #) &, .1, 20];\nlist2 = NestList[3 # (1.3 - #) &, .1, 20];\nlist3 = NestList[3 # (1.275 - #) &, .1, 20];\n\nManipulate[Grid[{{\n   If[lists != {}, ListLinePlot[\n  Tooltip@#[[windowStart ;; windowEnd]] & /@ (lists /. {1 -> \n       list1, 2 -> list2, 3 -> list3}), ImageSize -> 350, \n  AxesLabel -> {\"element\", None}, PlotMarkers -> Automatic,\n  GridLines -> {{n}, None},\n  GridLinesStyle -> Directive[Blue, Thickness[.007], Dashed]]],\n  Grid[Prepend[(lists /. {1 -> {1, list1[[n]]}, \n     2 -> {2, list2[[n]]}, 3 -> {3, list3[[n]]}}), {\"list\", \n   \"element \" <> ToString[n + windowStart - 1]}], Frame -> All]\n  } }],\n {{windowStart, 1, \"start element\"}, 1, windowEnd - 1, 1},\n {{windowEnd, Length[list1], \"end element\"}, 2, Length[list1], 1},\n {{n, 5, \"current element\"}, 1, Length[list1], 1},\n {{lists, {1}}, {1, 2, 3}, CheckboxBar}]\n\n\n\nI superimposed the graphs to save space. There are 3 lists in the present example. Two are selected and displayed.\nYou can select those lists you want to compare at any given moment.\nA current element slider highlights the element that you are comparing at the moment.\nA table of values shows the current value for each selected list\nTooltips can be read off by mousing over the line graph markers.\nwindowStart has a maximum value of the current value of windowEnd\n\n\nEdit: Multiple plots\nAlternatively, you may include multiple plots in a pane:\nlist1 = NestList[3 # (1.25 - #) &, .1, 20];\nlist2 = NestList[3 # (1.3 - #) &, .1, 20];\nlist3 = NestList[3 # (1.275 - #) &, .1, 20];\n\nManipulate[\n Pane[\n  Grid[{{\n   Column[If[lists != {}, ListLinePlot[\n      Tooltip@#[[2]][[windowStart ;; windowEnd]], \n      ImageSize -> {350, 200}, AxesLabel -> {\"element\", None}, \n      PlotMarkers -> Automatic,\n      PlotLabel -> \"List \" <> ToString[#[[1]]],\n      GridLines -> {{n}, None},\n\n      GridLinesStyle -> \n       Directive[Blue, Thickness[.007], \n        Dashed]] & /@ (lists /. {1 -> {1, list1}, 2 -> {2, list2},\n        3 -> {3, list3}})\n   ]],\n Grid[\n  Prepend[(lists /. {1 -> {1, list1[[n]]}, 2 -> {2, list2[[n]]}, \n      3 -> {3, list3[[n + windowStart - 1]]}}), {\"list\", \n    \"element \" <> ToString[n]}], Frame -> All]\n } }], {500, 450}, Scrollbars -> {False, True}],\n{{windowStart, 1, \"start element\"}, 1, windowEnd - 1, 1},\n{{windowEnd, Length[list1], \"end element\"}, 2, Length[list1], 1},\n{{n, 5, \"current element\"}, 1, Length[list1], 1},\n{{lists, {1}}, {1, 2, 3}, CheckboxBar}]\n\n", "plotting - How to change the default ColorData used in Mathematica's Plot?": "\nUpdate August 2014\nThe Legacy Solution below has been corrected to work in recent versions (9 and 10).\nAt the same time however the introduction of PlotTheme functionality makes my solution largely academic as plot themes are designed to combine in the same manner.  If no existing theme has the desired style you can create a custom one.\nThis example demonstrates setting new default plot colors as well a custom thickness and these correctly combining with the dashing directives in PlotStyle:\nSystem`PlotThemeDump`resolvePlotTheme[\"Thick5\", \"Plot\"] := \n Themes`SetWeight[{\"DefaultThickness\" -> {AbsoluteThickness[5]}}, \n  System`PlotThemeDump`$ComponentWeight]\n\nSetOptions[Plot, PlotTheme -> {\"DarkColor\", \"Thick5\"}];\n\nfns = Table[x^n, {n, 0, 5}];\ndash = Table[AbsoluteDashing[i], {i, 1, 6}];\n\nPlot[fns, {x, -1, 1}, PlotStyle -> dash]\n\n\n\nLegacy Solution\nThe following updated solution is based on the existing solutions from Janus and belisarius with considerable extension and enhancement.\nSupporting functions\nClearAll[toDirective, styleJoin]\n\ntoDirective[{ps__} | ps__] := \n  Flatten[Directive @@ Flatten[{#}]] & /@ {ps}\n\nstyleJoin[style_, base_] :=\n  Module[{ps, n},\n    ps = toDirective /@ {PlotStyle /. Options[base], style};\n    ps = ps /. Automatic :> Sequence[];\n    n = LCM @@ Length /@ ps;\n    MapThread[Join, PadRight[#, n, #] & /@ ps]\n  ]\n\nMain function\npp is the list of Plot functions you want to affect.\nsh is needed to handle pass-through plots like LogPlot, LogLinearPlot, DateListLogPlot, etc.\npp = {Plot, ListPlot, ParametricPlot, ParametricPlot3D};\n\nUnprotect /@ pp;\n\n(#[a__, b : OptionsPattern[]] :=\n   Block[{$alsoPS = True, sh},\n     sh = Cases[{b}, (\"MessagesHead\" -> hd_) :> hd, {-2}, 1] /. {{z_} :> z, {} -> #};\n     With[{new = styleJoin[OptionValue[PlotStyle], sh]}, #[a, PlotStyle -> new, b]]\n   ] /; ! TrueQ[$alsoPS];\n DownValues[#] = RotateRight[DownValues@#]; (* fix for versions 9 and 10 *)\n) & /@ pp;\n\n\nUsage\nNow different plot types may be individually styled as follows:\nSetOptions[Plot, PlotStyle -> ColorData[3, \"ColorList\"]];\n\nOr in groups (here using pp defined above):\nSetOptions[pp, PlotStyle -> ColorData[3, \"ColorList\"]];\n\n\nExamples\nPlotStyle options are then automatically added:\nfns = Table[x^n, {n, 0, 5}];\ndash = Table[AbsoluteDashing[i], {i, 1, 6}];\n\nPlot[fns, {x, -1, 1}, PlotStyle -> dash]\n\n\n\nPlot[...] and Plot[..., PlotStyle -> Automatic] are consistent:\nPlot[fns, {x, -1, 1}]\nPlot[fns, {x, -1, 1}, PlotStyle -> Automatic]\n\n\n\n\nPass-through plots (those that call Plot, ListPlot or ParametricPlot) can be given their own style:\nSetOptions[LogPlot, PlotStyle -> ColorData[2, \"ColorList\"]];\n\nLogPlot[{Tanh[x], Erf[x]}, {x, 1, 5}]\nLogPlot[{Tanh[x], Erf[x]}, {x, 1, 5}, PlotStyle -> {{Dashed, Thick}}]\n\n\n\n\nPlotStyle handling can be extended to different Plot types.\nI included ParametricPlot3D above as an example:\nfns = {1.16^v Cos[v](1 + Cos[u]), -1.16^v Sin[v](1 + Cos[u]), -2 1.16^v (1 + Sin[u])};\n\nParametricPlot3D[fns, {u, 0, 2 Pi}, {v, -15, 6},\n  Mesh -> None, PlotStyle -> Opacity[0.6], PlotRange -> All, PlotPoints -> 25]\n\n\n\nImplementation note\nAs it stands, resetting SetOptions[..., PlotStyle -> Automatic] will revert the colors to the original defaults.  If this behavior is undesirable, the code can be modified to give a different default color, in the manner of Janus' also function, upon which my styleJoin is clearly based.\n", "parallelization - DistributeDefinitions doesn't work as expected when used for table iterator bounds?": "\nThe problem is that capital-K is a reserved word.\n?K\n\n\nK is a default generic name for a summation index in a symbolic sum.\n\nOther single-character variables to avoid are:\nC, D, E, I, N, O\n\nGenerally, you should avoid using variables that start with a capital character. It is not forbidden, but starting with a lowercase character will prevent you from colliding with built-in definitions that all start with a uppercase character.\n", "plotting - Labelling ArrayPlot Charts": "\nThe FrameTicks should be entered in the following format: \nFrameTicks->{\n    {{ytick1, yvalue1}, {ytick2, yvalue2},...}, \n    {{xtick1, xvalue1}, {xtick2, xvalue2},...}\n}\n\nSo here's an example for your case that shows how to label the ticks:\nxticks = Transpose[{Range@15, Range[1997, 2011]}];\nyticks = Transpose[{Range@5, {\"Cats\", \"Dogs\", \"Sheep\", \"Frogs\", \"Mice\"}}];\nArrayPlot[RandomReal[1, {5, 15}], FrameTicks -> {yticks, xticks}]\n\n\n", "export - Does Mathematica support variable frame rate for any video format, in analogue of GIF-style \"DisplayDurations\"?": "\nThis is a solution specifically using the QTKit library in Mac OS X. I'm calling it through the built-in Python interface, using a script that could also be run as a Python module or in standalone mode. \nSince the goal here is to make a Mathematica function, I wrapped the call in a Run command inside a function exportMov. This required stuffing the Python code into a string that shows up as a single huge line in the code below (Python is sensitive to the placement of newlines and indentation, so the spaces and \\n characters in the string are all intentional). I've used the same technique for calling a Python script on the fly in this answer before. \nEdit:\nThe Python code is posted in a more readable and re-usable form on my website. End Edit.\nexportMov[name_String, frames_List, delays_: {.03}] := Module[\n  {\n   outFile = ExpandFileName[name],\n   fileNames,\n   script =\"printf \\\"from Foundation import NSNumber\\nfrom AppKit import NSImage\\nfrom QTKit import *\\n\\nclass QuickTimeError(Exception):\\n    @classmethod\\n    def from_nserror(cls, nserror):\\n        return cls(nserror.userInfo()['NSLocalizedDescription'])\\n\\ndef createQT(infiles, sequence, durations, outfile):\\n    attrs = {QTAddImageCodecType: 'avc1', QTAddImageCodecQuality: NSNumber.numberWithLong_(codecHighQuality)}\\n    mov, err = QTMovie.alloc().initToWritableFile_error_(outfile, None)\\n    if mov is None:\\n        raise QuickTimeError.from_nserror(err)\\n    n = len(durations)-1\\n    i = 0\\n    for index in sequence:\\n        img = NSImage.alloc().initWithContentsOfFile_(infiles[sequence[index]])\\n        t = durations[i]\\n        if i<n:\\n            i = i+1\\n        else:\\n            i = 0\\n        time = QTMakeTime(t, 600)\\n        mov.addImage_forDuration_withAttributes_(img, time, attrs)\\n    mov.updateMovieFile()\\n\\nif __name__ == '__main__':\\n    import os,sys,csv,string\\n\\n    buildfile = 'buildFile'\\n    framedata = csv.reader(open(buildfile, 'rb'), delimiter=' ')\\n    imagefiles = []\\n    durations = []\\n    for row in framedata:\\n        if os.path.exists(row[0]):\\n            imagefiles.append(row[0])\\n            if len(row)>1:\\n                durations.append(float(row[1]))\\n            else:\\n                durations.append(30)\\n        else:\\n            print row[0]+': File not found'\\n    if len(imagefiles)==0:\\n        print 'No images found. Movie not created'\\n    else:\\n        print 'Creating movie from frames'\\n        outfileName = os.path.abspath('out.mov')\\n        createQT(imagefiles, range(len(durations)), durations, outfileName) \\n\\\" | /usr/bin/python\",\n   tempDir = \n    FileNameJoin[{$TemporaryDirectory, \n      \"MathematicaOutput\" <> StringJoin[Map[ToString, DateList[]]]}]\n   },\n  CreateDirectory[tempDir];\n  SetDirectory[tempDir];\n  Export[\"frame00000001.png\", frames, \"VideoFrames\"];\n  fileNames = FileNames[];\n  Export[\"buildFile\", \n   MapThread[(# <> \" \" <> ToString[#2]) &, {fileNames, \n     600 PadRight[delays, Length[fileNames], delays]}], \"Text\"];\n  (* Process files *)\n  Run[script];\n  CopyFile[\"out.mov\", outFile];\n  (* Cleanup: *)\n  Map[DeleteFile, FileNames[]];\n  ResetDirectory[];\n  DeleteDirectory[tempDir]\n  ]\n\nThe example movie for which I defined the frames in the question above can now be exported as follows:\nexportMov[\"slowDownMovie.mov\", frames, \n Append[Range[Length[frames] - 1]/20, 2]]\n\nThe frames are first exported as single images into a temporary directory, then assembled into a movie with the name given as the first argument. \nThe third argument to exportMov is the list of frame durations, and that is of course the whole point of this function. In the above example, I used the same list of durations as for the GIF animation. The list of durations is optional (when omitted, a constant default duration is used). If the list of durations is shorter than the list of frames, then the given durations are repeated cyclically until all frames are used up.\n", "calculus and analysis - Incorrect results for elementary integrals when using Integrate": "\nAn experimental internal function Integrate`InverseIntegrate helps here, although it's intended more for integrands involving logs. This is what it returns in the development version:\nIntegrate`InverseIntegrate[Exp[-x Cosh[t]], {t, 0, Infinity}, Assumptions -> Re[x] > 0]\n(*  BesselK[0, x]  *)\n\n", "output formatting - How to format numbers with at least one figure after the decimal point": "\nHere is an idea:\nSetAttributes[myForm, Listable]\nmyForm[x_] := \n If[Abs[Mod[x, 1]] <= $MachineEpsilon, NumberForm[x, {Infinity, 1}], \n  x]\n\n", "programming - Mathematica usage (success stories) for financial back-ends": "\nHere are a few pointers.\nFor question 1 you can find information, for example here and here. There are some user stories on that page. Other companies/products in that area (and there are many more) are for example UnRisk or RapidBusinessModeling.\nConcerning point 2, yes unit testing is available via Wolfram Workbench UnitTesting. In fact most of Mathematica's unit tests are done with this. To run unit tests outside of Workbench have a look here.\nConcerning point 3, a large extend of Mathematica is written in Mathematica. More that 1MLOC can be managed with WolframWorkbench, no sweat. Concerning organization, a Mathematica Package is a unit which collects functionality in it's own context (name space).\n", "Unsupervised Machine Learning Algorithm for Autonomous Image Processing and Tracking": "\nHere is a starting point: Intrusion detection was featured on the Wolfram blog a while back :-) Perhaps that helps.\n", "graphics - Visualizing the output of a Voronoi diagram computation": "\nI didn't quite follow the description of your graph, but are you aware of this functionality?:\ndata = MapIndexed[Flatten[{##}] &, RandomReal[1, {100, 2}]];\n\nListDensityPlot[\n data,\n InterpolationOrder -> 0,\n ColorFunction -> Hue,\n Mesh -> All,\n Epilog -> Point@data[[All, {1, 2}]]\n]\n\n\nSpecifically note InterpolationOrder -> 0.\n", "output formatting - GridBox/packed array behaviour": "\nSeems like GridBox doesn't work well with packed arrays. Or at least not with DisplayForm\nr = RandomInteger[10, {4, 4}];\nDeveloper`PackedArrayQ[r]\nrnp = Developer`FromPackedArray[r];\nDisplayForm[GridBox[r]]\nDisplayForm[GridBox[rnp]]\n\nDiagonalMatrix returns a packed array\nDeveloper`PackedArrayQ[DiagonalMatrix[{1, 2, 3, 4, 5}]]\n\n\nTrue\n\nSo, I'd say it's a bug, but a workaround to ensure it all works fine is to wrap your variable in FromPackedArray before putting it in the GridBox\nfoo = DiagonalMatrix[{1, 1}];\nGridBox[Developer`FromPackedArray@foo] // DisplayForm\n\n", "plotting - Exporting a 3D plot into a 3D viewing format and axis scaling": "\nThe \"original scaling\" of the displayed plot in Mathematica is determined by the BoxRatios setting for the plot, so it isn't intrinsic to the surface you're trying to export. When you export the plot, only the mesh is kept, with its actual 3D coordinates and without the scaling due to BoxRatios. \nTherefore, if you want to export the surface in a \"squished\" form, you'll have to do the squishing yourself:\np = Plot3D[x^2+y^2,{x,-10,10},{y,-10,10}];\nWith[{zScale = .05},\n Export[\"squishedPlot.wrl\", \n  p /. Graphics3D[gr_, opts___] :> \n    Graphics3D[\n     GeometricTransformation[gr, ScalingTransform[{1, 1, zScale}]], \n     opts]]\n ]\n\nI checked that this produces the desired \"aspect ratio\" by importing the file into Blender.\n", "Interlacing a single number into a long list": "\nAnother possibility:\nThread[{1997,data1}]\n\n", "programming - Use OptionValue to deal with nested options": "\nYou can actually use OptionValue to extract options of options by doing something like OptionValue[option -> subOption]. For example\nOptions[ff] = {\"fruit\" -> {apple -> 1, pear -> 2, orange -> 3}}\nff[OptionsPattern[]] := {apple, OptionValue[\"fruit\" -> apple]}\n\nff[\"fruit\" -> {apple -> 4}]\n\n(* ==> {apple, 4} *)\n\n", "matrix - Bordermatrix from $ \\mathrm\\LaTeX $": "\nThis seems to work, at least for your example:\nTraditionalForm @ Grid[{{Null, Grid[{{x, y}}]}, {TableForm@{{A}, {B}}, \n  MatrixForm[IdentityMatrix[2]]}}]\n\n\nYou can make a little function that generalises it:\nmakeBordermatrix[mat_?MatrixQ, top_?VectorQ, side_?VectorQ] := \n TraditionalForm@\n  Grid[{{Null, Grid[{top}]}, {TableForm[Transpose@{side}], \n     MatrixForm[mat]}}]\n\nSo we have:\nmakeBordermatrix[IdentityMatrix[3], {x, y, z}, {A, B, C}]\n\n\n", "output formatting - Width-dependent MatrixForm": "\nThis is a start. \nClearAll[DecayingMatrixForm];\nUnprotect[$OutputForms];\nAppendTo[$OutputForms, DecayingMatrixForm];\nProtect[$OutputForms];\nDecayingMatrixForm /: \n Format[DecayingMatrixForm[mat_?MatrixQ], StandardForm] :=\n With[{m = Map[Defer, mat, {2}], mw=matrixWidth[mat]},\n  Dynamic[\n   If[First@CurrentValue[\"WindowSize\"] > mw, \n    MatrixForm[m], m]]]\n\nHere's the raw matrixWidth function. It is very raw, feel free to edit and improve it if you like, or replace it by a cool built-in...\nfsize2pixels = Interpolation[{{6, 8}, {7, 9}, {7.5`, 10}, {8, 11}, {9, \n    12}, {10, 13}, {10.5`, 14}, {11, 15}, {12, 16}, {13, 17}, {13.5`, \n    18}, {14, 19}, {14.5`, 20}, {15, 21}, {16, 22}, {17, 23}, {18, \n    24}, {20, 26}, {22, 29}, {24, 32}, {26, 35}, {27, 36}, {28, \n    37}, {29, 38}, {30, 40}, {32, 42}, {34, 45}, {36, 48}}]\n\nmatrixWidth[mat_?MatrixQ] := \n CurrentValue[\"Magnification\"] With[{w = Length@First@mat, \n   chars = Max[\n     StringLength /@ StringJoin /@ Map[ToString, mat, {2}]]}, \n  116 + 0.5 fsize2pixels[CurrentValue[\"FontSize\"]] (chars + w + 1)]\n\n", "plotting - Just what kind of transformations can TransformedDistribution handle?": "\nTransformedDistribution contains a collection of identities known to it, like that of sum of normals being equal in distribution to another normal random variable, and a general machinery to work out properties of the functions of random variables. \nMost of the time the computation will be done by the general machinery, which relies on solvers, like Expectation and Probability. Hence TransformedDistribution will be as strong as those are. \nThe major strength of TransformedDistribution, in my opinion, is that it allows for easy and efficient sampling. It is generally expensive to work out other properties of the random variable from this representation.\nIn this particular example of $(2 Z-1) X \\stackrel{d}{=} -(-1)^Z X$ the underlying solvers did not know how to handle the mixed case of discrete and continuous distribution: \nIn[11]:= di = \n  TransformedDistribution[(2 z - 1) x, {z \\[Distributed] \n     BernoulliDistribution[1/2], \n    x \\[Distributed] ExponentialDistribution[1]}];\n\nIn[12]:= CDF[di, z]\n\nOut[12]= CDF[\n TransformedDistribution[(-1 + \n     2 \\[FormalX]1) \\[FormalX]2, {\\[FormalX]1 \\[Distributed] \n    BernoulliDistribution[1/2], \\[FormalX]2 \\[Distributed] \n    ExponentialDistribution[1]}], z]\n\nAs it is often the case, one can work out the answer in an alternative way:\nIn[13]:= CharacteristicFunction[di, t] // Simplify\n\nOut[13]= 1/(1 + t^2)\n\nIn[14]:= pdf = \n InverseFourierTransform[%, t, x, FourierParameters -> {1, 1}]\n\nOut[14]= 1/2 E^-Abs[x]\n\n", "matrix - Non-commutative symbolic linear algebra": "\nSearke hints at the answer. Remembering that the dot product is a specific form of Inner:\nInner[Times,P,Q,Plus]\n\nWe can simply replace Times wtih NonCommutativeMultiply\nInner[NonCommutativeMultiply, P, Q, Plus]\n\nWith the output:\n{\n {P1 ** Q1 + P12 ** Transpose[Q12],P1 ** Q12 + P12 ** Q2}, \n {P2 ** Transpose[Q12] + Transpose[P12] ** Q1, P2 ** Q2 + Transpose[P12] ** Q12}\n}\n\n", "graphics - How can I model composite 3D structures?": "\nIndeed it's very easy. Just use Show. Here is an example:\nadhock = Graphics3D[{Blue, Cylinder[], Red, Sphere[{0, 0, 2}], Black, \n    Thick, Dashed, \n    Line[{{-2, 0, 2}, {2, 0, 2}, {0, 0, 4}, {-2, 0, 2}}], Yellow, \n    Polygon[{{-3, -3, -2}, {-3, 3, -2}, {3, 3, -2}, {3, -3, -2}}], \n    Green, Opacity[.3], Cuboid[{-2, -2, -2}, {2, 2, -1}]}];\n\n\nparametric = \n  ParametricPlot3D[{(3 + Cos[v]) Cos[u], (3 + Cos[v]) Sin[u], \n    Sin[v]}, {u, 0, 2 Pi}, {v, 0, 2 Pi}, \n   PlotStyle -> Specularity[White, 50], Mesh -> None];\n\n\nShow[adhock, parametric]\n\n\n", "intrpolation of 3D data - Mathmatica Stack Exchang": "\nMathematica's interpolation function, Interpolation, works on multidimensional data. For example,\ndata = Flatten[Table[{x, y, x^2 + y^2}, {x, -10, 10}, {y, -10, 10}], 1];\nint = Interpolation[data];\n\nThen, you can extract the values for values between the data points:\nint[1.1, 1.1]\n(* ==> 2.42 *)\n\nAnd Plot3D, or whatever else you want.\nPlot3D[int[x, y], {x, -10, 10}, {y, -10, 10}]\n\n\nNote, that the interpolation is pretty good:\nexact[x_, y_] := x^2 + y^2\nint[1.1, 1.1] == exact[1.1, 1.1]\n(* => True *)\n\nOr better yet (thanks @rcollyer):\n(int[1.1, 1.1] - exact[1.1, 1.1])/exact[1.1, 1.1]\n(* 1.83508*10^-16 *)\n\n\nUpdate Leonid's comment below pointed out that the accuracy of Interpolation will be worse with an unstructured grid. For example:\ndataDelete = Delete[data, RandomInteger[{1, Length[data]}]]\nintD = Interpolation[dataDelete]\n\nThen,\n(intD[1.1, 1.1] - exact[1.1, 1.1])/exact[1.1, 1.1]\n(* ==> 0.0743802 *)\n\nwhich is worse. It seems particularly bad close to the origin:\nPlot3D[(intD[x, y] - exact[x, y])/ exact[x, y], {x, -10, 10}, {y, -10, 10}]\n\n\n", "numerics - Numerically obtaining the inverse Laplace transform of data": "\nHere is my attempt at an answer - I had to make up an example, and obviously much of what follows is dependent on details of this example. \nEdit\nHowever, what I believe this example shows quite clearly is that a finite set of tabulated data at discrete points does not suffice to guarantee a good inverse Laplace transform, because the analytic structure of the function that interpolates between these data points is not uniquely determined by a finite number of points. You'll need additional information beyond the data table to get a correct inverse transform.\nEnd edit\nLet's start with a known function and its known Laplace transform, so we have something to compare the numerical results to:\noriginalFunction[t_] := t^4 Sin[t];\nl[s_] := Evaluate[LaplaceTransform[originalFunction[t], t, s]];\n\nNow I sample the Laplace transform l at discrete points to simulate the data that would be the given quantities of the problem:\ndata = Table[{s, l[s]}, {s, -5, 5, .1}];\n\nThe numerical inversion of this Laplace transform now can be performed by assuming a fit to the data that has a sufficiently simple functional form that allows us to do the inversion. I'll make the ansatz that we can fit the data with a rational function, leaving the degree of the numerator and denominator as parameters that may have to be adjusted by trial and error:\nfit[s_] := Evaluate[\n   Block[{numeratorN = 5, denominatorN = 8},\n    rationalFunction = \n     Total[Array[a, numeratorN + 1] s^Range[0, numeratorN]]/\n      Total[Array[b, denominatorN + 1] s^Range[0, denominatorN]];\n    rationalFunction /. \n     FindFit[data, rationalFunction, \n      Join[Array[a, numeratorN + 1], Array[b, denominatorN + 1]], s]]];\n\nThis fit function looks promising if we check the plot versus the data points:\nShow[ListPlot[data, PlotRange -> All], \n Plot[fit[s], {s, -5, 5}, PlotRange -> All]]\n\n\nSo we might feel somewhat confident that the inversion will work as follows:\nfitInverse[t_] := Evaluate[InverseLaplaceTransform[fit[s], s, t]];\n\nUnfortunately, the result isn't too good:\nPlot[{originalFunction[t], Re@fitInverse[t]}, {t, -1, 1}, \n PlotStyle -> {Directive[Thick, Red], Directive[Blue, Dashed]}]\n\n \nThe red curve is the original function that we're trying to recover with the inverse Laplace transform. This is a problem that will be hard to avoid in practice. In my example, I can indeed make the fit work out much better by just increasing the degree of the denominator to get a faster fall-off at infinity:\nfit[s_] := Evaluate[\n   Block[{numeratorN = 5, denominatorN = 10},\n    rationalFunction = \n     Total[Array[a, numeratorN + 1] s^Range[0, numeratorN]]/\n      Total[Array[b, denominatorN + 1] s^Range[0, denominatorN]];\n    rationalFunction /. \n     FindFit[data, rationalFunction, \n      Join[Array[a, numeratorN + 1], Array[b, denominatorN + 1]], s]]];\nShow[ListPlot[data, PlotRange -> All], \n Plot[fit[s], {s, -5, 5}, PlotRange -> All]]\n\n\nIn the plot interval chosen here, you won't see any difference in the fit, compared to the first attempt. But the small change is enough to make the inversion work:\nfitInverse[t_] := Evaluate[InverseLaplaceTransform[fit[s], s, t]];\nPlot[{originalFunction[t], Re@fitInverse[t]}, {t, -1, 1}, \n PlotStyle -> {Directive[Thick, Red], Directive[Yellow, Dashed]}]\n\n\nThe numerical inverse and the target function lie on top of each other now. So that's how you can do it in principle: Get a good fit to the data that also has the \"correct\" asymptotic behavior (i.e., falls off in the way you expect based on the physics or other knowledge about your data). Then do the InverseLaplaceTransform on that fit and hope for the best.\n", "Improved interpolation of mostly-structured 3d data": "\nHow to figure out where the missing grid points are... This maybe not as robust as it gets \nTake your data\ndata = Flatten[Table[{x, y, x^2 + y^2}, {x, -10, 10}, {y, -10, 10}], \n   1];\ndataDelete = Delete[data, RandomInteger[{1, Length[data]}]];\n\nand extract the domain coordinates\nd = dataDelete[[All, ;; -2]];\n\nChoose the step to be the commonest of the differences in each direction\nstep = #2@\n     First@Commonest[\n       Join @@ Differences /@ Sort /@ GatherBy[d, #]] & @@@ {\n    {First, Last},\n    {Last, First}\n   };\n\nChoose the range, the limits, to be the minimum and maximum of all rows and coloumns\nlimits = Through@{Min, Max}[#] & /@ Transpose@d;\n\nTake the complement of a perfect grid and your data grid\nComplement[Tuples[Range @@ Transpose@limits], d]\n\nI got {{-3, 6}}\n", "Changing color of an object in an image": "\nHere's a version using Manipulate with a Locator to pick the colour to replace. There is also a tolerance control which determines how wide a range of hues to replace.\ni=Import[\"http://i.stack.imgur.com/Qr7Tx.jpg\"];\n\n{h,s,b}=ColorSeparate[i,\"HSB\"];\n\ncolourchange[c_,from_,tol_,to_]:=Module[\n{offset=Mod[c-from+0.5,1]-0.5},\nIf[Abs[offset]>tol,c,to]];\n\nManipulate[\nColorCombine[\n{ImageApply[colourchange[#,ImageValue[h,pos],tol,ColorConvert[to,Hue][[1]]]&,h],s,b},\n\"HSB\"],\n{{to,Blue,\"Change to\"},Blue},\n{{tol,-0.01,\"Tolerance\"},-0.01,0.5},\n{{pos,{100,50}},Locator}]\n\n\n", "plotting - How to properly plot a response of a transfer function in Mathematica?": "\no1 isn't always real - it has a small imaginary component.  For example o1 /. t -> 4 gives 0.995493 - 5.18448*10^-7 I.  What you could do is Chop the output response:\no1 = Chop @ OutputResponse[tfm, UnitStep[t], t];\n\nThis gives you a nice smooth graph.\nBut on the other hand if you look at the unchopped version o1 /. t-> 8 you get 831840. + 332820. I.  Not a small imaginary component at all - so maybe chopping it wasn't a good idea.\nYou could also try an exact equation by replacing 43.35 with 4335/100.  This gives real results, but goes haywire when t > 5.\nUnfortunately I know nothing about transfer functions to say which might be right.\n", "string manipulation - print the name of the variable in a list without evaluation": "\nAlso\nSetAttributes[f, HoldAll];\nf[x_] := #[[1]] <> \"=\" <> #[[2]] &@ StringSplit[ToString@Definition@x, \":=\"]\n\n", "plotting - Vertical alignment of FrameTicks Text": "\nUsing Pane as in Szabolcs's answer or Framed (with FrameStyle->None) with a combination of settings for BaselinePosition, ImageMargins and FrameMargins:\n  Graphics[Circle[], Frame -> True, \n  FrameTicks -> {{\n  {{0, Style[Pane[Style[0.4, FontSize -> 48], \n    BaselinePosition -> (Top -> Bottom), \n    FrameMargins -> {{0, 0}, {0, 40}}, \n    ImageMargins -> {{0, 0}, {0, -40}}], \n   Background -> Green]}}, \n  {{0, Style[Pane[Style[0.4, FontSize -> 48], \n    BaselinePosition -> (Bottom -> Top), \n    FrameMargins -> {{0, 0}, {40, 0}}, \n    ImageMargins -> {{0, 0}, {-40, 0}}], \n   Background -> Green]}}}, {None, None}}]\n\nyou get\n\n", "graphics - Plotting vectors originating from the origin in 3D": "\nFor your problem, it is probably easiest to build the graphic out of graphics primitives rather than use a pre-made convenience function such as ListPointPlot3D.\nThis is one way to do it:\ndata = {{1, 2, 3}, {3, 4, 5}, {5, 6, 7}};\n\nGraphics3D[Arrow[{{0, 0, 0}, #}] & /@ data]\n\n\nI simply used the Arrow graphics primitive.  I constructed a pure function that makes an arrow starting from the origin, and mapped it over the data.\n", "dynamic - How to control variables of outer and inner Manipulates?": "\nThe outer Manipulate defines a list (voteList) for tracking all votes (thus I used integer values for k), and the inner Manipulate is using the actual value of the kth vote for the definition of vote. If the inner Yes/No setter is changed, it changes vote, voteList and the number of votes as well, due to the pure controlfunction SetterBar. I also moved the initialization code to the outer Manipulate, as votes should be local to the whole thing, not just the inner Manipulate.\nManipulate[Column[{\n   Manipulate[\n    vote,\n    {{vote, voteList[[k]]}, {True, False}, \n     SetterBar[\n       Dynamic[vote, (vote = #; voteList[[k]] = #; \n          votes = Total@Boole@voteList) &], {True -> \"Yes\", \n        False -> \"No\"}] &}\n    ],\n   (*voteList,*)\n   Button[\"Votes: \" <> ToString@votes, Print[votes]]\n   }],\n {k, 1, 5, 1, Appearance -> \"Labeled\"},\n {voteList, ControlType -> None},\n {votes, ControlType -> None},\n Initialization :> {votes = 0, voteList = Table[False, {5}]}]\n\n\nOf course in this example of yours there is no need to wrap the internal vote into Manipulate, but I guess that this was just a toy example of a more complex problem. I'm not sure my solution is eaxactly the thing you are looking for, but if you provide some feedback, I can modify the code to better fit your requirements.\n", "plotting - Why does Plot3D omit parts of the surface at kinks?": "\nThe reason for this is automatic exclusion detection:\nHere the discontinuity in the derivative is ugly:\nPlot3D[Max[p^2 - q^2, 0], {p, 0, 1}, {q, -1, 1}, \n Exclusions -> None]\n\n\nWe can get Mathematica to auto-detect it, and compute the contours precisely, making the plot smooth around the discontinuity:\nPlot3D[Max[p^2 - q^2, 0], {p, 0, 1}, {q, -1, 1}, \n Exclusions -> Automatic]\n\n\nThe side effect is a gap, as you noticed.  Often one would prefer this gap to be filled with the same style as the plot.  It can be accomplished by setting ExclusionsStyle, like this:\nPlot3D[Max[p^2 - q^2, 0], {p, 0, 1}, {q, -1, 1}, \n Exclusions -> Automatic, ExclusionsStyle -> Automatic]\n\n\nEDIT:  As @celtschk notes, mesh lines or contour lines are not drawn inside the excluded region.  This is very visible for large exclusions and can be prevented by forbidding exclusions with Exclusions -> None.  Then the plot can be made smoother by increasing MaxRecursion and PlotPoints.  Here's an example:\nPlot3D[UnitStep[y], {x, -1, 1}, {y, -1, 1}, Exclusions -> None, MaxRecursion -> 5]\n\n\n", "graphics - Unsatisfactory view of Panel, when transformed to pdf": "\nYou could mimic the panelled look by doing something like\npanelBox[pt0 : {x0_, y0_}, \n  pt1 : {x1_, y1_}] := {{GrayLevel[.7], Rectangle[pt0, pt1]}, {White, \n   Polygon[{Offset[{.3, .3}, pt0], Offset[{2, 2}, pt0],\n     Offset[{2, -2}, {x0, y1}], Offset[{-2, -2}, {x1, y1}], \n     Offset[{-.3, -.3}, {x1, y1}], Offset[{.3, -.3}, {x0, y1}]}]},\n  {GrayLevel[.2], \n   Polygon[{Offset[{.3, .3}, pt0], Offset[{2, 2}, pt0],\n     Offset[{-2, 2}, {x1, y0}], Offset[{-2, -2}, {x1, y1}], \n     Offset[{-.3, -.3}, {x1, y1}], Offset[{-.3, .3}, {x1, y0}]}]}}\n\npanel[gr_] := Module[{dim},\n  dim = Dimensions[Rasterize[gr][[1, 1]]][[{2, 1}]];\n  Graphics[{panelBox[{-10, -10}, dim + 10], \n    Inset[gr, Center, Center, dim]}, ImageSize -> dim + 20]]\n\npanel[Import[\"ExampleData/rose.gif\"]]\n\n\n", "X3D Export - adding a titl - Mathmatica Stack Exchang": "\nI think the answer is: No, it cannot be done using Export alone. According to the documentation, there is no meta data listed in the elements available for export, nor in the options.\nTo accomplish what you would like to do, however, can be done via a two step process. First, save your plot as an X3D file, and the Import it as an XML file, as follows\nExport[\"plot.x3d\"]\nplotxml = Import[\"plot.x3d\", \"XML\"]\n\nThen, it is just a matter of inserting your element into the XML tree. From a brief browsing of the X3D spec, I am not sure of the specific element you need to insert you data into. Likely, though, your new element will be a MetadataString, so it should look like\nmdat = XMLElement[\"MetadataString\", {\"name\" -> \"Title\", \"value\" -> \"MyPlot\", ...}, {}]\n\nAnd, once you have found which element it belongs in, you can use \nplotxml = plotxml /. XMLElement[\"ParentElement\", attrs_, data_]:>\n   XMLElement[\"ParentElement\", attrs_, Append[data, mdat];\n\nIt is likely that you will have to specify the attrs list to only affect the specific element you are looking for.\n", "front end - How can I style text like in a system usage message?": "\nThe style name is PrintUsage. It is defined in the stylesheet notebook Core.nb which you can find in the directory:\n$InstallationDirectory\\SystemFiles\\FrontEnd\\StyleSheets\n\nIt has the following settings:\nCellFrame -> {{0, 0}, {0, 3}}\nCellFrameColor -> RGBColor[1, 0.6000000000000001, 0] \nBackground -> RGBColor[1, 0.993332, 0.899718] \n\nYou can use the OptionInspector to set DefaultNewCellStyle or DefaultReturnCreatedCellStyle to PrintUsage. You can also change these settings  at the notebook, front-end session or front-end level using\nSetOptions[xx,DefaultNewCellStyle->\"PrintUsage\"]\n\nwhere xx is EvaluationNotebook[] or $FrontEndSession, or $DefaultFrontEnd.\nA third alternative is to use the right-click context menu on a cell bracket,choose Style->Other and type PrintUsage in the dialog box to change the style of that cell. \nOne important issue with the above approach is that a cell with PrintUsage style is not editable. So, you may want to define your custom style using something like \nthis answer by Mike Honeychurch:   \nSetOptions[EvaluationNotebook[], \n   StyleDefinitions -> \n   Notebook[{Cell[StyleData[StyleDefinitions -> \"Default.nb\"]], \n   Cell[StyleData[\"myPrintUsageStyle\"], Editable -> True, Evaluatable -> True,\n   CellFrame -> {{0, 0}, {0, 3}}, CellMargins -> {{66, 10}, {10, 5}},\n   CellFrameColor -> RGBColor[1, 0.6000000000000001, 0], \n   Background -> RGBColor[1, 0.993332, 0.899718]]}, \n   Saveable -> True, StyleDefinitions -> \"PrivateStylesheetFormatting.nb\"]];\n\nand use it in place of PrintUsage using any of the usage options mentioned above, e.g.,\nSetOptions[EvaluationNotebook[],  DefaultNewCellStyle -> \"myPrintUsageStyle\"]\n\n", "Custom Format for \"constructors\"": "\nI see in your question that you would rather not use MakeBoxes but I think this might be worth a try.\nPair /: MakeBoxes[linkedList : Pair[i_, p_Pair], fmt_] := \n TagBox[ToBoxes[LinkedList @@ Flatten[linkedList]], \n  InterpretTemplate[Pair[i, p] &], Editable -> False, \n  Selectable -> True, SelectWithContents -> True]\n\nThe InterpretTemplate affects how Mathematica will see your expression whereas the TagBox is how you will see it. \nThis allows for copy and paste and any of the various forms work just fine.\n", "plotting - How can I plot more than one value in the same date?": "\nThis will plot the date values regularly spaced apart, with the dates as rotated string labels on the x-axis, in a fashion similar to that you describe in Excel.\nWith[{labels = Rotate[DateString@#, (3 \\[Pi])/2] & /@ dateValues[[All, 1]]}, \n ListPlot[dateValues[[All, 2]], \n  Ticks -> {Transpose[{Range@Length@labels, labels}], Automatic},Filling->Axis]]\n\n\nWith a little more fiddling, it is possible to get something that tries to reflect the proper flow of the time line. Though it constrains points to have a minimum spacing between them.\n(* Ease points that are close to one another apart, \nby minimum separation MinSeparation * ( Max-Min ) of data  *)\n\nOptions[Relax] = {MinSeparation -> 0.02};\nRelax[data_, OptionsPattern[]] := \n With[{sep = OptionValue@MinSeparation (Max@data - Min@data)}, \n  Flatten[{First@data, First@data + Accumulate[If[# < sep, sep, #] & /@ Differences@data]}]]\n\nPlot the values with date labels:\nWith[{labels = Rotate[DateString@#, (3 \\[Pi])/2] & /@ dateValues[[All, 1]], \n  softCoords = Relax[AbsoluteTime /@ dateValues[[All, 1]]]}, \n ListPlot[{softCoords, dateValues[[All, 2]]}\\[Transpose], \n  Ticks -> {{softCoords, labels}\\[Transpose], Automatic}, \n  Filling -> Axis, AxesOrigin -> {First@softCoords - 10^6, 80}]]\n\n\nFor your revised data here is the Plotting code:\nWith[{labels = \n   Rotate[DateString@#, (3 \\[Pi])/2] & /@ dateValues2[[All, 1]], \n  softCoords = Relax[AbsoluteTime /@ dateValues2[[All, 1]]]}, \n ListPlot[{\n {softCoords, dateValues2[[All, 2]]}\\[Transpose], \n {softCoords, dateValues2[[All, 3]]}\\[Transpose], \n {softCoords, dateValues2[[All, 4]]}\\[Transpose]}, \n  Ticks -> {{softCoords, labels}\\[Transpose], Automatic}, \n  AxesOrigin -> {First@softCoords - 10^6, 0}, \n  Joined -> {False, False, True}, Filling -> {1 -> {2}}]]\n\nGiving a plot like this:\n\nRelax generates a set of new coordinates for the data, which have been eased apart.\nThese new coordinates then form the basis of the Relaxed plot constructed using ListPlot.\nEach set of data associated with a date can then be fed into ListPlot as a list of {softcoordinate,value } pairs ( i.e. {AbsoluteTime, value } ). This is achieved by the idiom:\n{softCoords, dateValues2[[All, 2]]}\\[Transpose]\n", "Adding elements to a collection of lists": "\nThis would be a neat way to do it:\nLISTS1 = {{1, 2, 3, 4, 5}, {2, 3, 4, 5, 6}, {3, 4, 5, 6, 7}, {4, 5, 6, 7, 8}};\n\nMapIndexed[Join[Table[0, #2], #1] &, LISTS1]\n\n\n{{0, 1, 2, 3, 4, 5}, {0, 0, 2, 3, 4, 5, 6}, {0, 0, 0, 3, 4, 5, 6, 7}, {0, 0, 0, 0, 4, 5, 6, 7, 8}}\n\n", "import - Using Differences on data: trouble with floats and doubles": "\nThere are many ways to control the accuracy.\nHere is one:\nt = Table[x + RandomReal[{0, 10^-7}], {x, 0, 1, .1}]\nRationalize[#, 10^-3] & /@ Differences[t]\n(* -> {1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10}*)\n\n", "Tabulating Numeric Approximation": "\nI recommend you look at RecurrenceTable as J. M. suggested. However to give you an idea of how you would implement subscripts (by which I think you mean recursion) in a \"normal\" way, here's a simple example using the Fibonacci sequence:\nf[0] = 1;\nf[1] = 1;\nf[n_] := f[n - 1] + f[n - 2];\n\nFor performance you would also \"memoize\", which just means that you store every result so that you don't have to recalculate it later:\nf[0] = 1;\nf[1] = 1;\nf[n_] := (\n   f[n] = f[n - 1] + f[n - 2]\n);\n\nNotice that the f[n] = within the function is not f[n_] :=, because we aren't matching to a generic pattern and we don't need to recalculate the expression every time it's used. We're telling Mathematica that f applied to the specific value that n has at that time is whatever it calculates on the right-hand side at that time, so the usage there is like array indexing. It's the same as was done in the first two lines specifying f[0] and f[1].\nAnd for the sake of completeness, here's the RecurrenceTable version of the Fibonacci sequence that I pulled straight out of the documentation:\nRecurrenceTable[{a[n] == a[n - 1] + a[n - 2], a[1] == 1, a[2] == 1}, a, {n, 10}]\n\n", "performance tuning - Efficiently generating n-D Gaussian random fields": "\nHere's a reorganization of GaussianRandomField[] that works for any valid dimension, without the use of casework:\nGaussianRandomField[size : (_Integer?Positive) : 256, dim : (_Integer?Positive) : 2,\n                    Pk_: Function[k, k^-3]] := Module[{Pkn, fftIndgen, noise, amplitude, s2},\n  Pkn = Compile[{{vec, _Real, 1}}, With[{nrm = Norm[vec]},\n                                        If[nrm == 0, 0, Sqrt[Pk[nrm]]]], \n                CompilationOptions -> {\"InlineExternalDefinitions\" -> True}];\n  s2 = Quotient[size, 2];\n  fftIndgen = ArrayPad[Range[0, s2], {0, s2 - 1}, \"ReflectedNegation\"];\n  noise = Fourier[RandomVariate[NormalDistribution[], ConstantArray[size, dim]]]; \n  amplitude = Outer[Pkn[{##}] &, Sequence @@ ConstantArray[N @ fftIndgen, dim]];\n  InverseFourier[noise * amplitude]]\n\nTest it out:\nBlockRandom[SeedRandom[42, Method -> \"Legacy\"]; (* for reproducibility *)\n            MatrixPlot[GaussianRandomField[]]\n        ]\n\n\nBlockRandom[SeedRandom[42, Method -> \"Legacy\"];\n            ListContourPlot3D[GaussianRandomField[16, 3] // Chop, Mesh -> False]\n            ]\n\n\nHere's an example the routines in the other answers can't do:\nAbsoluteTiming[GaussianRandomField[16, 5];] (* five dimensions! *)\n   {28.000959, Null}\n\n", "probability or statistics - Creating word histograms from lists of strings": "\nI have a slightly different strategy for splittling the string than rcollyer, because you can stick the pattern into StringSplit directly instead of needing to do a StringReplace first to prepare the string for splitting. For instance:\nIn[141]:= StringSplit[\"A dog is in the house.\", Except[WordCharacter]]\nOut[141]= {\"A\", \"dog\", \"is\", \"in\", \"the\", \"house\"}\n\nAlso, you can make StringHistogram simpler by using the built-in Tally function, which you've reimplemented (pretty darn well, I must say): \nStringHistogram[list_, opts : OptionsPattern[]] :=\n With[{tally = Tally@list},\n  BarChart[tally[[All, 2]],\n   BarOrigin -> Left,\n   ChartLabels -> tally[[All, 1]],\n   FilterRules[{opts}, Options[BarChart]]\n   ]]\n\nI use the BarOrigin option to make the bars come from the side, which makes everything much easier to read when you have many strings, and I pass options to BarChart in order to make tweaking things easier:\nStringHistogram[\n StringSplit[StringData2, Except[WordCharacter]] // Flatten, \n ImageSize -> 500, BaseStyle -> \"Label\"]\n\n\n", "\"Covering up\" text in Graphics": "\nYou can use Inset:     \n  Show[{Graphics3D[{Opacity[0.2], Sphere[], Opacity[1.0], Blue, \n  Inset[Graphics[Text[Style[\"Surprise!\", Green, 24]]], {0, 0, 0}]}],\n  ParametricPlot3D[{Sin[th] Cos[ph], Sin[th] Sin[ph], Cos[th]}, {th, \n   0, Pi}, {ph, 0, 2 Pi}, \n  RegionFunction -> Function[{x, y, z}, Abs[x] < .9], \n  PlotRange -> {-1, 1}, PlotStyle -> Red, Mesh -> None]}]\n\nwhich gives\n\nAlternatively, you can use Texture:\n  text = Style[\"Surprise!!\", 128];\n  vrtxtxtrcoords = {{0, 0}, {1, 0}, {1, 1}, {0,  1}}; \n  Show[{Graphics3D[{Texture[text], \n  Polygon[{{-.2, -.3, -.3}, {-.2, .3, -.3}, {-.2, .3, .3}, {-.2,  -.3, .3}},  \n  VertexTextureCoordinates -> vrtxtxtrcoords]}, \n  Lighting -> \"Neutral\"], \n  ParametricPlot3D[{Sin[th] Cos[ph], Sin[th] Sin[ph], Cos[th]}, {th, 0, Pi}, {ph, 0, 2 Pi}, \n  RegionFunction -> Function[{x, y, z}, Abs[x] < .9], \n  PlotRange -> {-1, 1}, PlotStyle -> Red, Mesh -> None]}]\n\nwhich gives\n\n", "functions - How to find Matano plane": "\nMaybe I'm missing something but isn't the value for z just the solution of the equation \n(z - xLimits[[1]])*yLimits[[1]] + (xLimits[[2]] - z)*yLimits[[2]] == area\n\nwhere area is the total area under the graph, i.e.\narea = NIntegrate[GetRLine3[{data}, 3][x], {x, xLimits[[1]], xLimits[[2]]}][[1]]\n\nTherefore, z is equal to\nz = (xLimits[[2]]*yLimits[[2]] - xLimits[[1]]*yLimits[[1]] - area)/\n      (yLimits[[2]] - yLimits[[1]])\n\n", "graphs and networks - How to find all vertices reachable from a start vertex following directed edges?": "\nOne can use VertexOutComponent[] to find all the vertices connected to a given vertex in a directed graph:\nIn[107]:= edges={1->3,1->4,2->4,2->5,3->5,6->7,7->8,8->9,9->10,6->10,1->6,2->7,3->8,4->9,5->10};\nIn[114]:= vertices=Sort@DeleteDuplicates[Flatten[List@@@edges]];\nIn[115]:= g=Graph[vertices,edges];\nIn[116]:= {#,VertexOutComponent[g,{#}]}&/@vertices//Grid\nOut[116]= 1 {1,3,4,5,6,7,8,9,10}\n2   {2,4,5,7,8,9,10}\n3   {3,5,8,9,10}\n4   {4,9,10}\n5   {5,10}\n6   {6,7,8,9,10}\n7   {7,8,9,10}\n8   {8,9,10}\n9   {9,10}\n10  {10}\n\nIt should work for any directed graph whether it's acyclic or not. The analogue of VertexOutComponent[] for undirected graphs is ConnectedComponents[].\n", "graphics - Creating ghost trail effects": "\nHere is a simple approach to create a ghost trail:\nobj[{xfunc_, yfunc_}, rad_, lag_, npts_][x_] := MapThread[\n {Opacity[#1, ColorData[\"SunsetColors\", #1]],\n  Disk[{xfunc@#2, yfunc@#2}, rad Exp[#1 - 1]]} &, \n Through[{Rescale, Identity}[Range[x - lag, x, lag/npts]]]]\n\nframes = Most@Table[Graphics[obj[{Sin[2 #] &, Sin[3 #] &}, 0.1, 1, 500][u], \n  PlotRange -> {{-2, 2}, {-2, 2}}, Axes -> False, ImageSize -> 300,\n  Background -> Black] ~Blur~ 3, {u, 0, 2 Pi, 0.1}];\n\nExport[\"trail.gif\", frames, \"DisplayDurations\" -> .03] \n\n\n", "pattern matching - Does Mathematica use first order or second order order unification?": "\nI am not an expert in the field, but ...\nAccording to Roman Maeder (and he is an expert):\n\nThe process of unification should be easy to understand for\n  Mathematica users, since a weaker form of it \u2014pattern matching\u2014 is the\n  fundamental operating principle of Mathematica\u2019s evaluator.\n\nSo, no unification is done in native Mma.\nIf you need it, Maeder presents in that 2 articles series a package with a modified evaluator that aims to bring second order unification to Mma.\nJust for those to whom unification means only a physics Grail, should Mma have  unification you could do things like:\nf[x_,a] /. f[b,y_]-> {x,y}\n(*\n-> {b,a}\n*)\n\n", "programming - Speed up Fourier for Booleans": "\nMost of your questions can be answered experimentally. You can find out a lot about Mathematica by just interactively playing and timing results. Let's see how it works out in this case:\n\ndoes it automatically optimize for the type of input data (just\n  integers 0 and 1)?\n\nd1 = RandomReal[1, 10^7];\n\nFourier[d1]; // AbsoluteTiming // First\n\n(*  ==> 1.0650609  *)\n\nd2 = RandomInteger[1, 10^7];\n\nFourier[d2]; // AbsoluteTiming // First\n\n(*   ==> 1.1050632 *)\n\nSo, no difference between integers and reals in this case. Note that Mathematica doesn't know no numerical Boolean values (0, 1), but only True and False and you can't perform a Fourier on that.\n\nIs Mathematica lazy enough to see that I only care about the first 100\n  frequencies and won't calculate the others?\n\nMathematica has some clever optimizations going on under the hood, but this is not one of them. Compare the previous Fourier timing with this one:\nFourier[d1][[1 ;; 100]]; // AbsoluteTiming // First\n\n(*  ==> 1.0740615  *)\n\nThe answer,therefore, is 'no'. The reason can be discovered easily, for instance, by using TracePrint \nFourier[{1, 2, 3, 4, 5}][[1 ;; 3]] // TracePrint\n\n Fourier[{1,2,3,4,5}][[1;;3]]\n  Part\n  Fourier[{1,2,3,4,5}]\n   Fourier\n   {1,2,3,4,5}\n  {6.708203932 +0. I,-1.118033989-1.538841769 I,-1.118033989-0.363271264I\n   ,-1.118033989+0.363271264 I,-1.118033989+1.538841769 I}\n  1;;3    \n   Span    \n   1    \n   3   \n {6.708203932 +0. I,-1.118033989-1.538841769 I,-1.118033989-0.363271264 I\n  ,-1.118033989+0.363271264 I,-1.118033989+1.538841769 I}[[1;;3]]\n\n {6.708203932 +0. I,-1.118033989-1.538841769 I,-1.118033989-0.363271264 I}\n\nAs you can see, Part, the function lurking behind [[...]] is performed on the full output of Fourier, which itself, is fully unaware that pieces of its output will be picked away.\n\nCan I give it some hints about the input?\n\nUsually, no, you can't. Compile itself needs to know the types of its inputs, but most other Mathematica functions are just as happy with reals as with integers. Exceptions are, of course, functions that explicitly deal with integers like IntegerDigits. \nFunctions you write yourself can be typed. For instance,\nf[x_Integer,y_Integer] := IntegerDigits[x][[y]]\n\nonly takes integers as arguments. \n", "plotting - Animate ParametricPlot3D for two different parametric equations": "\nMaybe you want an animation parameterized by the time $t$? This would do it in an interactive way:\nWith[{missileSize = 10},\n Manipulate[\n  Graphics[{\n    {Red,\n     Disk[\n      {100 t, 80 t - 16 t^2}, missileSize\n      ]},\n    {Blue,\n     Disk[\n      {500 - 200 (t - 2), 80 (t - 2) - 16 (t - 2)^2}, missileSize\n      ]}\n    },\n   Frame -> True,\n   GridLines -> Automatic,\n   PlotRange -> {{0, 800}, {-200, 400}},\n   AspectRatio -> Automatic],\n  {t, 0, 7}]\n ]\n\nAlternatively, you could create an animation like this:\nt = Table[Graphics[{\n     {Red,\n      Disk[\n       {100 t, 80 t - 16 t^2}, 10\n       ]},\n     {Blue,\n      Disk[\n       {500 - 200 (t - 2), 80 (t - 2) - 16 (t - 2)^2}, 10\n       ]}\n     },\n    Frame -> True,\n    PlotRange -> {{0, 800}, {-200, 400}},\n    AspectRatio -> Automatic],\n   {t, 0, 5, .1}];\n\nListAnimate[t]\n\n\nThe animation above was created with\nExport[\"missiles.gif\", t]\n\nEdit\nSince it was asked in the comment, I'll add the 3D analogue here, too - although Verbeia already did something like it with Manipulate:\nxMin = 0;\nxMax = 800;\nyMin = -200;\nyMax = 200;\nzMin = -200;\nzMax = 400;\nground = {Green, \n   Polygon[{{xMin, yMin, zMin}, {xMin, yMax, zMin}, {xMax, yMax, \n      zMin}, {xMax, yMin, zMin}}]};\n\nt = Table[\n   Graphics3D[{ground, {Red, \n      Sphere[{100 t, 0, 80 t - 16 t^2}, 10]}, {Blue, \n      Sphere[{500 - 200 (t - 2), 0, 80 (t - 2) - 16 (t - 2)^2}, 10]}},\n     Boxed -> True, \n    PlotRange -> {{xMin, xMax}, {yMin, yMax}, {zMin, zMax}}], {t, 0, \n    6, .1}];\n\nListAnimate[t]\n\n\nIf you compare to the 2D code, I just replaced Disk by Sphere, made the height the z coordinate and set the y coordinate of the projectiles to 0. \nThe other changes are just small tweaks: I defined the plot range as variables so I can use them to define a rectangular Polygon representing the ground. Instead of the Framed option, there is the Boxed option (which can also be omitted or set to False).\n", "probability or statistics - What do the options of SmoothKernelDistribution do?": "\nYou can click on each of these variables in the help for further explanation.\nMaxMixtureKernels: the maximum number of kernels to generate the estimate from. The example in the help file makes this quite clear:\n\nAs you can increase the number of kernels (tent poles, if you will) from 10, 15, 25, to 100, the smoother the estimate becomes, at the expense of complexity (more parameters to estimate).\nInterpolationPoints: How many points the interpolation function (kernel density estimate) is to be evaluated at.\n\n10 points on the left, 100 on the right. First you fix the number of kernels (consider the previous diagram), then you select where to sample the interpolant.\nMaxRecursion: An option for the Plot function to achieve better results in places where more samples are needed. Again, the help file provides some illuminating illustrations:\nMaxRecursion http://reference.wolfram.com/mathematica/ref/Files/MaxRecursion.en/O_4.gif\nHere the levels of recursion runs from 0,1,2,4.\n", "Comfortable Edge Labeling of Undirected Graph": "\nYou may:\nShow@Table[\n  CompleteGraph[3, \n   EdgeLabels -> {1 \\[UndirectedEdge] 3 -> Placed[1, p]}, \n   ImagePadding -> 10], {p, {1/6, 1/2, 5/6}}]\n\n\n", "front end - Remove CellMargins option from many cells": "\nAdd the following line to the end of the notebook you want to update:\nNotebookPut[NotebookGet[] /. Verbatim[Rule][CellMargins, e__] -> Sequence[]];\n\nAnd evaluate it. You should get a new notebook for which all CellMargins have been deleted. \n\nLooks like you can use the UI pretty easily to do this. First, highlight all the cells (if you want all the cells to have the same margins, just hit CTRL+a. \nThen, go to Format -> Options Inspector (also can use CTRL+SHIFT+O). In the search box, you can type in CellMargins:\n\nHere, I've set the marings to be {{66,10},{5,25}}. It looks like the default is {{66,10},{5,10}} and the settings are {{left,right},{top,bottom}}\n", "programming - How can I add row and column header images to my TableForm output?": "\nYou can use the TableHeadings option to supply the row and column headings (which can also be images). Here's an example (data is the matrix in your question):\nlena = ImageResize[ExampleData[{\"TestImage\", \"Lena\"}], {64, 64}];\nTableForm[With[{min = Min[#]}, # /. min -> Style[min, Red]] & /@ data, \n    TableHeadings -> {ConstantArray[lena, 3], ConstantArray[lena, 9]}]\n\n\n", "programming - What is the equivalent of a prototypical Manipulate in lower level functions?": "\nStart from \n{Slider[Dynamic[x], {1, 5, 1}], Dynamic[x]}\n\n\nNext localize control variable:\nDynamicModule[{x}, {Slider[Dynamic[x], {1, 5, 1}], Dynamic[x]}]\n\n\nAnd add some interface elements:\nPanel@DynamicModule[{x},  Column[{Slider[Dynamic[x], \n{1, 5, 1}], Panel[Dynamic[x], ImageSize -> 200]}]]\n\n\nAdd even more\nPanel@DynamicModule[{x},   Column[{Row[{\"x\", Spacer[10], \nAnimator[Dynamic[x], {1, 5, 1}, AnimationRunning -> False, \nImageSize -> Small]}], Panel[Dynamic[x], ImageSize -> 235]}]]\n\n\n", "cdf format - Trouble with CDF on Mac OSX": "\nPerhaps this is caused by an interaction between the embedding JavaScript and the Page Zoom feature in Safari. If you reset the page zoom to \"Actual Size\" by pressing Command-0 (or from the View menu), it hopefully will allow you to interact with the controls again. \nAfter that, it may even be possible to return to a larger zoom setting and still have the CDF work properly, because the display script may receive updated values for the available window size that it needs to calculate the offset between your mouse pointer and the controls.\n", "Need tips on improving this directed graph": "\n  g = Graph[Tooltip /@ t, \n  VertexSize -> \n  Append[Thread[{5, 7, 11, 13, 17} -> {\"Scaled\", .01}, List, 1], {\"Scaled\", .005}],\n  VertexStyle -> Thread[{5, 7, 11, 13, 17} -> Red],\n  VertexLabels -> Placed[\"Name\", Tooltip], \n  GraphLayout -> \"RadialDrawing\", ImageSize -> 700] //  Rotate[#, 90 Degree] &\n\ngives\n\nDoes not quite line up the nodes for the first five primes in the list, but it is a cheap alternative to building a custom layout from scratch using VertexCoordinates.\nEDIT: If the size of graph is reduced, one can use GraphPlot and its options to vertically line up the first five nodes. For this to work, I had to reduce the number of nodes to plot:\n tX = {}; z = 4; While[z < 240, y = Prime[z++]; prev = y; u = {};  x = y; \n While[x >= y, prev = x; x = lopf[3 x + 1]; \n u = AppendTo[u, {DirectedEdge[prev, x]}]; tX = AppendTo[tX, u];]];\n tX = Union[Flatten[tX]];\n tX2 = tX /. DirectedEdge[x_, y_] :> Rule[x, y];\n\nWith this dataset\n GraphPlot[tX2, PlotStyle -> Gray, \n VertexRenderingFunction -> Function[{p, l}, \n  Tooltip[{If[MemberQ[{5, 7, 11, 13, 17}, l], \n  Sequence @@ {Red, PointSize[.015]}, \n  Sequence @@ {Blue, PointSize[.008]}], Point[p]}, Text[l]]], \n VertexCoordinateRules ->  Thread[{5, 7, 11, 13, 17} -> {0, Automatic}, List, 1], \n DirectedEdges -> True,\n ImageSize -> 400]\n\ngives\n\nEDIT 2: Aligning the first  5 nodes in graph g above:\ncoordlist = PropertyValue[{g, #}, VertexCoordinates] & /@ VertexList[g][[;; 5]];\ncoordlist[[All, 2]] = 4;\nFold[SetProperty[{#1, #2}, \n    VertexCoordinates -> coordlist[[VertexIndex[g, #2]]]] &, g, \n       VertexList[g][[;; 5]]] \n// Rotate[#, 270 Degree] &\n\n\n", "front end - No Syntax Highlighting of Package Functions": "\nI don't know what is causing your problem, but presumably you can still specially color the symbols in those contexts as I do.  For example:\nSetOptions[$FrontEnd, \n  AutoStyleOptions -> {\"SymbolContextStyles\" ->\n     {\"Units`\" -> Brown, \"PhysicalConstants`\" -> Orange}\n   }\n]\n\n\nSince the above suggestion doesn't have effect on your machine even when you deselect highlighting of \"Global symbols that have no value assigned\" in the Preferences dialog, it sounds like something is really broken. Obviously backing things up first, try deleting the user configuration files. \n", "probability or statistics - Non-linear trend reduction with missing data": "\nYou can try to fill the missing values if it is suitable for your data by:\n\nmean values\nmean values of same class\nthe most probable value\nSpline smoothing\nYou can filter the data through a linear filter\n\nBut if you are building a nonlinear model in general, you should not detrend data before estimating nonlinear models. In the case of nonlinear grey-box models, do not detrend the data to make sure that the models represent the actual physical levels.\n", "import - How can I read in specific information from a TeX-file?": "\nThe regular expression approach is my favorite, but I would do it a little differently to make it more robust. The approach by David didn't quite get the } treated right. The approach by R.M relied on the newline characters in the file (but newlines are optional in $\\TeX$). So here is what I believe fixes these problems.\nFirst define the example $\\TeX$ content:\ntex = \"\\\\commandnameA{Bob}\n    blabla\n    \\\\commandnameB{It wasn't Bob}\n    \\\\commandnameC{2012}\n    bla\n    \\\\commandnameD{$\\\\frac{1}{3}$}\n    \\\\commandnameE{\\\\commandnameF{It was Bob!}}\n    \\\\commandnamefilename{29}\";\n\nNow comes the function that does the translation:\ntranslate[t_] := \n Module[{regex = \n    RegularExpression[\n     \"\\\\\\\\commandname[^{]*{([^{}]*({[^}]*})*([^{}]*))}\"]},\n  Flatten[{t, StringCases[t, regex :> translate[\"$1\"]]}]\n  ]\n\nAnd finally the application:\nRest[translate[tex]]\n\n\n{\"Bob\", \"It wasn't Bob\", \"2012\", \"$\\\\frac{1}{3}$\", \"\\\\commandnameF{It \\\n  was Bob!}\", \"It was Bob!\", \"29\"}\n\nThe translate function finds matching braces following any of the \\commandname keywords, and applies itself recursively to the resulting content.\nIt returns the supplied argument plus the result of the recursive translation. \nTherefore, the first entry in the result of translate is always the original text. That is why I use Rest to print the desired sub-strings.\n", "Drawing Graph Products - Mathmatica Stack Exchang": "\nI do feel that the question could be a bit more clear.  When you write \"each copy of the factors can have LinearEmbedding\", do mean that each factor is, in fact, a path graph?  Assuming so, perhaps something like the following could work.  (Seems to complicated, I admit.)\nm = 3;\nn = 2;\ng1 = Graph[\n   Table[UndirectedEdge[Subscript[u, i], Subscript[u, i + 1]], {i, 1, m - 1}],\n   VertexLabels -> \"Name\",\n   VertexCoordinates -> Table[{0, i}, {i, 1, m}]\n   ];\ng2 = Graph[\n   Table[UndirectedEdge[Subscript[u, i], Subscript[u, i + 1]], {i, 1, n - 1}],\n   VertexLabels -> \"Name\",\n   VertexCoordinates -> Table[{i, 0}, {i, 1, n}]\n   ];\ng1g2 = Graph[\n   Flatten@Join[\n     Table[\n      UndirectedEdge[{Subscript[u, i], Subscript[u, j]}, \n        {Subscript[u, i], Subscript[u, j + 1]}], {i, 1, m}, {j, 1, n - 1}],\n     Table[\n      UndirectedEdge[{Subscript[u, i], Subscript[u, j]}, \n         {Subscript[u, i + 1], Subscript[u, j]}], {i, 1, m - 1}, {j, 1, n}]\n     ],\n   VertexLabels -> \"Name\",\n   VertexCoordinates -> Flatten[Table[{i, j}, {i, 1, m}, {j, 1, n}], 1]\n   ];\nsize[1] = {100, 200};\nsize[2] = {200, 100};\nsize[3] = {300, 200};\nRow[MapIndexed[Show[GraphComputation`GraphConvertToGraphics[#],\n    ImageMargins -> 5, ImageSize -> size[#2[[1]]]] &, \n  {g1, g2, g1g2}],\n ImageSize -> 700, Alignment -> Center]\n\n\nThe bulk of this code involves the layout of the graph.  If you simply want a generalized Cartesian product of graphs without regard to the layout, then that's a bit easier.\nSeedRandom[1];\ng1 = RandomGraph[{5, 5},VertexLabels -> \"Name\"];\ng2 = RandomGraph[{5, 8},VertexLabels -> \"Name\"];\nmakeCartesianProductEdge[u_, UndirectedEdge[u2_, v2_]] := UndirectedEdge[{u, u2}, {u, v2}];\nmakeCartesianProductEdge[UndirectedEdge[u1_, v1_], v_] := UndirectedEdge[{u1, v}, {v1, v}];\ng1g2 = Graph[Flatten[{\n     Table[makeCartesianProductEdge[u, e],{u, VertexList[g1]}, {e, EdgeList[g2]}],\n     Table[makeCartesianProductEdge[e, u],{u, VertexList[g2]}, {e, EdgeList[g1]}]}], \n     VertexLabels -> \"Name\"];\ngraphToGraphics[g_Graph] := GraphComputation`GraphConvertToGraphics[g];\ngraphToGraphics[else_] := else;\nGraphicsGrid[Partition[graphToGraphics /@ {g1, g2, g1g2, SpanFromLeft}, 2]]\n\n\nIf you want a linear embedding of non-path graphs, then you'll need to do something to keep the edges from lying on top of one another.\ng1 = Graph[EdgeList[g1], VertexCoordinates -> Table[{i, 0}, {i, 1, Length[VertexList[g1]]}]];\ng2 = Graph[EdgeList[g2], VertexCoordinates -> Table[{i, 0}, {i, 1, Length[VertexList[g2]]}]];\ng1g2 = Graph[EdgeList[g1g2], VertexCoordinates -> VertexList[g1g2]]\n\n\nPerhaps the following EdgeShapeFunction will help, but I doubt it.\nesf[{u_, v_}, ___] := {Opacity[0.3], Arrow[BSplineCurve[Table[\n  (u + v)/2 + Norm[v - u] {Cos[t], Sin[t]}/2,\n  {t, ArcTan @@ (v - u), ArcTan @@ (v - u) + Pi, Pi/5}]]]};\nGraphicsRow[SetProperty[#, EdgeShapeFunction -> esf] & /@ {g1, g2, g1g2}]\n\n\n", "export - How to remove an expression from a file?": "\n\nFunctions like Read, Skip and Find usually operate on streams in an\n  entirely sequential fashion. Each time one of the functions is called,\n  the current point in the stream moves on.\n\nIn a Sequential file you can\u00b4t delete entries. The only option is shifting the \"tail\" of the file upwards.\n\n", "programming - Is Mathematica a Turing-complete language?": "\nIt has already been proven that the  Rule 110 cellular automata is Turing complete. Since Mathematica can implement this cellular automata, it must be true that Mathematica is Turing complete.\nIncidentally, it has been claimed that HTML + CSS3 is Turing complete, and Mathematica is a bit more expansive than that combination. So it should not be surprising that Mathematica is also Turing complete.\nAll this is with the standard limitation that a 'real' turing machine needs unlimited memory and time, both is not available to any physical thing.\n", "Problem using OptionValue with functions defined by SubValues, and the use of Options for function dispatch": "\nThere are two problems I see with this code. The first one, and the one which gives you immediate problem you reported, is that, as it looks, short (magical) form of OptionValue does not work with SubValues - based definitions. So, you should replace\nOptionValue[\"type\"]\n\nwith \nOptionValue[{opts}, \"type\"]\n\nOr, if you wish to associate the option with pump directly and use it within the SubValue, you need to use\nOptionValue[pump, {opts}, \"type\"]\n\ninstead.\nThe second, \"conceptual\" problem, is that you are really trying to use options for function dispatch, but in doing this your way, you give up the powerful rule-based function dispatch mechanism that is naturally available in mma. This is what I would do instead:\nClearAll[pump, dispatch];\n(a : pump[_, __])[\"curve QH\", opts : OptionsPattern[\"type\" -> \"plot\"]] :=\n    dispatch[pump, OptionValue[{opts}, \"type\"]][a, \"curve QH\", opts];\n\ndispatch[pump, \"plot\"][_, _, opts : OptionsPattern[]] :=\n   Plot[x, {x, 0, 2}, Frame -> True, FrameLabel -> {\"a\", \"b\"}, \n      Evaluate[FilterRules[{opts}, Options[Plot]]]];\n\ndispatch[pump, \"table\"][_, _, opts : OptionsPattern[]] :=\n   Table[x, {x, 0, 2, 0.1}]\n\nI delegated the dispatch to a new (extra) symbol dispatch, introduced specifically for this purpose. This looks cleaner and more extensible to me than using Which statement.\nEDIT\nAddressing the issue raised in comments: note that, as another manifestation of OptionValue - OptionsPattern magic being lost for SubValues- based functions, the above solution, as written, will not provide the intended default behavior, when the \"type\" option is not explicitly given. To make that work, one can do:\n(a : pump[_, __])[\"curve QH\", opts : OptionsPattern[\"type\" -> \"plot\"]] :=\n    dispatch[\n       pump, \n       OptionValue[{opts,\"type\" -> \"plot\"}, \"type\"]\n    ][a, \"curve QH\", opts];\n\nadding the default option explicitly in OptionValue.\n", "attributes - Package automated way of ReadProtecting all symbols": "\nMy guess would be this:\nToExpression[\n   Names[\"pack`*\"], \n   InputForm, \n   Function[sym,SetAttributes[sym, {ReadProtected(*,Locked*)}],HoldFirst] \n]\n\nThe problem is that functions defined with # - & notation do not hold their arguments.\n", "assignment - What is the story with Removed symbols?": "\nSome observations on Removed\nRemoved is not a normal head, but rather a print form. Consider a definition\nx := y\n\nOnce we Remove the y, we invalidate x in a subtle but permanent way - reintroducing the y into the session won't help. Remove is really a rather special-purpose destructuve operation, aimed more at removing auto-generated symbols. In a system of inter-connected functions (possibly from different packages), for this reason Remove is safe only if nothing depends on the symbol being removed. Resolving shadowing is the only mainstream (frequent, non-advanced) application of Remove I am aware of.\nI learned from the book of David Wagner (\"Power programming with Mathematica\",page 251), that while the removed symbol is printed (and has a FullForm) as Removed[\"sym\"], applying Head to it yields Symbol. The reason for that is that  Removed[\"sym\"] still represents a symbol, albeit marked for removal. For code like this: \nClear[b];b := a;Remove[a];b\n\nyou can not, e.g., \"resurrect\" a in b with this: \nb /. Removed[x_] :> ToExpression[x]\n\n\nRemoved[\"a\"]\n\nbut, since Removed[\"a\"] represents a symbol marked for removal, this will work, to at least reconstruct the value of b: \nb /. Cases[b, s_Symbol :> (s :> a), {0, Infinity}, Heads -> True]\n\n\na\n\nYou can also analyze which symbols in some expression were Remove-d, by something like this:\nClear[removedNames];\nremovedNames[expr_] :=\n  Flatten[\n    StringCases[\n      ToString /@ Union@Cases[expr, _Symbol, Infinity, Heads -> True],\n      ShortestMatch[\"Removed[\" ~~ x__ ~~ \"]\"] :> x]\n  ]\n\nSo that\nremovedNames[OwnValues[y]]\n\n\n{\"x\"}\n\nSummary\nSo, to summarize: \n\nRemoved is not a normal head but a display form. \nWhen you Remove a symbol, Removed[sym] still represents this symbol, but being marked for removal. My understanding is that this is still a reference to the symbol table, but it becomes opaque and not bound to the symbol name any more. However, apparently, Mathematica still allows you to manipulate it, pretty much as if you manipulated the normal symbol. In particular, you can, for the purposes of pattern-matching, still count on it being a Symbol. This allows us to do some things as if the symbol in question has not been removed, particularly by using local rule substitutions.\nAs you demonstrated, you can still change some ...Values for Remove-d symbols with local rules. While it looks like you can reconstruct many of the symbol's properties (except explicit symbol name), I would however limit such uses of these symbols to extreme cases when you need to make some definitions valid in a given Mathematica session. \n\nEDIT:  one constructive use - catching bugs induced by Remove\nHere is one possibly constructive use of the above behavior. Remove-ing symbols is dangerous because it subtly invalidates definitions for other symbols which were referencing the symbols being removed. We may wish to know when this happens, but often the effects are silent and insidious. Here is a function which enables one to trigger such events:\nClearAll[remove];\nSetAttributes[remove, HoldAll];\nremove::remvd = \"Stymbol `1` was removed!\";\nremove[s_Symbol, failCode_: Throw[$Failed, remove]] :=\n  Module[{defs},\n    With[{strsym = ToString[HoldForm[s]]},\n       With[{body := (\n          Message[remove::remvd , Style[strsym, Red]];\n          failCode\n           )},\n        defs :=\n          Module[{},\n            OwnValues[s] = HoldPattern[s] :> body;\n            UpValues[s] = HoldPattern[_[___, s, ___]] :> body;\n          ]]];\n    Remove[s];\n    defs;]; \n\nWhat it does is to assign certain definitions to symbols already after they have been removed, using the behavior discussed above. These definitions execute arbitrary user-defined code when evaluation comes to the Remove-d symbol, in most cases (except when the symbols are inside HoldAllComplete heads). To augment it, here is a dynamic environment, in which Remove will behave that way:\nClearAll[withCustomRemove];\nSetAttributes[withCustomRemove, HoldAll];\nwithCustomRemove[code_,failCode_: Throw[$Failed, remove]] :=\n  Module[{inRemove},\n    Internal`InheritedBlock[{Remove },\n     Unprotect[Remove];\n     Remove[arg_] /; ! TrueQ[inRemove] :=\n         Block[{inRemove = True}, remove[arg,failCode]];\n     Protect[Remove];\n     code]];\n\nand here is an example of use. First, the usual behavior:\nClearAll[f, a];\nf[x_] := x + a;\ng[] := Hold[a];\nRemove[a];\n{f[1], g[]}\n\n\n{1+Removed[a],Hold[Removed[a]]}\n\n\nNow, with our functions:\nwithCustomRemove[\n   ClearAll[f, a];\n   f[x_] := x + a;\n   g[] := Hold[a];\n   Remove[a];\n]\n{f[1], g[]}\n\n\n  During evaluation of In[78]:= remove::remvd: Stymbol a was removed!\n\n  During evaluation of In[78]:= Throw::nocatch: Uncaught Throw[$Failed,remove]\n           returned to top level. >>\n\n  Hold[Throw[$Failed,remove]]\n\n\nOne can specify a different behavior to be triggered on such an event. One can also generalize to Remove with several arguments. The idea is that you can take the code which is suspicious, and execute it inside withCustomRemove - which may often enable you to catch bugs related to attempts to use Remove-d symbols.\n", "programming - Is pure pattern matching without PatternTest and Condition Turing-complete?": "\nI cannot offer a rigorous answer to this question, but I will offer some thoughts...\nThis question asks whether the set of functions computable using basic patterns and MatchQ is isomorphic to the subset of Turing-computable functions whose results can be expressed in a single bit.  The one-bit subset restriction is important since MatchQ is clearly not fully Turing-complete since it cannot handle functions outside of that subset.\nBasic pattern-matching would seem to be a very close approximation of boolean circuits.  With suitable input encoding, we can implement the basic operations thus:\n\n    a OR b    -->    a | b\n    NOT a     -->    Except[a]\n    a AND b   -->    Except[Except[a], b]\n\nFor bounded input sizes, boolean circuits are known to be able to compute any boolean function (see, for example, Theorem 1.8.1 on page 32 of Clote and Kranakis: Boolean Functions and Computation Models).  The emphasis here is on bounded.  Boolean circuits are known not to be Turing-equivalent due to non-uniformity.  That is, a fixed-size Turing program can handle any input size while a boolean circuit must grow (exponentially!) in size as input size increases.\nWhat is not clear to me is whether the other pattern-matching features add capability that will let us will evade this conclusion.  Perhaps some creative use of BlankSequence, Repeated, Longest, Shortest, PatternSequence, etc. takes us outside of the realm of boolean circuits and toward (one bit) Turing-equivalence.\n", "front end - keyboard sequence for Magnify in version 8?": "\nThe keyboard sequence is Alt-W M on both Windows and Linux. This will open a drop down menu where you can select the magnification.\n", "import - Behavior of ImportString in Mathematica": "\nI have no idea why the first ImportString brings things in as strings, but if you import as \"CSV\" instead, it works as you want.\nIn[22]:= ImportString[\n  \"129,160,16,4\n  130,160,14,5\", \"CSV\"] // InputForm\nOut[22]= {{129, 160, 16, 4}, {130, 160, 14, 5}}\n\nYou can use InputForm to force the display of quote marks; you don't need the much more verbose FullForm.\n", "curated data - Highlighting individual countries on a world map": "\nIn the example code, CountryData[#, \"AntarcticNations\"] is a built in predicate that returns True or False.  You need something similar for your countries.  Perhaps,\nmyCountries={\n  \"Germany\",\"Hungary\",\"Mexico\",\"Austria\",\n  \"Bosnia\",\"Turkey\",\"SouthKorea\",\"China\"};\nGraphics[{If[MemberQ[myCountries,#],Orange,LightBrown],\n  CountryData[#,\"SchematicPolygon\"]}& /@ CountryData[]]\n\n\n", "numerics - Output of NonlinearModelFit differs from the correct result": "\nThis is the fit returned by Mathematica :\nnlm = NonlinearModelFit[data, b*t^a, {a, b}, t]\n\nThe model is \nnlm[t]\n\n(* 1.34232 t^0.615024 *)\n\nThe residuals (model(x)-y) are :\nnlm[\"FitResiduals\"]\n\n(* {-0.158097,-0.0558756,0.059473,0.0967975,0.00211152,0.132971,-0.103818,-0.0577413} *) \n\nThe sum of the squares of the residuals is :\nres1 = Total[nlm[\"FitResiduals\"]^2]\n\n(* 0.0728215 *)\n\nAn explicit check :\nTotal[(nlm[#[[1]]] - #[[2]])^2 & /@ data]\n\n(* 0.0728215 *)\n\nThe sum of the squares of the residual relative to the other model is  \ny[t_] = 1.23 t^0.6548\n\nres2 = Total[(y[#[[1]]] - #[[2]])^2 & /@ data]\n\n(* 0.152818 *) \n\nSince res1 < res2 I would say that Mathematica returns a better fit. Why do you say the best fit is the second function ?\n", "Plotting different PDFs of a distribution in the same graph": "\nHere is a simple way. The Evaluate is needed to ensure the line colors are different (see this question for an explanation of this).\nPlot[Evaluate[\n  PDF[WeibullDistribution[1/#, 10 #], x] & /@ Range[2, 5]], {x, 0.1, 5}]\n\n\nAs noted in the documentation, Plot and related functions quite happily draw multiple lines if they are given a list of functions (or data in the case of ListPlot and friends) as their first argument.\nNotice the use of Map (/@) and a pure function to avoid having to type out the WeibullDistribution bit of the code multiple times. (This page in the documentation will be useful in this regard.)\n", "How to Combine Pattern Constraints and Default Values for Function Arguments?": "\nPerhaps this?\nfoo[x : (_?IntegerQ) : 1] := x;\n\nfoo[]\nfoo[7]\nfoo[\"string\"]\n\n\n1\n7\nfoo[\"string\"]\n\n\n\nUpdate: since version 10.1 one does not need to explicitly include the default in the pattern as described below; see:\n\nVersion inconsistency with optional arguments: what if the default value doesn't match the pattern?\n\nAs Leonid reminds, if the default value does not match the test function it will not be returned.  To allow for this you can explicitly include the value in the pattern:\nClearAll[foo]\nfoo[x : (_?IntegerQ | \"default\") : \"default\"] := x;\n\nfoo[]\nfoo[7]\nfoo[\"string\"]\n\n\n\"default\"\n7\nfoo[\"string\"]\n\n\n\nIn the comments magma makes an excellent point.  You can use multi-clicking, or as I prefer Ctrl+. to examine parsing.  See this answer.\n", "front end - How to Enable Syntax Coloring of Pattern Match Variable Only (i.e. Without Coloring any Associated Pattern)?": "\nI don't think it's possible, but I hope for an answer proving me wrong.\nI don't think you can do anything about how the front-end interprets what you type as boxes.\nIf you could do that, you could make something like x_Integer parse into a certain StyleBox. However, it's interpreted as a single word. Try it, and in the cell expression you'll see BoxData[\"x_Integer\"]. I doubt the front-end allows you any way of treating parts of a word differently than others.\nThe front-end has some options regarding the syntax coloring, but, as you said, I found none that could apply to this. There are also some styles in the core.nb stylesheet that can be customized, such as the color of unmached brackets, but none related and particularly, none referring to \"parts of words\". \nSimilarly, the option AutoStyleWords only helps with specific full words (in box type cells). As John Fultz said in this answer\n\"This will only work to style things which are lexically word-type tokens. You cannot, for example, auto-style two words in sequence, a subexpression with an operator, or a substring of a word token.\"\nConclusion\nI'm not totally certain, but my best guess is that your only chance is by brute force. This means, some trigger, that runs code that reads your cell's box expressions and turns them into what you like. The trigger could be a CellEventHandler that catches keystrokes, or a ScheduledTask, or some manual input, palette, hotkey, context menu, etc.\nLeonid is using this approach in his syntax highlighter package, and if this is important to you, my bet is that the road through this link is your tough but best chance\n", "plotting - Custom formatting for DateListPlot": "\nSomehow DateListPlot is resistant to many styling options. Without fiddling with the internals, here is a starting point.\nWeekendQ[date_] := \n With[{d = DateString[date, \"DayName\"]}, \n  MatchQ[d, \"Saturday\" | \"Sunday\"]]\nweekStyle = {Blue};\nweekendStyle = {PointSize -> .015, Directive[Red]};\nstyleList = \n  Map[If[WeekendQ[#], weekendStyle, weekStyle] &, questionTimes];\nDateListPlot[Partition[Transpose[{questionTimes, hours}], 1],\n PlotStyle -> styleList, Filling -> Bottom, GridLines -> False,\n FillingStyle -> ColorData[1][1],\n Frame -> {True, True, False, False},\n PlotRange -> {0, 24}, \n Prolog -> {LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 6/24}]], \n  Rectangle[Scaled[{0, 20/24}], Scaled[{1, 1}]]}]\n\nLooks like:\n\n", "list manipulation - Is there a bug in Pick?": "\nThis confused me as well, but using Trace revealed what is going on:\nTrace@Pick[{1, 2, 3, 4, 5}, selection, elem_ /; elem =!= 0]\n\n{{selection,{0,1.2,3,0.,5}},\n Pick[{1,2,3,4,5},{0,1.2,3,0.,5},elem_/;elem=!=0],\n {{0,1.2,3,0.,5}=!=0,True},\n {1,2,3,4,5}}\n\nThe key is the 4th line: note that the pattern is applied to the full list, at level 0.  The full list selection does match (because it is not structurally equivalent to 0) thus the full first argument is picked out.\nThe reason why we don't see this behavior with Equal (i.e. ==) is that {0, 1.2, 3, 0., 5} != 0 stays unevaluated.\n(I did not find a way to restrict at which levels Pick operates, but it is possible to tweak the pattern instead, e.g. elem_?NumericQ/;elem=!=0, possibly with a performance hit.)\n", "How to use Interpolation to fill in missing data": "\nYou have to provide the values of independent variable. Assuming that the points correspond to equidistant values of an independent variable, you can do this, for example:\nint = \n Interpolation[\n   Select[Transpose[{Range[Length[data]], data}], NumericQ[Last[#]] &],\n   InterpolationOrder -> 1\n ]\n\nOf course, you may wish to scale the independent variable here in some way.\n", "graphics - Combining Rasterize with ParametricPlot": "\nFirst, you have to define bkgd differently because it's not a disk unless you make it a Graphics first: \nbkgd = Rasterize[Graphics@Disk[{0, 0}, 0.09]];\n\nThen use Inset:\nParametricPlot[{t, t^2}, {t, 0, 1}, \nEpilog -> {Inset[bkgd, {.5, .5}, Automatic, .2]}]\n\n\nThe position and size of the disk image are controlled by the last three arguments of Inset.\nYou will note that the last argument (the size scale) is a factor relative to the   plot region (with 1 corresponding to the whole width).\n", "algebraic manipulation - Is it possible to have Mathematica move all terms to one side of an inequality?": "\nAre you looking for Subtract?\neq=x>=y\nSubtract@@eq>=0\n\ngives:\n\nx-y>=0\n\nEdit\nIf one wants a function, which keeps the order sign and adds the 0, one may use:\noneSide=(Head[#][Subtract@@#,0]&)\n\nand call e.g.  eq//oneSide\n", "evaluation - Unexpected differences with various uses of NormFunction": "\nThis must have to do with the symbolic preprocessing, happening in FindFit. In all cases when you get 2.13284, this was a result of symbolic preprocessing, which was possible because the norm function could be evaluated on symbolic arguments. The subsequent result is likely explained by the mechanism described by @Searke. \nBut if you define your own norm as\nClearAll[norm];\nnorm[vec_?(VectorQ[#, NumericQ] &), alpha_] := Norm[vec, alpha];\n\nand replace Norm with norm in all your examples, you always get 2.12467. You can gain more insight into this by using Trace with TraceInternal -> True. \n", "plotting - Why can't I use Show with BoxWhiskerChart?": "\nThe reason this is cut off is because the ListLinePlot's PlotRange does not cover all the values:\nListLinePlot[d2]\n\n\nWhen this is included in the Show it is still cut off. If, instead, you do:\nListLinePlot[d2,PlotRange->All]\n\n\nit includes all the points. Then, the whole thing will show up when you use Show:\nShow[BoxWhiskerChart[d1, \"Outliers\"], ListLinePlot[d2, PlotRange -> All]]\n\n\n", "evaluation - Make a button that evaluates a function over and over": "\nMaybe you could do something like this\nSetAttributes[redoButton, HoldRest]\nredoButton[str_, fun_] := DynamicModule[{result = Null}, \n   Column[{Button[str, result = fun], Dynamic[result]}]]\n\nredoButton[\"press\", RandomInteger[20]]\n\n", "simplifying expressions - Does the Im function work with symbolic arguments?": "\nYou should assume that your variables are real, (if you want M to proceed further) because Mathematica treats variables in general as complex. One of many ways to do it :\n expr = A ((Cos[k y] + I Sin[k y]) 2 I Sin[t \u03c9]); \n Refine[ Im[ expr], (A | k y | t \u03c9) \u2208 Reals]\n\n\n2 A Cos[k y] Sin[t \u03c9]\n\n\nWe needn't use ComplexExpand defining expr, but in this case it is the simplest approach (pointed out by Heike) :\nComplexExpand @ Im @ expr\n\nSome other ways of imposing assumptions : \nAssuming[(A | k y | t \u03c9) \u2208 Reals, Refine[ Im[ expr] ] ]\n\nanother way yielding the same result :\nBlock[{$Assumptions = A \u2208 Reals && k y \u2208 Reals && t \u03c9 \u2208 Reals},\n       Refine @ Im[ expr] ]\n\n\n 2 A Cos[k y] Sin[t \u03c9]\n\n\n", "graphics - Is it possible to make more room in a graph layout for my VertexRenderingFunction?": "\nGenerally I'd recommend using Graph instead of GraphPlot. One way to solve your specific problem is to affect VertexCoordinates to scale your graph:\nM = {{0, 0, 1, 0}, {1, 0, 0, 1}, {1, 1, 0, 0}, {0, 1, 0, 0}};\nManipulate[ AdjacencyGraph[M, DirectedEdges -> True, VertexShapeFunction -> \n({EdgeForm[Black], LightRed, Disk[#1, {.7, .1}], Black, \nText[Subscript[\"C\", #2], #1]} &),  VertexCoordinates -> scale   \nAbsoluteOptions[AdjacencyGraph[M], VertexCoordinates][[2]]], {{scale, 2}, .1, 3}]\n\n\n", "tensors - Problems with CircleTimes and infix notation": "\nInfix is only an output form. You most probably want the expression which you'd get when typing v1 \u2297 v2 into Mathematica, which is entered with either \\[CircleTimes] or Escc*Esc. \nAs you can see by typing v1 \u2297 v2 //FullForm, this is CircleTimes[v1, v2]. The same is true for longer chains of \u2297, i.e. v1 \u2297 v2 \u2297 \u2026 \u2297 vn has the internal form CircleTimes[v1, v2, \u2026, vn].\nAlso note that a complicated procedural code isn't necessary either, because Mathematica already brings the building blocks you need. Therefore the function you want should be written\nTensorBasis[labels_List,d_Integer] := Outer[CircleTimes, Sequence@@Table[labels,{d}]]\n\n", "front end - Syntax Coloring for \"Possible Unwanted Assignment\" Issue": "\nThis is because you are using = (the assignment operator) in the condition (not the body) of While.  It is a typical beginner mistake to use = where == is meant, so Mathematica warns about this.\nSince you also use several ; in the condition, it gets a little confused and only highlights one of the = signs, not all of them.\n", "programming - How can I suppress Print in parallel evaluation?": "\nYou can use dynamic scoping, i.e. the Block construct, to temporarily \"forget\" or redefine Print.\nParallelTable[\nBlock[{Print},\nPrint; Unprotect[Print]; Print = Null &\nfunction[x],\n{x,0,10}\n]\n\nThis works with ParallelTable for me.\n", "performance tuning - How to reduce the InterpolatingFunction building overhead?": "\nYou can use binary search with Compile. I failed inlining (Compile was complaining endlessly about types mismatch), so I included a binary search directly into Compile-d function. The code for binary search itself corresponds to the bsearchMin function from this answer.\nClear[linterp];\nlinterp =\n   Compile[{{lst, _Real, 2}, {pt, _Real}},\n     Module[{pos  = -1 , x = lst[[All, 1]], y = lst[[All, 2]], n0 = 1, \n          n1 = Length[lst], m = 0},\n      While[n0 <= n1, m = Floor[(n0 + n1)/2];\n        If[x[[m]] == pt,\n          While[x[[m]] == pt  && m < Length[lst], m++];\n          pos = If[m == Length[lst], m, m - 1];\n          Break[];\n        ];\n        If[x[[m]] < pt, n0 = m + 1, n1 = m - 1]\n      ];\n      If[pos == -1, pos = If[x[[m]] < pt, m, m - 1]];\n      Which[\n        pos == 0,\n           y[[1]],\n        pos == Length[x],\n           y[[-1]],\n        True,\n        y[[pos]] + (y[[pos + 1]] - y[[pos]])/(x[[pos + 1]] - \n              x[[pos]])*(pt - x[[pos]])\n      ]],\n      CompilationTarget -> \"C\"];\n\nThis is about 20 times faster, on my benchamrks:\nAbsoluteTiming[\n   Table[Interpolation[list,InterpolationOrder->1][q],{q,0.0006,0.4,0.00001}];\n]\n\n\n{1.453,Null}\n\nAbsoluteTiming[\n   Table[linterp[list,q],{q,0.0006,0.4,0.00001}];\n]\n\n\n{0.063,Null}\n\n", "graphics3d - ParametricPlot3D output without the meshlines": "\nThis appears to work for older versions of Mathematica\ntube=ParametricPlot3D[2{Cos[t],Sin[t],u},{t,0,2Pi},{u,-5,5}]\ntube /. Polygon[a__]:> {EdgeForm[], Polygon[a]}\n\n", "Construct Context-free Grammar for the Language": "\nAs a hint, your first step is incorrect.  Once you've tried building each side independently, you will not have a way to ensure that they have the same number of 1s.\nInstead, try building the string from the outside inward.  If you were going to put 0s and 1s into each half of the string, how would you ensure that you did so in a way that always ensured that the number of 0s and 1s was the same?\nHope this helps!\n", "pattern matching - Successful match in Replace but not in Cases?": "\nMatchQ looks to see if the whole expression matches the pattern, so you need to add a blank to allow for the other elements of s:\nMatchQ[k, s[l[m, X_], l[j, X_], ___]]\n\nCases takes a list and checks each element in turn, so I think the pattern matcher only gets to see each l[a,b] in isolation. The best I could come up with is:\nCases[Subsets[k, {2}], s[l[m, X_], l[j, X_]] -> a[X]]\n\nFurther investigation\nHere are a couple of questions about Cases I have tried to answer experimentally. I don't know if this helps anyone else much, but it was useful for me to go through it and I think I now understand how Cases behaves, even if the why is a mystery.\nQ1. Does Cases take into account Orderless ?\nIn[1]:= SetAttributes[a,{Orderless}]\nIn[2]:= Cases[a[x,y],a[y,_]->0,{0}]\nOut[2]= {0}\n\nA1. Yes, it does. The pattern matcher understands that a[x,y] === a[y,x] which matches the pattern.\nQ2. Does Cases take into account Flat ?\nIn[3]:= SetAttributes[a,{Flat}]\nIn[4]:= Cases[a[x,y,z],a[onebit_,anotherbit_]:>{onebit+anotherbit},{0}]\nOut[4]= {{a[x]+a[y,z]}}\n\nA2. Yes, it does. The pattern matcher understands that a[x,y,z] === a[a[x],a[y,z]] which matches the pattern.\nQ3. Given that Cases can use the above transformation, will it get a \"hit\" on the pattern a[x] ?\nIn[5]:= Cases[a[x,y,z],a[x]->b,{0,Infinity}]\nOut[5]= {}\n\nA3. No, even though the transformed expression a[a[x],a[y,z]] clearly contains a match for a[x] at level 1, this doesn't count. Cases appears to require the entire expression at level n to match the pattern. The logic appears to be:\n\nLevel 0: expression a[x,y,x] does not match a[x]\nLevel 0: transformed expression a[a[x],a[y,z]] does not match a[x]\nLevel 1: expression x does not match a[x]\nLevel 1: expression y does not match a[x]\n\netc...\nThis is in contrast to ReplaceAll, which does pick up the a[x] in the transformed expression:\nIn[6]:= a[x,y,z]/.a[x]->b\nOut[6]= a[b,y,z]\n\nSo it seems like ReplaceAll applies Flat and Orderless transformations outermost, and then for each transformed expression it digs down into the subexpressions looking for a match. Whereas Cases digs down into the subexpressions of the untransformed original expression outermost, and for each subexpression it tries the various Flat and Orderless transformations looking for a match.\nI realise this is probably a complete misrepresentation of how the pattern matcher actually works, but as a hand-waving mental picture it seems to explain the different behaviour of Cases and ReplaceAll\n", "plotting - How to plot CDF of a Poisson distribution in Mathematica": "\nIt is worth noting two characteristic features of the question:\n\nThe sum is a complementary cumulative distribution function for a Poisson distribution: it's built in to Mathematica and needn't be computed explicitly.\nThe use of $C+1$ as a starting index in the sum, as well as the expression 1:1:20 in the code, indicate $C$ is considered an integer: this needs to be a discrete plot.\n\nIt can also help to draw clear parallels between the \u039cATLAB approach and an idiomatic Mathematica approach.  How about this?\nModule[{c = Range[20], \u03b3 = 0.75, p},\n p = {# Log[#], 1 - CDF[PoissonDistribution[#^\u03b3], #]} & /@ c;\n ListLogPlot[p]\n]\n\n\n", "performance tuning - Why do images in a PopupMenu sometimes make a program load sluggishly?": "\nFirst, let me note that 50kB for such a simple graphics is unbelievably much. In fact, I had to create large and randomized raster icons to achieve such a size. Your things on the other hand look really simple and should be extremely small as vector-graphics.\nSo here is what I tried:\nn = 200;\nMapIndexed[Export[StringJoin[\"tmp/\", ToString[#2[[1]]], \".pdf\"], \n       Colorize[\n    Blur[ImageAdd[RandomImage[0.6, {n, n}], \n      Rasterize[Style[#1, 24, White, \n                 Background -> Gray], \"Image\", ImageSize -> {n, n}, \n       Background -> Gray]], 5]]] & , \n   {\"=\", \"<\", \"\\[LessEqual]\", \">\", \"\\[GreaterEqual]\", \"\\[NotEqual]\"}]\n\nThis gives you icons in pdf format which are about 56k big and look like this\n\n\nUsing these icons and including them with With into your Manipulate the execution of the code takes under a second until the content is displayed and ready. \nThe thing which is expensive here, is only the loading of pdf files from disk. Two points:\n\nI use With since than the icons are planted directly into the Manipulate and it works even after restarting the kernel\nI use the parameter \"Image\" inside Import because usually images are a lot faster than Graphics objects.\n\nblub\nWith[{srules = (#1 -> \n       First[Import[StringJoin[\"tmp/\", ToString[#1], \".pdf\"], \n         \"Images\"]] & ) /@ \n         Range[6]}, \n Manipulate[If[newProblem, {op2, a2, b2, newProblem} = \n          {RandomInteger[{1, 6}], RandomInteger[{-5, 5}], \n     RandomInteger[4], False}]; \n      If[a >= 0, a = Min[a, 10 - Abs[b]], a = Max[a, -10 + Abs[b]]]; \n      solution = solutions[op2, a2, b2]; attempt = solutions[s, a, b]; \n      If[problemDisplay != 3 && solution === attempt, success, \n   plunk[]]; \n      Pane[Grid[DeleteCases[{If[problemDisplay == 1, \n                {Panel[\n         Style[solution /. {(b7_) || (a7__) :> \n             Row[Riffle[{b7, a7}, Style[\"  Or  \", \n                                  Gray]]]}, 19, \n          FontFamily -> \"Times\"]]}], If[problemDisplay == 2, \n                {Panel[absValueEquation[op2, a2, b2]]}], \n              {Show[{axes[{{-10.9, 10.9}, {-0.5, \n            If[MemberQ[display, 3] || MemberQ[display, 4], 2.5, \n                            1]}}], arrows[a, b], \n         segments[s, Blue, a, b]}, BaseStyle -> 16, \n                  ImageSize -> 550, AspectRatio -> Automatic]}, \n      If[MemberQ[display, 1], \n                {Style[\n         attempt /. {(b_) || (a__) :> \n            Row[Riffle[{b, a}, Style[\"  Or  \", Gray]]]}, 19, \n                    FontFamily -> \"Times\"]}], \n      If[MemberQ[display, 2], {absValueEquation[s, a, b]}], \n              Null}, Null], Spacings -> {2, 1}], 540, \n   Alignment -> Center], \n     {{problemDisplay, 3, \"problem:\"}, {1 -> \"solutions\", \n    2 -> \"equation or inequality\", \n         3 -> \"none\"}, ControlType -> RadioButtonBar, \n   ControlPlacement -> Top}, \n     {{newProblem, False}, {False, True}, \n   Enabled -> problemDisplay != 3, \n       ControlPlacement -> Top}, {{s, 2, \"\"}, srules, PopupMenu, \n   ControlPlacement -> Bottom}, \n     {{display, {1}, \"display:\"}, {1 -> \"solutions\", \n    2 -> \"equation or inequality\", 3 -> \"a\", \n         4 -> \"b  \"}, ControlType -> CheckboxBar, \n   ControlPlacement -> Bottom}, \n     {{a, 1}, -10, 10, 1, Appearance -> \"Labeled\", ImageSize -> 500, \n       ControlPlacement -> Bottom}, {{b, 2}, -10, 10, 1, \n   Appearance -> \"Labeled\", \n       ImageSize -> 500, ControlPlacement -> Bottom}, {{a, 1}, -10, \n   10, 1, ControlType -> None}, \n     {{b, 2}, -10, 10, 1, ControlType -> None}, {{a2, 3}, -10, 10, 1, \n   ControlType -> None}, \n     {{b2, 4}, -10, 10, 1, ControlType -> None}, {{op2, 1}, 1, 6, 1, \n   ControlType -> None}, \n     AutorunSequencing -> {1, {2, 3}, {3, 3}}, \n  TrackedSymbols :> Manipulate, \n     Initialization :> {axes[plotRange_] := \n     Plot[0, {x, -10, 10}, Axes -> {True, False}, \n              Ticks -> {Range[-10, 10, 1], None}, \n      PlotRange -> plotRange, BaseStyle -> 16, \n              ImageSize -> {550, 55}, AspectRatio -> Automatic]; \n          absValueEquation[operator_, center_, span_] := \n\n     Tooltip[Style[\n       If[MemberQ[display, 3], \n        Row[{\"|\", Style[\"x\", Italic], \" - (\", center, \n                      \")|\", \n          operator /. {1 -> \" = \", 2 -> \" < \", 3 -> \" \\[LessEqual] \", \n            4 -> \" > \", 5 -> \" \\[GreaterEqual] \", \n                          6 -> \" \\[NotEqual] \"}, span}], \n        Row[{\"|\", Style[\"x\", Italic], Which[center < 0, \" + \", \n                        center == 0, \"\", center > 0, \" - \"], \n          Which[center < 0, Abs[center], center == 0, \n                        \"\", center > 0, center], \"|\", \n          operator /. {1 -> \" = \", 2 -> \" < \", \n            3 -> \" \\[LessEqual] \", \n                          4 -> \" > \", 5 -> \" \\[GreaterEqual] \", \n            6 -> \" \\[NotEqual] \"}, span}]], 19, \n       FontFamily -> \"Times\"], \n\n      Row[{Style[\"|\", 14], Style[\"x-a\", 12, Italic], Style[\"| \", 14], \n        operator /. opRules, \n                  Style[\"b\", 12, Italic]}]]; \n    arrows[center_, span_] := \n\n     Graphics[{If[\n        MemberQ[display, \n         3], {{AbsoluteThickness[2], Gray, Arrowheads[0.03], \n                      Arrow[{{center, 2.2}, {center, 0}}, 0.25]}, \n         Text[Style[\"a\", Italic], \n                      {center, 2.2}]}, Black], \n       If[MemberQ[display, 4] && span != 0, \n                  {{Brown, AbsoluteThickness[1], Arrowheads[{0.02}], \n          Arrow[{{center, 1.25}, \n                          {center + span, 1.25}}, 0.05]}, \n         Text[Style[\"+b\", Italic], \n                      {center + span/2, 1.65}]}, Black], \n       If[MemberQ[display, 4] && span != 0, \n                  {{Brown, AbsoluteThickness[1], Arrowheads[{0.02}], \n          Arrow[{{center, 1.25}, \n                          {center - span, 1.25}}, 0.05]}, \n         Text[Style[\"-b\", Italic], \n                      {center - span/2, 1.65}]}, Black], \n       If[MemberQ[display, 3] && \n                    MemberQ[display, 4] && \n         span != 0, {{AbsoluteThickness[2], Gray, Arrowheads[0.03], \n\n          Arrow[{{span + center, 2.2}, {span + center, 0}}, 0.25]}, \n\n         Text[Style[\"a+b\", Italic], {span + center, 2.2}]}, Black], \n\n       If[MemberQ[display, 3] && MemberQ[display, 4] && span != 0, \n                  {{AbsoluteThickness[2], Gray, Arrowheads[0.03], \n          Arrow[{{center - span, 2.2}, \n                          {center - span, 0}}, 0.25]}, \n         Text[Style[\"a-b\", Italic], {center - span, 2.2}]}, \n                  Black], \n       If[MemberQ[display, 4] && \n         span == 0, {Text[Style[\"b=0\", Italic], \n                      {center, 1.65}]}, Black]}]; \n    solutions[op_, center_, span_] := \n\n     Module[{operator = \n        op /. {1 -> Equal, 2 -> Less, 3 -> LessEqual, 4 -> Greater, \n                      5 -> GreaterEqual, 6 -> Unequal}}, \n      Reduce[operator[Abs[x - center], span], x, \n                Reals]]; \n    plunk[n_: 0] := EmitSound[Sound[SoundNote[n, 0.25, \"Woodblock\"]]]; \n          success := EmitSound[Sound[SoundNote[\"F\", 1, 99]]]; \n    radius = 0.2; \n\n    opRules = {1 -> Style[\"=  \", 14], 2 -> Style[\"<  \", 14], \n      3 -> Style[\"\\[LessEqual]  \", 14], \n              4 -> Style[\">  \", 13], \n      5 -> Style[\"\\[GreaterEqual] \", 14], \n      6 -> Style[\"\\[NotEqual] \", 14]}; \n\n    pt[loc_, type_: \"Closed\"] := \n     If[type == \"Open\", Circle[loc, radius], Disk[loc, radius]]; \n\n    segments[o_, c_, a1_, b1_] := \n     Graphics[{{If[(o == 2 || o == 4 || o == 6) && b1 >= 0, \n                    {c, pt[{b1 + a1, 0}, \"Open\"], \n          pt[{-b1 + a1, 0}, \"Open\"]}, c], \n\n        If[(o == 1 || o == 3 || o == 5) && b1 >= 0, {c, \n          pt[{b1 + a1, 0}], \n                      pt[{-b1 + a1, 0}]}, c], AbsoluteThickness[4], \n        If[(o == 2 || o == 3 || o == 6) && \n\n          b1 > 0, {Line[{{Abs[b1] + a1 - radius, \n             0}, {-Abs[b1] + a1 + radius, 0}}]}, Black], \n\n        If[(o == 4 || o == 5 || o == 6) && b1 >= 0, {c, \n          Arrow[{{Abs[b1] + a1 + radius, 0}, \n                          {10.9, 0}}], \n          Arrow[{{-Abs[b1] + a1 - radius, 0}, {-10.9, 0}}]}, Black], \n                  If[(o == 4 || o == 5 || o == 6) && b1 < 0, \n                    {c, Line[{{a1 - radius, 0}, {a1 + radius, 0}}], \n          Arrow[{{a1 + radius, 0}, \n                          {10.9, 0}}], \n          Arrow[{{a1 - radius, 0}, {-10.9, 0}}]}, Black]}}]}]]\n\n", "dynamic - Manipulate BarChart with Mathematica": "\nHere's my attempt. The tricky part turned out to be to only change the height of a bar when the mouse cursor is close enough to its top edge. By default, the vertical distance between the mouse cursor and the top edge needs to be less than .5 in order to drag the bar. You can change this value by setting the option \"resolution\". \nI've also implemented the constraint that the sum of the heights is constant so when one bar is dragged the heights of other bars change to keep the total height constant. \nNote that dragBar accepts any option of BarChart so you can still use all the  features of BarChart.\nSetAttributes[dragBar, HoldFirst];\nOptions[dragBar] = Append[Options[BarChart], \"resolution\" -> .5];\n\ndragBar[values_, opt : OptionsPattern[dragBar]] := \n DynamicModule[{widths, ind, pt = {0, 0}, index},\n  widths = Reap[BarChart[ConstantArray[1, Length[values]], \n      ChartElementFunction :> ((If[Head[#1] === List, Sow[#1[[1]]]];) &), \n      FilterRules[{opt}, Options[BarChart]]]][[2, 1]];\n  ind[x_] := Piecewise[\n    Table[{i, widths[[i, 1]] < x < widths[[i, 2]]}, {i, Length[widths]}], 0];\n\n  LocatorPane[Dynamic[pt,\n    {(index = ind[#[[1]]]; \n      If[index == 0 || Abs[#[[2]] - values[[index]]] > OptionValue[\"resolution\"], \n        index = None]) &,\n     (If[IntegerQ[index],\n        values += (values[[index]] - #[[2]])/(Length[values] - 1);\n        values[[index]] = #[[2]]]) &,\n     None}],\n   Dynamic[BarChart[values, FilterRules[{opt}, Options[BarChart]]]], Appearance -> None]]\n\nvalues = RandomInteger[10, 10];\ndragBar[values, BarSpacing -> .6]\n\n\n", "plotting - Creating a stacked RectangleChart": "\nActually, RectangleChart does accept ChartLayout -> \"Stacked\". Consider for example\ndata = Table[{i^2, RandomReal[]}, {i, 5}, {j, 5}];\n\nRectangleChart[data, ChartLayout -> \"Stacked\"]\n\n\n", "kernel - Generating figures over remote connection (using terminal)": "\nSince graphics can no longer be exported without access to a front end, even with remote connections you have to have X11 installed and working on your local machine. Therefore, the first thing you should do is: go to the web site http://xquartz.macosforge.org/landing/ and download the latest version of X11 appropriate for your OS X version. After installing it, everything should work.\nEdit\nIn view of the comments, it's worth asking what the alternatives are to creating graphics on a remote host. Since the X11 protocol slows down the interaction between Kernel and FrontEnd, it's not practical on Mac OS X to create graphics that way any more. Unless you have older versions of Mathematica running on the remote host, that's the end of the line for this approach. \nSo what to do? You can hope you have a VNC server so you can start the interactive session entirely on the host. That's a good solution if it's available. \nIf not, then perhaps you'll be best off running the graphics generation as a background job on your own computer. If you have a multicore machine, you can start a Kernel session in the Terminal and let it run there, while doing other things in an interactive notebook session. At least in this way, you won't have to worry about not finding the FrontEnd. \nOn my Mac, I've set up a math command that starts /Applications/Mathematica.app/Contents/MacOS/MathKernel from the Terminal (see this page for details), and in such a Kernel session I would then (without calling JavaGraphics) do the graphics generation, e.g.:\nt = Table[ParametricPlot3D[{Sin[u], Sin[v], Sin[u + v]}, {u, 0, 2 Pi}, {v,0, 2 Pi}, RegionFunction -> Function[{x, y, z}, z < a],\u00a0PlotRange -> {{-1, 1}, {-1, 1}, {-1, 1}}],{a, -1,1,.01}];\nExport[\"t.gif\",t]\n\nWhile that's running, I'm able to use the Mathematica notebook interface in parallel. \nI said not to call JavaGraphics, because once that is initialized the Kernel session will want to display all the pictures you create. One can turn that off again by adding DisplayFunction->Identity to the plot command options, but if the plan is to do a non-interactive job, I'd suggest not loading JavaGraphics in the first place. \n", "export - How to change working directory for calculation and save": "\nThe Documentation page for ResetDirectory says under \"MORE INFORMATION\" field:\n\nSuccessive calls to ResetDirectory yield earlier and earlier current\n  directories.  \nResetDirectory uses the directory stack given by DirectoryStack[].\nResetDirectory removes the last element from the directory stack,\n  and makes the second-to-last element current.\n\nAnd the page for DirectoryStack[] says:\n\nEach call to SetDirectory prepends one element to the directory stack;\n  each call to ResetDirectory drops one.\n\nSo it is not surprizing that DirectoryStack[] initially is a blank list. The call to SetDirectory adds to this list one element: previous working directory. To get the current working directory you should evaluate Directory[].\n", "custom notation - Having the derivative be an operator": "\nA general idea as to how this can be done in a consistent way is explained in the help documents under NonCommutativeMultiply. The thing is that you want to use your operators in an algebraic notation, and that's what that page discusses. \nIf, on the other hand, you're happy with a more formal Mathematica notation, then you would have the easier task of defining operators simply as \ndx := D[#, x] &\ndy := D[#, y] &\n\nand using them as follows:\ndx@f[x, y, z]\n\n\n$f^{(1,0,0)}(x,y,z)$\n\nCombining operators would then be done using Composition: \ndxy = Composition[dx, dy];\ndxy[f[x, y, z]]\n\n\n$f^{(1,1,0)}(x,y,z)$\n\nEdit\nHere is another approach that's sort of intermediate between the very simple D[#,x]& scheme and the more complicated realization of an operator algebra in the linked reference from the documentation.\nTo make the operators satisfy the axioms of a vector space, we'd have to define their addition among each other and the multiplication with scalars. This can be done most conveniently if we don't use patterns to represent the operators, but Functions. So here I repeat the operator definitions - they act the same way as the dx, dy defined above, but their definition is stored differently:\ndx = Function[{f}, D[f, x]];\ndy = Function[{f}, D[f, y]];\n\nNow I define the multiplication of an operator with a scalar: \nmultiplyOp[scalar_, op_] := Function[{f1}, scalar op[f1]];\n\nFor simplicity, I always assume that the scalar is given as the first argument, and the second argument is an operator, e.g., dx etc. Note that the arguments here are not x or y (the assumed independent variables on which functions depend), because multiplyOp maps operators onto operators.\nFinally, we need the addition of two (or more) operators, which is again a mapping from operators (a sequence of them) onto operators:\naddOps[ops__] := Function[{f1}, Total@Map[#[f1] &, {ops}]];\n\nBoth addition and multiplication are mapped back to their usual meaning in these functions, by defining how the combined new operators act on a test function f1 (which is in turn a function of x, y, and z - depending on the dimension).\nTo illustrate the way these operations are used, take the example in the question,\n$\\left(\\partial_x+\\partial_y+z\\right)x\\psi$\nand write it with our syntax:\naddOps[dx, dy, multiplyOp[z, Identity]]@(x \u03c8[x, y])\n\n\n$x \\psi ^{(0,1)}(x,y)+x \\psi ^{(1,0)}(x,y)+\\psi (x,y)+x z \\psi (x,y)$\n\nThis is the correct result (the result quoted originally in the post was actually missing an x). \nNote how I added the scalar z above: in this syntax, it first has to be made into an operator using multiplyOp[z, Identity]. The Identity operator is very useful for this. \nOf course these expressions with addOps and multiplyOp aren't as easy to read as the ones with simple + signs, but on the bright side it can also be beneficial pedagogically to separate the \"operator operations\" clearly from the operations between the functions they act on. \nEdit 2\nIn response to the comment, I'll add a nicer notation, but without modifying the last approach. So I'll simply introduce new symbols for the operations defined above, using some of the operator symbols that Mathematica knows in terms of their operator precedence, but has no pre-defined meanings for:\n\nCirclePlus \u2295 typed as escc+esc\nCircleDot \u2299 typed as escc.esc\nCircleTimes \u2297 typed as escc*esc\n\nI'll use them as follows:\nCirclePlus[ops__] := addOps[ops];\nCircleDot[scalar_, op_] := multiplyOp[scalar, op];\nCircleTimes[ops__] := Composition[ops];\n\nWith this, we can now use Infix notation to write in a more \"natural\" fashion:\n(dx \u2295 dy \u2295 z\u2299Identity)@(x \u03c8[x,y])\n\n\n$x \\psi ^{(0,1)}(x,y)+x \\psi ^{(1,0)}(x,y)+\\psi (x,y)+x z \\psi (x,y)$\n\nAs the third operator, CircleTimes \u2297, I've also defined the composition of operators. That allows us to do things like commutators:\ncommutator = dx \u2297 x\u2299Identity \u2295 (-x)\u2299Identity \u2297 dx;\n\nI'm relying on the fact that \u2299 has higher precedence than \u2297 which in turn has higher precedence than \u2295 (according to the documentation).\nAs expected, the commutator is unity, as we can check by applying to a test function:\ncommutator@f[x]\n\n\nf[x]\n\n", "list manipulation - Finding all length-n words on an alphabet that have a specified number of each letter": "\nPermutations is already duplicate-aware:\nPermutations[{\"A\", \"A\", \"B\"}]\n\n\n{{\"A\", \"A\", \"B\"}, {\"A\", \"B\", \"A\"}, {\"B\", \"A\", \"A\"}}\n\n\nPerhaps you are looking for combinations of a particular length (which can then be permuted).  One way to get those is this:\nf[k_, {}, c__] := If[+c == k, {{c}}, {}]\n\nf[k_, {x_, r___}, c___] := Join @@ (f[k, {r}, c, #] & /@ 0~Range~Min[x, k - +c])\n\nUse:\nf[4, {1, 3, 2}]\n\n\n{{0, 2, 2}, {0, 3, 1}, {1, 1, 2}, {1, 2, 1}, {1, 3, 0}}\n\n\nThese represent the words of length 4 for a list with unique items repeated, 1, 3, and 2 times at most.\nYou can then construct the actual words from these lists, e.g.:\nchar = {\"A\", \"B\", \"C\"};\n\nStringJoin@MapThread[ConstantArray, {char, #}] & /@ f[4, {1, 3, 2}]\n\n\n{\"BBCC\", \"BBBC\", \"ABCC\", \"ABBC\", \"ABBB\"}\n\n\nOr:\nInner[#2 ~Table~ {#} &, f[4, {1, 3, 2}], char, StringJoin]\n\n\n{\"BBCC\", \"BBBC\", \"ABCC\", \"ABBC\", \"ABBB\"}\n\n\nAnd with permutations:\nInner[#2 ~Table~ {#} &, f[4, {1, 3, 2}], char, Join]\n\nPermutations /@ %\n\n\n{{B,B,C,C},{B,B,B,C},{A,B,C,C},{A,B,B,C},{A,B,B,B}}\n\n{{{B,B,C,C},{B,C,B,C},{B,C,C,B},{C,B,B,C},{C,B,C,B},{C,C,B,B}}, . . . }\n\n\n", "front end - How to let output and message be print to two separate external files?": "\nSounds like you are looking for $Messages and $Output, and maybe also $PrePrint or $Post. $Messages and $Output are a list of streams to which corresponding output is written (note that $Output is only getting output from Prints, not from return values of shift-return-evaluations). To cover return values of shift-return-evaluations you might want to manipulate $PrePrint or $Post so it will also write to the desired output file.\nYou can open a file for each with OpenWrite and append the resulting streams to the two lists and the messages and output will be written to those files. You can use the option FormatType of OpenWrite to write to those files in OutputForm. But since these are text files the outcome is not very useful in my opinion: For lengthy expressions the multiline ASCII art is usually harder to read than input form and these files will not be readable for any program. So I'd rather stick with the default InputForm.\nFor return values of shift-return-evaluations you could use something like:\n$PrePrint = Function[Write[outstream,#];#]\n\nwhere outstream is the open stream to your output file.\n", "evaluation - A notebook created on demand from a main document showing executable input along with output cells": "\nWith minor modification of your code, you can use      \n   button3[expr_, sz_: 300] := \n   Button[\"Show expression\", \n   nb = CreateDocument[{ExpressionCell[expr, \"Input\"], \n   ExpressionCell[\n   Button[\"Evaluate\", \n    CellPrint@ExpressionCell[expr /. Defer[x_] :> x, \"Output\"]], \n   \"Input\"]}, WindowSize -> {sz, sz}]];\n   button3[Defer@Expand[(x + y)^2]]\n\nor\n   button3[expr_, sz_: 300] := \n   Button[\"Show expression\", \n   nb = CreateDocument[{ExpressionCell[expr, \"Input\"], \n   ExpressionCell[\n   Button[\"Evaluate\", \n    CellPrint@ExpressionCell[ReleaseHold@expr, \"Output\"]], \n   \"Input\"]}, WindowSize -> {sz, sz}]];\n   button3[HoldForm@Expand[(x + y)^2]]\n\nEDIT: I would go with Heike's s solution. But the following maybe of pedagocial value: ClearAll[func] preceeding definitions of functions that you edit/re-edit until you find a working version is a good practice. Forgetting this is the reason for the convoluted workaround in my original answer. So, the following works as OP intended:\n   ClearAll[button4]; \n   SetAttributes[button4, HoldFirst]; \n   button4[expr_, sz_: 300] := \n   Button[\"Show expression\", \n   nb = CreateDocument[{ExpressionCell[Defer@expr, \"Input\"], \n   ExpressionCell[expr,\"Output\"], \n   ExpressionCell[Button[\"Close window\", NotebookClose[nb]]]}, \n   WindowSize -> {sz, sz}]]; \n   button4[Expand[(x + y)^2]]\n\n", "curated data - Finding all dictionary words that can be made with a given set of characters (Wordfeud/Scrabble)": "\nMy attempt:\nFirst we define the existing row, using dots to represent empty squares, and our hand of 7 letters.\nrow=\"...t.t...r..e..\";\nletters=\"aodalip\";\n\nNext define a function to count how many times each of our letters appears in a given string. Also run this function on our letters, to count how many of each we have.\nlettercount[str_]:=StringCount[str,#]&/@Characters[letters];\nmylettercounts=lettercount[letters];\n\nNext consider where our new word could start and finish. It can't start immediately to the right of an existing letter, nor can it finish immediately to the left of an existing letter.\ncantstarthere=StringPosition[row,Except[\".\"]][[All,1]]+1;\nstartpoints=Complement[Range[14],cantstarthere];\ncantendhere=cantstarthere-2;\nendpoints=Complement[1+Range[14],cantendhere];\n\nNow that we have the list of valid start and end points, construct a list of substrings of row that could become our new word. It is also handy to keep note of what the start point is for each one. An additional constraint is that our new word must include one of the existing letters, so we remove any substrings of row which are all dots.\nsubrows=Flatten[Table[{m,StringTake[row,{m,n}]},{m,startpoints},{n,Select[endpoints,#>m&]}],1];\nsubrows=Select[subrows,Not@StringMatchQ[#[[2]],\".\"..]&];\n\nNow convert each substring of row into a regular expression, replacing each dot with ([any of our letters]).\nstarts=subrows[[All,1]];\nregexes=StringReplace[subrows[[All,2]],\".\"->\"([\"<>letters<>\"])\"];\n\nNext we search the dictionary for any words matching the regular expression. A slight wrinkle is that we might have used one of our letters twice, so we use the regular expression again in StringCases to pick out which letters were used to match the ([any of our letters]) templates. We use this information to weed out any words which we can't actually make.\nresults=Table[\nreg=regexes[[j]];\npossiblewords=DictionaryLookup[RegularExpression[reg]];\nlettersused=Flatten[StringCases[#,RegularExpression[reg]->\"$1$2$3$4$5$6$7\"]&/@possiblewords];\nokay=(Max[(lettercount[#]-mylettercounts)]<1)&/@lettersused;\n{starts[[j]],Pick[possiblewords,okay]}\n,{j,Length[regexes]}];\n\nFinally do a bit of tidying up, and present the words we can make along with their start points.\nColumn[DeleteDuplicates[Flatten[#]]&/@SplitBy[Select[results,#[[2]]!={}&],First]/.{a_Integer,b__}:>Rule[a,{b}]]\n\n\n1->{dolt,plot}\n2->{apt,dot,lit,lot,oat,opt,pat,pit,pot}\n3->{at,it}\n4->{tat,tot,total}\n6->{ta,ti,to,tad,tap,til,tip,top,tapir}\n8->{air,oar,par,lard,lira,lord,para,parade,parole,paroled}\n9->{or,pro,drape,pride,prole}\n10->{rape,ride,rile,ripe,rode,role,rope,raped,riled,riped,roped}\n12->{lea,led,lei,pea,deal,deli,lead,leap,peal}\n\n", "string manipulation - Thousands separator (comma) option for NumberString/StringCases?": "\nThis is admittedly a bit of a hack, but you could remove the commas first, using StringReplace:\nStringCases[\n StringReplace[\" 1,142.123 \", \",\" -> \"\"], \n Whitespace ~~ NumberString ~~ Whitespace, 1]\n\n(* ==> {\" 1142.123 \"} *)\n\n", "syntax - Constructing a Summation with a Variable Number of Inner Sums": "\nLet's concentrate on the inner multiple sum. First note that we know d because it is given from the outer sum. If we want to write the expression \n$$-\\exp\\left[k_1+k_2+\\ldots+k_d\\right]$$\nin Mathematica we could do this very easy. First we create the list {k[1],k[2],...,k[d]} and remember, that this is internally nothing more than List[k[1],k[2],...,k[d]]. If we would now replace the List head with Plus, then it is exactly what we want. For this we can use Apply which is written @@ in infix notation. That leaves how to create the {k[1],k[2],...,k[d]} list. Here we can use Table or Array or we think of it as _mapping the function k over the list {1,2,...,d}. This can be written as\nk /@ Range[d]\n\nfor a known d. All together this gives\nExp[-Plus @@ k /@ Range[d]] \n\nNow we need to build a multiple Sum, summing over d different k. Again, this can be done in several ways. One way is to create a function which gets as arguments the indices for a Sum\nf = Function[Sum[1, ##]]\n\nI only use 1 in the sum for the sake of simplicity.\nYou may ask now, what this ## is: it's the sequence of all arguments given to f.  So lets try it:\nIn[63]:= {Sum[1, {3}], f[{3}]}\n\nOut[63]= {3, 3}\n\nIn[62]:= {Sum[1, {3}, {5}], f[{3}, {5}]}\n\nOut[62]= {15, 15}\n\nSeems to work. The only think which is left now, is to create the ranges {k[i],1,q} where i is always a concrete number. Here we can use again the trick with Range and for a known d this gives a list of ranges:\n{k[#], 1, q} & /@ Range[d] \n\n(* For d = 3 for instance\nOut[64]= {{k[1], 1, q}, {k[2], 1, q}, {k[3], 1, q}}\n*)\n\nThe last thing is to think about, that our Sum function needs a Sequence of arguments and the above is a List. But we already solved the problem of replacing the List with something different by using @@. This gives all together:\nSum[Exp[-Plus @@ k /@ Range[d]], ##] & @@ ({k[#], 1, q} & /@ Range[d])\n\nDon't be afraid of the expression, because now you know every single piece of it and you know what every piece does. You could try it by for instance\nWith[{d = 4},\n Sum[Exp[-Plus @@ k /@ Range[d]], ##] & @@ ({k[#], 1, q} & /@ Range[d])\n ]\n\nand get $$\\frac{e^{-4 q} \\left(e^q-1\\right)^4}{(e-1)^4}$$ or you use this to plant it directly into your outer sum\nmysum[p_Integer] := \n Sum[Exp[-d]*\n     Sum[Exp[-Plus @@ k /@ Range[d]], ##] & @@ ({k[#], 1, q} & /@ \n     Range[d]), {d, 1, p}]\n\nI put it into a function mysum, because p needs to be a number to make all the Ranges work. Now you should check mysum[2]\n$$\\frac{e^{-2 q-2} \\left(e^q-1\\right)^2}{(e-1)^2}+\\frac{e^{-q-1}\r\n   \\left(e^q-1\\right)}{e-1}$$\n", "reference request - What Mathematica book to buy?": "\nAfter having used Mathematica for a couple of years, more or less only to abuse it as a neat plotting and integral solving engine, Leonid Shifrin's Mathematica Programming was my first book that brought me closer to actually understanding how Mathematica works. I soon lost my fear of # & @ @@ @@@ /@ //@.\n(Plus the book is free, and if you still need help: Leonid is a regular on this site.)\n", "list manipulation - Counting elements skipped using Reap & Sow": "\nIf you want to count the dropped values, for each application of your distance function you have exactly one outcome. Either the value is fine and included in you list or the value is dropped. \nIn my opinion a simpler approach is to not use Reap and Sow. Instead, use a simple Map and transform the list afterwards. Furthermore, you have to note that your first element is always dropped because you set z to your first element of the list and get zero in the numerator of your distance function.\nMaybe a better approach is here to not include the first element of the list manually but to fix the initial value of z. If your data is always positive, you could do for instance\nBlock[{z = First[data]/(2 + delta)},\n If[Abs[# - z]/z > delta, z = #; z, Dropped] & /@ data\n ]\n\nTest this in comparison with your function:\ndata = {7, 1, 8, 9, 6, 3, 1, 2, 4, 3, 7, 9, 2, 7, 3, 9, 7, 1, 10, 3};\ndelta = .4;\n\nBlock[{z = First[data]/(2 + delta)},\n If[Abs[# - z]/z > delta, z = #; z, Dropped] & /@ data\n]\n\n(* \n{7, 1, 8, Dropped, Dropped, 3, 1, 2, 4, Dropped, 7, Dropped, 2, 7, 3, \n 9, Dropped, 1, 10, 3}\n*)\n\nNow the only thing you have to do is to gather all Dropped symbols, count them and give the other list as your result:\nmyfilter[data_] := {#1, \"Dropped\" -> Length[#2]} & @@\n  GatherBy[Block[{z = First[data]/(2 + delta)},\n    If[Abs[# - z]/z > delta, z = #; z, Dropped] & /@ data\n    ], # === Dropped &]\n\nand then\nIn[68]:= myfilter[data]\n\nOut[68]= {{7, 1, 8, 3, 1, 2, 4, 7, 2, 7, 3, 9, 1, 10, 3}, \n \"Dropped\" -> 5}\n\nUpdate\nIf you want to build a list where you see where and how many drops happened you could leave out the GatherBy thing and work on the number list with the Dropped inside. Example:\ndata = {7, 1, 8, 9, 6, 3, 1, 2, 4, 3, 7, 9, 2, 7, 3, 9, 7, 1, 10, 3};\ndelta = .4;\n\nres = Block[{z = First[data]/(2 + delta)}, \n If[Abs[# - z]/z > delta, z = #; z, Dropped] & /@ data]\n\nSplit[res, #1 === #2 === Dropped &] /. \n   {{i_Integer} :> i, d : {Dropped ..} :> {Length[d]}}\n\n(*\n{7, 1, 8, {2}, 3, 1, 2, 4, {1}, 7, {1}, 2, 7, 3, 9, {1}, 1, 10, 3}\n*)\n\nI packed the drop-length information inside list braces so one sees what is output and what is drop-information.\nNote, when I see this right the second argument to Split is not necessary because it cannot happen that there are same numbers next to each other. \n", "Constructing a function with Flat and OneIdentity attribute with the property that otimes[a]:>a": "\nI see now. The problem arises with Flat then. Just set the attributes after setting the definitions. Or at least the Flat attribute\nClearAll[otimes];\nSetAttributes[otimes, OneIdentity]\notimes[a_] := a\nSetAttributes[otimes, Flat]\n\nCheck out this answer for more details on why this works.\nBasically, MMA remembers if the symbol was Flat or not at the time each DownValue is defined. The infinite recursion is more related to this:\nSetAttributes[f, Flat];\nReplace[Hold@f[2], Hold@f[i_] :> Hold[i]]\n\nSo, when you did otimes[2] and it checked the otimes[a_]:=a downvalue, it matched a with otimes[2], so you got your infinite recursion\n", "output formatting - Functions in a different context are replaced with infix forms of their namesake in System`": "\nIt seems like the StandardForm (default for output) of Times in any context (or Plus, etc) is with the * and + symbols.\nBut your assumption isn't wrong I think, the symbols * and + are mapped to System Times and System Plus. Try\nPrependTo[$ContextPath, \"blo`\"];\nblo`Times[a_, b_] := 8;\n\nFullForm@MakeExpression[RowBox[{\"a\", \"*\", \"b\"}], StandardForm]\n\nI think that this goes against Mathematica policy that \"StandardForm generates output that gives a unique and unambiguous representation of Mathematica expressions, suitable for use as input\"\n", "syntax - What does the slash-colon symbol do?": "\n/: is the short-hand notation for TagSetDelayed, which is creating UpValues.  It's useful for over-loading how a particular function behaves with a specific head.  For example:\nIn[1]:= h /: Plus[x : h[arg1_, arg2_], y : h[arg3_, arg4_]] := Plus[arg1, arg2, arg3, arg4]\n\nIn[2]:= h[1, 2] + h[3, 4]\nOut[2]= 10\n\nThe benefit being you don't have to Unprotect[Plus] to set the definition, and if you Remove[h] this definition will be wiped out as well.\n", "recursion - Solving recurrence relation using Mathematica defined in a piecewise way": "\nThis works:\nRSolve[{\n  p[1] == l p0/m,\n  p[n + 1] == l /(2 m) p[n]},\n  p[n], n]\n (*\n  -> {{p[n] -> 2^(1 - n) (l/m)^n p0}}\n *)\n\n(The overspecification of p[0] and p[1] is not to the taste of RSolve)\nAnother way:\nk[0] = k0;\nk[1] = l k[0]/m;\nk[i_] := l k[i - 1]/(2 m) /; i > 1;\nFindSequenceFunction[Table[k[i], {i, 1, 10}], n]\n(*\n-> 2^(1 - n) k0 (l/m)^n\n*)\n\nEdit\nReader, beware! As of v8.0, RSolve and FindSequenceFunction are both immature implementations (I think), and there a lot of cases where the output is just the input.\n", "Connecting to a remote machine": "\nFrom your update, your situation is very similar to mine, where I can connect to hostA through the internet, but to hostB only via hostA. Here is the pared down settings from my ~/.ssh/config that you can adapt to your machines:\nHost hostA\n    HostName hostA.school.edu\n    User rm\n    ForwardX11 yes\n    ForwardX11Trusted yes       \n    ControlMaster auto\n    ControlPath ~/.ssh/control:%h:%p:%r\n\nHost hostB\n    Hostname hostB.school.edu\n    User rm\n    ProxyCommand ssh -T -a hostA nc %h %p\n\nHere, using ControlMaster and ControlPath lets you tunnel all subsequent connections to hostA via an existing connection. So this means that you need to have only 1 open connection (need password, if not using keys) and you needn't enter your password again as long as that session is alive (extremely convenient and useful in general!).\nThe second, using ProxyCommand allows you to login to the second through the first. So if you have one open connection to hostA, you can then simply ssh hostB on your local machine and the connection will automatically be routed through hostA. Now if you didn't set up ControlMaster and ControlPath, you'll have to enter 2 passwords \u2014 one for hostA and another for hostB.\n", "evaluation - Speeding up mathematica by subsitituting numerical values": "\nI await a more complete question, but for now my best guess is:\na = 0.5; b = 0.2;\n\nDo[N[.95*a + (1. - .95) b], {1*^5}] // AbsoluteTiming\n\n\n{0.0670038, Null}\n\n\nDo[N[k*a + (1. - k) b /. k -> .95], {1*^5}] // AbsoluteTiming\n\n\n{0.3310190, Null}\n\n\nWith[{k = 0.95},\n  Do[N[k*a + (1. - k) b], {1*^5}]\n] // AbsoluteTiming\n\n\n{0.0800046, Null}\n\n\nWith on the outside does the replacement before evaluating the Do loop.\n\nSeeing your application I can recommend another considerable improvement.  Even in your new form, With is inside Plot and reevaluated many times.  If you force this to evaluate first it will be much faster.  Here are three ways to do that, take your pick:\nPlot[#, {x, 0., 1.}] & @ With[{k = x}, Mean[k*m1 + (1. - k)*m2]]\n\nPlot[Evaluate @ With[{k = x}, Mean[k*m1 + (1. - k)*m2]], {x, 0., 1.}]\n\nPlot[With[{k = x}, Mean[k*m1 + (1. - k)*m2]], {x, 0., 1.}, Evaluated -> True]\n\nPlease note two things:\n\nIn each case above the global symbol x is not localized, as a result of the pre-evaluation.  If it is possible to vary k directly, e.g. Plot[... {k, 0, 1}] you should probably do it.\nBecause of the pre-evaluation you will find that the various lines are now styled in different colors.  See this question and answers for an explanation.  If you want uniform color lines add the option PlotStyle -> ColorData[1][1] to Plot.\n\n", "plotting - Shading between polar graphs": "\nYou have a (or more) curves. If you don't use PolarPlot you could use ParametricPlot instead but you would have to make the transformation from polar coordinates by yourself.\nKnowing this, you could think about what your functions mean. For instance 2 (1 - Cos[phi]) is just the radius of your curve for a given phi. If you want to draw the region outside your curve, the only thing you have to do is (attention, I'm mixing polar and Cartesian coord.):\nCheck a every point $\\{x,y\\}$ whether the radius $\\sqrt{x^2+y^2}$  is larger than $2(1-\\cos(\\varphi))$  where $\\varphi=\\arctan(y/x)$.\nUsing this, your filling can be achieved with RegionPlot and your graphics\nShow[\n PolarPlot[Evaluate[{{1, -1} Sqrt[2 Cos[t]], \n   2 (1 - Cos[t])}], {t, -\\[Pi], \\[Pi]}],\n RegionPlot[\n  Sqrt[x^2 + y^2] > 2 (1 - Cos[ArcTan[x, y]]) &&\n  Sqrt[x^2 + y^2] < Re@Sqrt[2 Cos[ArcTan[x, y]]]\n  , {x, -2, 2}, {y, -3, 3}],\n PlotRange -> All\n ]\n\n\nIf you encounter dark mesh lines in the filling and want to get rid of them, please read the question of david here. You then have to include \nMethod -> {\"TransparentPolygonMesh\" -> True}\n\nas option.\n", "programming - Iteration of a function": "\nJ.M.'s comment points you in the direction of why this doesn't work. Iterating $x^7$ 50 times (even if $k=0$) is $(x^7)^{50}$.\n(x^7^50)\n\n(* x^1798465042647412146620280340569649349251249 *)\n\nThat exceeds the maximum number representable in Mathematica: \nIn[1]:= $MaxNumber\n\nOut[1]= 5.297557459040040*10^323228467\n\nEven if we considered $x^2 + k$ instead of $x^7 + k$, it will still overflows.\nff[x0_, k_] := NestList[ #1^2 + k &, x0, 50]\n\nIn[10]:= ff[1., 0.1]\n\n\n During evaluation of In[10]:= General::ovfl: Overflow occurred in computation. >>\n\n\nOut[10]= {1., 1.1, 1.31, 1.8161, 3.39822, 11.6479, 135.773, 18434.5, \n 3.39832*10^8, 1.15486*10^17, 1.33369*10^34, 1.77873*10^68, \n 3.16389*10^136, 1.00102*10^273, 1.002046001003433*10^546, \n 1.004096188126972*10^1092, 1.008209155011116*10^2184, \n 1.016485700248229*10^4368, 1.033243178809133*10^8736, \n 1.067591466555603*10^17472, 1.139751539462343*10^34944, \n 1.299033571706781*10^69888, 1.687488220421276*10^139776, \n 2.847616494060564*10^279552, 8.108919697245777*10^559104, \n 6.575457865638055*10^1118209, 4.323664614278137*10^2236419, \n 1.869407569676091*10^4472839, 3.494684661562269*10^8945678, \n 1.221282088375859*10^17891357, 1.491529939387699*10^35782714, \n 2.224661560089872*10^71565428, 4.949119056941505*10^143130856, \n 2.449377943978157*10^286261713, Overflow[], Overflow[], Overflow[], \n Overflow[], Overflow[], Overflow[], Overflow[], Overflow[], \n Overflow[], Overflow[], Overflow[], Overflow[], Overflow[], \n Overflow[], Overflow[], Overflow[], Overflow[]}\n\nOf course, if you have a starting value $x0<1$, your original function is fine, and converges quickly. \nIn[12]:= ff7[x0_, k_] := NestList[ #1^7 + k &, x0, 50]\n\nIn[13]:= ff7[0.5, 0.1]\n\nOut[13]= {0.5, 0.107813, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, \\\n0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, \\\n0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, \\\n0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1}\n\nPower values below 1 are also fine: \nIn[16]:= ff2[x0_, k_] := NestList[ #1^0.8 + k &, x0, 50]\n\nIn[17]:= ff2[1., 0.8]\n\nOut[17]= {1., 1.8, 2.40036, 2.81475, 3.08851, 3.2649, 3.37689, \\\n3.44736, 3.49147, 3.51898, 3.53611, 3.54676, 3.55338, 3.55748, \\\n3.56003, 3.56162, 3.5626, 3.56321, 3.56359, 3.56382, 3.56397, \\\n3.56406, 3.56411, 3.56415, 3.56417, 3.56418, 3.56419, 3.56419, \\\n3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, \\\n3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, \\\n3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642}\n\nBut in this case, I question why keeping the last ten iterations makes any sense. The function will have converged by then. It is behaviour of the first ten iterations that is more interesting.\n", "plotting - Show parameters on graph": "\nThe following is what you get using the code posted in my answer linked here:\nAll you have to do is make the plot, and call the function autoLegend I defined in the link:\nstyles = {Black, Directive[Dashed, Black], \n  Directive[DotDashed, Black], Directive[Dotted, Black]}\nparameters = {1/2, 1/3, 1/5, 1/1000};\np = Plot[Evaluate[\n    PDF[ExponentialDistribution[#]][x] & /@ parameters], {x, 0, 50}, \n   AxesOrigin -> {0, 0}, PlotStyle -> styles];\nautoLegend[p, parameters]\n\n\n", "plotting - Plot curves different way so that one can see them when printing black and white": "\nIn addition to Dashing, there are also DotDashed and Dotted line styles. So you could define a set of plot styles as follows, varying first the dashing and second the gray shade:\nstyles = Flatten@\n  Table[{Directive[color], Directive[Dashed, color], \n    Directive[DotDashed, color], \n    Directive[Dotted, color]}, {color, {Black, Gray}}]\n\nThen the plot that is supposed to be printed in black and white would be created by this:\np = Plot[Evaluate[\n   PDF[ExponentialDistribution[#]][x] & /@ {1/2, 1/5, 1/25, \n     1/1000}], {x, 0, 50}, AxesOrigin -> {0, 0}, PlotStyle -> styles]\n\n\n", "combinatorics - Mathematica function/package for shuffle permutations": "\n1) The number of all (p,q) shuffles is\nBinomial[p+q,p]\n\nsince when you chose the first p elements, the whole thing (and its order) is given.\n2)The actual shuffles are given by: (See JM's comment below*)\nWith[{x = Range@#1}, {#, Complement[x, #]} & /@ Subsets[x, {#2}]] &[p + q, p]\n\nExample:\np = 3; q = 2;\nWith[{x = Range@#1}, {#, Complement[x, #]} & /@ Subsets[x, {#2}]] &[p + q, p]\n\n(*\n->\n{{{1, 2, 3}, {4, 5}}, {{1, 2, 4}, {3, 5}}, {{1, 2, 5}, {3, 4}}, {{1, 3, 4}, {2, 5}}, \n {{1, 3, 5}, {2, 4}}, {{1, 4, 5}, {2, 3}}, {{2, 3, 4}, {1, 5}}, {{2, 3, 5}, {1, 4}}, \n {{2, 4, 5}, {1, 3}}, {{3, 4, 5}, {1, 2}}}\n\n3) The sign of each permutation (for the above shuffles) is given by:\nSignature/@ With[{x=Range@#1}, Join[#, Complement[x, #]] & /@ Subsets[x, {#2}]] &[p+q,p]\n\nExample:\np = 3; q = 2;\nSignature/@ With[{x=Range@#1}, Join[#, Complement[x, #]] & /@ Subsets[x, {#2}]] &[p+q,p]\n(*\n-> {1, -1, 1, 1, -1, 1, -1, 1, -1, 1}\n*)\n\n", "Plotting the results of iterating a function": "\nThere is no a in your definition of the function w[], so it's no wonder that you can't get it to work. \nYou could try the following, but you would hit the same Overflow problems as in your previous question.\nw[a_] := Take[NestList[f[a], 0, 1000], 100]\n\nI would suggest an alternative approach using NestWhile: \nw[a_] := NestWhile[f[a], 0, Abs[#] < 1000. &, 1, 100]\n\nYou will only get the \"last\" element in the iteration, defined either as the 100th iteration - it will have converged by then if it was going to - or the last iteration before the absolute value of the result broke through 1000 (i.e. it was diverging). That way, you break out before the iteration overflows.\nYou can then get your list of results using the Table function (notice I've also preserved the values of $a$, which I've labeled $i$ for the purpose of defining the iteration in the table, so the values of the $a$ parameter are shown correctly in the subsequent plot:\nresult=Table[{i, w[i]}, {i, -0.2, 1.8, 0.01}];\n\nAnd plot using ListLinePlot:\nListLinePlot[result, PlotRange -> All, Frame -> True, AxesOrigin -> {0, 0}]\n\n\nOne thing I would mention is that it's not clear whether you should focus on a single starting point. You could instead define:\nff[a_, x0_] := NestWhile[#^2 + a &, x0, Abs[#] < 100. &, 1, 100]\n\nAnd construct your results as:\nresult = Table[{i, ff[i, 0.1]}, {i, -0.2, 1.8, 0.01}];\n\nYou could then even have a two dimensional table:\nresult2 = Flatten[\n  Table[{i, j, ff[i, j]}, {i, -0.2, 1.8, 0.01}, {j, -0.2, 0.9, 0.1}],  1];\n\nWhich you could visualise using ListDensityPlot:\nListDensityPlot[result2]\n\n\n", "programming - How to avoid conflicts between local variable names and symbolic arguments in Block constructs?": "\nIf you don't want to have the Module inside the function, you can also put it around the function, and then use Block inside, as in\nModule[{s,r},\n  f[param_List]:=Block[{s = First[param], r = Rest[param]}, ... ]\n]\n\nHowever, for this special case, I'd use the abilities of the pattern matcher:\nf[{s_,r___}] := ...\n\n", "programming - Using Apply inside Compile": "\nFirst question : With accepts a syntax like\n  With[{var:=value}, expression]\n\nin which case, value is injected into expression unevaluated. As far as I know, this syntax is not documented. You can achieve a similar effect with the replacement rules, by using \nUnevaluated[expression]/.HoldPattern[var]:>value\n\nThere are some subtle differences between the semantics of With and repalcement rules though, mostly related to the treatment of nested scoping constructs and variable name conflicts in them. \nSecond question: vars appear twice because they must first be Block-ed, and then there is a massive assignment to them performed in the body of the Block. This is probably the most economical way of blocking a number of variables and assigning values to them simultaneously - otherwise a more complex code-generation will be needed. You can see another example of that in   this answer (and if you look at the revision history for that answer, you can find an alternative, harder way to do this, in one of the previous revisions).\nThird question: this does not work because the apply function was made HoldAll (which isn't quite necessary), and the pattern-matching does not work. There were some past discussions on this topic on SO, but can't find them right now. But I discussed this topic at length also in my book. The idea is that at the pattern-matching time, all seen by apply is a variable objectiveFunction, and because it does not evaluate it, the pattern _CompiledFunction is not matched. The solution is to make apply HoldRest, and then it works:\nClearAll[apply];\nSetAttributes[apply, HoldRest];\napply[...]:=...\n\n", "programming - Question about collections of custom GUI controls for Mathematica": "\nOne of the excellent places to look is the Wolfram Demonstration Project. There are many cases with custom controls there. You can test out controls immediately and download the source code. Because I know that site pretty well I will keep the list here. \nRelief-Shaded Elevation Map\n\n3D Waves\n\nPotter's Wheel\n\nMotion Blur\n\nContours of Algebraic Surfaces\n\nPolar Area Sweep\n\nColor Quantization... Tracing Contour... Creating Posters...\n\nRelationship between the Tone Curve and the Histogram of a Photographic Image\n\nComplex nested controls: Two-Dimensional Block Cellular Automata with a 2\u00d72 Neighborhood\n\nInteresting type - the content is the control: Block Builder\n\nConstrained locators: Sweet Heart\n\n", "plotting - How to plot a curve with border around the line?": "\nYou could plot the curve twice, with two different styles:\nPlot[{Sin[x], Sin[x]}, {x, 0, 2 Pi}, \n     PlotStyle -> {Directive[Thickness[0.03], White], Black}]\n\n\nChanging the background to gray:\nPlot[{Sin[x], Sin[x]}, {x, 0, 2 Pi}, \n     PlotStyle -> {Directive[Thickness[0.03], White], Black}, \n     Background -> Gray]\n\n\n", "programming - Bifurcation Diagram for 1D Map": "\nPerhaps you are looking to build a bifurcation diagram. There are a few approaches in Mathematica mentioned in Documentation, which I give below. Also please take a look at apps of similar nature at the Wolfram Demonstration Project. I do not have time to dive into your specific problem, and give classic examples of logistic map which also a quadratic function.\nSimplest way\nListPlot[ParallelTable[Thread[{r, Nest[r # (1 - #) &, \nRange[0, 1, 0.01], 1000]}], {r, 0, 4, 0.01}], PlotStyle -> PointSize[0]]\n\n\nUsing RecurrenceTable\nk = 1000; r = Range[3., 4., 1/(k - 1)];\nrhs[x_?VectorQ] := r x (1 - x);\niterates = RecurrenceTable[{x[n + 1]==rhs[x[n]], x[0] ==ConstantArray[1./\\[Pi], k]}, \n           x, {n, 10^4, 2 10^4}];\ndata = Transpose[Ceiling[iterates k]];\n\ncount[data_, i_] := Module[{c, j},\n   {j, c} = Transpose[Tally[data]];\n   Transpose[{j, ConstantArray[i, Length[j]]}] -> Log[N[c]]];\n\nS = SparseArray[Table[count[data[[i]], i], {i, k}], k];\nArrayPlot[Reverse[S], ColorFunction -> \"Rainbow\"]\n\n\nStructuring data for ArrayPlot\nline[r_, dy_, np_, n0_, n_] := Module[{pts},\n  With[{logistics = Function[x, r x (1 - x)]}, \n  pts = Join @@ NestList[logistics, Nest[logistics,RandomReal[{0, 1},np],n0],n - 1]];\n  Log[1.0 + BinCounts[pts, {0, 1, dy}]]]\n\n    With[{w = 400, h = 250, r0 = 2.95, r1 = 4.0}, \n     ArrayPlot[ParallelTable[line[r, 1/(w - 1), w, 500, 50], \n     {r, r0, r1, (r1 - r0)/(h - 1)}], ImageSize -> {w, h}, PixelConstrained -> True]]\n\n\n", "Export Plots to $\\LaTX$ - Mathmatica Stack Exchang": "\nI usually Export to hi-res PNG bitmaps for ease of use (there are a number of discussions on how best to export high-quality images on this forum. Take a peek at the right column of this page under \"Related\"). Personally I like notebooks that do not need any mouse-clicking or any other user interaction to produce output which makes reruns that much more comfortable and and most of all reproducible.\nFor ease of use when dealing with many different graphics I prepare a notebook for each of these and also generate the LaTeX code for insertion in my document. The graphics get their name from the notebook so you can easily spawn different versions by renaming the notebook. \nplot = Plot[Sin[x], {x, 0, 10}]\n\n\n(*gfxname = StringTake[FileNameSplit[NotebookFileName[]][[-1]], {1, -4}]*)\n\nEDIT: more concise and portable:\ngfxname = FileBaseName[NotebookFileName[]]\n\n\n\"2012-05-04_Plot_Export\"\n\nExport[gfxname <> \".png\", plot];\n\nStringReplace[\"\\\\begin{figure}[!htb]\\\\centering\n \\\\includegraphics[width=1\\\\textwidth]{XXX}\n \\\\caption{Put your caption here.} \n \\\\label{fig:XXX}\n \\\\end{figure}\n \", \"XXX\" -> gfxname]\n\nThe resulting output can be copied as plaintext or you might even splice it directly into your document (although this is a bit much for casual use).\n\\begin{figure}[!htb]\\centering\n\\includegraphics[width=1\\textwidth]{2012-05-04_Plot_Export}\n\\caption{Put your caption here.} \n\\label{fig:2012-05-04_Plot_Export}\n\\end{figure}\n\n", "color - Is there a way to access the (lexically) current colour inside Graphics?": "\nCurrentValue[\"Color\"] seems to be doing the trick (not documented).\nmydisk[p_, r_] := {Dynamic[EdgeForm[Darker[CurrentValue[\"Color\"]]]], \n  Disk[p, r]}\n\nDynamic is needed because the value has to be evaluated by FrontEnd at the time of rendering. Here is the result:\nGraphics[{EdgeForm[AbsoluteThickness[10]], Red, mydisk[{0, 0}, 1], \n  Green, mydisk[{1, 1}, 1]}]\n\n\nCurrentValue is like a box of chocolate. It has a lot of features (mostly FE callbacks), many undocumented, but usually a very present surprise when it works.\nA few other items that work with CurrentValue: \"Thickness\", \"Opacity\", \"Dashing\", \"FontFamily\", \"FontSize\", \"FontSlant\", \"FontWeight\", \"FontColor\" and \"FontOpacity\".\n", "education - Some way to identify the source of a notebook file?": "\nMathematica notebook files are plain text files.  This means that you can open them up with a text editor and check their contents.\nNotebook files don't seem to contain any information that could be used to track their source (the computer on which they were created).  What it does contain, and you might be able to use, is the creation and modification dates of all cells (CellChangeTimes cell option).\nYou can access this information using the Front End as well.  Go to Cell -> Notebook History....  It will give you a window that will show the modification times of each cell (an interval for each single edit that happened in the notebook's lifetime), to 1-second precision.  You can click a line in the graph view to select that cell and see the creation and last modification time, or you can click \"Copy raw data\" to get all the data (use DateList to convert them to something more human readable from the AbsoluteTime format).\nIf two homework submissions have the same modification times, up to the second, then it's likely they have a common source.\nWith a bit of programming you can automate the process of checking all submissions against each other, and selecting those whose first few modification times coincide.\n", "front end - Text replacement rules in $FrontEnd?": "\nNormally you could use:\nSetOptions[$FrontEndSession,\n  InputAutoReplacements -> {\"<-\" -> \"\\[LeftArrow]\"}\n]\n\nBut this fails because Mathematica already parses <- differently.  Specifically the documentation states:\n\nIn expression input, automatic replacements can be performed only on strings of characters that correspond to complete input tokens. \n\nYou can see that this setting works for other strings, e.g.:\nSetOptions[$FrontEndSession,\n  InputAutoReplacements -> {\"stuff\" -> \"\\[LeftArrow]\"}\n]\n\nThen typing (with a space):\nx stuff \n\nWill render:\nx \\[LeftArrow] \n\n", "Using function with multiple definitions in Manipulate": "\nAs already explained: MatchQ[0, 0.] is False.\nGenerally, I suggest using:\nboxcox[data_, x_ /; x == 0] := Log[data]\n\nThis works even for expression that are not expressly 0 or 0., e.g.:\nMatchQ[E^(I Pi/4) - (-1)^(1/4), x_ /; x == 0]\n\n\nTrue\n\n\nIt also works in cases like this:\nMatchQ[0.0000000000000000000, x_ /; x == 0]\n\n\nTrue\n\n\nCompare:\nMatchQ[0.0000000000000000000, 0 | 0.]\n\n\nFalse\n\n\n", "programming - Finding a percolation path": "\nA percolation network is just a kind of network, so I went in the direction of proposing a graph-theoretic approach. You seem to be measuring distances between nodes multiple times, but given the points don't move, you need only do it once:\ned = Outer[EuclideanDistance, randPts, randPts, 1];\n\nYou can get the positions of the nodes you are trying to connect like so:\nleftmost = Position[randPts, {Min[randPts[[All, 1]] ], _}][[1, 1]]\n\nrightmost = Position[randPts, {Max[randPts[[All, 1]] ], _}][[1, 1]]\n\nHere is an auxiliary function that determines which nodes are no more than r distance from each other. I exclude zero distances to avoid the complication of self-loops.\nlinked[mat_?MatrixQ, r_?Positive] := Map[Boole[0 < # < r] &, mat, {2}]\n\nIt is easy to use this auxiliary function to create an adjacency matrix which can be visualised with the correct coordinates using the VertexCoordinates option.\ngg = AdjacencyGraph[linked[ed, 2.], VertexCoordinates -> randPts]\n\n\nFinding out whether the left-most and right-most points are connected is a matter of determining if FindShortestPath yields a non-empty result.\nFindShortestPath[gg, leftmost, rightmost]\n(* ==> {56, 16, 126, 156, 142, 174, 65, 49, 23, 88, 6, 45, 122, 68, 131, 139, 80} *)\n\nLet's put all this together. I am going to build the option to test if the network is a percolation network in the same function that visualises the network.\nOptions[isPercolationNetwork] = {ShowGraph -> False}\n\nisPercolationNetwork[points : {{_?NumericQ, _?NumericQ} ..}, \n  r_?Positive, opts : OptionsPattern[]] :=\n  Module[{ed = Outer[EuclideanDistance, points, points, 1], \n   leftmost =  Position[points, {Min[points[[All, 1]] ], _}][[1, 1]], \n   rightmost = Position[points, {Max[points[[All, 1]] ], _}][[1, 1]]},\n  With[{gg =  AdjacencyGraph[linked[ed, r], VertexCoordinates -> points]},\n   If[OptionValue[ShowGraph],\n    HighlightGraph[gg, PathGraph[FindShortestPath[gg, leftmost, rightmost]]], \n    Length[FindShortestPath[gg, leftmost, rightmost] ] > 1]]\n  ]\n\nIf the option ShowGraph is True, it shows the graph and the connecting path; if it is False, it just returns True or False.\nisPercolationNetwork[randPts, 2., ShowGraph -> True]\n\n\nIt is pretty straightforward to put all this together to find the minimum distance to create a percolation network.\nminimumPercolationNetwork[points:{{_?NumericQ, _?NumericQ}..}, r0_?Positive] :=\n Module[{r = r0},\n  While[isPercolationNetwork[randPts, r], r = r - 0.01]; \n  Print[r + 0.01]; \n  isPercolationNetwork[points, r + 0.01, ShowGraph -> True] ]\n\nAnd the result:\nminimumPercolationNetwork[randPts, 3.]\n\n\n1.97\n\n\n\nExecution is reasonably fast: Timing of the above example was a bit above 6s on my machine, but it depends on the initial value you pick for r.\n", "list manipulation - Recursion on a moving window": "\nFrom your question, it looks like you need to implement some form of a linear predictor and step forward in time starting with an initial state. The solution is still the same as my previous version \u2014 i.e., using Nest, but it's now written in a clearer form:\npredict[samples_] := Total[samples] (* Replace Total with your function *) \nstep[state_, n_: 2] := state ~Join~ {predict[state[[-n ;;]]]}\nNest[step[#, 3] &, initialState, 10] (* enter your lag (here 3), initialState, iterations *)\n\nAn example to generate the Fibonacci series with the above:\nNest[step, {0, 1, 1}, 10]\n(* {0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144} *)\n\n\nOriginal answer:\nYou can do it easily with NestList:\nNestList[myFunction, initialState, 5]\n(* {{1, 2, 3}, {2, 3, 1}, {3, 1, 3}, {1, 3, 3}, {3, 3, 5}, {3, 5, 5}} *)\n\n", "coding style - Are these nested Tables necessary?": "\nNo, they are not needed. You can specify as many \"iterators\" (the parameters of the form {x, xmin, xmax} or {x, xmin, xmax, dx}) as you wish. (See the last form list in the documentation.)  For example,\nTable[i j, {i, 3}, {j, 3}]\n\nproduces\n{{1, 2, 3}, {2, 4, 6}, {3, 6, 9}}\n\nAdditionally, any iterator can rely on those that came before it, but not those that come after it, in the list, e.g.\nTable[i j, {i, 3}, {j, i, 3}]\n\ngives\n{{1, 2, 3}, {4, 6}, {9}}\n\nwhile \nTable[i j, {i, j, 3}, {j, 3}]\n\ngenerates the error\nTable::iterb: \"Iterator {i,j,3} does not have appropriate bounds.\"\n\n", "syntax - Finding the position of a specific value in a list": "\nYou can use the Position function. Which returns a list of the positions of the pattern you are searching for.\nk = RandomInteger[10, {10, 2}]\n(* ->{{2, 10}, {9, 3}, {9, 10}, {8, 1}, {2, 0}, {10, 10}, {10, 0}, {10,6}, {3, 1}, {3, 2}} *)\n\nPosition[k, 3]\n\nreturns\n{{2, 2}, {9, 1}, {10, 1}}\n\nWhich is a list of the indices of the three occurrences of 3 in the list, k.\n", "printing - How can parts of a list of lists be printed to the nb, at regular interval positions?": "\nYou can select every 21st element using\nmylist[[21;; ;; 21]]\n\nYou can print them using \nDo[Print[mylist[[i]]], {i, 21, 441, 21}]\n\nRegarding memory, having these displayed in the Front End will take more memory than just having the data in kernel memory, so Print /@ mylist[[21;; ;; 21]] may be better.  Why do you want to print them?  If you're aim is to write to a file, there are other ways.\nEDIT\nTo number the parts, you can use Do[Print[Style[i/21, Large]; Print[mylist[[i]]], {i, 21, 441, 21}]\n", "performance tuning - How to read data file quickly?": "\nFor a one-off read you can Skip a number of records:\nstr = OpenRead[\"test.tsv\"];\nSkip[str, Record, n - 1];\ndata = ReadList[str, {Record, Number, Record}, 100, RecordSeparators -> {\"\\t\", \"\\n\"}];\nClose[str];\n\nIf you will be reading from the same file many times, it may be worth building an index you can use with SetStreamPosition\nstr = OpenRead[\"test.tsv\"];\nindex = Table[pos = StreamPosition[str]; Skip[str, Record]; pos, {100000}];\n\nreadlines[n_, m_] := Block[{},\nSetStreamPosition[str, index[[n]]];\nReadList[str, {Record, Number, Record}, m, RecordSeparators -> {\"\\t\", \"\\n\"}]]\n\ndata = readlines[50000,100]\n\nOn my PC building the index took about half a second for 10^5 rows in the file, assuming it scales linearly this would be about a minute for 10^7 rows. So this is only worth doing if you are going to be doing a lot of reads.\n", "grid layouts - Generating schedules/timetables in Mathematica": "\nIf you can put your schedule into a list like this:\nschedule =  {\n   {\"Lundi\", \"09:30\", 1, \"Inorg 1\", \"N-515\", Lighter[Orange, 0.5]},\n   {\"Lundi\", \"10:30\", 1, \"Physique 4\", \"N-515\", Lighter[Cyan, 0.5]},\n   {\"Mardi\", \"9:30\", 2, \"Macromol 2\", \"G-815\", Lighter[Green, 0.3]},\n   {\"Mardi\", \"14:30\", 1, \"Inorg 1\", \"r\u00e9pet N-515\", Lighter[Orange, 0.5]}, \n   {\"Mecredi\", \"9:0\", 2, \"Analytique 2\", \"G-815\", Lighter[Gray, 0.5]},\n   {\"Mecredi\", \"11:00\", 0.5, \"Inorg\", \"N-515\", Lighter[Orange, 0.5]},\n   {\"Mecredi\", \"12:30\", 1, \"Organique 3\", \"r\u00e9pet 1015\", Lighter[Yellow, 0.2]},\n   {\"Mecredi\", \"13:30\", 2, \"Physique 4\", \"G-615\", Lighter[Cyan, 0.5]},\n   {\"Jeudi\", \"9:30\", 1, \"Analytique 2\", \"G-615\", Lighter[Gray, 0.5]},\n   {\"Jeudi\", \"10:30\", 2, \"Organique 3\", \"r\u00e9pet 1015\", Lighter[Yellow, 0.2]},\n   {\"Jeudi\", \"14:00\", 2, \"Physique 4\", \"N-515\", Lighter[Cyan, 0.5]},\n   {\"Vendredi\", \"09:30\", 1, \"Macromol 2\", \"G-615\", Lighter[Green, 0.3]},\n   {\"Vendredi\", \"10:30\", 1, \"Organique 3\", \"G-615\", Lighter[Yellow, 0.2]}\n   };\n\nthen a Manipulate like this:\n\nisn't too difficult to make, just fiddly in places. Unfortunately, \"pretty\" isn't an easy word - much gets lost in translation... :) My attempt may be more to my taste than yours...\ndays = {\"Lundi\", \"Mardi\", \"Mecredi\", \"Jeudi\", \"Vendredi\"};\ntimeStringToDecimal[time_] := Module[\n  (* 24 hour clock, of course *)\n  {hours = \n    ToExpression[First[StringSplit[time, \":\"]]], \n    minutes = ToExpression[Last[StringSplit[time, \":\"]]]},\n  N[hours + (minutes / 60)]]\n\neventStart[time_] := \n  timeStringToDecimal[time];\n\neventStarts = \n  With[{time = #[[2]]}, timeStringToDecimal[time]] & /@ schedule;\n\nfirstEvent = Min[eventStarts]; lastEvent = Max[eventStarts];\n\neventsForDay[day_] :=\n  Select[schedule, #[[1]] == day &] ;\n\ngraphicsForEvent[event_, boxHeight_, opacity_, y_] := Module[\n   {eventStartPoint = eventStart[event[[2]]],\n    eventDuration = event[[3]],\n    eventName = event[[4]], \n    eventLocation = event[[5]]},\n   {event[[6]],\n    Opacity[opacity],\n    Rectangle[{eventStartPoint, y}, {eventStartPoint + eventDuration, \n      y + boxHeight}, RoundingRadius -> 0.1],\n    Opacity[1],\n    Black,\n    Text[eventName,  {eventStartPoint + eventDuration /2, \n      y + (2 * boxHeight/3)}],\n    Text[eventLocation, {eventStartPoint + eventDuration /2, \n      y + (boxHeight/3)}]\n    }\n   ];\n\nManipulate[\n yH = Length[days];\n g = Graphics[{\n    Reap[\n      Do[{\n        (* background grid boxes - continue for an extra 2 hours *)\n        Sow[Table[{Lighter[Gray, .9], \n              Rectangle[{t, yH }, {t + 0.45, yH + boxheight}]}, \n             {t, Floor[firstEvent], lastEvent + 2, 0.5}]];\n        (* event boxes *)\n        Do[\n         Sow[\n          graphicsForEvent[event, boxheight, opacity, yH]], \n           {event, eventsForDay[day]}];\n          yH = yH - (boxheight + boxspacing )}, \n       {day, days}]][[2]]}, \n   BaseStyle -> {fontHeight, FontFamily -> \"Helvetica\", Bold}, \n   ImageSize -> 800, \n   Epilog -> \n    {\n     Table[{Gray, \n       Line[{{x, Length[days] + boxheight}, {x, Length[days] + 1}}], \n       Text[x, {x + 0.1, Length[days] + (boxheight * 1.15)}]}, \n       {x, Floor[firstEvent], Ceiling[lastEvent] + 2}]\n     }\n   ],\n {opacity, 0.5, 1},\n {boxheight, 0.5, 1.5, Appearance -> \"Labeled\"},\n {boxspacing, 0.1, 0.5, Appearance -> \"Labeled\"},\n {{fontHeight, 10}, 7, 12, Appearance -> \"Labeled\"},\n Button[\"Export as PDF\", Export[\"g.pdf\", g]],\n ContinuousAction -> False\n ]\n\n", "debugging - Wolfram Workbench - Mathematica Development Alternatives": "\nThere are indeed some open source alternatives, as other posters have suggested, but you will miss the unique facilities of WB to develop state of the art documentation. So if you want to develop some serious work in MMA, for yourself or others, you should seriously consider WB. Having said that, I use WB in a (probably) unconventional way. Within WB you can select which editor you want to use for the various file types. The default being: editing the .m file with the internal WB editor. Well, I instead chose to edit the .nb (package) file using the standard front end (linked to WB), this action will automatically update the .m file and then use all the standard WB facilities to integrate documentation. In this way you have the all the cool front-end editing tools plus all the cool WB documentation and debugging tools at your disposal.\nThis technique is described in more detail in my answer in Managing formatted usage messages in Wolfram Workbench\n", "plotting - Coloring Points in a List Plot": "\nOne way is to use Joined -> True and replace Line with Point afterwards:\nListPlot[RandomReal[1, {100, 2}], PlotStyle -> Thick, Joined -> True, \n  ColorFunction -> Function[{x, y}, Hue[(x + y)/2]]] /. Line[a__] :> Point[a]\n\n\n", "programming - How do I access the name of a list in a function?": "\nYou need to use HoldForm instead of Hold.\nClear@f\nSetAttributes[f, HoldAll]\nf[data_?VectorQ] := f[data, ToString@HoldForm@data]\nf[data_?VectorQ, name_?StringQ] := \"Save data as \" <> name\n\nWith this:\nf[ape]\n(* \"Save data as ape\" *)\n\nf[ape, \"bird\"]\n(* \"Save data as bird\" *)\n\nTo get Null or False for f[ape+bear], you can use StringFreeQ[name, \"+\"] to see if the input is of that form. Similarly, \"{\" for list arguments (no need to check for \"}\"). So the second definition for f above would be:\nf[data_?VectorQ, name_?StringQ] := \n    If[StringFreeQ[name, \"+\" | \"{\"], \"Save data as \" <> name, False]\n\nf[{1, 2, 3}]\n(* False *)\n\nf[ape + bear]\n(* False *)\n\n", "vrsion 8 - Customiz startup - Mathmatica Stack Exchang": "\nI find it easiest to create a Notebook with the features I want, and then open that Notebook to launch Mathematica.\nSave this code as a .nb file.  If you want Mathematica to also open \"Maximized\" rather than in the slightly-less-than-Maximized form it usually does, also create a shortcut to this Notebook and change the properties to Maximized, then use that.\nNotebook[{},\n  Saveable->False,\n  WindowSize->Scaled[1],\n  WindowMargins->{{Automatic, 0}, {Automatic, 0}},\n  Magnification->1.3,\n]\n\n", "Splitting a list at a particular position": "\nThis can be accomplished easily using Part ([[ ]]) and Span (;;), as follows:\ndata = {{x1, y1}, {x2, y2}, {x3, y3}, {x4, y4}, {xz, yz}};\ndata[[;; 3]]\ndata[[4 ;;]]\n\n(* ->\n{{x1, y1}, {x2, y2}, {x3, y3}}\n{{x4, y4}, {xz, yz}}\n*)\n\n", "export - CDF file posted in WordPress won't run": "\nI downloaded your notebook to my Download directory and opened it. The Download directory is unsafe. This is what it looked like:\n\nSo the reason why you get a grey box in your embedded CDF is that it is perceived as being unsafe.\nModify your code to this:\ncdf.embed('http://www.abstractmath.org/Mathematica/Elaborate Riemann \nExample.cdf', 427, 536,{fullscreen:'true'});\n\nand it will allow the enable dynamics button to appear. You can then switch on the dynamic content and the CDF will be treated as safe. This will get you to the next stage. Whether or not it will work after that will depend on what other things you have in your CDF -- i.e. as long as you have content that is allowed (no import/export etc.) it should work.\n", "notebooks - Is it possible to embed the Mathematica editor?": "\nHere is an idea - it's by no means perfect, but then again, the comments indicate that there won't be a perfect solution:\n\nIn your .NET application, create a web view (I don't know the details for this, but that would go beyond the scope of this forum anyway - I've done similar things in Cocoa on Mac, so you should be able to find analogous libraries for .NET)\nAs the URL for the web view, give the address of an HTML page with an embedded  Mathematica CDF notebook. This could mean simply using an <embed> tag, as described on Wolfram's web site. Here I'm talking about a HTML file stored locally with your .NET bundle.\nMake sure you use the non-free version of a CDF (the one you get via Save As...). It should allow you to edit inside of it. \nOf course the next question is how to exchange data. That depends on what data you need. But basically, you can try to do it with Export (or Import) from the CDF. This is where the \"deployed\" free CDF will not work, but the non-free ones (requiring Mathematica to be installed) will, at least according to what I'm seeing on my machine. Then the .NET application would have to be notified when an exported file is ready to be passed to it. The CDF could accomplish that on its own, or you could have the .NET application monitor a certain data file (used by the CDF) for changes. \n\nRegarding the data exchange problem, see also this CDF related post.\n", "How do I get VertexList to work directly on older graphs defined using rules?": "\nThe built-in function VertexList (or System`VertexList) requires that you input a graph object (i.e., something with the head Graph), whereas {a -> b} has the head List. So if you have a list of rules denoting the edges, then just wrap it in Graph for it to work. For example:\nVertexList[Graph[{a -> b}]]    \n(* {a, b} *)\n\n\nThe weird behaviour you see only when you load the GraphUtilities` package is because the package adds a definition to System`VertexList. Note that there is no such function as GraphUtilities`VertexList as you seem to assume in the question. \nIf you browse $InstallationDirectory/AddOns/Packages/GraphUtilities/GraphUtilities.m you'll find the following in the code (line numbers in comments):\n(* 449 *) u = Unprotect[{AdjacencyMatrix, EdgeList, VertexList}];   \n(* 464 *) VertexList[x_?InternalGraphQ, r___] := With[{res = Network`GraphPlot`VertexList[x, r]},\n(* 465 *)     res/;ListQ[res]];    \n(* 483 *) Protect @@ u;    \n(* 487 *) InternalGraphQ := Network`GraphPlot`GraphQ;\n\nEssentially, the modification made is to simply call Network`GraphPlot`VertexList if your input is a list.\nSo to get a consistent behaviour for VertexList, you simply need to add the definition above and you needn't load GraphUtilities` just to get this behaviour.\n", "graphics - Using Mathematica or WebMathematica to develop interactive, crowdsourced timeline visualizations": "\nSince it appears that you wish to use live input for your Timeline, webMathematica will be the best solution.  CDF cannot accept anything but input from what is in the file itself. \nDocumentation can be found here: http://www.wolfram.com/products/webmathematica/\nUser Guide is located here: http://reference.wolfram.com/mathematica/webMathematica/tutorial/Overview.html\n", "front end - Automating Esc [[ Esc formatting?": "\nSome approaches are discussed in this question on StackOverflow. Original references to these go to Szabolcs's webpage and a MathGroup posting by Mr.Wizard. \nTo summarize, you copy the file: $InstallationDirectory/SystemFiles/FrontEnd/TextResources/Macintosh/KeyEventTranslations.tr to $UserBaseDirectory/ (with the same directory tree) and add the following modifications after EventTranslations[{ in the file:\nItem[KeyEvent[\"[\", Modifiers -> {Control}],\n        FrontEndExecute[{\n            FrontEnd`NotebookWrite[FrontEnd`InputNotebook[],\n                \"\\[LeftDoubleBracket]\", After]\n        }]],\nItem[KeyEvent[\"]\", Modifiers -> {Control}],\n        FrontEndExecute[{\n            FrontEnd`NotebookWrite[FrontEnd`InputNotebook[],\n                \"\\[RightDoubleBracket]\", After]\n        }]], \nItem[KeyEvent[\"]\", Modifiers -> {Control, Command}],\n        FrontEndExecute[{\n            FrontEnd`NotebookWrite[FrontEnd`InputNotebook[],\n                \"\\[LeftDoubleBracket]\", After],\n            FrontEnd`NotebookWrite[FrontEnd`InputNotebook[],\n                \"\\[RightDoubleBracket]\", Before]\n        }]], \n\nThese provide the following shortcuts:\n\n\u301a using Ctrl+[\n\u301b using Ctrl+]\n\u301a\u301b using Ctrl+Cmd+]\n\nReplace Command with Alt for Windows/Linux and modify the paths above accordingly. \nYou can also try Andrew Moylan's suggestion, in the same post, but I haven't tried it.\n", "Is it possible to make a variable wrapped in Dynamic non-dynamic?": "\nYou have the option of only updating the Dynamic object when a specified set of symbols changes, but all symbol values will update when an update is triggered.  For example:\na = 1; b = 2;\nDynamic[{a, b}, TrackedSymbols :> {a}]\n\nThen evaluating b = 3; should not change the output.  Nevertheless, when you evaluate a = 4; you will get {4, 3} rather than {4, 2}.\nYou could use Dynamic only on the objects you want to be dynamic, e.g. {Dynamic[a], b}, but since this is an obvious solution there is presumably a problem with that.\n\nIncorporating my comment for persistence:\nIf I understand your problem you can force evaluation of the symbols outside of Dynamic, e.g. Dynamic[{a, #}]& @ b will use the fixed value of b, assuming that b has a value at the time of evaluating that expression.\n", "plotting - Mapping multiple parameters of a function to specific values": "\nThere are two main ways of accomplishing this, both have their merits, but Map may be easier to understand initially.  For instance, using (b/a)*((a/x)^(b+1)) I would do the following,\n(#[[2]]/#[[1]])(#[[1]]/x)^(#[[2]]+1)& /@ parameters\n\nwhere #[[1]] and #[[2]] are a and b, respectively. But, this makes it difficult to read, alternatively you can use With to improve the readability, as follows,\nWith[{a = #[[1]], b = #[[2]]}, (b/a)*((a/x)^(b+1))]& /@ parameters\n\nIt is longer, but it is more readable. I tend to use With in this way. The second method is to use Apply, as outlined by R.M. Here With can also be used,\nWith[{a = #1, b = #2}, (b/a)*((a/x)^(b+1))]& @@@ parameters\n\nbut it is less likely to be confusing when you come back to the code a month later.\n", "plotting - Change the height of a function being plotted": "\nMaybe AspectRatio -> Automatic which gives a 1:1 scaling of your function? \nPlot[Sin[x], {x, -12, 12}, AspectRatio -> Automatic]\n\n\nIf you take issue with the tight spaced tick-marks you can control that with Ticks:\nPlot[Sin[x], {x, -12, 12}, AspectRatio -> Automatic, Ticks -> {Automatic, {-1, 1}}]\n\n\n", "equation solving - Conditional expression": "\nIt's a bit unclear to me what you are asking, but if I interpret your question and your comment to Peter Breitfeld's answer correctly you want to solve the system\neqs = {g'[x] == 1, x^2 + x + c == 0}\n\nfor x and c. This can be done using Solve, e.g.\nSolve[eqs, {x, c}]\n\n(* output: {{x -> -(I/2), c -> 1/4 + I/2}, {x -> I/2, c -> 1/4 - I/2}} *)\n\n", "plotting - How can I plot Intensity values(Z) based on X and Y position. Data stored as 3 columns in CSV file": "\n(*Testing ...\nFirst we generate some points*)\npoints = Flatten[Table[{x, y, PDF[BinormalDistribution[{0, 0}, {1, 2}, .5], {x, y}]}, \n                       {x, -3, 3, .1}, {y, -3, 3, .1}], 1];\n(*\nNow we export it as a csv\n*)\nExport[\"c:\\\\points.csv\", points];\n\n(* The file looks like this:\n-3.,-3.,0.0010207851317789406\n-3.,-2.9,0.0010190852401957891\n-3.,-2.8,0.0010140025313558822\n-3.,-2.7,0.0010055876210847213\n-3.,-2.6,0.0009939239359647277\n...\n*)\n(* Finally import it and plot*)\n\nListDensityPlot[Import[\"c:\\\\points.csv\"]]\n\n\nEdit\nI had no problems at all downloading your sample file and plotting it:\n\n", "warning messages - What do I do when I get an \"Iterator does not have appropriate bounds\" error?": "\nThis is because the number you used is extremely large.  The number of iterations supported (in either Table or Do) seems to be $2^{31}-1$, i.e. the maximum size of a signed machine integer.  I believe this is also an upper bound on the size of an array in Mathematica.\nThis limitation is not unreasonable: the size of the Table you are trying to construct is too large to fit into memory anyway.  (Even if each element could be stored on a single byte, you'd be asking for 600 GB of memory.)\nIf you change the step size in the iterator to a large number, it will work:\nTable[600851475143/i, {i, 1, 600851475143, 100000000}]\n\n", "Combining lists - Mathmatica Stack Exchang": "\nYou need Join : \nlist = Join[list1, list2]\n\nsometimes you would choose :\nlistU = Union[list1, list2]\n\nThe latter doesn't include duplicates, as the first approach could, if some of elements in list1 and list2 were common.  \nEdit\nIt should be emphasized that since for small lists different approaches (pointed out in the other answers)  are elegant and quite satisfactory, however for big lists Join is much superior. We compare their efficiency in a few different cases : \n\nlA1 = RandomReal[1, {500000, 2}];\nlA2 = RandomReal[1, {500000, 2}];\n\nJoin[lA1, lA2]; // AbsoluteTiming // First\n## & @@@ {lA1, lA2}; // AbsoluteTiming // First\n{lA1, lA2}~Flatten~1; // AbsoluteTiming // First\n\n\n0.0210000\n0.8090000\n0.4620000\n\n\nlB1 = RandomReal[1, {2500000, 2}];\nlB2 = RandomReal[1, {1500000, 2}];\n\nJoin[lB1, lB2]; // AbsoluteTiming // First\n## & @@@ {lB1, lB2}; // AbsoluteTiming // First\n{lB1, lB2}~Flatten~1; // AbsoluteTiming // First\n\n\n0.0820000\n3.1500000\n1.9000000\n\n\nlC1 = RandomReal[1, {300000, 2}];\nlC2 = RandomReal[1, {900000, 2}];\n\nJoin[lC1, lC2]; // AbsoluteTiming // First\n## & @@@ {lC1, lC2}; // AbsoluteTiming // First\n{lC1, lC2}~Flatten~1; // AbsoluteTiming // First\n\n\n0.0220000\n0.9320000\n0.6640000\n\n\n\nWe can see that Join is roughly about 20-30 times faster than {list1, list2}~Flatten~1; and the latter is about 1.5-2 times faster than  ## & @@@. \n", "evaluation - Why doesn't Evaluate appear to work in this RegionPlot example with MatchQ?": "\nAs it turns out, the Evaluate is only evaluated immediately if it is top level in the argument, as the following code shows:\nClearAll[test];SetAttributes[test,HoldAll];test[x_]:=Hold[x]\ntest[Evaluate[1+1]]\n(*\n==> Hold[2]\n*)\ntest[f[Evaluate[1+1]]]\n(*\n==> Hold[f[Evaluate[1+1]]]\n*)\n\nSince in your code it is not top level, it is passed on together with the rest of the expression to RegionPlot. It is evaluated at a point where the variables already have numerical values. And this gives a complex result with imaginary part numerically zero, as the following proves:\nClearAll[f];SetAttributes[f,HoldAll];f[x_]:=Block[{a=1.,b=1.},x]\nf[Head[Evaluate[(a+I b)(a-I b)]]]\n(*\n==> Complex\n*)\nf[(a+I b)(a-I b)]\n(*\n==> 2.+0. I\n*)\n\nYou can get rid of the numerically zero imaginary part by using Chop:\nRegionPlot[MatchQ[Chop@Evaluate[Expand[(a+I b) (a-I b)]],_Real],{a,-2,2},{b,-2,2}]\n\nMore generally, to evaluate just part of an expression passed to a function with HoldAll attribute, you can use With:\nWith[{expr=Expand[(a+I b)(a-I b)]},\n     RegionPlot[MatchQ[expr,_Real],{a,-2,2},{b,-2,2}]]\n\n", "How to import all files of a folder at once?": "\nHave a look at FileNames:\nfiles=FileNames[\"*.pdf\", NotebookDirectory[]]\n\n\n{\"a.pdf\",\"b.pdf\",\"c.pdf\"}\n\nwill get you a list of all files in the directory where your notebook resides (of course you can choose any path) that match \"*.pdf\". You can then import the files like this:\nImport[#]&/@files\n\nor if you want certain files (look at the help for Part and Span):\nImport[#]&/@files[[-3;;-1]] (*last three files*)\nImport[#]&/@files[[1;;10]]  (*first ten files*)\n\nIf you want to use more arguments with Import like in your question then you can add them after the #, e.g. like this: Import[#,\"Text\"]&/@files. Otherwise you can save typing effort by choosing the the shorter version Import/@files (as pointed out by @AlbertRetey).\n", "dynamic - Detecting KeyUp events": "\nTo answer the second part of your question, you can use CurrentValue[\"EventKey\"] to get the current key that is being pressed. Modifying your example above:\nEventHandler[InputField[], \"KeyDown\" :> Print[CurrentValue[\"EventKey\"]]]\n\n", "evaluation - DSolve cannot solve for certain branches of the solution": "\nI can offer a small workaround. Your problem is equvalent to\nsol=FullSimplify[DSolve[{y'[x] == A0 + A1 y[x] + A2 y[x]^2, y[0] == y0}, y[x], x]]\n\n\nBy expanding and comparing with your variables:\ny'[x] == c d - (c + b d) y[x] + b y[x]^2\ny'[x] == A0 + A1 y[x] + A2 y[x]^2\n\nWe can get your formulation by the substitution:\nPowerExpand[FullSimplify[sol /. {A0 -> c d, A1 -> -(c + b d) , A2 -> b}]]\n\n\nYou can check now by direct substitution that this is indeed solution to your differential equation. \n==== Edit: answering \"why does not work?\" question ===\nI can try to guess the trouble of your formulation - I think it is in your choice of parameters. As Sjoerd C. de Vries in his answer noticed a general solution leads to\nDSolve[y'[x] == c*(d - y[x]) - b*(d - y[x])*y[x], y, x]\n\n\nNow Solve cannot \"solve\" your initial value problem:\n\nUsing Reduce you can arrive to a complex conditions set for the solution:\n\nWhich looks glorious ;-) but not simple. With a bit different formulation above (via A0, A1, A2) you do not run into this problem - Solve can handle easily your initial condition. This is rather a rare case - you were lucky to hit exactly problematic choice of parameters. This was some quick thinking - it's subject to verification. \n", "combinatorics - Combinatorica Graph from Edge List": "\nTwo examples:\n   Needs[\"Combinatorica`\"]\n   GraphicsRow[\n    {ShowGraph[ \n       g1 = Graph[{{{1, 2}}, {{2, 3}}, {{3, 1}}}, {{{1, 1}}, {{2, 1}}, {{3, 3}}}], \n        VertexNumber -> True], \n     ShowGraph[\n      g2 = Graph[\n            {{{1, 2}, EdgeLabel -> \"lbl1\"}, {{2, 3}, EdgeColor -> Green}, \n             {{3, 1}, EdgeLabel -> \"(3,1)\", EdgeDirection -> True, EdgeLabel -> True, \n                EdgeLabelPosition -> UpperLeft}}, \n           {{{1, 1}, VertexLabel -> True, VertexLabelColor -> Blue, \n   VertexLabelPosition -> LowerRight}, \n             {{2, 1}, VertexNumber -> True, VertexNumberColor -> Orange}, \n             {{3, 3}}}]\n    ]}]\n\nto get\n\nEDIT: Before loading Combinatorica you can transform the data using:\n   toCombGrphData[gr_] :=  gr // \n       Sequence @@ {EdgeList[#] /. UndirectedEdge[x__] :> {List[x]}, \n                    List /@ (AbsoluteOptions[#, VertexCoordinates][[2]])} &\n\nUpdate: For Version 9, we need to change the part specification above from [[2]] to [[1,2]] (thanks: @sam84).\nExample:\n  combgrpg = toCombGrphData[CompleteGraph[3]]\n\ngives the edge list and vertex coordinates needed as input for Combinatorica ``Graph`:\n  (*  Sequence[{{{1, 2}}, {{1, 3}}, {{2, 3}}}, {{{0.866025, -0.5}}, {{-0.866025, -0.5}}, {{-2.44929*10^-16, 1.}}}] *)\n\nThen, \n  Needs[\"Combinatorica`\"]\n\n  ShowGraph[Graph[combgrph]]\n\ngives\n\n", "combinatorics - When to use built-in Graph/GraphPlot vs. Combinatorica": "\nYou should always use the built-in Graph unless there is a specific reason to use Combinatorica instead.\nValid reasons to use Combinatorica could be:\n\nWorking with very old code, originally written for Combinatorica\nThe need for an algorithm that is neither available as a built-in, nor in any supported package. (There are still a few of these, e.g. ListGraphs).  Update: The IGraph/M package now provides replacements for many of such Combinatorica functions. As for ListGraphs, I suggest using the geng tool from the Nauty suite. It's output format, Graph6, can be read directly by Mathematica.\nYou are learning about graph theory and combinatorics from the Combinatorica Book\n\nProblems when using Combinatorica:\n\nNot supported anymore. There will be inconvenient conflicts with built-in symbols. See here for how to make this less painful.  Minor compatibility problems with recent Mathematica versions could happen.\nThe documentation is lacking.  The expectation is that you would buy the Combinatorica Book.\nPerformance is not great.  All functions are implemented purely in Mathematica.  (On the upside: you can read the source code, and the algorithms/implementations are explained in the Combinatorica Book.)  Because of this is not suitable for \"network science\" type applications.  It is meant for (mathematical) graph theory.\n\n\nHere's the guide on replacing Combinatorica with builtin functionality:\n\nhttp://reference.wolfram.com/language/Compatibility/tutorial/Combinatorica.html\n\nThe GraphUtilities` package contains the ToCombinatoricaGraph function which can convert a built-in Graph expression to a Combinatorica`Graph, in case you need some algorithms from Combinatorica.\n\nA for GraphPlot, it is purely for visualization, and almost all of its functionality is already built into Graph.\n", "list manipulation - Are there guidelines for avoiding the unpacking of a packed array?": "\nI will try to list some cases I can recall. The unpacking will happen when:\n\nThe result, or any intermediate step, is a ragged (irregular) array. For example\n Range /@ Range[4]\n\nTo avoid this, you can try to use regular structures, perhaps padding your arrays with zeros appropriately\nThe result (or any intermediate step) contains numbers of different types, such as a mix of integers and reals, or when some of the elements are not of numeric types at all (symbols, expressions)\nThis usually happens by mistake for 1D lists. For multi-dimensional lists, there are several ways out. One is to convert all numbers to a single type (e.g. Reals to Integers or vice versa), when that is feasible. One such example is here.\nAnother way out is to store an array parts separately. For example, you have two arrays of the same length, but different element types, which logically belong together (such as a result of Tally operation on reals, for example, as illustrated below). While our usual reaction would be to store it in transposed (and thus unpacked) form, one can also store them as {list1,list2}, which will be unpacked, but the parts list1 and list2 inside it will remain packed - just don't transpose it. One example of such treatment is here\nThis trick can be generalized to even ragged arrays. In the already cited post, I used it to convert an imported ragged array to a more space-efficient form, with elements being packed arrays, with \npacked =  Join @@Map[Developer`ToPackedArray, list]\n\nSome of the numbers don't fit into the numerical precision limits (for example, very big integers). This can be insidious, because this may be data-dependent and happen in the middle of a computation, and it may not be clear what is going on.\nHere, you can try to predict in advance whether or not this is likely, but other than that, there is little of what can be done, short of changing the algorithm.\nThe packed array is a part of an expression used with some rule-based code and subject to pattern-matching attempts. This will happen in cases when the match is not established before the pattern-matcher comes to the array. Here is an example:\nCases[f[g[Range[5]]], g[l_List] :> g[l^2], Infinity]\n\nDuring evaluation of In[14]:= Developer`FromPackedArray::unpack: \nUnpacking array in call to f. >>\n\n\n{g[{1, 4, 9, 16, 25}]}\n\nwhile this does not unpack:\nf[g[Range[5]]] /. g[l_List] :> g[l^2]\n\n\nf[g[{1, 4, 9, 16, 25}]]\n\nThis happened because Cases searches depth-first (and therefore reaches elements before heads, and then must unpack), while ReplaceAll replaces from expressions to sub-expressions. I  discussed this  extensively here.\nThis situation is typical for the pattern-matching - it will generally unpack. Note also that the pattern-matching goes inside held expressions, and will unpack even there:\nFreeQ[Hold[Evaluate@Range[10]], _Integer]\n\nThe only way I know to generally prevent it is to make sure that the pattern will either match or be rejected before the pattern-matcher comes to a given packed array. Note that there are certain exceptions, e.g. like this:\nMatchQ[Range[10], {__Integer}]\n\nIn which case, there is no unpacking. \nIn certain cases, you will not see the unpacking message, but the result returned by a function may be packed or unpacked, depending on its type. Here is an example:\ntst = RandomInteger[10,20]\n\n\n{6,9,9,4,6,4,0,9,7,1,3,2,2,0,7,2,1,0,7,5}\n\nntst = N@tst;\n\ntally = Tally[tst]\n\n\n{{6,2},{9,3},{4,2},{0,3},{7,3},{1,2},{3,1},{2,3},{5,1}}\n\nntally = Tally[ntst]\n\n\n{{6.,2},{9.,3},{4.,2},{0.,3},{7.,3},{1.,2},{3.,1},{2.,3},{5.,1}}\n\nDeveloper`PackedArrayQ/@{tally,ntally}\n\n\n{True,False}\n\nYou can see that the ntally was returned as an unpacked array, because it contains elements of different types, and there was no message to tell us about it, since indeed, nothing was unpacked - the result is a new array.\nAs I metnioned already, one way here is to separate frequencies and elements themselves, and store them separately packed.\nAs elaborated by @Mr.Wizard, Apply leads to unpacking. This also refers to Apply at level 1 (@@@). The way out here is just not to use Apply - chances are, that you can achieve your goal by other means, with packed lists.\nMap will unpack on short lists, with lengths smaller than \"SystemOptions\"->\"CompileOptions\"->\"MapCompileLength\". This may come as a surprise, since we are used to the fact that Map does not unpack. For example, this unpacks:\nMap[#^2 &, Range[10]] \n\nThe way out here would be to change the system options (\"MapCompileLength\") accordingly, to cover your case, or (perhaps even better), to manually pack the list with Developer`ToPackedArray after Map is finished. This often does not matter much for small lists, but sometimes it does.\nMap will also unpack for any function which it can not auto-compile:\nClearAll[f];\nf[x_] := x^2;\nMap[f, Range[1000]]\n\nwhile this does not unpack:\nMap[#^2 &, Range[1000]]\n\nThe solution here is to avoid using rule-based functions in such cases. Sometimes one can also, perhaps, go with some more exotic options, such as using something similar to a withGlobalFunctions macro from this answer (which expands certain rule-based functions at run-time).\nFunctions like Array and Table will produce unpacked arrays for functions or expressions which they can not auto-compile. They will not produce any warnings. For example:\nArray[f, {1000}] // Developer`PackedArrayQ\n\n\nFalse\n\nSimilar situation for other functions which have special compile options.\nIn all these cases, the same advice:  make your functions/expressions (auto)compilable, and / or change the system settings. Sometimes you can also manually pack the resulting list afterwords, as an alternative.\nWhile this reiterates on one of the previous points,  innocent-looking functions which combine packed arrays of different types will often unpack both:\nTranspose[{Range[10], N@Range[10]}]\n\nIn cases like this, often (also as mentioned already) you can live with such lists as they are, without transposing them. Then, the sub-lists will remain packed.\nWhen you use Save to save some symbol's definitions and Get to get them back, packed arrays will be generally unpacked during Save. This is not the case with DumpSave, which is highly recommended for that. Also, Compress does not unpack.\nImport and Export will often not preserve packed arrays. The situation is particularly grave with Import, since often it takes huge memory (and time) to import some data, which could be stored as a packed array, but is not recognized as such. \n\nThere are probably many more cases. I intend to add to this list once I recall some more, and invite others to contribute. One characteristic feature of unpacking is, however, general: whenever a final result or some intermediate expressions can not be represented as regular arrays (tensors) of the same basic type (Integer, Real or Complex), most of the time unpacking will happen. \n", "evaluation - Attaching persistent assumptions to symbol definition": "\nA slightly more flexible approach is to use assumptions as an option for u[..]:\nClearAll[u, assuming, asmptns];\nasmptns = And @@ \nFlatten@{(# > 0) & /@ {\u03bb, w, R, r, \u03b8}, (# \u2208 Reals) & /@ {\u03bb, w, R, r, \u03b8}, -\u03c0 < \u03b8 <= \u03c0};\nOptions[u] = {\"assuming\" -> asmptns};\nu[p_, m_, \u03bb_, w_, R_, \u03c8_, \u03c80_, r_, \u03b8_] := \nSqrt[(2 p!)/((1 + DiscreteDelta[0, m]) \u03c0 (m + p)!)] \nExp[I (2 p + m + 1) (\u03c8 - \u03c80)]/w ((Sqrt[2] r)/w)^ m \nLaguerreL[p, m, (2 r^2)/ w^2] \nExp[-I (2 \u03c0)/\u03bb r^2/ 2 (1/R - I \u03bb/(\u03c0 w^2)) + I m \u03b8];\nAbs[u[0, 0, \u03bb, w, R, 0, 0, r, \u03b8]]^2 // \nSimplify[#, OptionValue[u, \"assuming\"]] &\n\ngives\n\nand, re-simplify with modified assumptions\nSetOptions[u, \"assuming\" -> asmptns && (w == 2)];\nAbs[u[0, 0, \u03bb, w, R, 0, 0, r, \u03b8]]^2 // \nSimplify[#, OptionValue[u, \"assuming\"]] &\n\nto get\n\n", "graphs and networks - Visualize the output of Trace in a tree structure": "\nThis shows a graphical tree of the expression.\nHoldForm[{{{{x, 5}, 3 + 5, 8}, 8^2, 64}, {{x, 5}, 5 - 1, 4}, \n   Mod[64, 4], 0}] // TreeForm\n\n\n", "plotting - How does one set a logarithmic scale in a ContourPlot?": "\nOne possibility is to plot the contour plot with linear scales using ContourPlot and use ListLogLogPlot to transform this plot to one with logarithmic scales:\npl = Normal@\n  ContourPlot[\n   Sin[3 x] + Cos[3 y] == 1/2, {x, .01 Pi, 3 Pi}, {y, .01 Pi, 3 Pi}, \n   PlotPoints -> 30]\n\n\nListLogLogPlot[Cases[pl, Line[a_, b___] :> a, Infinity], \n Joined -> True, Frame -> True, PlotRange -> All, AspectRatio -> 1, \n PlotStyle -> ColorData[1][1]]\n\n\n", "probability or statistics - Doing a chi-square independence test in Mathematica": "\nWhen conducting a Chi-square test on a two-way table, you want to create and inspect the following.  (The calculations are made in a way that generalizes to any $r$ by $c$ table.)\n\nThe data:\ndata = {{11, 206}, {32, 1374}}; \nrc =  {{\"Row 1\", \"Row 2\"}, {\"Column 1\", \"Column 2\"}};\nTableForm[data, TableHeadings -> rc]\n\nThe fit.  This is obtained from the row and column sums:\nfit = Outer[Times, Plus @@@ data, Plus @@@ Transpose[data]] / Plus @@ Flatten[data];\nTableForm[fit // N, TableHeadings -> rc]\n\nThe residuals, equal to the differences between the data and the fit:\nresidual = data - fit;\nTableForm[residual // N, TableHeadings -> rc]\n\n(For a 2 by 2 table, all residuals will have equal size.)\nThe squared residuals, scaled by the reciprocal of the fit.  Where these are substantially larger than $1$ in absolute value, they signal bad fits:\n\u03c72array = residual^2 / fit;\nTableForm[\u03c72array // N, TableHeadings -> rc]\n\nIn this example, the entry for row 1, column 1 has a value of 4.8, suggesting a (slightly) bad fit there.  The other entries are all small, indicating decent to excellent fits.  (Appropriately signed square roots of these values are normally considered \"residuals\", but it's not really necessary to do this extra computation.)\nThe sum of these scaled squared residuals.  This is the chi-squared statistic, $\\chi^2$.  It is an overall measure of how well the fit matches the data.\n\u03c72 = Plus @@ Flatten[\u03c72array];\n\u03c72 // N\n\nHere, it equals 5.68632.\nThe p-value.  This assesses the chance that a chi-squared random variable could attain a value of $\\chi^2$ or larger.  As a preliminary step, we need to compute the \"degrees of freedom\" (df) of the statistic.\ndf = Length[Flatten[data] ] - Length[data] - Length[Transpose[data]] + 1;\n1 - CDF[ChiSquareDistribution[df], \u03c72] // N\n\nThis calculation returns 0.0170977, or about 1.7%, based on one degree of freedom.\n\nIn a full report of the test, all these results would be presented.  In an  abbreviated report, only df, $\\chi^2$, and the p-value would be given (as computed in steps 5 and 6).\nFinally, to conduct the test at the 5% level, one would remark that the p-value is less than 5%.  Because you have generated these intermediate results and inspected the residual tables (steps 3 and 4), you might remark that this low p-value appears to be due solely to a lack of fit in the first row and column.  You might urge some caution in the interpretation because (looking at the data and fit tables, steps 1 and 2) you notice the counts in this cell (11 and 5.75) are small.  In fact, you might elect to confirm your result with a permutation test or, when applicable, Fisher's Exact Test.\nAs a double-check--because these calculations have been coded from scratch--you might compare the results to a calculation with other software, such as R; e.g.,\nchisq.test(matrix(c(11,32,206,1374), nrow=2), correct=FALSE)\n\nThis produces the abbreviated summary:\n\nX-squared = 5.6863, df = 1, p-value = 0.01710\n\nBy saving the result of this calculation you can inspect the auxiliary material and compare it with the Mathematica calculations.  Unlike R (or almost any other statistical program), Mathematica will present exact results: simply remove the \"// N\" bits from the code.  (It can be surprising how many people have gotten into trouble by over-rounding intermediate results in their statistical calculations; using exact arithmetic avoids that problem.)\n", "programming - Question about modifying a Slider2D control": "\nSomething like the following?\n Manipulate[If[(iOld != i || jOld != j), lata[[1]] = i; lata[[2]] = j];\n i = lata[[1]];\n j = lata[[2]];\n iOld = i;\n jOld = j;\n lata, \n Column[{Row[{Opener[Dynamic[zz]], \" lata\"}], \n PaneSelector[{True -> \n Row[{Column[{Row[\n  {Control[{{i, 0, \"\"}, {-5, -5}, {5, 5}, {0.25, 0.25}, Animator[#, {-5, 5, 0.25}, \n     AnimationRunning -> False, AnimationRate -> 4/5, Appearance -> Small, \n     AppearanceElements -> {\"ResetButton\",\"PlayPauseButton\", \"StepLeftButton\", \n              \"StepRightButton\", \"FasterSlowerButtons\", \"DirectionButton\"}] &}], \n   Spacer[5], \n   Control[{{i, 0, \"\"}, {-5, -5}, {5, 5}, {0.25, 0.25}, \n          InputField[#, FieldSize -> {4, 1}] &}]}] , \n   Row[{Control[{{j, 0, \"\"}, {-5, -5}, {5, 5}, {0.25, 0.25}, \n        Animator[#, {-5, 5, 0.25}, AnimationRunning -> False, \n        AnimationRate -> 4/5, Appearance -> Small, \n        AppearanceElements -> {\"ResetButton\",\"PlayPauseButton\", \"StepLeftButton\", \n           \"StepRightButton\", \"FasterSlowerButtons\",\"DirectionButton\"}] &}], \n   Spacer[5],             \n   Control[{{j, 0, \"\"}, {-5, -5}, {5, 5}, {0.25, 0.25}, \n          InputField[#, FieldSize -> {4, 1}] &}]}]}], Spacer[15], \n   Control[{{lata, lata, \"\"}, {-5, -5}, {5, 5}, {0.25, 0.25}}]}],\n  False -> \n  Control[{{lata, lata, \"\"}, {-5, -5}, {5, 5}, {0.25, 0.25}}]}, \n  Dynamic[zz]]}], \n  Initialization -> {lata = {0, 0}, i = lata[[1]], j = lata[[2]], jOld = j, iOld = i}]\n\nscreenshots:\n\n\n", "plotting - About number truncation of ticks display in ListPlot": "\nYou can define your own function for FrameTicks :\nticks[min_, max_] := {#, NumberForm[#, 20]} & /@ \n  N[FindDivisions[{min, max}, 5]]\n\nListPlot[{RandomReal[#] + 10^4, \n    RandomReal[#]} & /@ (Range[100] 10^-10), Frame -> True, \n FrameTicks -> {{Automatic, None}, {ticks, None}}]\n\n\nJust choose your own preferred presentation format of the given values...\nticks[min_, max_] := {#, Grid[{{min}, {\"+\"}, {# - min}}]} & /@ \n  N[FindDivisions[{min, max}, 5]]\n\nListPlot[{RandomReal[#] + 10^4, \n    RandomReal[#]} & /@ (Range[100] 10^-10), Frame -> True, \n FrameTicks -> {{Automatic, None}, {ticks, None}},FrameStyle->Medium]\n\n\n", "output formatting - Rationalize the Denominator by Default": "\nIn the old days, when \"making the Numerator rational\" was often wanted, I came up with the following set of rules:\nEvaluiereAt[pos:(_Integer|{__Integer}),f_:Identity][expr_]:=\n  ReplacePart[expr,pos->Extract[expr,pos,f]];\nEvaluiereAt[pos:{{__Integer}..},f_:Identity][expr_] :=\n  Fold[ReplacePart[#1, #2 -> Extract[#1, #2, f]] &, expr, Reverse[Sort[pos]]];\n\n$pinkHoldColor = ColorData[\"HTML\"][\"HotPink\"];\npinkHold[x_] := Style[Tooltip[HoldForm[x], \"held\"], $pinkHoldColor];\n\nAttributes[rootRational] = {Listable};\nrootRational[expr_] := \n  Module[{zw, res, pos}, zw = expr /. Sqrt[a_] :> Sqrt[Together[a]];\n   res = zw /. Sqrt[a_/b_] :> Sqrt[Expand[a b]]/b;\n   res = res /. {a_./(b_ + d_. Sqrt[c_]) -> (a (b - d Sqrt[c]))/(b^2 -\n           d^2 c), \n      a_./(b_ - d_. Sqrt[c_]) -> (a (b + d Sqrt[c]))/(b^2 - d^2 c)};\n   res = res /. Sqrt[Rational[a_, b_]] :> pinkHold[Sqrt[a b]]/b;\n   res = res /. (a_/Sqrt[b_]) :> a pinkHold[Sqrt[b]]/b;\n   res = res /. \n     b_. Power[a_, Rational[-1, 2]] :> b pinkHold[Sqrt[a]]/a;\n   pos = Position[res, _?NumberQ];\n   If[Flatten[pos] =!= {}, res = EvaluiereAt[pos][res]];\n   res];\n\nAttributes[pinkUnhold] = {Listable};\npinkUnhold[expr_] := \n  ReleaseHold[expr /. Style[Tooltip[a_, __], __] -> a];\n\nthe function rootRational tries to achieve this. To show, that something is in HoldForm, I marked it with a pink color. To ReleaseHold and take away the color an tooltip there is the function pinkUnhold.\nExamples:\nw = Sqrt[6]/9 \n% // rootRational \n% // pinkUnhold Clear[a]; \nw = Sqrt[(1 + a)/(1 - a)] // rootRational \n% // FullSimplify \nrootRational[Sqrt[b]/b] \nrootRational[1/Sqrt[b]]\n\n\n", "list manipulation - Smooth/histogram a 2D set": "\nLet's start with your sample data:\nIn[1]:= data = {{0.1, 1.0}, {0.2, 2.0}, {0.3, 3.0}, {0.35, 3.5}, {0.4, 4.0}, {0.5, 5.0}};\n\nFirst we can use GatherBy to group entries by bin:\nIn[2]:= GatherBy[data, Ceiling[First[#], 0.2] &]\n\nOut[2]= {{{0.1, 1.}, {0.2, 2.}}, {{0.3, 3.}, {0.35, 3.5}, {0.4, 4.}}, {{0.5, 5.}}}\n\nThen select the second element of each pair (Last) and calculate the means:\nIn[3]:= Mean[Last /@ #] & /@ %\n\nOut[3]= {1.5, 3.5, 5.}\n\n", "plotting - Background Shading in Histogram3D": "\nIs this what you mean? I put different colors in the background, to make clear what I added:\nShow[Histogram3D[dataHistogramSet, FaceGrids -> {Bottom, Front, Left},\n   ChartStyle -> \"GrayTones\", ViewPoint -> {2.78, 1.3, 1.43}, \n  PlotLabel -> \"Histogram of Dataset 1\"],\n Graphics3D[\n  Translate[{EdgeForm[],\n    {Red, \n     Polygon[{{1995, 0, 0}, {1995, 0, 100}, {2002, 0, 100}, {2002, 0, \n        0}, {2002, 300, 0}, {1995, 300, 0}}]}, {Orange, \n     Polygon[{{2002, 0, 0}, {2002, 0, 100}, {2005, 0, 100}, {2005, 0, \n        0}, {2005, 300, 0}, {2002, 300, 0}}]}, {Yellow, \n     Polygon[{{2005, 0, 0}, {2005, 0, 100}, {2010, 0, 100}, {2010, 0, \n        0}, {2010, 300, 0}, {2005, 300, 0}}]}}, {0, -3, -3}]]\n ]\n\n!\n", "How to draw a directed graph with arrows showing vertically from bottom to top": "\nAs mentioned by others, you could use LayeredGraphPlot for this. However, LayeredGraphPlot orders vertices in such a way that directed edges are generally pointing down. To flip the graph over, you could reverse the edges and supply a custom EdgeRenderingFunction, e.g.\nedges = {2 -> 1, 3 -> 1, 4 -> 1, 5 -> 2, 6 -> 1, 7 -> 3, 8 -> 7, 9 -> 8};\nLayeredGraphPlot[Reverse /@ edges, DirectedEdges -> True,\n EdgeRenderingFunction -> (Arrow[Reverse[#1], .05] &)]\n\n\n", "dynamic - Manipulating a continuous stream of sounds": "\nThe key to getting separate sounds to join smoothly is to make the waveform continuous. For example this sound contains an integer number of cycles, and we can emit a sequence of these with no audible gaps:\ntestsound=Sound[SampledSoundFunction[Sin[0.4Pi #]&,1000,8000]];\nDo[EmitSound[testsound],{5}]\n\nContrast with this next one, where I have adjusted the frequency slightly:\ntestsound=Sound[SampledSoundFunction[Sin[0.401Pi #]&,1000,8000]];\nDo[EmitSound[testsound],{5}]\n\nThere is also a timing problem to be dealt with. As noted in the question, if the sounds are too short there will be gaps between them. If the sounds are too long they will queue up and lag behind the Locator motion. The update rate of the Locator position is not uniform, so we can't simply pick a single \"perfect\" duration for the sounds. We could use \"Preemptive\" as a second argument to EmitSound to force the sound to play right now, but this will scupper the attempt to make the waveform continuous.\nMy approach is to measure the time between updates to the Locator position, and use this as the duration of the sound to play. The idea is that this should keep the time elapsed moving the Locator roughly in step with the cumulative duration of sounds played. The sound duration is however clipped to prevent any overly long or short sounds.\nSo here is my attempt at the problem. I have defined these functions:\nsoundfunc takes a frequency and a number of samples, and returns a Sound with the frequency tweaked to ensure an integer number of cycles over the duration of the sound.\nkillsound immediately stops any currently playing sound. This is used to stop sound output sharply when the Locator is released.\nvaltofreq simply converts a function value in the range -1 to +1 to a frequency.\nsoundfunc[f_,n_]:=Sound[SampledSoundFunction[Sin[2Pi  Round[f,8000/n]#/8000.]&,n,8000]]\nkillsound := EmitSound[SampledSoundList[{0.}, 8000], \"Preemptive\"]\nvaltofreq[val_] := 500 (1.3 + val)\n\npt = {0, 0};(*initialize locator*)\nfunc = Sin[Pi*2*#1*#2] &;(*arbitrary surface*)\n\nLocatorPane[Dynamic[pt,{\n(t2=t1=AbsoluteTime[];f=valtofreq[func@@#])&,\n(pt=Clip@#;f=valtofreq[func@@#];\nt2=AbsoluteTime[];deltat=t2-t1;t1=t2;\nEmitSound[soundfunc[f,Round[8000Clip[deltat,{0.001,0.2}]]]];)&,\n(killsound)&}],\nContourPlot[func[x,y],{x,-1,1},{y,-1,1},ImageSize->200]]\n\nIt's not perfect, but it works reasonably well if the Locator is moved slowly. There is still a definite sense of separate notes strung together, rather than the continuously varying pitch the question asks for. It should be possible to make it smoother by varying the frequency gradually from the beginning to the end of each Sound, but it wasn't immediately obvious to me how to do that while maintaining the waveform continuity.\n", "partitions - Subsets of a list": "\nI would use:\ndata = {1, 20, 3, 40};\n\nJoin @@ Permutations /@ IntegerPartitions[Length@data];\n\nresults = Internal`PartitionRagged[data, #] & /@ %\n\n\n{{4}, {3, 1}, {1, 3}, {2, 2}, {2, 1, 1}, {1, 2, 1}, {1, 1, 2}, {1, 1, 1, 1}}\n\n{{{1, 20, 3, 40}},\n {{1, 20, 3}, {40}},\n {{1}, {20, 3, 40}},\n {{1, 20}, {3, 40}},\n {{1, 20}, {3}, {40}},\n {{1}, {20, 3}, {40}},\n {{1}, {20}, {3, 40}},\n {{1}, {20}, {3}, {40}}}\n\n\n\nIntegerPartitions is used get the ways in which you can split a list, to be used with the function above.  Permutations is used to get all orders of these.  By the way, you could use the function Compositions from the Combinatorica package in place of both of these if you want to include zeros.\nThese specifications are fed to Internal`PartitionRagged which splits a list into given lengths, e.g. [{1,2,3,4,5}, {2,1,2}] -> {{1,2}, {3}, {4,5}}.  Users of Mathematica versions prior to 8 can use my dynamicPartition function in its place.\n", "How to visualize large graphs with directed edge bundling?": "\nCommunityGraphPlot has this feature implemented internally:\ng = ExampleData[{\"NetworkGraph\", \"DolphinSocialNetwork\"}];\nCommunityGraphPlot[g]\n\n\nThe information about bundling is calculated by CommunityGraphPlot (i.e. it is not supplied with the example data), though unfortunately there are no documented options available to finetune the bundling (but see below), only the region (CommunityRegionStyle) and boundary styles (CommunityBoundaryStyle). \nThough one can extract from the community graph the BezierCurve that generates the bundled edges (with low opacity EdgeStyle by default), it will contain references to vertex coordinates like DynamicLocation[\"VertexID$1\", Automatic, Center]. Unfortunate again that due to the dynamical nature of a CommunityGraphPlot, ordinary Graph functions like VertexList or PropertyValue[{g, 1}, VertexCoordinates] will fail, so there is no easy way to extract the real vertex coordinates which otherwise could have been matched with the various \"VertexID$1\" references.\nThe method to find communities can be customized with FindGraphCommunities.\nUndocumented functionality\nYou have to dig deep to ultimately find any bundling-related code in GraphComputation`GraphCommunitiesPlotDump`communitiesPlot. It accepts the following internal options (above default ones):\n \"EdgeLayout\" -> Automatic\n \"CommunityEdgeWeight\" -> Automatic\n \"CommunityRegionFunction\" -> Automatic\n\nIf \"EdgeLayout\" has the value \"DividedEdgeBundling\", the following suboptions are available to control the bundling process (with their defaults):\n\"CoulombConstant\" -> 4.5\n\"VelocityDamping\" -> 1\n\"SmoothEdge\" -> True\n\nExamining its internal usage and a bit of experimentation yielded the following results:\nSetProperty[g, {GraphLayout -> {\"EdgeLayout\" -> {\"DividedEdgeBundling\",\n      \"CoulombConstant\" -> 5, \"VelocityDamping\" -> .6, \"SmoothEdge\" -> True},\n    \"VertexLayout\" -> {Automatic}}}]\n\n\nSetProperty[g, {GraphLayout -> {\"EdgeLayout\" -> {\"DividedEdgeBundling\", \n      \"CoulombConstant\" -> 100, \"VelocityDamping\" -> .5, \"SmoothEdge\" -> False}}}]\n\n\nSetProperty[g, {\n  GraphLayout -> {\"EdgeLayout\" -> {\"DividedEdgeBundling\", \n      \"CoulombConstant\" -> 44, \"VelocityDamping\" -> .87, \"SmoothEdge\" -> False}}}]\n\n\nSetProperty[g, {\n  GraphLayout -> {\"EdgeLayout\" -> {\"DividedEdgeBundling\", \n      \"CoulombConstant\" -> 100, \"VelocityDamping\" -> .5, \"SmoothEdge\" -> False},\n    \"VertexLayout\" -> {\"SpringEmbedding\", \"EdgeWeighted\" -> True,\n       \"Multilevel\" -> False}}}]\n\n\nFor larger graphs it really helps to use transparent edges:\nsm = SocialMediaData[\"Facebook\", \"FriendNetwork\"];\n{\n SetProperty[sm, {ImageSize -> 300, GraphLayout -> {\"EdgeLayout\" -> None}}],\n SetProperty[sm,\n  {ImageSize -> 300, EdgeStyle -> Opacity@.1,\n   GraphLayout -> {\"EdgeLayout\" -> {\"DividedEdgeBundling\", \n       \"CoulombConstant\" -> 500, \"VelocityDamping\" -> .5, \"SmoothEdge\" -> False}}}]\n }\n\n\n", "graphics - How to change ColorFunction after plotting": "\nOne solution that works quite well and is fast (interpolation would've been slow), is to use Nearest on a fine grid. The advantage is that you don't have to re-evaluate your plot, or modify it prior to generating it like Yu-Sung's answer does. Here's an example:\n(* Create a rule list of original RGB colors to value and a nearest function *)\nlist = List @@ ColorData[\"LakeColors\"][#] -> # & /@ Range[0, 1, 0.001];\nnf = Nearest[list];\n\n(* function to convert original RGB triplets to those of chosen color data *)\nconvert[s_String][x_List] := List @@ ColorData[s][First@nf[x]]\n\n(* Apply to plot *)\nplot /. Rule[VertexColors, x_List] :> Rule[VertexColors, (convert[\"Temperature\"] /@ x)]\n\n\n\n", "Solving complx quations - Mathmatica Stack Exchang": "\nUnless I'm mistaken, the reason why this doesn't work is that Solve and Reduce do not have an Assumptions option, so Assuming has no effect on them.\nUsing Reduce\nWe can tell Reduce that these variables are all real-valued like this:\nReduce[a + I b == zr + I zi && Element[{a, b, zr, zi}, Reals], zi]\n\n(* ==> (zr | b) \\[Element] Reals && a == zr && zi == b *)\n\nUsing Solve\nThere's a note in the documentation:\n\nSolve[expr && vars \\[Element] Reals, vars, Complexes] solves for real values\n  of variables, but function values are allowed to be complex.\n\nHowever, Solve[a + I b == zr + I zi && (a | b | zr | zi) \\[Element] Reals, zi, Complexes] returns {} which means that there are no solutions.  Why does this happen?  zi has a real value only if a == zr, so in general (for arbitrary a, zr values) there is no real solution for zi.  The main difference between Reduce and Solve is that Reduce will try to generate those specific conditions under which a solution exists while Solve does not.\n\nWhy doesn't Assuming work?\nGenerally, Assuming works by setting $Assumptions temporarily:\nIn[1]:= $Assumptions\nOut[1]= True\n\nIn[2]:= Assuming[x > 0, $Assumptions]\nOut[2]= x > 0\n\nIt will have an effect on functions that have an Assumptions option.  These functions have Assumptions -> $Assumptions as a default setting:\nIn[3]:= Options[Integrate]\nOut[3]= {Assumptions :> $Assumptions, GenerateConditions -> Automatic,\n  PrincipalValue -> False}\n\nIn[4]:= Options[Simplify]\nOut[4]= {Assumptions :> $Assumptions, ComplexityFunction -> Automatic,\n  ExcludedForms -> {}, TimeConstraint -> 300, \n TransformationFunctions -> Automatic, Trig -> True}\n\nIt will not have an effect on functions that do not have this option:\nIn[5]:= Options[Solve]\nOut[5]= {Cubics -> True, GeneratedParameters -> C, \n InverseFunctions -> Automatic, MaxExtraConditions -> 0, \n Method -> Automatic, Modulus -> 0, Quartics -> True, \n VerifySolutions -> Automatic, WorkingPrecision -> \\[Infinity]}\n\nIn[6]:= Options[Reduce]\nOut[6]= {Backsubstitution -> False, Cubics -> False, \n GeneratedParameters -> C, Method -> Automatic, Modulus -> 0, \n Quartics -> False, WorkingPrecision -> \\[Infinity]}\n\nI could imagine though that Solve or Reduce make internal use of some function that does take $Assumptions into account.  I do not know if this is the case or not, but I doubt that generally $Assumptions would have an effect on them.\n", "numerical integration - How to use NDSolve to track a deviation from equilibrium?": "\nNow, you did put some pressure on me by giving a working example :-). This is most probably not a solution yet, but some thoughts after trying to run your code:\nProblem Size: that's another point in making your question more friendly to people trying to answer it: make the problem size as small as possible, it's just no fun to wait minutes for a result just to see it's structure. I reduced your example from 141 equations to 11, which will of course be much simpler to handle. In this case the 141 equations are solved very fast with machine precision, but it took too long to run these with the high precision that you define, so I stopped it and reduced the problem size. Trying new things as your event handler to detect deviation from equilibrum is also something I'd strongly recommend to first try with a problem as simple as possible. Only when you have that working alright you should run your real problem.\nWorkingPrecision: since you give it equations with lower precision than what you want NDSolve to use it complains (thats the NDSolve::precw warning). What it basically does (I think) is giving that warning and ignore it. If you want it to really use that precision, you'll need to give your input in at least that precision. What I tried was making the input exact with Rationalize[...,0] which indeed will not give the NDSolve::precw warning anymore. I don't think you'll actually need it, at least for my reduced example the (trivial) result doesn't change when using MachinePrecision but of course will be much faster...\nReal Number: the warning about something not being a real number is issued because the right hand side of the initial conditions ci is not set to a number but to a list with one number, which you can see when looking e.g. at ci[[3]]. It's easy enough to change that by adding another 1 to Part. With these changes the code will work in Version 8, but not in Version 7. I think this is probably because of an error which will replace the integers in y[n][t] to real numbers, so in the event checks there appears something like y[20.][0.0144971] which doesn't work. One way to circumvent that is to replace those integers with strings, like I show in the code below. For other readers I'd like to emphasize that this is only necessary for Version 7 (and maybe earlier versions as well). \nVersion Information: I admit that in this case this was absolutely not to be expected, but part of your problem seem to be a bug in version 7. Noone trying with version 8 could have ever see that error, so this information was essential to have a chance to help you, so if not using the most recent version it probably is always useful to include that information as you did.\nRuleDelayed for event specification: You will notice that I have used RuleDelayed (shortcut: :>) instead of Rule (shortcut ->) to define the values for the option \"EventAction\" as well as \"Event\". This is probably only necessary for \"EventAction\" always, but usualy is also a good idea for \"Event\": you want these expression only to be evaluated at every single step and the RuleDelayed will ensure that this is so.\nAltogether the following will work with no errors (but doesn't stop because the problem doesn't actually show the behavior that the event tries to tests for):\npsi = Pi;\nDo[w[i] = 1/2, {i, 1, 11}];\nfext = 1;\nk = 35529/1000.;\nci = Table[y[i][0] == RandomReal[{-Pi, Pi}], {i, 1, 11}];\nAppendTo[ci, y[0][0] == y[11][0] - psi];\n\nlckm = {y[0]'[t] == fext, y[11]'[t] == fext, \n   Table[y[i]'[t] == \n     w[i] + k (Sin[y[i + 1][t] - y[i][t]] + \n         Sin[y[i - 1][t] - y[i][t]]), {i, 1, 10}]};\n\nsol = NDSolve[{lckm, ci}, Table[y[i], {i, 0, 11}], {t, 0, 800}];\n\nv1 = y[10][t] /. sol[[1]];\nv2 = y[11][t] /. sol[[1]];\nnorm = Sin[v1 - v2] /. t -> 800;\nk = 35526/1000.;\nci = Table[\n   y[i][0] == Part[{y[i][t] /. sol} /. t -> 800, 1, 1], {i, 1, 11}];\nAppendTo[ci, y[0][0] == y[11][0] - psi];\n\nlckm = {\n   y[0]'[t] == fext,\n   y[11]'[t] == fext, \n   Table[y[i]'[t] == \n     w[i] + k (Sin[y[i + 1][t] - y[i][t]] + \n         Sin[y[i - 1][t] - y[i][t]]), {i, 1, 10}]\n   };\n\nsol = NDSolve[Evaluate[{lckm, ci} /. y[n_] :> y[ToString[n]]], \n   Table[y[ToString[i]], {i, 0, 11}], {t, 0.0, 800}, \n   Method -> {\"EventLocator\", \n     \"Event\" :> (Abs[Sin[y[\"10\"][t] - y[\"11\"][t]]/norm - 1] - 1/10\n       ), \"EventAction\" :> Print[\"t:\", t]}, MaxSteps -> Infinity];\n\nPlot[Evaluate[Table[y[ToString[k]][t] /. sol, {k, 1, 11}]], {t, 0, 800}]\n\nIf your real problem needs it and you want NDSolve to really use WorkingPrecision->30, then you could run the NDSolve as here:\nsol = NDSolve[Evaluate[Rationalize[{lckm, ci}, 0]], \n   Table[y[i], {i, 0, 11}], {t, 0, 800},\n   WorkingPrecision -> 30, AccuracyGoal -> 15, PrecisionGoal -> 15, \n   MaxSteps -> Infinity\n   ];\n\nwhich will not issue any warnings and should really use the higher precision, but of course will take a lot longer than the standard settings (I think it will switch to use software floating point arithmetic for these settings, which is a lot more expensive...).\n\nPS: (you'll note that I coudn't resist to get rid of the For-loop, for reasons I gave in Are there any cases when For[] loops are reasonable?).\n", "variable definitions - Define a mathematical set": "\nPerhaps the following\nSetAttributes[set, Orderless];\n\nset[elms___] := \n With[{nodups = DeleteDuplicates@{elms}}, \n  set @@ nodups /; {elms} =!= nodups]\n\nSo set[a, b, c, d] would represent a set with elements a, b, c, and d.\nTo compare, just use == or ===. It automatically sorts and removes duplicates\ns1 = set[a, b, c, d];\ns2 = set[\"o\", b, a, aa, dd];\n\ns1 == set[b, b, d, a, c]\n\n\nTrue\n\nIt seems like built-ins Intersection, Union, and Complement work also with any head so you could use them naturally with set (However, they probably sort first, not taking advantage of the fact that your sets are already sorted.)\nIntersection[s1, s2]\n\n\nset[a, b]\n\nUnion[s1, s2]\n\n\nset[\"o\", a, aa, b, c, d, dd]\n\nComplement[set[a, b, c, d, e], s1]\n\n\nset[e]\n\nIf you ever need to convert to lists, just do List@@s1\n", "list manipulation - Point belonging to a Disk in a Cartesian Coordinate System": "\nEdit: Version 1 using Nearest\nI think Nearest can be put to good use here anyway. This one uses the idea (inspired by @DanielLichtblau) that you can carry useful information in a NearestFunction that is not relevant for the actual distance by scaling those values with a small factor, finding the nearest points/vectors and the re-scaling the stowaways. While this is not exact, it can be very useful if you want to use \"mixed\" vectors and still get the performance gained by repeated use of a NearestFunction (here together with timing information). \nSlight reformatting (scaling time with small factor):\nfixations2 = Flatten[#]*{1, 1, 2^-20} & /@ fixations;\n\nadding a 0 for compatibility...\nDisks2 = Insert[#, 0, 3] & /@ Disks;\n\nhere we go (NearestFunction nf is called with additional arguments {n, radius}):\nnf = Nearest[fixations2];\n\nhits = Map[#*{1, 1, 2^20} &, \n   nf[#[[1 ;; 3]], {Infinity, #[[-1]]}] & /@ Disks2, {2}][[All, All, \n   3 ]]\n\n\n{{155}, {}, {}, {145}, {}, {160}, {}, {377, 130}}\n\nTotal /@ hits\n\n\n{155, 0, 0, 145, 0, 160, 0, 507}\n\nThis should scale pretty well with larger samples.\nVersion 2 (straightforward)\nAnother, very simple version with a bit of pattern mumbo-jumbo for versatile use with different input types (will become slow for large sample numbers):\nfixations = {{{20.3899, 14.8931}, 238}, {{27.0063, 18.8899}, \n    428}, {{25.8113, 24.8679}, 377}, {{24.2579, 22.022}, \n    106}, {{25.3208, 24.022}, 130}, {{21.739, 12.1792}, \n    175}, {{29.2673, 8.88994}, 295}, {{30.3868, 17.6572}, \n    160}, {{31.217, 22.6761}, 145}, {{22.9686, 20.6918}, \n    155}, {{19.6321, 20.2704}, 145}};\n\nDisks = {{22.8176, 19.9696, 0.974938}, {29.5314, 10.7197, \n    0.974938}, {17.5112, 19.7207, 0.974938}, {30.8997, 23.2454, \n    0.974938}, {28.0588, 6.09759, 0.974938}, {30.8524, 17.0661, \n    1.53205}, {21.0393, 10.7137, 1.53205}, {25.451, 25.1336, 1.53205}};\n\ntimeindisk[{{x_?NumericQ, y_?NumericQ}, time_}, {u_?NumericQ, \n   v_?NumericQ, r_?NumericQ}] := \n If[Norm[{x, y} - {u, v}] <= r, time, 0]\n\ntimeindisk[#, Disks[[1]]] & /@ fixations\n\n\n{0, 0, 0, 0, 0, 0, 0, 0, 0, 155, 0}\n\nThreaded over fixes:\ntimeindisk[fixes_List, {u_?NumericQ, v_?NumericQ, r_?NumericQ}] := \n timeindisk[#, {u, v, r}] & /@ fixes\n\ntimeindisk[fixations, Disks[[1]]]\n\n\n{0, 0, 0, 0, 0, 0, 0, 0, 0, 155, 0}\n\nThreaded over fixes and disks:\ntimeindisk[fixes_List, disks_List] := timeindisk[fixes, #] & /@ disks\n\ntimes = timeindisk[fixations, Disks]\n\n\n{{0, 0, 0, 0, 0, 0, 0, 0, 0, 155, 0}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n        0}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, {0, 0, 0, 0, 0, 0, 0, 0, 145,\n         0, 0}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, {0, 0, 0, 0, 0, 0, 0, \n        160, 0, 0, 0}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, {0, 0, 377, 0, \n        130, 0, 0, 0, 0, 0, 0}}\n\n(*    Time within disks: Total*)\nTotal /@ times\n\n\n{155, 0, 0, 145, 0, 160, 0, 507}\n\n", "Filter a list generated with Tuples": "\nWhile you've already gotten an answer to your question, filtering out the unwanted tuples after generating all of them can be a huge waste of memory if there are many such tuples. Therefore it may be a better idea to generate only the wanted tuples to begin with. The following function does that:\nnoreptuples[{f_List, r__List}] := \n  Flatten[Function[x, (Prepend[#1, x] & ) /@ noreptuples[DeleteCases[{r}, x, {2}]]] /@ f, 1]\n\nnoreptuples[{l_List}] := List /@ l\n\nNote that I didn't time this function; it probably is slower for some cases (straightforward Mathematica code vs. likely very optimized code for Tuples) and faster for others (due to less elements to process).\nFor the example in your question, 160000 tuples are generated, from which only 2880 tuples remain. Given that each tuple has 8 numbers, and assuming storage in a packed array (basically, 4 bytes per integer), you are generating an array of almost 5 megabytes, and after filtering keep only about 90 kilobytes of that. Given that the memory needed for the tuples grows exponentially with tuple length, this means that the filtering method may quickly become impractical.\n", "How to modularize custom controls for Manipulate?": "\nNot sure if this helps, but you can define a control in Manipulate as\nManipulate[\n  some code,\n  {{var, init, label}, func}, \n  ...\n]\n\nwhere func is a function defining a custom control. The first argument given to func is then Dynamic[var]. \nAs an example, suppose that instead of an ordinary slider you want a red dot which you can move along a scale. You could define your customSlider as\ncustomSlider[Dynamic[i_], str_, b_, e_, st_] :=\n LocatorPane[Dynamic[{i, 0}, (i = Round[#[[1]], st]) &],\n   Dynamic[\n    Graphics[{Red, Disk[{i, 0}, Abs[e - b]/40]},\n     PlotRange -> {{b, e}, All},\n     ImagePadding -> 10,\n     PlotLabel -> Row[{str,i}], Axes -> {True, False}]], Appearance -> None]\n\nYou can then use this control in Manipulate as\nManipulate[{i, 2 i, 3 i},\n {{i, 0}, (customSlider[#1, \" i= \", -11, 11, 1] &)}, \n SaveDefinitions -> True]\n\n\n", "bugs - Mathematica script - passing command line arguments": "\nSolution (tested on Linux)\nUse this as first line of your script:\n#!/usr/local/bin/MathematicaScript -runfirst \"$TopDirectory=\\\"/usr/local/Wolfram/Mathematica/8.0\\\"\" -script\n\nIf you installed Mathematica in a different directory, you have to adjust the path of $TopDirectory.\nHow did I debug this?\nThe first error message is quite clear: the system cannot open the file /SystemFiles/CharacterEncodings/ISO8859-1.m and obviously the system is correct, because this file does not exist in this directory.\nYou could now use strace to track down what happens (maybe you better redirect the output into a file)\nstrace -s 128 ./script.m 1 2 3 4 5\n\nLooking into the output you probably stumble over the line\nexecve(\n\n\"/usr/local/Wolfram/Mathematica/8.0/SystemFiles/Kernel/Binaries/Linux-x86-64/MathKernel\", \n[\"\", \"-runfirst\", \"$TopDirectory=\\\"/usr/local/Wolfram/Mathematica/8.0\\\"\", \"-script\", \n\"./script.m\", \"--\", \"./script.m\", \"1\", \"2\", \"3\", \"4\", \"5\"]\n\n, [/* 54 vars */]) = 0\n\nYou see that basically you script-call is of course just a call to the MathKernel. If you execute this on the command-line, your script runs fine. This seems to suggest, that by providing 5 or more parameters, the setting of the $TopDirectory is somehow removed. Therefore, I tried to set it explicitly in the MathematicaScript-call which seems to work.\n", "dynamic - Why do buttons with ChoiceDialog freeze the front end?": "\nTry the following two alternatives, pressing the button while the Do loop is waiting.\nButton[\"Click Here\", Print[10!], Method -> \"Preemptive\"]\nDo[Print[x]; Pause[5], {2}]\n(*\n -> x\n -> 3628800\n -> x\n*)\n\nand   \nButton[\"Click Here\", Print[10!], Method -> \"Queued\"]\nDo[Print[x]; Pause[5], {2}]\n(*\n -> x\n -> x\n -> 3628800\n*)\n\nSome Explanation:\nYou can see that in the first case, the Do loop is interrupted for processing the Button procedure, but in the second case it is just queued and the Button processing is postponed until the Do loop ends. \nIn the case of the \"Preemptive\" method, Mma wants to assure that you are not stealing the CPU forever and impeding the Do loop finalization, so it gives you a certain time slice to process the Button procedure. If you yield control to human input (as in InputString[]), that time slice expires and thus the results you are getting.\n", "graphs and networks - Is it possible to generate a Hasse diagram for a defined relation?": "\nIn versions 10+, we can compose TransitiveReductionGraph and RelationGraph to get a Hasse diagram function with takes the same arguments and options as RelationGraph: \nClearAll[hasseF]\nhasseF = TransitiveReductionGraph @* RelationGraph\n\nExamples:\nhasseF[SubsetQ, Subsets[Range[4]], VertexShapeFunction -> \"Name\"]\n\n\nsubstringQ[s1_, s2_] := UnsameQ[s1 , s2] && StringMatchQ[s1, ___ ~~ s2 ~~ ___]\n\nhasseF[substringQ, {\"a\", \"b\", \"c\",\"ab\", \"ac\",\"abc\", \"abcd\"},\n   VertexShapeFunction -> \"Name\"]\n\n\n", "import - When importing GIF animation, how to find the correct list of \"DisplayDurations\"?": "\nI don't know if you can persuade Import to return the correct durations, but luckily the format of .gif files is pretty straight forward so it's not that hard to extract the correct durations manually from the raw data.\nIn an animated gif the frame durations are stored in a so called Graphic Control Extension or GCE preceding each frame. A GCE starts with the byte sequence 21 F9 04 followed by 4 data bytes and is closed by 00. Of these data bytes, the second and third byte are the frame duration in hundreds of seconds ordered least significant byte first.\nSo a crude way to extract the frame durations is to read in the file, find the positions of the byte sequence 21 F9 04 and extract the fourth and fifth byte after each of these positions, e.g.\nlst = BinaryReadList[\"~/test.gif\"];\nseq = FromDigits[#, 16] & /@ StringSplit[\"21 f9 04\"];\npos = Position[Partition[lst, 3, 1], seq];\ndurations2 = (Extract[lst, pos + 4] + 256 Extract[lst, pos + 5])/100\n\n(* ==> {1/20, 1/10, 3/20, 1/5, 1/4, 3/10, 7/20, 2/5, 9/20, 1/2, 2} *)\n\n", "numerics - Finding a fit to a multi-dimensioned function": "\nWithout a specific example, I can only make general suggestions here.\nThe first thing that comes to mind is that you could fit each of the two components of your vector field independently. I.e., if  $\\vec{f}: \\mathbb{R}^2\\to\\mathbb{R}^2$ is split up into $\\vec{f} = \\{f_x, f_y\\}$ with $f_{1,2}: \\mathbb{R}^2\\to\\mathbb{R}$, then FindFit would work on each of these component functions. \nIf you don't want the fits to be determined independently, it could still be possible to use FindFit by introducing an auxiliary variable $s$ that labels the two component functions above, $f_s$, and then provide the fitting data with this variable s included. Here, s can only have two discrete values (I borrowed the idea from spin-half quantum mechanics). Let's choose s = 0 for the function $f_x$ and s = 1 for $f_y$. So you'd have data in the form\ndata = {{x1, y1, 0, fx1}, {x1, y1, 1, fy1}, ...}\n\nwhere fx1 is the first value of $f_x$ and fy1 the first value of $f_y$, both at the point x1, y1.\nYour model could then look something like this:\nmodel[x_, y_, s_] := modely[x, y]*s + modelx[x, y]*(1 - s)\n\nwhere modely[x, y] is the model for $f_y$ and modelx[x, y] is the model for $f_x$. The variables in the FindFit call would be x, y, s, and the parameters  in the models modelx, modely could be the same (or different). \nThere are probably many other reasonable ways to do such a fit, but these are some ideas.\n", "plotting - How to export transparent raster plots?": "\nInstead of using Save Image As... you can use the Export command, like this:\nExport[\"transparent.png\", Graphics[Circle[]], Background -> None]\n\nFor this to work it is important that Background -> None is also set inside Graphics.  This is the default though so unless you changed it, it should be fine.\nSimilarly, to convert to an image with alpha channels, use\nRasterize[Graphics[Circle[]], \"Image\", Background -> None]\n\nThe output of this can be saved even using Save Image As..., but this effort needed is the same because of the Rasterize function.\n", "equation solving - How to find the smallest root": "\nBriefly, one can use  : \nReduce[ D[ F[x], x] == 0, x, Reals]\n\nor if the function is not strictly monotonic one should select the maximal element out of the result in the boolean form, e.g.\nMax @ (( List @@ Reduce[ D[ F[x], x] == 0, x, Reals] // Quiet)[[All, 2]])\n\nThe major problem is to provide some examples to demonstrate how it works. Since there have been none I will give the following :\nEx. 1. a class of $C^{1}$ functions\nWe define a family of differentiable i.e. $C^{1}$ functions F numbered with an eps parameter  :\nP[x_] := a x^3 + b x^2 + c x + d\nW[x_, eps_] := P[x] //. Flatten @ Solve[{ #^2 == P[#], 1 == P[1], 2 # == P'[#], 1 == P'[1]}, \n                                        {a, b, c, d}]& @ (1 - eps)\nZ[x_, eps_] := P[x] //. Flatten @ Solve[{ # == P[#], 2 == P[2], 1 == P'[#], 0 == P'[2]},\n                                        {a, b, c, d}]& @ (2 - eps)\nF[x_, eps_] := Piecewise[{ { x^2, 0 < x < 1 - eps}, \n                           { W[x, eps], 1 - eps <= x < 1}, \n                           { x, 1 <= x < 2 - eps}, \n                           { Z[x, eps], 2 - eps <= x < 2},\n                           { 2, x >= 2} } ]\n\nThis definition is slightly involved because it is constructed with a few pieces of differentiable functions. The result fulfills the requirements. We introduced auxiliary functions P, W and Z  to define F (monotonic, differentiable, and constant after x exceeds a certain point x0, (here x0 == 2)).\nNow we can test the result for any eps (every eps > 0 define a differentiable function F[x, eps] ), e.g.   \n Manipulate[ Plot[ F[x, eps], {x, 0, 2.3}, PlotRange -> {0, 2.3}] // Quiet, {eps, 0, 1}]\n\nor showing a graph of F[x, eps] with a running parameter eps on the background of graphs for various eps :   \n    Animate[ \n        Show[ Plot[ Evaluate @ Table[ F[x, ep], {ep, 0, 1, 0.1}], {x, 0, 2.3}, \n                    PlotRange -> {0, 2.1}, ImageSize -> {650, 450}] // Quiet, \n              Plot[ F[x, eps], {x, 0, 2.3}, PlotRange -> {0, 2.1}, \n                    PlotStyle -> Thick, ImageSize -> {650, 450}] // Quiet, \n              Graphics[{ PointSize[0.015], Magenta,\n                         Point @ {{1 - eps, F[1 - eps, eps]}, {2 - eps, F[2 - eps, eps]}}}]\n            ],  {eps, 0, 1}]\n\n\nReduce[ D[F[x, 0.4], x] == 0, x, Reals] // Quiet\nMax @ ( List @@ Reduce[ D[ F[x, 0.4], x] == 0, x, Reals] // Quiet)[[All, 2]]\n\n\n x <= 0 || x > 2.\n 2.\n\n\nThe answer is x == 2.\nEdit\nWe would like to test the method when the interesting point changes its location, therefore we add another class of functions to demonstrate the reliability of the approach based on Reduce. \nEx. 2. a class of $C^{\\infty}$ functions\nWe construct a family of G functions numbered with an eps parameter, but this family is smooth (i.e. $C^{\\infty}$) and the gluing point x == x0 is movable : \nG[x_, eps_] := \n    Piecewise[{ {1 - eps^2/10 - eps Exp[-(1/(1 - 1/eps - x))], x < 1 - 1/eps},\n                {1 - eps^2/10, x >= 1 - 1/eps} }]\n\nThis family of functions G is not analytic of course, (precisely, the only point where the functions are not analytic is x == 1 - 1/eps), however they  are still smooth, i.e. we can find their derivatives of any order in x == 1 - 1/eps, for any eps, e.g. \nLimit[ Table[ D[G[x, eps], {x, n}], {n, 1, 10}], x -> 1 - 1/eps, Direction ->  1]\nLimit[ Table[ D[G[x, eps], {x, n}], {n, 1, 10}], x -> 1 - 1/eps, Direction -> -1]\n\n\n{0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n{0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n\n\nthus its expansion in a Taylor series around x0 == 1 - 1/eps is constant  unlike the function itself for x <= x0.\nWe can test that for any eps we get the correct result :\nManipulate[{Reduce[ D[ G[x, eps], x] == 0, x] // Quiet, 1 - 1/eps}, {eps, 0.1, 1}]\n\n\nand we make a plot of a few functions :\nGraphicsColumn[\n    {Plot[ Evaluate @ Table[ G[x, eps], {eps, 0.2, 1.1, 0.1}], {x, -5, 2}, \n           PlotStyle -> Thick, PlotRange -> All, PerformanceGoal -> \"Speed\"], \n\n     Plot[ Evaluate @ Table[ G[x, eps], {eps, 0.5, 0.9, 0.1}], {x, -5, 2},  \n           PlotStyle -> Thick, PlotRange -> {{-1.5, 0.1}, {0.9, 0.98}}, \n           PlotPoints -> 200, MaxRecursion -> 8]}]\n\n\n", "plotting - About the number format in ticks": "\nPerhaps this?\nLogPlot[Abs[BesselJ[1, x] Sin[x]^2], {x, -10, 10}, Frame -> True, \n FrameTicks -> {{{#, Superscript[10, Log10@#]} & /@ ({10^0, 10^-1, \n       10^-2, 10^-3, 10^-4, 10^-5}), None}, {None, None}}]\n\n\n\nHere's a completely different approach, manipulating the existing tick labels in the generated graph, and preserving the unlabeled ticks.  This seems much cleaner to me than Peter's approach, assuming that it works on version 8 as it does on version 7.\nformat =\n  Replace[#, {p_, n_?NumericQ} :> {p, Superscript[10, Round@Log10@n]}, {#2}] &;\n\nticks = MapThread[format, {Options[#, {Ticks, FrameTicks}], {3, 4}}] &;\n\nUse:\np = LogPlot[Abs[BesselJ[1, x] Sin[x]^2], {x, -10, 10}, Frame -> True];\n\nShow[p, ticks[p]]\n\n\n\nUpdate 2015\nThe new Ticks subsystem\nRecent versions of Mathematica use a different ticks rendering system wherein functions specified for Ticks or FrameTicks are passed to the Front End (which calls the Kernel) rather than being evaluated beforehand.  If we look at the options of p above we now see:\nOptions[p, {Ticks, FrameTicks}]\n\n\n{\n Ticks -> {Automatic, Charting`ScaledTicks[{Log, Exp}]}, \n FrameTicks -> {{Charting`ScaledTicks[{Log, Exp}], \n    Charting`ScaledFrameTicks[{Log, Exp}]}, {Automatic, Automatic}}\n}\n\n\nWe could use these functions to compute tick specifications external to plotting, but to follow the spirit of the new paradigm we can modify the output of these functions instead.\nScaledTicks returns (at least?) three different label formats which we must handle:\nCharting`ScaledTicks[{Log, Exp}][-11.7, 1.618][[2 ;; 4, 2]] // InputForm\n\n\n{Superscript[10, -4], 0.001, NumberForm[0.01, {Infinity, 3}]}\n\n\nThe Superscript is already our desired format.  The other two may be handled with replacement:\nformat2 =\n  Replace[#, n_?NumericQ | NumberForm[n_, _] :> Superscript[10, Round@Log10@n]] &;\n\nWe can then use this to apply the formatting:\nrelabel = # /. CST_Charting`ScaledTicks :> (MapAt[format2, CST[##], {All, 2}] &) &;\n\nLogPlot[Abs[BesselJ[1, x] Sin[x]^2], {x, -10, 10}] // relabel\n\n\nrelabel also works with framed plots.\nSpelunking internal functions\nOne may be interested is the source of the original label formatting.  Charting`ScaledTicks calls:\nCharting`SimplePadding\n\nwhich takes the option \"CutoffExponent\" which we would like to use, but unfortunately ScaledTicks overrides it.  If we use:\nClearAttributes[Charting`ScaledTicks, {Protected, ReadProtected}]\n\nAnd then modify the definition to replace:\n\"CutoffExponent\" -> \n If[{Visualization`Utilities`ScalingDump`f, \n    Visualization`Utilities`ScalingDump`if} === {Identity, Identity}, 6, 4]\n\nWith:\n\"CutoffExponent\" -> 1\n\nWe will find that the desired formatting has been effected:\nLogPlot[Abs[BesselJ[1, x] Sin[x]^2], {x, -10, 10}, Frame -> True]\n\n\nThis modification is inadvisable however, and sadly Charting`ScaledTicks does not itself take \"CutoffExponent\" as an option that would be passed on.  One could modify its definition to add this option, but it is safer to use relabel defined above.\n", "graphics3d - Extract current viewing parameters from a 3D view?": "\nYou can dynamically extract ViewPoint and others like this (also useful for synchronization of different plots etc.):\nvp = Options[Graphics3D, ViewPoint][[1, 2]];\n\nGraphics3D[Cuboid[], ViewPoint -> Dynamic[vp]]\n\n\nThis value is now constantly updated:\nDynamic[vp]\n\n\n{1.3, -2.4, 2.}\n\nThis seem also to work fine with other functions that use the ViewPoint option. Below, ViewPoint and ViewVertical are in sync for both objects:\n{vp, vv} = Options[Graphics3D, {ViewPoint, ViewVertical}][[All, 2]];\n\nGrid[{{Graphics3D[Cuboid[], ViewPoint -> Dynamic[vp], \n    ViewVertical -> Dynamic[vv]], \n   ParametricPlot3D[{Cos[u], Sin[u] + Cos[v], Sin[v]}, {u, 0, \n     2 Pi}, {v, -Pi, Pi}, ViewPoint -> Dynamic[vp], \n    ViewVertical -> Dynamic[vv]]}}]\n\n\n", "polynomials - Computing the genus of an algebraic curve": "\nFor computing the genus of a plane algebraic curve implicitly defined by a squarefree polynomial $f(x,y)$ there are different softwares available in the literature.\nRemark: I assume you are interested in computing the genus when the coefficients of the defining polynomial of the curve are either integers or rationals right? This is the case of exact data. For instance, $f(x,y)=x^2-y^3$ represents an exact data polynomial, but $f'(x,y)=1.00 \\, x^2-1.01 \\, y^3$, with $n=0.01$ the noise in the coefficients is an inexact data polynomial. Basically, the algorithms/their implementations for computing the genus are divided into two main classes: the algorithms for exact data and the algorithm for exact and inexact data.\nAlternatives: In the case of exact data you can use some libraries, I find the following the most practical:\n\nalgcurves in Maple. See the author's instructions on how to compute the genus.\nnormal.lib package in Singular\n\nIn Mathematica there is no implementation (at present time from my knowledge) of an algorithm for computing the genus of plane algebraic curve. There are several reasons for this, if you want to know more about these details, just let me know.\nWe also have an implementation for computing the genus of a plane algebraic curve at, please see here.\nRoughly, the implementation is in C++ (see the instructions for more details). Our library computes the genus of curves defined by polynomials with exact data and with inexact data. We did not write our library in Mathematica for different \"strong\" reasons, so if you really want to use Mathematica for computing the genus I am afraid I do not have a good news for you. But, for the exact case, the algcurves package is very good, and for the exact and inexact case (or simply the exact case) you can use our library. I hope this is not too confusing for you.\nIf you need more help/information, please just let me know.\nNote: Here are some reasons for which we did not implement at first our algorithm for genus computation in Mathematica (Artes, thanks for the question on this issue, I was kind of hoping to discuss a bit more about this). \nFor computing the genus, we need an algorithm for solving the following decisive problem: for a real plane algebraic curve C defined by the polynomial f(x,y)=0, we need to compute a graph G=(V,E), where V is a set of points in the 2-dimensional Euclidean plane together with their Euclidean coordinates and E is a set of edges connecting them. In addition, the graph G has the special property that it can be continuously deformed into the curve C. Intuitively, the computed graph G is a piecewise linear approximation of the differential curve C. At present (from my knowledge) in Mathematica there are no algorithms for computing the graph G for an input curve C. Still, at present we are working (I am actually very interested in this problem) on developing a new algorithm for computing such a special graph G for a real plane (and space) real algebraic curve. And I am working on the implementation of the algorithm in Mathematica. After this algorithm will be available in Mathematica, we can have an implementation for the genus of a plane algebraic curve in Mathematica as well.\n", "image processing - Filtering pixels of a certain color": "\ni = Import[\"http://i.stack.imgur.com/zzUdB.gif\"];\n\n{h, s, b} = ColorSeparate[i, \"HSB\"];\n\nManipulate[\n Column[\n  {\n   Graphics[{Hue[c], Rectangle[]}, ImageSize -> 40],\n   ImageMultiply[i, \n    Binarize[Abs[Mod[ImageData[h] - c, 1, -1/2]] // Image, \n      tolerance] // ColorNegate]\n   }\n  ],\n {c, 0, 1},\n {{tolerance, 0.1}, 0, 0.5}\n ]\n\n\n\n\n\nGIF image source \n", "performance tuning - How can I use Mathematica's graph functions to cheat at Boggle?": "\nPreview and comparative results\nThe implementation below may be not the most \"minimal\" one, because I don't use any of the built-in functionality (DictionaryLookup with patterns, Graph-related functions, etc), except the core language functions. However, it uses efficient data structures, such as Trie, linked lists, and  hash tables, and arguably maximally avoids the overheads typical in Mathematica programming. The combined use of Trie, linked lists, and recursion allows the main function to copy very little. The use of trie data structure allows me to be completely independent of the system DictionaryLookup function. \nWhy is this critical here? Because the nature of the problem makes only a single last letter important for the next traversal step, and constructing the whole word (containing all previous letters) just to check that it exists is a waste, and this is arguably the reason why other solutions are both much slower and do not scale so well.\nAlso, the preprocessing step, while rather costly (takes about 6 seconds on my machine), has to be done only once, to initialize the \"boggle engine\" (moreover, the resulting trie can be stored in e.g. .mx file for later reuse, avoiding this overhead for subsequent uses), while in other posted solutions some preprocessing has to be done for every particular board.\nThe main message I want to deliver is that, for the top-level Mathematica code, the choice of efficient data structures is crucial. Our Mathematica programming instincts demand that we reuse as much of the built-in functionality as possible, but one always has to question how well the existing functionality matches the problem. In this particular case, my opinion is that neither the built-in Graph - related functions nor the DictionaryLookup with patterns bring much to the table. To the opposite, these functions force us to use unnatural for this problem data representations and/or algorithms, and this is what leads to the slowdowns. I may be over-emphasizing this point, but this was exactly the essence of the question.\nNow, some timing comparisons (note that for the solution of @R.M., I had to include the pieces defining adjnodes, letters and dict variables, into the timing measurements):\n\nBoard 4x4 (the original one):\n\nPillsy   3.3 sec\nR.M.     1.4 sec\nL.S.     0.04 sec\n\nBoard  5x5:\n\"E I S H R\n B D O I O\n T R O E X\n Z U Y Q S\n I A S U M\"\n\n\nPillsy   18.8 sec\nR.M.     7.6  sec\nL.S.     0.05 sec\n\nBoard 7x7\n\"E I E G E O T\n A O B A U R A\n N E I P L A Y\n O O I I C A T\n I I F U N L A\n S T I N G E W\n U H L E O X S\"\n\n\nPillsy   373.8 sec\nR.M.     191.5 sec\nL.S.     0.18 sec\n\n\nSo, you can see that for larger boards, the difference between the running times is even more dramatic, hinting that the solutions have different computational complexities. \nI took the trouble to perform and present all these timings because I think that this problem  is an important counterexample to the \"conventional wisdom\" to favor shorter implementations utilizing built-ins over the hand-written top-level mma code. While I agree that in general this is a good strategy, one has to always examine the case at hand. To my mind, this problem presents one notable exception to this rule. \nImplementation\nThe following solution will not use Mathematica graphs, but will be about 100 times faster (than the timings you cite), and will rely on this post. I will borrow a function which builds the word tree from there:\nClearAll[makeTree];\nmakeTree[wrds : {__String}] := makeTree[Characters[wrds]];\nmakeTree[wrds_ /; MemberQ[wrds, {}]] := \n     Prepend[makeTree[DeleteCases[wrds, {}]], {} -> {}];\nmakeTree[wrds_] := \n    Reap[If[# =!= {}, Sow[Rest[#], First@#]] & /@ \n       wrds, _, #1 -> makeTree[#2] &][[2]]\n\nIts use is detailed in the mentioned post. Now, here is a helper function which will produce rules for vertex number to letter conversion, and adjacency rules:\nClear[getLetterAndAdjacencyRules];\ngetLetterAndAdjacencyRules[letterMatrix_?(MatrixQ[#, StringQ] &)] :=\n  Module[{a, lrules, p, adjRules},\n    lrules = Thread[Range[Length[#]] -> #] &@Flatten[letterMatrix];\n    p = \n      ArrayPad[\n          Partition[Array[a, Length[lrules]], Last@Dimensions@letterMatrix], \n          1\n      ];\n    adjRules = \n      Flatten[\n       ListConvolve[{{1, 1, 1}, {1, 2, 1}, {1, 1, 1}}, p] /. Plus -> List /.\n         {left___, 2*v_, right___} :> {v -> {left, right}} /. a[x_] :> x];\n    Map[Dispatch, {lrules, adjRules}]\n  ];\n\nIt is pretty ugly but it does the job. Next comes the main function, which will find all vertex sequences which result in valid dictionary words:\nEDIT\nApparently, there is a problem with Module-generated inner functions. I used Module in getVertexSequences initially, but, because in my benchmarks I happened to use a previous incarnation of it with a different name (where I did not yet modularize the inner functions), I did not see the difference. The difference is an order of magnitude slow-down. Therefore, I switched to Block, to get back the performance I claimed (You can replace back the Block with Module to observe the effect). This is likely related to this issue, and is something anyone should be aware of IMO, since this is quite insidious.  \nEND EDIT\nClear[getVertexSequences];\ngetVertexSequences[adjrules_, letterRules_, allTree_, n_] :=\nBlock[{subF, f, getWordsForStartingVertex},\n  (* A function to extract a sub-tree *)\n  subF[v_, tree_] := \n    With[{letter = v /. letterRules},\n      With[{res = letter /. tree},\n        res /; res =!= letter]];\n  subF[_, _] := {};\n  (* Main function to do the recursive traversal *)\n  f[vvlist_, {{} -> {}, rest___}] := f[Sow[vvlist], {rest}];\n  f[_, {}] := Null;\n  f[vvlist : {last_, prev_List}, subTree_] :=\n     Scan[\n       f[{#, vvlist}, subF[#, subTree]] &,\n       Complement[last /. adjrules, Flatten[vvlist]]\n     ];\n  (* Function to post-process the result *)\n  getWordsForStartingVertex[v_] :=\n    If[# === {},\n       #,\n       Reverse[Map[Flatten, First@#], 2]\n    ] &@Reap[f[{v, {}}, subF[v, allTree]]][[2]];\n  (* Call the function on every vertex *)\n  Flatten[Map[getWordsForStartingVertex, Range[n]], 1]\n]\n\nAt the heart of it, there is a recursive function f, which acts very simply. The vvlist variable is a linked list of already visited vertices. The second argument is a sub-tree of the main word tree, which corresponds to the sequence of already visited vertices (converted to letters. To understand better what the sub-tree is, see the mentioned post). When the sub-tree starts with {} -> {}, this means (by the way word tree is constructed), that the sequence of vertices corresponds to a valid word, so we record it. In any case, if the subtree is not {}, we Scan our function recursively on adjacent vertices, removing from them those we already visited.\nThe final functions we need are the one to convert vertex sequences to words, and the one to construct the trie data structure. Here  they are:\nClear[wordsFromVertexSequences];\nwordsFromVertexSequences[vseqs_List, letterRules_] :=\n   Map[StringJoin, vseqs /. letterRules];\n\nClearAll[getWordTree];\ngetWordTree[minLen_Integer: 1, maxLen : (_Integer | Infinity) : Infinity] :=\n  makeTree[\n     Select[ToLowerCase@DictionaryLookup[\"*\"], \n     minLen <= StringLength[#] <= maxLen &]];\n\nThe function to bring this all together:\nClearAll[getWords];\ngetWords[board_String, wordTree_] :=\n   getWords[ToLowerCase@ImportString@board, wordTree];\ngetWords[lboard_, wordTree_] :=\n   Module[{lrules, adjrules},\n   {lrules, adjrules} = getLetterAndAdjacencyRules[lboard ];\n   wordsFromVertexSequences[\n       getVertexSequences[adjrules, lrules, wordTree, \n          Times @@ Dimensions[lboard]],\n       lrules\n   ]\n];\n\nIllustration\nFirst, construct a full tree of all words in a dictionary. This preprocessing step can take a little while:\nlargeTree = getWordTree[];\n\nNow, construct the word matrix:\nwmat = ToLowerCase@ImportString@\n  \"F X I E\n   A M L O\n   E W B X\n   A S T U\"\n\n\n{{\"f\", \"x\", \"i\", \"e\"}, {\"a\", \"m\", \"l\", \"o\"}, {\"e\", \"w\", \"b\",\"x\"}, \n         {\"a\", \"s\", \"t\", \"u\"}}\n\nNext, construct the rules for vertex-to-letter conversion and adjacency rules:\n({lrules,adjrules} = getLetterAndAdjacencyRules[wmat])//Short[#,3]&\n\n\n{Dispatch[{1->f,2->x,3->i,4->e,5->a,6->m,7->l,8->o,9->e,10->w,11->b,\n  12->x,13->a,14->s,15->t,16->u},-DispatchTables-],\n    Dispatch[{1->{2,5,6},<<14>>,16->{11,12,15}},<<1>>]}\n\n\nWe are now ready to use our function:\n(seqs = getVertexSequences[adjrules,lrules,largeTree,16])//Short//AbsoluteTiming\n\n\n{0.0185547,{{1,5},{1,5,2},{1,5,6,9},{1,6},<<89>>,{15,14},\n     {15,16,11},{15,16,11,14},{15,16,12}}}\n\n\nNote that it took very little time to get the result. We can finally convert it to words:\nwordsFromVertexSequences[seqs,lrules]//Short\n\n\n{fa,fax,fame,fm,xi,xml,xl,<<84>>,twas,tb,ts,tub,tubs,tux}\n\nThe way to call a final function:\n(* Do this only once per session *)\n$largeTree = getWordTree[3];\n\nboard = ToLowerCase@ImportString@\"F X I E\n  A M L O\n  E W B X\n  A S T U\"\n\ngetWords[board, $largeTree]\n\n\n{fax,fame,xml,imf,eli,elm,elma,<<59>>,stub,twa,twa,twas,tub,tubs,tux}\n\n(note that the result differs from that in illustration section, since I am now using the word tree with words with less than 3 letters excluded - using the $largeTree rather than largeTree now).\nDiscussion\nOf course, I was a bit cheating in the sense that the preprocessing time takes a while, but this has to be done only once. My main point is that I think, the Trie data structure (my interpretation of it) is the right one here, and coupled with linked lists and hash tables (Dispatch-ed rules), it leads to a rather simple solution. The essence of the solution is expressed in function f, which is just a few lines long and more or less self-documenting. And, also, the solution itself turns out quite fast (especially given that this uses just the top-level mma, no packed arrays, Compile, etc). \nEDIT 2\nTo address the question in your edit, and generally the question on applicability of Mathematica's new Graph functionality to this problem: I think, that while you can use new Graphs to solve the problem, it is not a natural choice here. I may be wrong, of course, but these are my reasons:\n\nThe graph traversal you need for this problem does not fit directly into either one of DepthFirstScan and BreadthFirstScan built-in graph-traversal functions. Rather, it is a kind of enumeration of all possible depth-first traversals starting at a given vertex.\nThose traversals should stop as soon as it becomes clear that no words can be constructed by going to any of the adjacent vertices. This can be also achieved in DepthFirstScan through the use of Catch and Throw, but it is rather inelegant, and will also induce an overhead.\nThe general ideology of DepthFirstScan and BreadthFirstScan is somewhat similar to a visitor design pattern used for a tree traversal. The idea is that the traversal is done for you, while you have to supply the functions to be called on tree (or graph) nodes. This approach works well when your traversal matches exactly the one implemented by the pattern. For example, most of the time, a tree is traversed depth-first. However, I had many chances to observe (in other languages) that as soon as I have to modify the traversal even slightly, using the tools like that creates more problems than it solves.\nThe main question to ask yourself is this: does you traversal (sequence of visited vertices) depend on the content of the vertices (information you get during the traversal)? If yes, then it is more than likely that custom general traversal functions will not give you a good solution, because you then need more control over the way traversal is performed. The whole idea of visitor pattern (used for tree traversals) and the like is that you can separate the traversal itself from the information-processing during the traversal, and it's just not true for data-dependent traversals, where you can not really decouple traversal from the data-processing of the tree (or graph) nodes.\n\nI think that we should separate cases where graphs represent just a useful abstraction to think about the problem, from those where the problem can be solved by means of more or less standard graph-theoretical functionality (in particular that present in Mathematica), once it is reformulated in an appropriate way. The case at hand clearly looks to me like belonging to the first category. \n", "dynamic - Strange behavior of CreateDialog's WindowSize option": "\nThe following works for me with Mathematica 8.0.4\nDynamicModule[{switch = 1},\nCreateDialog[\nglobalvar = DocumentNotebook@TextCell@Dynamic@Switch[switch, 1, \"A\", 2, \"B\"], \nWindowSize -> {200, 100}]];\n\nHowever making the variable local to the DynamicModule does not work:\nDynamicModule[{switch = 1, localvar},\nCreateDialog[\nlocalvar = DocumentNotebook@TextCell@Dynamic@Switch[switch, 1, \"A\", 2, \"B\"], \nWindowSize -> {200, 100}]];\n\nIt also fails if the variable is localized in a Module wrapping the whole thing:\nModule[{localvar},\nDynamicModule[{switch = 1},\nCreateDialog[\nlocalvar = DocumentNotebook@TextCell@Dynamic@Switch[switch, 1, \"A\", 2, \"B\"],\nWindowSize -> {200, 100}]]];    \n\n", "Quadruple-precision (128 bit) arithmetic": "\nAs the comments indicate, there is no completely hardware-based solution - but that doesn't mean you can't do some tweaking. The trick is always: stick with machine precision as long as you can, then switch to arbitrary precision only to refine your results. \nInstead of making up an example (which is hard because Mathematica implements the above principle automatically in many cases, as observed in the comment - which caused me to delete an earlier example), I'll address the problem given in your question some more. It can also be sped up considerably by deferring the use of arbitrary precision (in this case the application of N[...,36] etc.) to the end:\n{#, First@AbsoluteTiming[N[Sin[num], #];]} & /@ Range[32, 36]\n\n\n{{32, 0.931845}, {33, 0.871302}, {34, 0.858584}, {35, 0.852693}, {36, \n    0.849243}}\n\nAll I did was to move the N outside the Sin, and the timing is an order of magnitude faster. \n", "Defining a non-linear optimization-problem": "\nI'm not sure I fully understand the problem, but maybe this will give you some directions to try.\n(*Exemplary data:*)\nSeedRandom[11112222333];\nWeeklyCapacity = Table[189*7.5, {t, 6}];\nWeeklyDemand = Table[RandomInteger[{2000, 5000}], {i, 10}];\n CycleTimes = (1/#) & /@ Table[RandomInteger[{40, 125}], {i, 10}];\n\nProductionProgram = Table[Subscript[x, i, t], {i, 10}, {t, 6}];\nCapaDemand = Transpose@ProductionProgram.CycleTimes;\n\nConstraintDemand = \n  Map[# == 0 &, Total /@ ProductionProgram - WeeklyDemand];\nConstraintCapa = Map[# <= 0 &, Total /@ CapaDemand - WeeklyCapacity];\n\nconstraints = Join[ConstraintDemand, ConstraintCapa];\nvars = Flatten[ProductionProgram];\n\nMinVarProductionProgram = \n  Simplify[Variance /@ ProductionProgram, \n   Assumptions -> Element[vars, Reals]];\n\nHere I am not sure whether it is the total or total-of-squares (or something else entirely) to be minimized.\nTiming[{min, vals} = \n  FindMinimum[{Total[MinVarProductionProgram], constraints}, vars]]\n\nOut[294]= {0.1, {-8.53712*10^-11, {Subscript[x, 1, 1] -> 389.5, \n   Subscript[x, 1, 2] -> 389.5, Subscript[x, 1, 3] -> 389.5, \n   Subscript[x, 1, 4] -> 389.5, Subscript[x, 1, 5] -> 389.5, \n   Subscript[x, 1, 6] -> 389.5, Subscript[x, 2, 1] -> 549.167, \n   Subscript[x, 2, 2] -> 549.167, Subscript[x, 2, 3] -> 549.167, \n   Subscript[x, 2, 4] -> 549.167, Subscript[x, 2, 5] -> 549.167, \n   Subscript[x, 2, 6] -> 549.167, Subscript[x, 3, 1] -> 703.667, \n   Subscript[x, 3, 2] -> 703.667, Subscript[x, 3, 3] -> 703.667, \n   Subscript[x, 3, 4] -> 703.667, Subscript[x, 3, 5] -> 703.667, \n   Subscript[x, 3, 6] -> 703.667, Subscript[x, 4, 1] -> 495.167, \n   Subscript[x, 4, 2] -> 495.167, Subscript[x, 4, 3] -> 495.167, \n   Subscript[x, 4, 4] -> 495.167, Subscript[x, 4, 5] -> 495.167, \n   Subscript[x, 4, 6] -> 495.167, Subscript[x, 5, 1] -> 759.833, \n   Subscript[x, 5, 2] -> 759.833, Subscript[x, 5, 3] -> 759.833, \n   Subscript[x, 5, 4] -> 759.833, Subscript[x, 5, 5] -> 759.833, \n   Subscript[x, 5, 6] -> 759.833, Subscript[x, 6, 1] -> 764.167, \n   Subscript[x, 6, 2] -> 764.167, Subscript[x, 6, 3] -> 764.167, \n   Subscript[x, 6, 4] -> 764.167, Subscript[x, 6, 5] -> 764.167, \n   Subscript[x, 6, 6] -> 764.167, Subscript[x, 7, 1] -> 637.333, \n   Subscript[x, 7, 2] -> 637.333, Subscript[x, 7, 3] -> 637.333, \n   Subscript[x, 7, 4] -> 637.333, Subscript[x, 7, 5] -> 637.333, \n   Subscript[x, 7, 6] -> 637.333, Subscript[x, 8, 1] -> 476.5, \n   Subscript[x, 8, 2] -> 476.5, Subscript[x, 8, 3] -> 476.5, \n   Subscript[x, 8, 4] -> 476.5, Subscript[x, 8, 5] -> 476.5, \n   Subscript[x, 8, 6] -> 476.5, Subscript[x, 9, 1] -> 666.833, \n   Subscript[x, 9, 2] -> 666.833, Subscript[x, 9, 3] -> 666.833, \n   Subscript[x, 9, 4] -> 666.833, Subscript[x, 9, 5] -> 666.833, \n   Subscript[x, 9, 6] -> 666.833, Subscript[x, 10, 1] -> 511., \n   Subscript[x, 10, 2] -> 511., Subscript[x, 10, 3] -> 511., \n   Subscript[x, 10, 4] -> 511., Subscript[x, 10, 5] -> 511., \n   Subscript[x, 10, 6] -> 511.}}}\n\nFor sum of squares of variances:\nTiming[{min2, vals2} = \n  FindMinimum[{MinVarProductionProgram.MinVarProductionProgram, \n    constraints}, vars]]\n\nOut[296]= {2.28, {2.51657*10^8, {Subscript[x, 1, 1] -> 478.496, \n   Subscript[x, 1, 2] -> 373.593, Subscript[x, 1, 3] -> 373.593, \n   Subscript[x, 1, 4] -> 373.593, Subscript[x, 1, 5] -> 373.593, \n   Subscript[x, 1, 6] -> 364.134, Subscript[x, 2, 1] -> 686.262, \n   Subscript[x, 2, 2] -> 523.509, Subscript[x, 2, 3] -> 523.509, \n   Subscript[x, 2, 4] -> 523.509, Subscript[x, 2, 5] -> 523.509, \n   Subscript[x, 2, 6] -> 514.701, Subscript[x, 3, 1] -> 877.119, \n   Subscript[x, 3, 2] -> 668.976, Subscript[x, 3, 3] -> 668.976, \n   Subscript[x, 3, 4] -> 668.976, Subscript[x, 3, 5] -> 668.976, \n   Subscript[x, 3, 6] -> 668.979, Subscript[x, 4, 1] -> 346.338, \n   Subscript[x, 4, 2] -> 552.386, Subscript[x, 4, 3] -> 552.386, \n   Subscript[x, 4, 4] -> 552.386, Subscript[x, 4, 5] -> 552.386, \n   Subscript[x, 4, 6] -> 415.116, Subscript[x, 5, 1] -> 861.299, \n   Subscript[x, 5, 2] -> 743.336, Subscript[x, 5, 3] -> 743.336, \n   Subscript[x, 5, 4] -> 743.336, Subscript[x, 5, 5] -> 743.336, \n   Subscript[x, 5, 6] -> 724.357, Subscript[x, 6, 1] -> 937.424, \n   Subscript[x, 6, 2] -> 727.414, Subscript[x, 6, 3] -> 727.414, \n   Subscript[x, 6, 4] -> 727.414, Subscript[x, 6, 5] -> 727.414, \n   Subscript[x, 6, 6] -> 737.922, Subscript[x, 7, 1] -> 775.12, \n   Subscript[x, 7, 2] -> 611.552, Subscript[x, 7, 3] -> 611.552, \n   Subscript[x, 7, 4] -> 611.552, Subscript[x, 7, 5] -> 611.552, \n   Subscript[x, 7, 6] -> 602.671, Subscript[x, 8, 1] -> 612.536, \n   Subscript[x, 8, 2] -> 451.053, Subscript[x, 8, 3] -> 451.053, \n   Subscript[x, 8, 4] -> 451.053, Subscript[x, 8, 5] -> 451.053, \n   Subscript[x, 8, 6] -> 442.253, Subscript[x, 9, 1] -> 766.477, \n   Subscript[x, 9, 2] -> 650.705, Subscript[x, 9, 3] -> 650.705, \n   Subscript[x, 9, 4] -> 650.705, Subscript[x, 9, 5] -> 650.705, \n   Subscript[x, 9, 6] -> 631.703, Subscript[x, 10, 1] -> 523.304, \n   Subscript[x, 10, 2] -> 523.034, Subscript[x, 10, 3] -> 523.034, \n   Subscript[x, 10, 4] -> 523.034, Subscript[x, 10, 5] -> 523.034, \n   Subscript[x, 10, 6] -> 450.56}}}\n\nHope this gives some ideas for how to proceed.\n--- edit ---\nSince the objective is nonlinear Mathematica only has NMinimize to try to enforce integrality of variables. Here is the altered code for this situation. I start by rounding the result from FindMinimum, to be used as initial variable ranges for NMinimize.\nIn[35]:= Timing[{min2, vals2} = \n   FindMinimum[{MinVarProductionProgram.MinVarProductionProgram, \n     constraints}, vars];]\n\nOut[35]= {2.16, Null}\n\nIn[39]:= firstGuess = Round[vars /. vals2];\ndelta = 50;\nranges = Transpose[{vars, firstGuess - delta, firstGuess + delta}];\n\nI use these ranges in NMinimize.\nTiming[{min3, vals3} = \n  NMinimize[{MinVarProductionProgram.MinVarProductionProgram, \n    Append[constraints, Element[vars, Integers]]}, ranges, \n   MaxIterations -> 1000]]\n\nDuring evaluation of In[42]:= NMinimize::cvmit: Failed to converge to the requested accuracy or precision within 1000 iterations. >>\n\nOut[42]= {153.86, {5.87444, {Subscript[x, 1, 1] -> 389, \n   Subscript[x, 1, 2] -> 390, Subscript[x, 1, 3] -> 390, \n   Subscript[x, 1, 4] -> 389, Subscript[x, 1, 5] -> 389, \n   Subscript[x, 1, 6] -> 390, Subscript[x, 2, 1] -> 548, \n   Subscript[x, 2, 2] -> 550, Subscript[x, 2, 3] -> 547, \n   Subscript[x, 2, 4] -> 550, Subscript[x, 2, 5] -> 550, \n   Subscript[x, 2, 6] -> 550, Subscript[x, 3, 1] -> 704, \n   Subscript[x, 3, 2] -> 704, Subscript[x, 3, 3] -> 704, \n   Subscript[x, 3, 4] -> 705, Subscript[x, 3, 5] -> 703, \n   Subscript[x, 3, 6] -> 702, Subscript[x, 4, 1] -> 495, \n   Subscript[x, 4, 2] -> 495, Subscript[x, 4, 3] -> 495, \n   Subscript[x, 4, 4] -> 496, Subscript[x, 4, 5] -> 495, \n   Subscript[x, 4, 6] -> 495, Subscript[x, 5, 1] -> 759, \n   Subscript[x, 5, 2] -> 759, Subscript[x, 5, 3] -> 761, \n   Subscript[x, 5, 4] -> 760, Subscript[x, 5, 5] -> 760, \n   Subscript[x, 5, 6] -> 760, Subscript[x, 6, 1] -> 764, \n   Subscript[x, 6, 2] -> 763, Subscript[x, 6, 3] -> 764, \n   Subscript[x, 6, 4] -> 765, Subscript[x, 6, 5] -> 765, \n   Subscript[x, 6, 6] -> 764, Subscript[x, 7, 1] -> 638, \n   Subscript[x, 7, 2] -> 638, Subscript[x, 7, 3] -> 636, \n   Subscript[x, 7, 4] -> 638, Subscript[x, 7, 5] -> 637, \n   Subscript[x, 7, 6] -> 637, Subscript[x, 8, 1] -> 477, \n   Subscript[x, 8, 2] -> 476, Subscript[x, 8, 3] -> 477, \n   Subscript[x, 8, 4] -> 476, Subscript[x, 8, 5] -> 476, \n   Subscript[x, 8, 6] -> 477, Subscript[x, 9, 1] -> 666, \n   Subscript[x, 9, 2] -> 666, Subscript[x, 9, 3] -> 667, \n   Subscript[x, 9, 4] -> 667, Subscript[x, 9, 5] -> 668, \n   Subscript[x, 9, 6] -> 667, Subscript[x, 10, 1] -> 511, \n   Subscript[x, 10, 2] -> 511, Subscript[x, 10, 3] -> 511, \n   Subscript[x, 10, 4] -> 511, Subscript[x, 10, 5] -> 511, \n   Subscript[x, 10, 6] -> 511}}}\n\nAs the message indicates, possibly one could do better. Notice though that the min is now considerably lower than what we had from FindMinimum, so progress has been made in the globval optimization effort. And of course we can keep going. This time I'll narrow the start range lengths.\nnextGuess = vars /. vals3;\ndelta2 = 10;\nranges2 = Transpose[{vars, nextGuess - delta2, nextGuess + delta2}];\n\nTiming[{min4, vals4} = \n  NMinimize[{MinVarProductionProgram.MinVarProductionProgram, \n    Append[constraints, Element[vars, Integers]]}, ranges2, \n   MaxIterations -> 1000]]\n\nOut[66]= {135.86, {0.461111, {Subscript[x, 1, 1] -> 389, \n   Subscript[x, 1, 2] -> 389, Subscript[x, 1, 3] -> 390, \n   Subscript[x, 1, 4] -> 390, Subscript[x, 1, 5] -> 390, \n   Subscript[x, 1, 6] -> 389, Subscript[x, 2, 1] -> 549, \n   Subscript[x, 2, 2] -> 549, Subscript[x, 2, 3] -> 550, \n   Subscript[x, 2, 4] -> 549, Subscript[x, 2, 5] -> 549, \n   Subscript[x, 2, 6] -> 549, Subscript[x, 3, 1] -> 704, \n   Subscript[x, 3, 2] -> 704, Subscript[x, 3, 3] -> 704, \n   Subscript[x, 3, 4] -> 703, Subscript[x, 3, 5] -> 703, \n   Subscript[x, 3, 6] -> 704, Subscript[x, 4, 1] -> 496, \n   Subscript[x, 4, 2] -> 495, Subscript[x, 4, 3] -> 495, \n   Subscript[x, 4, 4] -> 495, Subscript[x, 4, 5] -> 495, \n   Subscript[x, 4, 6] -> 495, Subscript[x, 5, 1] -> 760, \n   Subscript[x, 5, 2] -> 760, Subscript[x, 5, 3] -> 760, \n   Subscript[x, 5, 4] -> 759, Subscript[x, 5, 5] -> 760, \n   Subscript[x, 5, 6] -> 760, Subscript[x, 6, 1] -> 764, \n   Subscript[x, 6, 2] -> 765, Subscript[x, 6, 3] -> 764, \n   Subscript[x, 6, 4] -> 764, Subscript[x, 6, 5] -> 764, \n   Subscript[x, 6, 6] -> 764, Subscript[x, 7, 1] -> 637, \n   Subscript[x, 7, 2] -> 638, Subscript[x, 7, 3] -> 638, \n   Subscript[x, 7, 4] -> 637, Subscript[x, 7, 5] -> 637, \n   Subscript[x, 7, 6] -> 637, Subscript[x, 8, 1] -> 477, \n   Subscript[x, 8, 2] -> 476, Subscript[x, 8, 3] -> 477, \n   Subscript[x, 8, 4] -> 476, Subscript[x, 8, 5] -> 477, \n   Subscript[x, 8, 6] -> 476, Subscript[x, 9, 1] -> 666, \n   Subscript[x, 9, 2] -> 667, Subscript[x, 9, 3] -> 667, \n   Subscript[x, 9, 4] -> 667, Subscript[x, 9, 5] -> 667, \n   Subscript[x, 9, 6] -> 667, Subscript[x, 10, 1] -> 511, \n   Subscript[x, 10, 2] -> 511, Subscript[x, 10, 3] -> 511, \n   Subscript[x, 10, 4] -> 511, Subscript[x, 10, 5] -> 511, \n   Subscript[x, 10, 6] -> 511}}}\n\nSeems to be stabilizing.\n--- end edit ---\n", "databaselink - What format to use to store expressions in database?": "\nIt sounds like all you are looking for is a generic storage using MySQL. Then your translation of _String to TEXT makes sense, but I would consider _Real as a DOUBLE column, depending on your precision requirements. \nAdditionally, I would probably separate the inner list:\n{_String, {_String, _Real}, _Real}\n\ninto:\n{_String, _String, _Real, _Real}\n\nSo that you would have four columns (TEXT, TEXT, DOUBLE, DOUBLE). You can translate back and forth with some patterns like:\n{a_String, b_String, c_Real, d_Real} -> {a, {b, c}, d}\n\nand \n{a_String, {b_String, c_Real}, d_Real} -> {a, b, c, d}\n\nBefore and after import. \nIf you need to store MMA expressions, then the most portable way, I believe, is to store them as InputForm, as mentioned by FJRA in the comment to the question. To do so, you would need to do:\nToString[InputForm[expression]]\n\nAnd then the reverse:\nToExpression[importedString,InputForm]\n\n", "replacement - Replace expressions by self defined symbols": "\nLet's represent your bracket expression using the head bb, so\nbb[x, y] == x ** y - y ** x\n\nThen we can just use a simple replace rule:\n{{X00 ** X10 + X01 ** X10 - X10 ** X01 - X10 ** X00 }, \n {X01 ** X10 - X10 ** X01 - X02 ** X10}, \n {X00 ** X12 -  X12 ** X00}, {X01 ** X12 - X12 ** X01}, {X02 ** X13}} \\\n   //. x_ ** y_ - y_ ** x_ :> bb[x, y]\n\n(* ==>\n  {{bb[X00, X10] + bb[X01, X10]}, \n   {bb[X01, X10] - X02 ** X10}, \n   {bb[X00, X12]}, {bb[X01, X12]}, {X02 ** X13}}\n*)\n\nWe can automate the conversion between the two representations using\ntoBracket[expr_] := expr //. x_ ** y_ - y_ ** x_ :> bb[x, y]\nfromBracket[expr_] := expr /. bb[x_, y_] :> x ** y - y ** x\n\nIf you wish to have a prettier notiation, you could for example use AngleBracket instead of bb.  It is formatted like this:\n\nYou can enter the brackets using the key sequence Esc<Esc.\n", "plotting - Why doesn't PlotMarker option None return no PlotMarkers?": "\nThe answer to your first question is that PlotMarkers doesn't really use a graphics primitive, but uses font based markers as a proxy for it. This can lead to errors in positioning on some OSes.\nI'm guessing that PlotStyle has something of the form ToString@HoldForm[...] when the input is a list, which is why None and False or anything else get converted to strings. This might well be a bug/undesired behaviour, because AxesLabel -> None and AxesLabel -> {\"x\", None} don't behave the same way. It does seem to work for Null though, although I wouldn't have guessed it at first.\nFor the second question, you can adapt Yu-Sung's answer and use CurrentValue[\"Color\"] to colour your markers. Here's your example modified to do this:\nListPlot[Table[n^(1/p), {p, 4}, {n, 10}], Joined -> True, PlotMarkers :> \n    {{Graphics[{Dynamic@EdgeForm[{CurrentValue[\"Color\"], Thick}], \n        FaceForm[White], Disk[{0, 0}, 1]}], 0.05}}\n]\n\n\n", "How to get FullSimplify to fully simplify my expression with custom complexity function?": "\nWe can confirm that the desired form never gets tried, by viewing the expressions sent to the ComplexityFunction with Sow and Reap:\nvc := (Count[ToBoxes[Sow@#], Except[\" \" | \"(\" | \")\", _String], Infinity]) &\n\nUnion@Reap[FullSimplify[(-1 + a) (-1 + b), ComplexityFunction -> vc]][[2, 1]]\n(*  {-1 + a, -1 + b, (-1 + a) (-1 + b), 1 - a + (-1 + a) b, 1 - a - b + a b}  *)\n\nTherefore it seems that it will be essential to add to TransformationFunctions. First I tried generalising from the specific case given in your comment:\ntf = {Automatic, # /. (x_ + a__) (y_ + b__) :> (-x - a) (-y - b) &};\nSetOptions[FullSimplify, ComplexityFunction -> vc, TransformationFunctions -> tf];\n\nFullSimplify[expr]\n(*  (1 - a) (1 - b)  *)\n\nUnfortunately this fails in certain cases, because ReplaceAll makes the first replacement it finds, which might happen to be one that doesn't decrease the complexity measure:\n(* this doesn't work *)\nFullSimplify[(a - b) (-1 + c) (-1 + d)]\n(*  (a - b) (-1 + c) (-1 + d)  *)\n\n(* but this does *)\nFullSimplify[(-1 + c) (-1 + d) (e-f)]\n(*  (1 - c) (1 - d) (e - f)  *)\n\nSince it is problematic to find the correct pairs of terms to negate, my next approach was to convert all forms like (-1+a) into -(1-a), but in such a way that the complexity function would ignore the overall multiplier of -1 (and therefore prefer the latter form).\ntf = {Automatic, $minusone (-#) &};\nvc := (Count[ToBoxes[#], Except[\"$minusone\" | \" \" | \"(\" | \")\", _String], Infinity]) &\n$minusone /: $minusone^2 = 1;\n$minusone /: x_ + $minusone = x - 1;\n\nspecialSimplify[x_] := \nFullSimplify[x, ComplexityFunction -> vc, TransformationFunctions -> tf] /. $minusone -> -1\n\nspecialSimplify tries negating expressions and tests whether this decreases their complexity measure. The overall sign of the expression is kept correct by the symbol $minusone which is ignored by the complexity function. $minusone squared is converted to 1, and $minusone when it appears as part of a sum is converted back to -1. Any residual $minusone at the end of the simplification is converted back to -1.\nThis seems to well enough on toy examples, though I haven't tested it thoroughly. Note that in the last example specialSimplify prefers to have an overall minus sign than an expression like (-a+b)\nspecialSimplify[(-1 + a) (-1 + b)]\n(*  (1 - a) (1 - b)  *)\n\nspecialSimplify[(a - b) (-1 + c) (-1 + d)]\n(*  (a - b) (1 - c) (1 - d)  *)\n\nspecialSimplify[(b - a) (-1 + c) (-1 + d)]\n(*  -(a - b) (1 - c) (1 - d)  *)\n\n", "gui construction - Interdependent controls in Manipulate": "\nNot sure if this is the best way, but you could consider something like this:\nManipulate[\n {x, y},\n {x, Manipulator[Dynamic[x, (x = #; y = 1/#) &], {.1, 10}] &},\n {y, Manipulator[Dynamic[y, (y = #; x = 1/#) &], {.1, 10}] &},\n Initialization :> ({x, y} = {1, 1})]\n\nEdit V10\nSince V10 one can use a shorter form:\nManipulate[\n    {x, y}\n  , {x, .1, 10, TrackingFunction :> ((x = #; y = 1/#) &)}\n  , {y, .1, 10, TrackingFunction :> ((y = #; x = 1/#) &)}\n  , Initialization :> ({x, y} = {1, 1})\n]\n\n", "front end - Running a package automatically when it's saved": "\nThis will assign a 'Save and Run` function to control-shift F:\nFrontEndExecute[FrontEnd`AddMenuCommands[\"Save\",\n  {MenuItem[\"Save and &Run\",\n    FrontEnd`KernelExecute[NotebookSave[SelectedNotebook[]];\n     Get[StringJoin[\n       StringDrop[NotebookFileName[SelectedNotebook[]], -3], \".m\"]]],\n    MenuKey[\"F\", Modifiers -> {\"Control\", \"Shift\"}],\n    System`MenuEvaluator -> Automatic]}]]\n\nTo test, include the following as an initialisation cell in the working notebook (with auto-create package):\ntest := Print[\"Change this text, then execute Save and Run and run test\"]\n\nBy using AddMenuCommands the menu addition only appears when the procedure is run, so doesn't affect the standard setup.  It only needs to be run once, and the menu addition disappears upon restart.  The 'Save and Run' command is placed under Save on the File menu.\n", "bugs - NExpectation behaves oddly with EmpiricalDistribution": "\nThis isn't perhaps exactly what you are looking for but here are some points worth noting.\nIn version 8 NExpectation uses numerical integration and summation methods whereas N[Expectation[...]] uses direct integration or summation and then approximates numerically after the fact. \nThough the idea is for data-distributions in M to behave just like regular distributions they are very different creatures under the hood. EmpiricalDistribution is perhaps the most different in that it is hard to categorize as discrete or continuous (whereas something like HistogramDistribution or SmoothKernelDistribution is continuous). \nTaking both of these into consideration, general NExpectation methods won't work for EmpiricalDistribution directly out of the box.\nExpectations for EmpiricalDistribution are computed in the same way as those for raw lists of data.  For example...\nExpectation[f[x], x \\[Distributed] Range[10]] == Expectation[f[x], \n   x \\[Distributed]EmpiricalDistribution[Range[10]]]\n\n==> True\n\nThis is effectively accomplished by simply mapping the function f over the list and taking the mean. \nIn my opinion there isn't a very good reason not to have a special case for NExpectation[EmpiricalDistribution[...]] that is effectively N[Expectation[EmpiricalDistribution[...]]]. It just isn't there in 8.\n", "list manipulation - What is the cleanest way to prevent divide-by-zero warnings?": "\nYou could remove the zero from the denominator, and the corresponding entry from the numerator:\na = {1, 2, 3, 4};\nb = {5, 6, 0, 8};\n\nPick[a, Positive[b]]/Pick[b, Positive[b]]\n\n(*\n==> {1/5, 1/3, 1/2}\n*)\n\n", "export - Support for Compressed Sparse Column sparse matrix representation": "\nThe first Google hit for \"compressed sparse column\" is this page, which explains that it's also called the Harwell-Boeing format.  If this is what you need, this format is supported by Mathematica.\n", "graphics - Orthogonal Graph layout": "\n=== UPDATE ===\nFunctionality and concept are updated and discussed here:\nOrthogonal aka rectangular edge layout for Graph\n=== OLDER ===\nThe main problem here I think is laying out edges along orthogonal lines. This can be addressed with splines. First define function that triples every element in the list to make a spline to pass sharply through the points. \nmlls[l_] := Flatten[Transpose[Table[l, {i, 3}]], 1];\n\nIn the function below I'll define a special EdgeRenderingFunction, a trick learned from @Yu-SungChang . Using LayeredGraphPlot:\nOrthoLayer[x_] := LayeredGraphPlot[x, VertexLabeling -> True,\n  PlotStyle -> Directive[Arrowheads[{{.02, .8}}], GrayLevel[.3]],\n\n  EdgeRenderingFunction -> (Arrow@\n      BezierCurve[\n       mlls[{First[#1], {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, \n          First[#1][[2]]}, {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, \n          Last[#1][[2]]}, Last[#1]}]] &)]\n\nNow I will use data from HERE and test the function \nOrthoLayer[g]\n\n\nOr similarly using Graph function:\nOrthoLayer[x_] := Graph[x,\n   GraphLayout -> \"LayeredDrawing\",\n  VertexLabels -> \"Name\", VertexSize -> .1, VertexStyle -> Red,\n  EdgeStyle -> Directive[Arrowheads[{{.015, .8}}], GrayLevel[.3]],\n  EdgeShapeFunction -> (Arrow@\n      BezierCurve[\n       mlls[{First[#1], {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, \n          First[#1][[2]]}, {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, \n          Last[#1][[2]]}, Last[#1]}]] &), \n  PlotRange -> {{-.1, 4.4}, {-.1, 2.5}}]\n\nOrthoLayer[g]\n\n\nUsing splines allows us to take advantage of various GraphLayout settings and still keep orthogonal edges.\ng = {\"John\" -> \"plants\", \"lion\" -> \"John\", \"tiger\" -> \"John\", \n   \"tiger\" -> \"deer\", \"lion\" -> \"deer\", \"deer\" -> \"plants\", \n   \"mosquito\" -> \"lion\", \"frog\" -> \"mosquito\", \"mosquito\" -> \"tiger\", \n   \"John\" -> \"cow\", \"cow\" -> \"plants\", \"mosquito\" -> \"deer\", \n   \"mosquito\" -> \"John\", \"snake\" -> \"frog\", \"vulture\" -> \"snake\"};\n\nOrthoLayer[x_, st_] := \n Graph[x, GraphLayout -> st, VertexLabels -> \"Name\", VertexSize -> .3,\n   VertexStyle -> Red, \n  EdgeStyle -> Directive[Arrowheads[{{.015, .8}}], GrayLevel[.3]], \n  EdgeShapeFunction -> (Arrow@\n      BezierCurve[\n       mlls[{First[#1], {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, \n          First[#1][[2]]}, {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, \n          Last[#1][[2]]}, Last[#1]}]] &), PlotRange -> All, \n  PlotRangePadding -> .2]\n\nOrthoLayer[g, #] & /@ {\"CircularEmbedding\", \"LayeredDrawing\", \n  \"RandomEmbedding\", \"SpiralEmbedding\", \"SpringElectricalEmbedding\", \n  \"SpringEmbedding\"}\n\n\nNot perfect, but a start. Many things can be adjusted to customize specific data.\n", "Syntax for prefix mode with multiple arguments using @ shorthand": "\nIf you use Sequence instead of List for listing the multiple arguments, then @ also works: \nf@Sequence[x, y, z]\n(* ==> f[x, y, z]  *)\n\nor\nf@({x, y, z}/.List->Sequence)\n\n", "syntax - Using D to find a symbolic derivative": "\nIf you need to work with a set of variables symbolically, but you also need to substitute in values for them occasionally, a good approach is to use a rule list:\nvalues = {a -> 0.04, L1 = 1, L0 -> 1}\n\nIf the symbols have no values assigned, you can use them normally in symbolic calculations:\nL[s_, L0_, L1_, a_] := L1 + L0/(1 + s/a)\n\nD[L[s, L0, L1, a], s]\n\n(* ==>  -(L0/(a (1 + s/a)^2)) *)\n\nWhen you need to substitute in numerical values, use ReplaceAll:\nD[L[s, L0, L1, a], s] /. values\n\n(* ==> -(25./(1 + 25. s)^2) *)\n\nI wrote a bit more about using parameter list (rule lists) in this answer.\n", "plotting - Real Size Image Printing": "\nQuite redundant after the other answers and links, but I use something like this for vector-based technical drawings and CNC data (using mm as unit). This is not foolproof  as it might e.g. screw up with conflicting options and such, so make sure to check the output.\nImportant: SetPlotRange for your graphics explicitely: \ngfx = Graphics[Line[{{10, 10}, {110, 10}, {110, 110}}], \n  PlotRange -> {{0, 200}, {0, 200}}]\n\nExportScaled[filename_, gfx_, format_: {210, 297}, opts___?OptionQ] :=\n  Module[{mm}, mm = 72/25.4;\n  Export[filename, \n   Show[gfx, ImageSize -> format*mm, ImageMargins -> 0, \n    ImagePadding -> None, AspectRatio -> Automatic], opts]]\n\nFor proper scaling, your graphics\u00b4 PlotRange and the exported ImageSize need to correspond.\nExportScaled[\"test.pdf\", gfx, -Subtract @@@ (PlotRange /. \n     Options[gfx, PlotRange])]\n\nBelow: Output measured in Acrobat (Again: It is usually a good idea to test a few cases by measuring them with Ghostview, Acrobat or such. Works just as well for EPS export).\n\n", "Is it possible to get the order of inputs when \"overloading\" an orderless function?": "\nWell, you can sort of do this, by creating something like a continuation. This requires playing games with the Stack, and I don't claim that it is robust, but it may represent some theoretical interest, particularly to those of us looking for ways to implement continuations in Mathematica. Here is the code  (edit please note that I had to add Update[matrix] to address some improper behavior noted in the comments end edit):\nClearAll[matrix, inMatrix];\nmatrix /: HoldPattern[Times[pre___, a_matrix, post___]] :=\n  (\n      Update[matrix];\n      ReleaseHold[NonCommutativeMultiply @@@ $stack]\n  );\nmatrix[args__] /; ! TrueQ[inMatrix] :=\n  Block[{inMatrix = True},\n    Update[matrix];\n    $stack = Stack[_][[-5]];\n    matrix[args]]\n\nIt combines UpValues, Villegas-Gayley trick to redefine a function, and manipuations with Stack. What happens is that first, of course, the attributes of Times are applied, I can't fight that. Then, the DownValues of matrix are applied, and at this point I record the relevant part of the Stack. Then, UpValues of matrix are applied, and at that point I communicate the recorded part of the stack, where the attributes of Times weren't yet applied, and Times gets replaced with NonCommutativeMultiply, after which I re-evaluate this, as if it was not evaluated before. The Update sommand is used to prevent caching the values for the $stack, as this is inappropriate here and resulted in some erroneous behavior noted in the comments. \nHere are some examples:\na = matrix[\"a\"];\nb = matrix[\"b\"];\n\na*c*b\n\n\nmatrix[a]**c**matrix[b]\n\nf[g[1 + c*a*d*b*e]]\n\n\nf[g[1 + c ** matrix[\"a\"] ** d ** matrix[\"b\"] ** e]]\n\nI would not probably recommend such tricks for serious use, it is just interesting that you can use them to divert evaluation sequence in ways which seem to be impossible otherwise.\n", "export - How to save all data in all variables so that loading it is fast?": "\nAssuming you haven't placed your variables in a non-standard context you can save them all at once using DumpSave's second syntax form, which saves everything in the indicated context.\nQuit[] (* start a fresh kernel *)\n\nx = 1; (* define some symbols *)\ny = 2;\nz[x_] := x^2\n\nNames[\"Global`*\"] (* Check they're there *)\n\n(* ==> {\"x\", \"y\", \"z\"}  *)\n\n(* Save everything in the context *)\nDumpSave[\"C:\\\\Users\\\\Sjoerd\\\\Desktop\\\\dump.mx\", \"Global`\"];    \n\nQuit[] (* kill kernel to simulate a new start *)\n\nNames[\"Global`*\"] (* Are we clean? *)\n(* ==> {} *)\n\n(* Get the save symbols *)\n<< \"C:\\\\Users\\\\Sjoerd\\\\Desktop\\\\dump.mx\"\n\n(* Are they there? *)\nNames[\"Global`*\"]    \n(* ==> {\"x\", \"y\", \"z\"} *)\n\nz[y]    \n(* ==> 4 *)\n\n", "Implementing bookmarks in the front end when editing a package": "\nThis answer implements Ajasja's suggestion from the comments to use comments (e.g., (* ::BOOKMARK::7:: *)  ) as bookmarks and simply finds them with NotebookFind. \nThe following code (when inserted into KeyEventTranslations.tr) binds Ctrl-Alt-Numpad 1 to creating a (sequentially numbered) bookmark comment at the cursor location and Ctrl-Numpad 1 to cycling through the bookmark comments.\nOne could also modify this code to bind a number of named bookmarks to specific shortcuts. \nItem[KeyEvent[\"Keypad1\", Modifiers -> {Control, Command}],\n    FrontEndExecute[{\n        NotebookWrite[InputNotebook[], \" (* ::BOOKMARK::\" <> \n            Block[{Inherited = 1}, \n                ToString[Increment[CurrentValue[InputNotebook[], {TaggingRules, \n                \"BookmarkCounter\"}]]]] <> \":: *) \" ]\n    }],\n    MenuEvaluator->Automatic\n],\n\nItem[KeyEvent[\"Keypad1\", Modifiers -> {Control}],\n    FrontEndExecute[{\n        FrontEnd`NotebookFind[FrontEnd`InputNotebook[], \"(* ::BOOKMARK:\"]\n    }]\n], \n\n", "interoperability - How can I deploy DLL files created by a Fortran function and call them from Mathematica": "\nEven the path is corrected, it still cannot run, since the argument type should {\"double*\", \"double*\"}.\nHere is my memo on calling dll created by gfortran using NETLink:\n\nAdvantages of NETLink as compared to Mathlink:\n\nFortran functions and subroutines can be called using NETLink without writing an additional C wrapper which is necessary in Mathlink. \nNETLink can access all the functions and subroutines in the fortran code by calling the dll file, not only one.\nAnd it seems to me NETLink is faster than Mathlink.\n\nCalling a fortran function\n\n\nSuppose we have a fortran code testfunction.f90\nREAL(8) FUNCTION testfunction(x,y)\n  REAL(8), DIMENSION(2) :: x\n  REAL(8) :: y\n  testfunction = (x(1)+x(2)) * y\nEND FUNCTION\n\nWe can compile it and build a dll\ngfortran -c testfunction.f90\ngfortran -shared -mrtd -o testfunction.dll testfunction.o\n\nNow the function testfunction(x,y) in testfunction.dll can be called after loading the .NET/Link package\nNeeds[\"NETLink`\"]\nReinstallNET[\"Force32Bit\" -> True]; (* or InstallNET[\"Force32Bit\"->True] *)\n\n(* set to the directory of the notebook, and the dll file is in the same dir *)\nSetDirectory[NotebookDirectory[]]; \npath = FileNameJoin[{Directory[], \"testfunction.dll\"}];\nTestFunction = DefineDLLFunction[\"testfunction_\", path, \"double\", {\"double[]\", \"double*\"}];\n\nTestFunction[{1.0, 2.0}, 3.0] gives the correct result 9.0.\nExplanations:\nDefineDLLFunction: the first argument is the function name to be called. It has changed from testfunction to testfunction_, and might be TESTFUNCTION or other depending on the fortran compiler. path is the complete path to the dll file. \"double\" is the return type. The last argument contains the types of the arguments. Note the presence of [] for an array and * for others. \nIf * is missing, there will be an error message saying \nNET::netexcptn: A .NET exception occurred: \nSystem.AccessViolationException: Attempted to read or write protected memory. \nThis is often an indication that other memory is corrupt. \nat Wolfram.NETLink.DynamicDLLNamespace.DLLWrapper...testfunction_(Double[],Double).\n\nIf [] is missing or written as * by mistake, the error message is\nNET::methodargs: Improper arguments supplied for method named testfunction_.\"\n\nBefore making revisions to the dll file, one should use ReinstallNET[\"Force32Bit\" -> True] to quit and restart the .NET runtime\n\nCalling a fortran subroutine\n\nsee also the post here\ntestsubroutine.f90\nSUBROUTINE testsubroutine(x,y,z)\n  REAL(8), DIMENSION(2), INTENT(in) :: x\n  REAL(8), INTENT(in) :: y\n  REAL(8), DIMENSION(2), INTENT(out) :: z\n  z(1) = x(1) * y\n  z(2) = x(2) * y\n  RETURN\nEND SUBROUTINE\n\ntestsubroutine.dll can be built as before. In Mathematica, after loading NETLink and ReinstallNET[\"Force32Bit\" -> True],\npath2 = FileNameJoin[{Directory[], \"testsubroutine.dll\"}]\nTestSubroutine = DefineDLLFunction[\"testsubroutine_\", path2, \"void\", \n{\"Double[]\", \"Double*\", \"Double[]\"}]\n\nNow we should create a .NET object, which is to be sent to testsubroutine_ at the place of z to store the results\n(* Any real or integer numbers can be put in the list. \n\"System.Double[]\" is necessary if any of the numbers is an integer. *)  \nres = MakeNETObject[{0, 0.}, \"System.Double[]\"] \n\nNow let's test a case:\nTestSubroutine[{1., 2.}, 3., res] (* res receives the calculated results *)\n\n(* translate the .NET object results into a Mathematica expression  *)\nNETObjectToExpression[res]  \n\nThe results are the desired {3., 6.}.\n", "image processing - How to record the stream of data (PixelPosition) dynamically?": "\nFile Output\nUse an output stream.\ns = OpenWrite[\"your_filename\"];\n\nDynamic[With[{a = ImageKeypoints[EdgeDetect[CurrentImage[], 30], \"PixelPosition\"]}, \n  Write[s, a]; a], Deinitialization :> Close[s]]\n\nIt will close the stream upon the deletion of the dynamic cell. It is not a bad idea to put time stamp with it.\nDynamic[With[{a = ImageKeypoints[EdgeDetect[CurrentImage[], 30], \"PixelPosition\"]}, \n      Write[s, AbsoluteTime[] -> a]; a], Deinitialization :> Close[s]]\n\nNotebook Output\nUse NotebookWrite.\nDynamic[With[{a = ImageKeypoints[EdgeDetect[CurrentImage[], 30], \"PixelPosition\"]}, \n  NotebookWrite[nb, Cell[RawBoxes[ToBoxes[a]]]]; a],\n  Initialization :> (nb = CreateDocument[, WindowTitle -> \"PixelPosition\"])]\n\nAppending to List\nAlready answered by Mr. Sjoerd C. de Vries...\n", "export - Exporting animations under duration constraints for viewing on an iPad": "\nThere exists no movie format on the iPad that can do a frame duration of .001 seconds. 30 frames per second (as for NTSC video) is the fastest you'll be able to do, corresponding to roughly .03 seconds per frame. This means your movies will be 100 seconds long if it has 3000 frames. \nIt is easy to export a list of frames to Quicktime (Apple's own format) if you run Mathematica on the Mac:\nExport[\"movie.mov\", frameList]\n\nshould do it. \nFor more control, you would follow these instructions:\nAfter making the list of frames by creating a Table of Graphics and calling the output list frameList, execute the following line:\nMap[Print, frameList]\n\nThis will create all the plots conveniently bracketed in a CellGroup which you can select with a single click. With this, QuickTime export can proceed by selecting in the Frontend menu the item Edit \u2192 Save Selection As.... Quicktime.\nIf you want even more control, e.g., to select a different display duration for each frame, just use (assuming you're on a Mac) the export function defined in the linked answer. To get a single constant frame duration d (in seconds), you'd invoke it as exportMov[\"movie.mov\", frameList, {d}].\nIf this still doesn't satisfy you, it's always possible to export the individual movie frames and use an external program to make the final movie, as described in this answer.\n", "Evaluating a function using arguments from a sliding window over a list": "\nThere is a function exactly for this: Developer`PartitionMap:\nDeveloper`PartitionMap[f, {1, 2, 3, 4, 5, 6}, 3, 1]\n(* {f[{1, 2, 3}], f[{2, 3, 4}], f[{3, 4, 5}], f[{4, 5, 6}]} *)\n\nThe first argument to Developer`PartitionMap is the function that's being used (f) and all successive arguments and options are exactly the same as in Partition. \n", "performance tuning - Speeding up random walk for many particles": "\nThis will give a modest improvement. I'm probably missing a few more though.\nOne other remark: this way of choosing a \"random\" direction is far from uniform.\nnumparticles = 10^4;\nnumsteps = 10^3;\nradius = 1.;\nparticles = ConstantArray[{1.001, 0., 0.}, numparticles];\nrnew = Map[#.# &, particles];\nnumcrossings = ConstantArray[0., numparticles];\n\nIn[120]:= \nrunSim = Compile[{{numsteps, _Integer}, {radius, _Real}, \\\n{origparticles, _Real, 2}},\n   Module[\n    {numparticles, thetarand, phirand, rold, rnew, next, \n     particles = origparticles, isitoutside, switchsides, \n     numcrossings},\n    numparticles = Length[particles];\n    numcrossings = ConstantArray[0., numparticles];\n    rnew = Map[#.# &, particles];\n    Do[thetarand = RandomReal[{0., Pi}, numparticles]; \n     phirand = RandomReal[{0, 2.*Pi}, numparticles];\n     rold = rnew;\n     next = \n      Transpose[\n       0.01*{Sin[thetarand]*Cos[phirand], Sin[thetarand]*Sin[phirand],\n          Cos[thetarand]}];\n     particles = particles + next;\n     rnew = Map[#.# &, particles];\n     isitoutside = (rold - radius)*(rnew - radius);\n     switchsides = Clip[isitoutside, {0, 0}, {1, 0}];\n     numcrossings = numcrossings + switchsides;\n     , {numsteps}];\n    Round[numcrossings]\n    ], CompilationTarget -> \"C\"];\n\nIn[121]:= Timing[nc = runSim[10^3, radius, particles];]\n\nOut[121]= {1.53, Null}\n\n", "symbolic - Representing a value in an output as a self defined variable": "\nMy solution below uses TagSetDelayed and associates the transformation rules with Power. Although I very much dislike using structural manipulations for such purposes, it might be a viable option here since the use case is narrow.\nUnprotect[Power]\nPower /: Power[-1, Rational[n_Integer, _]] := \u03c1^n\nProtect[Power]\n\n\n\nIf you want to define it only for the cube roots of unity, you needn't use a general pattern like the above. Instead, restrict it by changing the _ to 3.\n", "plotting - Why does the shape of my function change when plotted alongside another function?": "\nAll the plots are correct, but what may be catching you out is the windowing of the Y-axis and your tick specification. Adding PlotRange -> {{-4, 4}, {0, 2}} should help you see what is happening.\nPlot[Cos[Cos[x]], {x, -4, 4}, Ticks -> {Table[x*Pi, {x, -2, 2, 1/2}]},\n  AspectRatio -> .1, PlotRange -> {{-4, 4}, {0, 2}}]\n\n\nPlot[Cos[Sin[x]], {x, -4, 4}, Ticks -> {Table[x*Pi, {x, -2, 2, 1/2}]},\n  AspectRatio -> .1, PlotRange -> {{-4, 4}, {0, 2}}]\n\n\nSo for the combined plot you would get:\nPlot[{Cos[Cos[x]], Cos[Sin[x]], Cos[Cos[x]] + Cos[Sin[x]]}, {x, -Pi, \n  Pi}, Ticks -> {Table[x*Pi, {x, -1, 1, 1/2}]}, AspectRatio -> 1/2, \n PlotRange -> {{-4, 4}, {0, 2}}]\n\n\n", "notebooks - NotebookFind and String Pattern Expressions": "\nOk so this is going to be a long one. This is definitely not a general purpose implementation, but It shows the general idea that one could use.\nSo you basicly want to be able to type out NotebookFind[\"(.?foo\\d.?)\"], which would match to for example \"(something something foo4 dark side)\". However you only want it to highlight foo4, and not the rest. So the way to do this is to first search through the notebook and figure out that our pattern matches the entire string, and search only for the particular realized sub-expression \"foo4\" and figure out which of the potentially many search result for foo4 collides with the search for the entire pattern. \nSo for the purpose of this implimentation I'll assume that you have a RegularExpression pattern, where the part you want to highlight the first matched subpattern (Which means you enclose it in parenthesis in the search string). So the above pattern would be: RegularExpression[\"[(].?(foo[\\d]+).?[)]\"]. We then:\n\nsearch through strings in the notebook expression for cases where this matches\nthen extract the subexpression matched, \nthen sort out how many times we match the subexpression without matching the full.\nThen call NotebookFind[] enough times to land on the correct match.\n\nSo here goes for the actual code. It doesn't work for matching notebook level expressions and only searches through strings. \nThis function just creates a pattern for the actual substitution based on the search pattern.\nStringPatternWrapper[stringpattern_]:=  \n (a_String/;StringMatchQ[a,stringpattern]):>StringCases[a,stringpattern:>\"$1\"]\n\nThis function finds the positions and cases of the matched pattern. The pattern provided for this function should first be sent through StringPatternWrapper[]-\n findPostionAndExactMatch[nbexp_,pattern_]:=\n     {Position[nbexp,pattern[[1]],\u221e],\n      Cases[nbexp,pattern,\u221e]}//ridiculousFormatingFunction\n\nwhere ridiculousFormatingFunction is a messy function for reformating the output.\n ridiculousFormatingFunction[list_] := \n    Map[(a\\[Function]Map[{a[[1]],#}&,a[[2]]]),Transpose[list]]//\n    (Flatten[Table[{#[[1,1]],#[[1,2]],n},{n,1,#[[2]]}]&/@Tally[Flatten[#,1]],1])&\n\nAnd then a function for finding all the matches to the matched subexpression\nfindAllExactMatches[nbexp_,exact_] := \n  Flatten[Map[Table[#, {Length@StringCases[nbexp[[Sequence@@#]],exact]}]&,\n  Position[nbexp,a_String/;StringMatchQ[a,exact],\u221e]],1]\n\nBecause some stings might contain more then one match, we need some fixing of the numbers\nrepeatNumberForMatch[match_,nbexp_] := \nFirst@Position[\n    findAllExactMatches[nbexp,RegularExpression[\".*?\"<>match[[2]]<>\".*?\"]],match[[1]]\n][[match[[3]]]]\n\nAnd finally we have a nice little function which returns a list of all the matches, which expressions they apear in, and how many times you need to skip when using NotebookFind.\n matchTable[nbexp_,pattern_] := Prepend[#,repeatNumberForMatch[#,nbexp]]&/@\nfindPostionAndExactMatch[nbexp,pattern]\n\nHere is an output example from Match table using the provided example notebook below:\n  matchTable[NotebookGet[nb], \n   StringPatternWrapper[\n    RegularExpression[\".*?\" <> \"[(].*?(foo[\\\\d]+).*?[)]\" <> \".*?\"]]] //\n   Prepend[#, {\"Repat find number\", \"Indices\", \"Exact Match\", \n     \"Number inside string\"}] & // Grid\n\n\nHere is a short usage example \nnotebookFindN[nb_,find_,n_]:=\n    (SelectionMove[nb,Before,Notebook];Do[NotebookFind[nb,find,Next],{n}])\n\nclickerUI[nb_,pattern_]:=\n    Button[#[[3]],notebookFindN[nb,#[[3]],#[[1]]]]&/@matchTable[NotebookGet[nb],pattern]\n\nAnd some test code and a test notebook:\n nb = {\n     Cell[\"This is a direct match for the realised sub-pattern foo1 but not the full\", \"Text\"], \n     Cell[\"This is another match identical to the realised one foo2, and still not the full, however this one needs to be skiped when using NotebookFind\", \"Text\"],\n     Cell[\"And finally ( we have a full match for foo2 the pattern ) (foo2) <- That's another one, and so is that -> (foo4)\", \"Text\"],\n     Cell[\"Some times a single string can have more then one entry foo2 foo2, so we need to count how many and which ones we are looking for, which makes the code slightly messy.\", \"Text\"],\n     Cell[\"And finally ( we have one last full match for foo2 ) enclosed in parenthesis\", \"Text\"]\n     } // CreateDocument;\n\n clickerUI[nb, \n   StringPatternWrapper@\n   RegularExpression[\".*?\" <> \"[(].*?(foo[\\\\d]+).*?[)]\" <>\".*?\"]\n ] // Row\n\nHope this can be of some help. Personally I'd like to have code that could equally well search though strings and notebook level expressions, however this requires a better structuring of the method I think. \n", "probability or statistics - Wald\u2013Wolfowitz Runs Test": "\nThis is not built into the system as far as I can tell. However, it's a really good example of how to construct a fairly sophisticated function using just a few lines of code. I've taken the definition directly from the Wikipedia page, and applied it to Sign[data] on the assumption that if you are testing residuals from a regression, you are interested in runs of positive and negative values. \nrunstest[x:{__?NumericQ}] := \n Module[{n = Length[x], res = Sign[x], n1, n2, runs, mu, sig2, y},\n  {n1, n2} = Last /@ Tally[res];\n  runs = Split[res];\n  mu = 2 n1 n2/n + 1;\n  sig2 = (mu - 1) (mu - 2)/(n - 1);\n  NProbability[y <= Length[runs], \n    y \\[Distributed] NormalDistribution[N@mu, N@sig2]] ]\n\nSome notable things about this code:\n\nThe pattern {__?NumericQ}. This ensures that the function only works on vectors of numeric data.\nThe use of local variables via Module, some of which can be set initially in the first argument of Module, while others can wait till later, perhaps because they depend on other local variables.\nThe use of Tally and Split, built-in functions that automatically divide lists into sublists of like elements.\nThe use of NProbability to work out the one-tailed test. Alternatively the last line could be something like N@CDF[NormalDistribution[mu, sig2], Length[runs]]: it gives the same answer except where the p-value is so tiny that numerical error creeps in (but seriously, who cares if it's $10^{-16}$ or $10^{-20}$?). It's possible that you want to express the test a different way, in which case that line is easy to modify.\n\nHere is some test data that should definitely be rejected as random because of strong serial correlation: \ntestdata1 = \n  FoldList[0.98 #1 + #2 &, RandomReal[], \n   RandomVariate[NormalDistribution[0, 0.5], 100]];\n\nAnd here is some data that should probably pass the test.\ntestdata2 = RandomVariate[NormalDistribution[0, 0.5], 100];\n\nSure enough:\nrunstest[testdata1]\n\n(* -7.90479*10^-14 *)\n\nrunstest[testdata2]\n\n(* 0.451757 *)\n\n", "Simplify an expression containing NonCommutativeMultiply": "\nWhat you need here is actually expanding the expression (i.e. transforming all (a+b) ** c type expressions to a**c + b**c).  There's no built-in support for this kind of manipulation of non-commutative expressions.  You'd need to implement them yourself, which can be quite a bit of work.\nHowever, instead of bothering with implementing all these simple operations yourself, I recommend using a dedicated package.  @gpap suggested the NCAlgebra package in an answer to your previous question.\nAfter installing NCAlgebra by placing the NC directory in my $UserBaseDirectory/Applications directory, I could do this:\n<< NC`\n<< NCAlgebra`\n\nexpr = -a ** (b ** c - c ** b) + b ** (a ** c - c ** a) - \n  c ** (a ** b - b ** a) + (a ** b - b ** a) ** \n   c - (a ** c - c ** a) ** b + (b ** c - c ** b) ** a\n\nNCExpand[expr]\n\n(* ==> 0 *)\n\n", "parallelization - Does parallel programming use up large quantities of memory in Mathematica?": "\nFirst off, you shouldn't be worried that Mathematica hasn't returned the memory to the system. The memory may as well be (and is being) held onto by the process that last had it, and if some other program needed this memory it would be handed back to the system without a problem.\nMaxMemoryUsed reports the maximum amount of memory used, but it is only interacting to the current kernel. If you wanted to interact with the other kernels, you would have to use ParallelEvaluate. This paper contains a nice example of a table displaying the max memory used on each processor, along with the processor ID and some other information. (You will have to update some of the commands though, it was written in 2004.)\nWhen I have used ParallelTable commands in the past I always was sending the bulk of the data in my current application for processing through ParallelTable, and so an entire copy of the data often was transferred to the memory of each parallel kernel. The answer by acl points out that the memory sent to each parallel kernel is dependent on what you send to it, and it may not necessarily need to send the entire memory state from the main kernel.\nWhat OS are you running Mathematica on? In Linux, pulling up the System Monitor (or a command like top) should show the kernels loading in real-time, and if you sort by memory you should get a very clear picture of what's happening.\nI don't have any tips to avoid this - it's a trade off, if you want faster processing of data and you have the RAM to spare then use the ParallelTable command. If you don't have the RAM to spare then stick with the regular Table command and brew some coffee.\nAs a last ditch attempt to scrape up some spare RAM, you can try throwing the Share[] command in every once in a while, but I haven't seen significant improvements from this myself either. As long as you're not actually running out of RAM, however, it's nothing to worry about. The fact that Mathematica hangs on to that extra RAM even after it's done processing the data is standard procedure, and you shouldn't concern yourself with it. If you want to prove that another application can access that RAM if needed, just run some RAM intensive process and watch in real time using the System Monitor / top.\n\nI was reminded by Albert Retey that you can use distributed contexts to reduce the amount of information transferred to each kernel. The effectiveness of this approach will vary with your particular application, i.e. if you have a lot of information in memory before you perform ParallelTable on a small subset of that data.\n", "compile - How do I get Mathematica to recognize a C compiler on a 64-bit Windows machine?": "\nFirst, be sure to read the Specific Compilers section of the CCompilerDriver User Guide.  This is the official place where the nuts and bolts of using external C compilers is discussed.\nIn that section, \"Visual Studio Express and 64-Bit Targets\" is where compilation on 64-bit Windows is discussed.\nSome things to check when setting up:\n\nBe sure to install .NET Framework 4 before Windows SDK 7.1.  Without this, the Windows SDK installer may (if you don't have it) give a warning about this, and the Visual C++ component will be grayed out.  \nIn the install wizard for the Windows SDK, be sure any components that say \"Visual C++\" are selected for installation.\n\nIf you're not sure if you have the .NET Framework 4, you can try running the Windows SDK 7.1 installer and look carefully for a warning dialog.  If you don't get a dialog warning that .NET Framework is not detected, and the Visual C++ component is selectable for installation, then you may proceed with installing just the Windows SDK.\nI can confirm that you don't need to install Visual Studio Express first, you can get away with installing only the .NET Framework 4 (if needed) and then the Windows SDK.\nEdited to add:\nIn answer to \"If the compiler is installed correctly, should Mathematica automatically recognize it, or do I have to point Mathematica to a very specific folder to find it?\", for Visual Studio it is automatically recognized through an environment variable or the registry.  Of the compilers that are directly supported, as opposed to a \"Generic\" C compiler, they are all automatically detected in some form, depending on the specifics of the compiler.\n", "export - Converting a notebook to plain text programmatically": "\nSaving is done by the front end, which you can exploit programatically by using FrontEndExecute. I think this is what you need:\nnb=InputNotebook[];\nfn=FileNameJoin[{\"output.txt\"}];\nFrontEndExecute[FrontEndToken[nb,\"Save\",{fn,\"Text\"}]]\n\nEdit: Of course you can also save it as a package by replacing \"Text\" with \"Package\".\n", "plotting - How do I plot Thomae's function in Mathematica?": "\nI'd suggest producing a list of rational numbers and then plot the function there, like so:\nmaxq = 100;\nfracs = Table[p/q, {q, 2, maxq}, {p, 2, q}] // Flatten // DeleteDuplicates;\npq = {#, 1/Denominator @ #} & /@ fracs;\n\nListPlot[pq, PlotRange -> {0, 1}]\n\n\n", "plotting - Creating Marker (Tags) on Top of Plots": "\nThe interesting question is: how do we get labels into a plot without having the frame and/or axis range of that plot automatically adjust to enclose the labels. After all, you want labels on top of the plot, which means they will have to be \"hovering\" above the maximum vertical height of the axes. \nI think Overlay is really good for such tasks in principle. Let's say the y-axis is supposed to extend from $-5$ to $5$, then the first thing we have to do is create some empty space on top of that range. This can be done by setting PlotRegion. In the plot below, I want the extra height (in the coordinate system of the plot) to be up to yExtra = 8.5. \nThe problem with Overlay is that it aligns two objects using scaled coordinates that are \"agnostic\" of the plot coordinates we're interested in (e.g., the center of the plot is always {0, 0} for Overlay). But we are trying to put labels at specific horizontal positions in the original plot coordinates.\nTo make the overlays align properly, especially in the horizontal direction where the placement has to be most accurate, I put the annotation into an invisible copy of the original plot. That guarantees that the overlays will fit together nicely:\ng = With[{yMax = 5, yExtra = 8.5},\n  p = Plot[\n    {-.1 x, Tan[x]}, {x, 0, 3 Pi},\n    PlotRange -> {-yMax, yMax},\n    AxesLabel -> {x, y},\n    ImageSize -> 400\n    ];\n  Overlay[{\n    Show[p,\n     PlotRegion -> {{0, 1}, {0, 2 yMax/(yMax + yExtra)}}],\n    Show[p, \n     AspectRatio -> (AspectRatio /. \n         Options[p, AspectRatio]) (1 + yExtra/yMax)/2, \n     BaseStyle -> Opacity[0],\n     PlotRange -> {-yMax, yExtra},\n     Epilog -> {Opacity[1], \n       Table[{Arrow[{{(2 i + 1)/2 Pi, 6.5}, {(2 i + 1)/2 Pi, \n            5.5}}], \n         Text[Row[{x, \" = \", (2 i + 1)/(2 L) Pi}], {(2 i + 1)/\n            2 Pi, 7.4}]}, {i, 0, 3}]}\n     ]\n    }\n   ]\n  ]\n\n\nThe invisible layer is created in Show[p, BaseStyle -> Opacity[0]... and the annotation is added to that layer as Epilog -> {Opacity[1],... (the specific annotation with text and arrows is created in the Table). \nFor the original plot p, I use Show[p, PlotRegion ->...] to make sure it is shown with the empty space on top. That PlotRegion specification can't be added to the initial definition of p because then it would disappear when the plot is displayed inside Overlay.\nThe horizontal coordinates of the original plot and the overlay are identical, but the vertical coordinates are not. This is due to the axis label y that isn't contained in the spacing calculations.\nHowever, you can now use the Epilog in the overlay to add annotations that overlap the plot any way you like - partly inside and outside of the coordinate frame. E.g., you could try changing the Arrow specification above to Arrow[{{(2 i + 1)/2 \u03c0, 6}, {(2 i + 1)/2 \u03c0, 4}}] to make the arrows reach deeper into the plot:\n\nEdit: make it prettier\nA separate issue is to make the arrows nicer:\nWith[{yMax = 5, yExtra = 7.5}, \n  p = Plot[{-.1 x, Tan[x]}, {x, 0, 3 Pi}, PlotRange -> {-yMax, yMax}, \n    AxesLabel -> {x, y}, ImageSize -> 400];\n  Overlay[{Show[p, \n     PlotRegion -> {{0, 1}, {0, 2 yMax/(yMax + yExtra)}}], \n    Show[p, AspectRatio -> (AspectRatio /. \n         Options[p, AspectRatio]) (1 + yExtra/yMax)/2, \n     BaseStyle -> Opacity[0], PlotRange -> {-yMax, yExtra}, \n     Epilog -> {Opacity[1], \n       Table[{Arrow@\n          BezierCurve[{{(2 i + 1)/2 Pi, 6.5}, {(2 i + 1)/2 Pi + 1, \n             5}, {(2 i + 1)/2 Pi, 3.5}}, SplineDegree -> 2], \n         Text[Row[{x, \n            \" = \", (2 i + 1)/(2 L) Pi}], {(2 i + 1)/2 Pi - .5, \n           6.5}]}, {i, 0, 3}]}]}]]\n\n\nThe arrows have been modified to have a curved appearance by using BezierCurve. All you have to do is replace Arrow by Arrow@BezierCurve and add one extra point in-between the start and end point of the original (straight) arrow. That point is the handle that pulls the curve to one side. \n", "plotting - How can I turn off SingleLetterItalics in PlotLabel, etc, when the Options Inspector won't do it?": "\nI don't know if it qualifies as an answer to your question if I suggest to change the structure of the labeling in the first place. As you write it, the m is -- from the rendering point of view -- treated  as a symbol, if you inclose it with quotation marks it will be treated as a string and no auto-italic is performed at all. E.g.:\nPlotLabel -> \"Test Label in k(\\!\\(\\*SuperscriptBox[\\(\\\"m\\\"\\), \\\\(2\\)]\\))\"\n\ninstead of\nPlotLabel -> \"Test Label in k(\\!\\(\\*SuperscriptBox[\\(m\\), \\(2\\)]\\))\"\n\nanother thing you should be aware of is that you can use arbitrary expressions as labels, e.g.:\nPlotLabel -> Row[{\"Test Label in k(\", Superscript[\"m\", 2], \")\"}]\n\nwhich I find much easier to automatically create and manipulate as well as manually maintain than those cryptic strings...\nIf, as your comments suggest, you don't have control over how these labels are created, the following could be the solution you are after:\nListLinePlot[fakedata101, Filling -> Axis, PlotStyle -> Red, \n  FillingStyle -> Red, \n  PlotLabel -> \"Test Label in k(\\!\\(\\*SuperscriptBox[\\(m\\), \\(2\\)]\\))\",\n  FormatType -> (Style[TraditionalForm[##],SingleLetterItalics -> False] &)\n]\n\n", "linear algebra - Constructing a symbolic Hermitian matrix": "\nBy default, Mathematica assumes symbols to be complex. However the elements on the main diagonal of a Hermitian matrix are necessarily real. To force Mathematica to interpret the elements on diagonal of m to be real you could replace them by their real part, i.e.\nm = {{Re[n], a, b, b}, {Conjugate[a], Re[n], b, b}, \n     {Conjugate[b], Conjugate[b], Re[c], d}, \n     {Conjugate[b], Conjugate[b], Conjugate[d], Re[e]}};\n\nHermitianMatrixQ[m]\n\n(* output: True *)\n\nCholeskyDecomposition[m]\n\n", "plotting - Is it possible to use styled (e.g., colored) text in PlotLabel?": "\nYeah, use Style and Column to format the PlotLabel:\nPlotLabel -> Column[{Style[\"Red curve: x^2\", Red], Style[\"Blue curve: x^3\", Blue]}]]\n\nExample:\n\n", "manipulate - How to use Locators on a graphic in a tabview": "\nMaybe something like\npltrng = {{-1, 1}, {-1, 1}};\n\nManipulate[pnts = LocatorPane[Dynamic[p], \n   Dynamic @ Graphics[Point[p], PlotRange -> pltrng], \n   LocatorAutoCreate -> True];\n tbl = Dynamic @ Grid[MapIndexed[{#2[[1]], #} &, p]];\n ln = Dynamic @  Graphics[{Red, Thick, Line[p]}, PlotRange -> pltrng]; \n bzc = Dynamic @ Graphics[{Blue, BezierCurve[p]}, PlotRange -> pltrng];\n dsk = Dynamic @ Graphics[{Orange, Disk[#, .1] & /@ p}, PlotRange -> pltrng];\n plygn = Dynamic@ Graphics[{Green, Polygon[p]}, PlotRange -> pltrng];\n allviews =  Grid[{{pnts, tbl, dsk}, {ln, bzc, plygn}}, Dividers -> {All, All}];\n Dynamic @ TabView[{\"locators\" -> pnts, \"table\" -> tbl, \"line\" -> ln, \n   \"beziercurve\" -> bzc, \"disks\" -> dsk, \"polygon\" -> plygn, \"all\" -> allviews}, \n   Alignment -> Center], \n {{p, {{-.5, -0.5}, {-.25, .5}, {.6, 0.6}}}, None}]\n\n\n", "cdf format - Mathematica Source-Code Control for CDF files in multi-user scenario": "\nShort answers: \n\nit's very well possible to manage CDF-documents in a source control system, but you will loose some of the more attractive features of such systems.\nmost probably any system will do equally well (or bad).\n\nSome elaboration:\nI don't know TFS, but all source control systems I know basically do work line oriented with plain text documents (which is a very common format for source code after all). It could well be that some source control tools can handle other formats, e.g. office documents, but that I don't know and I'd be very surprised if any could handle notebook files. \nCDF documents basically are just notebook files with a signature, and notebook files are plain text, but unfortunately not line oriented but \"cell oriented\". That means that line breaks will be added and removed even when the content actually (or appearingly) has not changed. Notebooks also do contain formatting information which you might or might not want to be source controlled and they contain caching information which you probably never want to be source controlled. \nAFAIK there is no source control system which is aware of CDF-documents (or notebooks), but I think almost all of them will handle them correctly as \"binary files\". That means they can identify whether files have changed or not but can't provide you with useful information about what has changed or do automated merges in a meaningful way. So many of those features that a source control system makes really useful will not work. So the answer is that yes, you can manage notebooks and CDF-documents in probably any source control system you like, but you will loose much of its power, and I think there is not much difference between them concerning the handling of those files. \nThere are some tools out there which will e.g. remove the caching information on checkin or remove the output cells of a notebook before checkin, which makes some sense for notebooks. But since the signature of a CDF document will become invalid with every change to the document, I don't think that is an option for CDF documents.\nAnother thing to have in mind is that the FrontEnd now handles package files reasonably well and there is also the Workbench, so interest in that direction has declined over the years, and most of those tools seem to be somewhat outdated.\nAnother tool which compensates for the fact the the source control systems can't handle notebook files is the notebook diff that newer versions of Mathematica (or the workbench?) do install under the hood and which pops up rather unexpectedly when using some version control systems and you try to compare two different versions of a notebook. I haven't investigated where that is stored and how you'd configure a source control system to use it if that isn't handled automatically, but you might want to get that working. That at least lets you compare notebook differences much more comfortable then any pure text utility. Another tool worth mentioning is the notebook diff tool in Workbench which lets you make a \"diff\" on the notebook expression of two notebooks and shows that in an extra view. But that view is rather something for a Mathematica programmer interested in the structure than for someone working on the layout of such a document.\nOne more thought: The best thing to do would actually be to generate those CDFs automatically, as WRI is suggesting e.g. in the CDF-Workshop (specifically here). You could then only put the generating code into source control and treat the generated CDF-documents as \"generated content\" like compiled binaries, which of course would not need to be stored within the version control system. But since that would probably be a huge change in how your users have to work, this might not be something you can inforce. Anyway I think it still should be in this answer in case someone is reading it who has the chance to make such a change...\n", "Solving an equation and finding a couple of results given that they are integer": "\nThe following might be of use:\nReduce[x + y == y^2 && x^2 + y != 1, {x, y}, Integers]\n\nTo ease things, we consider the numerator and denominator separately. Here, we are asking Mathematica for conditions on integer x and y such that the numerator is zero, and the denominator isn't.\nSolve[x + y == y^2 && x^2 + y != 1, {x, y}, Integers]\n\nis useful as well.\n\nIf you need examples, you can use\nFindInstance[x + y == y^2 && x^2 + y != 1, {x, y}, Integers, 10]\n\nChange 10 to the number of examples you wish to generate.\n", "output formatting - Question about evaluation control": "\nThis works nicely:\nL[f_, a_, b_] := HoldForm[Integrate[#, {\\[FormalX], a, b}]] &[f[\\[FormalX]]]\n\nNote that I used \\[FormalX] to prevent conflicts with the usual x, which may have had a previous definition. Try L[E^-Sqrt[#] &, 0, 1] with this definition:\n\n", "error trapping - Check does not interrupt evaluation of the expression when a Message is emitted": "\nA simple method for accomplishing this is to have Message Throw an error when it is called, interrupting the current execution. Here is a replacement for Check which does that, with the same calling signature:\nClearAll[InterruptingCheck]\nSetAttributes[InterruptingCheck, HoldAll]\n\nInterruptingCheck[expr_, failexpr_, msgs : {___MessageName } : {}] :=\n Internal`InheritedBlock[{Message, $msgFlag},\n      (* Module localizes tag while not polluting the global namespace *)\n      Module[{ tag },\n      Unprotect[Message];\n      (* \n      Attach hook to message, where failexpr is thrown after the \n      first Message is raised. msgFlag is used to prevent recursion,\n      so that when msg is called the original def is used.\n      *)\n      msg : Message[m_, ___] /; ! TrueQ[$msgFlag] := Block[{$msgFlag = True},\n     msg;\n     If[Length@msgs == 0 || MemberQ[msgs, m], Throw[failexpr, tag]]];\n     Catch[expr, tag]\n  ]\n ]\n\n(* With Leonid's suggestion, this now works correctly. *)\nInterruptingCheck[expr_, failexpr_, msgGroup_String] := \n Hold[msgGroup] /. $MessageGroups /. \n  Hold[messages_List] :> InterruptingCheck[expr, failexpr, messages]\n\n\\begin{Edit}\nMy original code for the supplying a message group failed to work correctly. The fix is shown above.  It works by replacing msgGroup with the appropriate list of messages, but using Hold to prevent them from being replaced by their string equivalents. (That is part of the reason for the HoldAll attribute being used here, to begin with.) Then, the held messages are extracted from Hold and inserted into InterruptingCheck still held because of HoldAll.\n\\end{Edit}\nWhen applied to the example in the question, \nres2 = {};\nInterruptingCheck[\n MapIndexed[\n  If[# < 0, \n    Message[Test::wrpt, #2[[1]]]; Unevaluated[Sequence[]], \n    res2 = {res2, #}; #] &,\n  dat[[;; 10]]~Join~{-1}~Join~dat],\n $Failed,\n     {Test::wrpt}\n     ]\n     (* Test::wrpt: Negative point at 11\n     $Failed\n *)\n\nand res2 is\n{0.288047, 0.026642, 0.361008, 0.28977, 0.573743, \n0.272747, 0.937062, 0.330572, 0.192807, 0.916764}\n\nshowing that it did stop execution at after the tenth element in the data.\n", "list manipulation - Populating and storing a very large array in Mathematica": "\nThe large data framework\nOk, here is a shameless plug for the  large-data framework, which I developed some time ago for similar purposes. While it is not a proper and / or final place to store it, I put its code (straight from the linked post) to this gist, so that it is easier to copy and paste as a single piece of code (note that this is not yet a package).Here, I will illustrate how and why to use it for your case. \nWhy use it here?\nLet us start with why. The short answer: because it was written to address exactly the (rather wide) class of use cases to which the case at hand seems to belong. \nThese are the advantages of using it here:\n\nOnce you convert your array to the file-backed representation, you don't have to care any more about possible kernel crashes - you can always load things back, and load only those parts you need (so, you don't have to think much about the memory either)\nYou don't have to convert your list all at once, neither do you have to wait until you have constructed all its elements. In fact, you can even build the list already in the file-backed form, by using the framework's API (it has two - higher-level for typical operations on lists such as appending a list, and lower-level one for accessing and possibly modifying individual parts of a list).\nThe framework adds syntactic sugar, so that, when working with parts of your list, you use code which looks like it is a normal list. In other words: while the real data structure responsible for the file-backed list is more like a hash-table filled with class instances (with each class instance pointing at a specific file location where the appropriate part of the list is stored), it is hidden by an interface which overloads most list operations and implements the list abstraction in a rather complete way. So, you can work on a much higher, and familiar to most Mathematica users, level of abstraction, and not really be concerned with the details of how the parts of your list are actually backed by files, saved, loaded, etc (not that it is too complicated, but the whole point is in information hiding - these details are largely irrelevant from the point of view of the higher-level operations we perform on lists). For you, this will look just like a regular list, in most important respects.\nYou can release memory used by the loaded parts of your list selectively, and right after you used this part - so the memory used will only be as much as many parts of your list you have to keep in memory at the same time. In the case of writing to a disk, this is just one part.\nYou can set your writing-to-disk code up in such a way that a possible crash in the middle will only invalidate the last part being written, and you will be able to reload the kernel and start from where you stopped - and again, with minimal memory requirements.\n\nHow to use it here\nFirst, run the code of the framework.\nThen, run this initialization code, to switch to .mx files (which are very fast):\n$fileNameFunction = mxFileName;\n$importFunction = mxImport;\n$exportFunction = mxExport;\n$compressFunction = Identity;\n$uncompressFunction = Identity;\n\nNow, we create a test array:\nmyArray = RandomReal[10^6, {10000, 50, 15, 40}];\n\nThis took quite a bit of RAM, so you better have at least 5Gb of RAM available. Now, initialize the symbol used to represent your list in the framework:\nClearAll[test];\ninitList[test]\n\nNow, convert your list to the file-backed list - this is the main operation (use the correct path on your machine. The directory must exist)\nappendList[test,myArray,\n   DestinationDirectory:>\"C:\\\\Temp\\\\LargeData\"\n];//AbsoluteTiming\n\n\n{327.4692831,Null}\n\n\nNote that I have a very fast SSD (like 10x the usual HDD speed), so this part may be slower on your machine, if you have a regular HDD or SSD drive. In any case, several minutes for a file of a couple of Gb large is pretty decent I think.\nNote also that, if you monitor the memory consumption, the additional memory used by this procedure is very little - below 50Mb according to what I saw.\nNow, the last step: save the main symbol (again, use the correct path on your machine):\nstoreMainList[test,DestinationDirectory:>\"C:\\\\Temp\\\\LargeData\"]//AbsoluteTiming\n\n\n{37.4501953,Null}\n\n\nFor the test list I generated, this file is about 7Mb. The write time is slow here because it is a normal .m file, not .mx file.\nWe can now quit the kernel:\nQuit\n\nOn the fresh kernel, you have to execute the framework's code again. We can then reconstruct the top-level structure of our file-backed list:\nretrieveMainList[test,\n     DestinationDirectory:>\"C:\\\\Temp\\\\LargeData\"\n]//AbsoluteTiming\n\n\n{66.3115234,Null}\n\n\nThis does not take much memory - just a few extra Mb. You can now do a few tests:\nLength[test]\n\n\n10000\n\n\ntest[[1]]//Dimensions\n\n\n{50,15,40}\n\n\nLet us now write a few first elements to a disk, to illustrate how this is done. I will write the first 10 out of 10000 elements.\nmp[x_] := NumberForm[SetPrecision[x, 16], 16, ExponentFunction -> (Null &)];\n\ntestLength = 10;\nw=OpenWrite[\"C:\\\\Temp\\\\myLargeArray.dat\"];\ntime = \n  AbsoluteTiming[\n    Do[\n      Do[WriteString[w,mp[x],\"\\n\"],\n        {jrow,test[[irow]]},{krow,jrow},{x,krow}\n      ];\n      releasePart[test,irow],\n      {irow,1,testLength}\n    ]\n  ];\nClose[w];\ntime\n\n\n{7.4648438,Null}\n\n\nNote that I was sloppy with stream closing (in the sense that I don't always guarantee that the stream will be close in case of exception or Abort in the middle) - but this is not my main point here.\nNote also that I use the lower-level API provided by the framework, to release the memory used by a given part of the file-backed list, right after it was used. This makes the memory use minimal.\nFrom the timing, it will take about 2 hours for you to write the entire file. What is important is that you can arrange your code to stop at any time and resume later, without the need to load the full huge array into the kernel each time.\nTaking yet more advantage of the framework\nNote also, that you can, instead of transferring the array to file-backed form only at the end, do so as you build an array. You can use the appendList function to add any number of elements to the file-backed representation of your array, so you can, for example, call it on every new element (which is, 3D array in your case), or every 10 new elements, etc. \nOne catch here is that, to be on the safe side, you will have to call the function storeMainList periodically as well, since those parts saved to disk can not be used by themselves, without this higher-level element. This takes time (for the final array it took about 40 sec. on my machine), but if your computation takes many hours, I think you can afford doing this every half an hour say. In this way, you will also protect your computation, so that, in the case of a crash, you will be able to resume from where you stopped, rather than starting from scratch.\n", "export - Changing the speed of exported AVI videos": "\nThe trick is using a combination of \"FrameRate\", an option of Export, and AutorunSequencing, an option of Manipulate. The former determines the number of frames/second of the movie whereas the latter determines how long a sweep of the control takes. With one control, that will be the length of the movie. \nExport[\"output.avi\", \n Manipulate[\n   Plot[Sin[k  x], {x, 0, 2 \\[Pi]}], \n   {k, 1, 5}, \n   AutorunSequencing -> {{1, 10}}\n ], \"FrameRate\" -> 2\n]\n\n\n", "gui construction - How to save data to a variable by clicking a button, using Widget Panel": "\nIf GUIkit isn't really a prerequisite you could try the standard controls present in Mathematica in all versions as of 6:\nPanel[\n Column[\n  {\n   \"Please provide the following coefficients:\",\n   \"  Value for p1\",\n   InputField[Dynamic[p1tf]],\n   \"            \",\n   Button[\n    \"Submit\", (If[\n       ImaginaryQ@p1tf == False, \n       {\n         MessageDialog[\"The provided value is not valid. You need to enter complex value\"], \n         Exit[]\n       }\n     ];)]\n   }\n  ]\n ]\n\n\n", "export - Issue with Grid command": "\nYou could try defining myGrid = Grid[..., ImageSize -> All]. Consider for example the following test data\nheadings = Range[20];\ncountryList = Cases[CountryData[\"Countries\"], \n   c_ /; CountryData[c, \"BorderingCountries\"] =!= {}, 1, 8];\nsalesTrend[c_, p_] := \n With[{t = CountryData[c, \"BorderingCountries\"]},\n  {t, RandomReal[1, {20, Length[t]}]}]\n\nThen with \nmyGrid = Grid[Partition[\n    Column[{\"\", Style[#, Bold, FontSize -> 36], \"\", \n        chartTrends[#, 0.9]}, Alignment -> Center] & /@ countryList, \n    4], Alignment -> Center, Frame -> All, \n   FrameStyle -> Directive[LightGray], ItemSize -> All];\n\nExport[\"myGrid2.pdf\",myGrid]\n\nI get\n\ncompared to the original (Note the wrapping of Afghanistan plus the elongated legend)\n\n", "plotting - Manipulate and ExclusionsStyle": "\nYou can give explicit lhs == rhs style exclusions to get dashed lines:\nManipulate[Plot[{1/(a - x), x/(x - b)}, {x, -10, 10}, \n    Exclusions -> {x == b, x == a}, \n    ExclusionsStyle -> Dashed], {{a, 0}, -10, 10}, {{b, 0}, -10, 10}]\n\n\n", "graphics - Encoding format used by GraphicsData?": "\nI found an example on the web.  Here is code that will convert the PICT data from the format stored in the notebook file into a .pict file that can be opened by an image viewer (e.g. Photoshop).\nDecodePICT[data_String] := Module[\n    {slash, backslash, zero, LF, CR, decode, codes, len, i},\n    {slash, backslash, zero, LF, CR} = ToCharacterCode[\"/\\\\0\\n\\r\"];\n    decode[char_] := If[char == slash, backslash-zero, char-zero];\n    len = Length[codes = ToCharacterCode[data]];\n    i = 1;\n    Join[Table[0,{512}], Last@Last@Reap@While[i <= len-1,\n        Which[\n            codes[[i]] == LF || codes[[i]] == CR,\n            i++,\n            codes[[i]] == backslash,\n            i += 4,\n            True,\n            Sow@BitAnd[BitOr[\n                BitShiftLeft[decode[codes[[i]]], 2],\n                BitShiftRight[decode[codes[[i+1]]], 4]\n            ], 255];\n            i++;\n            If[i <= len-1,\n                Sow@BitAnd[BitOr[\n                    BitShiftLeft[decode[codes[[i]]], 4],\n                    BitShiftRight[decode[codes[[i+1]]], 2]\n                ], 255]\n            ];\n            i++;\n            If[i <= len-1,\n                Sow@BitAnd[BitOr[\n                    BitShiftLeft[decode[codes[[i]]], 6],\n                    BitShiftRight[decode[codes[[i+1]]], 0]\n                ], 255]\n            ];\n            i += 2;\n        ]\n    ]]\n];\n\nstr = \"0N801`0]05815@0A0_l<0?ooool0;@0000L0004E0000DP000000002Q0O@0hd=U\n  K6aK8U`lG0eSKgEbHVEKM5mM83Xm80eLM51QLV5]IGAbJF=@K6md<dAKN`eLM2Pb\n  :b1d84=_Le]fGBU3Kg=K<WIM;0eLM2Pb:b1d84=_Le]fGBUCJFiK<WIM;0eLM7@P\n  DfU^FgIMOBakMR`P<2`P<R1@JGeM83]L3E`n8R`P8TU^L7Ed8R`=8219KF5WIE=Y\n  NVD]?W/b<c8/83LeOB`=8219KF5WIDeQLVMYKW<]?W]k<2`P<7d/87/`;20`OGd/\n  3B0PBFeQIfEBIFMYKfh]?W]k<2`P<Gd/87/`;20aOGeM000N01[oooooool00@0:\n  00L0;@1B0AD0<@0602d0DP9203401`920582@P0J0000000002`01@R^0Te30003\n  2:h0104000d0300^00@0o`0002/]4PiSKgEbHVEKM5mM83Xm8000:b0?4U1QLV5]\n  IGAbJF=@K6md<dAKN`00:PlE:38[87@P@fmcFgIM:D=_Le/bMUd/000Z3aDX<R/P\n  M213Kg=KMUdYDfU^Fc9fGB`002X?6G@PDfU^FgIMOBakMR`P<2`P<R1@JGeM83/0\n  0?l\";\n\nExport[\"~/Desktop/foo.pict\", DecodePICT[str], \"Binary\"]\n\n", "differential equations - Starting NDSolve from intermediate time step?": "\nYou could integrate up to some intermediate time, tintermediate, and then feed the result as initial conditions to the solver to propagate from tintermediate to tmax, like so:\ntmin = 0;\ntintermediate = 2;\ntmax = 5;\nsol = NDSolve[{D[u[t, x], t] == D[u[t, x], x, x], u[0, x] == 0, \n    u[t, 0] == Sin[t], u[t, 5] == 0}, \n   u, {t, tmin, tintermediate}, {x, 0, 5}];\nsol2 = NDSolve[{D[u[t, x], t] == D[u[t, x], x, x],\n    u[tintermediate, x] \\[Equal] First@(u[tintermediate, x] /. sol), \n    u[t, 0] == Sin[t], u[t, 5] == 0}, \n   u, {t, tintermediate, tmax}, {x, 0, 5}];\n\n", "debugging - MUnit test debug breakpoints in Workbench not working": "\nYou have to set breakpoints in what is considered a source file, ie a .m package file. Breakpoints set within test or scrapbook files are not supported.\nSo you would have a test that executes a function defined in a package, set the breakpoint in the package, and when you debug the test, it will suspend.\n", "front end - TextAlignment->Center in a notebook with WindowSize->All": "\nThere is no easy solution involving multi-cells.\nI want to explain why it is a problem--you can call it a bug, but it is rather a tricky situation for Mathematica.\nTo determine the TextAlignment or TextJustification correctly, Mathematica needs to know the width of an enclosing window of the cell. Now, the problem is, the window width can be only determined when you know the width of the contents, since it is set to WindowSize->All. So we are in effect creating a circular argument: Mathematica can't decide one value because it depends on each other.\nThere are a number of similar situation. Try Pane[..., {Full, All}] for instance. In this case, the width of Pane should be determined by the enclosing cell, but works only when it is explicit (otherwise, the same circular argument). Compare these two cases:\nCreateDialog[Framed[Pane[\"A\", {Full, Full}], FrameMargins -> 0]];\nCreateDialog[Framed[Pane[\"A\", {Full, Full}], FrameMargins -> 0], WindowSize -> {100, All}];\n\n\n\nYou can easily tell which one is which (besides, the second image is correct. Full means that the pane should extend to the full width of the enclosing object--in this case, the notebook).\nAnything involving undetermined object size which depends on the enclosed contents (WindowSize with All, or ImageSize with All, Automatic, Full) and the content properties (such as Scaled or ImageScaled size, coordinates, alignment, etc...) which depend on the size of the enclosing object (whether it is Notebook or Graphics, etc..), it is always very tricky to get a right solution. Mathematica tries its best to do a sensible thing, but like this case, sometimes it just can't handle it well... \n", "functions - How to load a package without naming conflicts?": "\nShadowing occurs only when there are two functions with the same name that are in $ContextPath. So right after you do <<Combinatorica`, do the following:\n$ContextPath = Rest@$ContextPath;\n\nWhat this does is that it removes Combinatorica (which is the package you just loaded). Now the only Graph function that's on the path is System`Graph and you can call it simply by the name, without the prefix. To access any functions from the package, use the prefix, as Combinatorica`Graph.\nIf Combinatorica` was loaded a while ago and you have loaded other packages in between, Rest@... is not going to be helpful. In that case, use:\n$ContextPath = DeleteCases[$ContextPath, \"Combinatorica`\"];\n\n", "plotting - ImageCrop for vector graphics": "\nEdit\nCome to think of it, one case where I often want to crop the output is Graphics3D (one can do it with ViewAngle etc., but it's not always convenient - one could also convert to bitmap, but again that's not always desirable). So I decided to allow the cropGraphics function below to be used with any object, not just 2D Graphics. Here is an example:\nq = Show[ExampleData[{\"Geometry3D\", \"Cow\"}], ImageSize -> 360, \n  Background -> Darker[Green]]\n\n\ncg = cropGraphics[q, -0.8, -0.4, 200, 200]\n\n\nIn the simple form defined below, cropGraphics requires the input object to have an explicit ImageSize setting. But it works for a wide range of objects. It can even be used to convert Overlay objects to Graphics while at the same time cropping them.\nSpeaking of Overlay, here is a continuation of the above example:\nplot = Overlay[{Plot[Sin[x], {x, 0, 2 Pi}, GridLines -> Automatic, \n    Frame -> True, ImageSize -> 360],\n   Magnify[cg, .5]}, Alignment -> {.5, .5}]\n\n\nThis is an overlay with the cropped graphics created previously. Now crop this plot once again:\ncropGraphics[plot, 0.5, 0, 300, 120]\n\n\nEnd Edit\nHere is the function that does the above. It is based on Inset, and it assumes for simplicity that the graphic you want to crop is going to be positioned in the crop window by placing the original coordinate {0,0} (in the coordinate system of the graphics) at a scaled position {x,y}. Here, x and y are between 0 and 1, with x = 0.5 corresponding to the center of the crop window. I'll explain this in an example:\ncropGraphics[g_, x_, y_, w_, h_] := \n Graphics[Inset[g, {x, y}, {0, 0}], PlotRange -> {{0, 1}, {0, 1}}, \n  ImageSize -> {w, h}, AspectRatio -> Full]\n\nHere is a sample graphic; I would suggest always giving it a definite setting of ImageSize to begin with:\npl = Graphics[{{Red, Rectangle[{0, 0}, {.5, .5}]}, {Blue, \n    Disk[{1, 1}, .5]}}, PlotRange -> {{0, 1.5}, {0, 1.5}}, \n  ImageSize -> 400]\n\n\nFor reference, the bottom left corner of the square is at {0, 0}, and the graphics is 400 pixels wide and high.\nNow we crop it:\ncropGraphics[pl, 0, 0, 300, 300]\n\n\nThe coordinates 0, 0 mean that the bottom left corner of the square is still where it was before, but the new image width and height are 300. \nIf we want to crop part of the square instead, all we have to do is move its lower left corner {0, 0} outside the crop window by giving it negative scaled coordinates:\ncropGraphics[pl, -.25, -.1, 300, 300]\n\n\nFinally, an example of a non-square crop area:\ncropGraphics[pl, 0.5, -.24, 400, 300]\n\n\nOne could improve on this by changing the scaled coordinates x and y to something absolute in pixels, but I wanted to keep it simple for now, to focus on the main issue: use Inset with a variable position in a \"wrapper\" graphic whose coordinate system ranges from 0 to 1 to make the inset position a scaled coordinate, and whose ImageSize has the value desired for the crop.\n", "probability or statistics - Some questions about random numbers": "\nYou can obtain discrete uniform or normally distributed numbers from random.org, which allows you to generate 200k bits/day.\nImport[\"http://www.random.org/cgi-bin/randbyte?nbytes=1024&format=f\", \"Binary\"]\n\n", "mathematical optimization - How to find all the local minima/maxima in a range": "\nThis can be done using event location within NDSolve. I start off as below (note f is slightly modified from what you have, mostly to rescale it).\nGetRLine3[MMStdata_, IO_: 1][x_: x] := \n  ListInterpolation[#, InterpolationOrder -> IO, Method -> \"Spline\"][\n     x] & /@ (({{#[[1]]}, #[[2]]}) & /@ # & /@ MMStdata);\ndata = Transpose[{# + RandomReal[]*0.1 & /@ Range[-10, 30, 0.4], \n    Tanh[#] + (Sech[2 x - 0.5]/1.5 + 1.5) /. x -> # & /@ \n     Range[-4, 4, 0.08]}];\n\nxLimits = {Min@#1, Max@#1} & @@ Transpose[data];\nf = First[100*D[GetRLine3[{data}, 3][x], x]];\n\nWe'll recapture f using NDSolve, and locate the points where the derivative vanishes in the process.\nvals = Reap[\n    soln = y[x] /. \n      First[NDSolve[{y'[x] == Evaluate[D[f, x]], \n         y[-9.9] == (f /. x -> -9.9)}, y[x], {x, -9.9, 30}, \n        Method -> {\"EventLocator\", \"Event\" -> y'[x], \n          \"EventAction\" :> Sow[{x, y[x]}]}]]][[2, 1]];\n\nVisual check:\nPlot[f, {x, -9.9, 30}, \n Epilog -> {PointSize[Medium], Red, Point[vals]}]\n\n\n", "manipulate - Question about making TabView remember what tab to open": "\nI may have misunderstood your problem, but it looks like you just need to create a persistent local variable keeping the value of the tab which was last open. One way to do this:\nDynamicModule[{tab},\n   myCustomTab[] :=\n      TabView[\n       {\n          {patt, \"Pattern\" -> 1},\n          {motif, \"Motif\" -> \n             Column[{\n               Button[\"Type\", Print[\" NOT IMPLEMENTED YET\"], ImageSize -> 100],\n               Button[\"New shape\", Print[\" NOT IMPLEMENTED YET\"], ImageSize -> 100],\n               Button[\"Pixel\", Print[\" NOT IMPLEMENTED YET\"], ImageSize -> 100]}]}\n       },\n       Dynamic[tab]]\n]\n\nWhat matters is that you create a closure, so the variable tab is not local to the function myCustomTab (in the sense that it is not re-initialized on every function's invocation).\nEDIT\nOk, it is probably a good time to explain what I mean by code generation, since I mentioned this technique many times already. Basically, I mean that you will be better off by creating your own DSL for UI. I will illustrate it here simplistically with rule application, but generally I would rather use recursion, which is more powerful. You can notice that your code is full of repeated elements, and this is true even for such a small code snippet. Here is one way to reduce the boilerplate:\nThis is a function written by @Szabolcs, which will be handy here\nClearAll[withRules]\nSetAttributes[withRules, HoldAll]\nwithRules[rules_, expr_] :=\n  First@PreemptProtect@Internal`InheritedBlock[\n    {Rule, RuleDelayed},\n    SetAttributes[{Rule, RuleDelayed}, HoldFirst];\n    Hold[expr] /. rules\n]\n\nThis is the starting point:\nmyTab = \n  myTabView[\n   {\"Pattern\" -> 1,\n     \"Motif\" -> Column[{\n         myButton[\"Type\", noimpl[]],\n         myButton[\"New shape\", noimpl[]],\n         myButton[\"Pixel\", noimpl[]]}]\n    }];\n\nThis is an auxiliary function:\nClear[dressTabView];\ndressTabView[lrules_] :=\n   t : myTabView[{__Rule}] :>\n     DynamicModule[{tab},\n        Append[\n           Replace[t, e : (label_ -> w_) :> {withRules[lrules, label], e}, 2],\n           Dynamic[tab]]];\n\nThis is a chain of transformations needed to generate your widget with tab memory:\nmyTab /. dressTabView[{\"Motif\" :> motif, \"Pattern\" :> patt}] /.\n    myButton[args__] :> Button[args, ImageSize -> 100] /.\n       noimpl[] :> Print[\" NOT IMPLEMENTED YET\"] /.\n          myTabView -> TabView\n\nThe main point is, as usual, to separate the specific from the general.          \n"}